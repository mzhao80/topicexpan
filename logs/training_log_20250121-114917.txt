Starting training at 20250121-114917

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 38, 41, 42, 43, 44, 46, 47, 48, 49, 54, 55, 60, 62, 64, 66, 68, 70, 71]
Input sequence lengths: [512, 512, 512, 236, 356, 512, 512, 512, 64, 137, 234, 125, 512, 512, 512, 356, 204, 236, 512, 258, 449, 87, 512, 512, 512, 512, 81, 512, 234, 512, 512, 137]
Target phrase lengths: [5, 6, 8, 7, 5, 6, 4, 6, 8, 7, 4, 5, 5, 8, 8, 4, 8, 8, 4, 6, 7, 8, 6, 4, 5, 7, 5, 6, 7, 4, 8, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.013, 0.126]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 36
Pred: 60 | True: 42
Pred: 40 | True: 44

Phrase Generation Sample:
Generated: nell nell nell nell ellis „osition nell „
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 112.1725
Generation Loss: 8.2741
Total Loss: 120.4466
Topic Prediction Accuracy: 0.0000
Generation Perplexity: 3921.0981
Train Epoch: 1 [0/334 (0%)] Loss: 120.446587
Train Epoch: 1 [64/334 (19%)] Loss: 118.522064
Train Epoch: 1 [128/334 (38%)] Loss: 108.007896
Train Epoch: 1 [192/334 (57%)] Loss: 103.761200
Train Epoch: 1 [256/334 (77%)] Loss: 100.262680
[2025-01-21 11:49:22] Starting validation for epoch: 1

Generation Samples:
Topic 52:
Generated: [CLS] benz rand religions peerage struggling languages providers pas [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] republicans known facilitate connections america indianapolis leaves sob [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] them holland defense trouble compound canning foliage incomplete [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 1 [0/10 (0%)] Loss: 97.747147

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 41, 44, 49, 51, 52, 53, 54, 55, 57, 58, 61, 63, 65, 70, 71]
Input sequence lengths: [485, 356, 512, 121, 512, 78, 485, 334, 512, 512, 145, 512, 453, 236, 512, 512, 512, 512, 512, 512, 92, 449, 512, 512, 159, 512, 236, 512, 512, 512, 449, 512]
Target phrase lengths: [5, 5, 6, 5, 6, 6, 8, 4, 4, 8, 8, 5, 8, 5, 4, 5, 4, 4, 5, 5, 5, 4, 8, 6, 5, 8, 8, 4, 6, 7, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.109, 0.246]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 57 | True: 57
Pred: 38 | True: 55
Pred: 38 | True: 65

Phrase Generation Sample:
Generated: [CLS] winning gold medal [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] winning gold medals [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 99.7192
Generation Loss: 2.9749
Total Loss: 102.6942
Topic Prediction Accuracy: 0.3125
Generation Perplexity: 19.5882
Train Epoch: 2 [0/334 (0%)] Loss: 102.694168
Train Epoch: 2 [64/334 (19%)] Loss: 92.317757
Train Epoch: 2 [128/334 (38%)] Loss: 74.947746
Train Epoch: 2 [192/334 (57%)] Loss: 87.392143
Train Epoch: 2 [256/334 (77%)] Loss: 67.713440
[2025-01-21 11:49:26] Starting validation for epoch: 2

Generation Samples:
Topic 40:
Generated: [CLS] structure demonic linux shipped congress terminology american confess [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] michigan rational major religion do carlos soccer henan [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 73:
Generated: [CLS] beth logistical kernel stranded express mohawk jail cards [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 2 [0/10 (0%)] Loss: 68.452156

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 43, 45, 47, 49, 52, 54, 55, 57, 58, 60, 62, 64, 65, 66, 68, 70, 72]
Input sequence lengths: [512, 512, 512, 91, 512, 512, 204, 512, 485, 125, 121, 512, 512, 87, 268, 512, 512, 125, 453, 512, 512, 268, 512, 512, 512, 512, 236, 512, 512, 125, 268, 356]
Target phrase lengths: [4, 7, 6, 4, 8, 6, 8, 6, 8, 7, 4, 8, 4, 6, 8, 4, 7, 8, 8, 4, 4, 8, 8, 4, 4, 4, 8, 4, 6, 4, 8, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.228, 0.436]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 66
Pred: 36 | True: 65
Pred: 40 | True: 47

Phrase Generation Sample:
Generated: [CLS] house rules [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] house rules [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 60.5400
Generation Loss: 1.5843
Total Loss: 62.1243
Topic Prediction Accuracy: 0.6875
Generation Perplexity: 4.8757
Train Epoch: 3 [0/334 (0%)] Loss: 62.124306
Train Epoch: 3 [64/334 (19%)] Loss: 51.378269
Train Epoch: 3 [128/334 (38%)] Loss: 46.050060
Train Epoch: 3 [192/334 (57%)] Loss: 48.995731
Train Epoch: 3 [256/334 (77%)] Loss: 62.083195
[2025-01-21 11:49:30] Starting validation for epoch: 3

Generation Samples:
Topic 38:
Generated: [CLS] coasts prose matter recipient kidding ship stating trouble [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] shiny nominate gershwin liberation fossil hospitality nesting historically [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] maple linux christi battery speaks seductive penal olympia [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 3 [0/10 (0%)] Loss: 39.324982

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 40, 41, 43, 46, 47, 48, 49, 51, 53, 54, 55, 56, 58, 59, 60, 63, 66, 67, 70, 71]
Input sequence lengths: [512, 512, 449, 92, 81, 512, 78, 512, 356, 512, 64, 512, 512, 512, 512, 236, 512, 512, 449, 512, 512, 334, 356, 125, 512, 512, 512, 356, 512, 512, 366, 449]
Target phrase lengths: [3, 6, 7, 6, 8, 6, 7, 5, 4, 8, 7, 4, 8, 5, 5, 6, 6, 5, 7, 4, 5, 7, 5, 6, 4, 5, 6, 4, 6, 4, 3, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.287, 0.536]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 63 | True: 63
Pred: 56 | True: 56

Phrase Generation Sample:
Generated: [CLS] washington [SEP] and and and [SEP] and and
Target: [CLS] washington [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 44.2396
Generation Loss: 1.1150
Total Loss: 45.3547
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 3.0497
Train Epoch: 4 [0/334 (0%)] Loss: 45.354691
Train Epoch: 4 [64/334 (19%)] Loss: 46.133080
Train Epoch: 4 [128/334 (38%)] Loss: 49.350616
Train Epoch: 4 [192/334 (57%)] Loss: 58.058659
Train Epoch: 4 [256/334 (77%)] Loss: 59.776520
[2025-01-21 11:49:34] Starting validation for epoch: 4

Generation Samples:
Topic 52:
Generated: [CLS] holland nomination avalon itunes titanium aircraft northeastern freeing [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 61:
Generated: [CLS] reorganized merged bomb already chevy iss constitutional arbitrary [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] denotes defining shipped linux discussed greek verbal roaring [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 4 [0/10 (0%)] Loss: 35.961082

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 41, 42, 43, 44, 48, 50, 51, 52, 54, 56, 57, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71]
Input sequence lengths: [366, 449, 512, 236, 512, 512, 159, 388, 512, 512, 512, 125, 512, 159, 512, 121, 159, 512, 453, 449, 512, 512, 485, 512, 512, 512, 78, 449, 512, 512, 81, 125]
Target phrase lengths: [5, 5, 5, 8, 6, 7, 4, 4, 8, 5, 7, 5, 4, 7, 6, 4, 5, 8, 8, 8, 4, 7, 7, 4, 8, 4, 6, 4, 8, 4, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.293, 0.538]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 59 | True: 59
Pred: 56 | True: 56
Pred: 47 | True: 44

Phrase Generation Sample:
Generated: [CLS] wise sayings [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] wise sayings [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 52.4216
Generation Loss: 0.8867
Total Loss: 53.3083
Topic Prediction Accuracy: 0.6562
Generation Perplexity: 2.4272
Train Epoch: 5 [0/334 (0%)] Loss: 53.308292
Train Epoch: 5 [64/334 (19%)] Loss: 44.710560
Train Epoch: 5 [128/334 (38%)] Loss: 37.688526
Train Epoch: 5 [192/334 (57%)] Loss: 59.446289
Train Epoch: 5 [256/334 (77%)] Loss: 23.630720
[2025-01-21 11:49:38] Starting validation for epoch: 5

Generation Samples:
Topic 36:
Generated: [CLS] flynn nintendo programs holland wright wrestling sound celebrating [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] schultz arbitrary pledged conducts darrell hamid historically much [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] rite truss funding damned gaming conduct battery spending [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 5 [0/10 (0%)] Loss: 38.494530

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 39, 40, 41, 43, 47, 53, 54, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69]
Input sequence lengths: [512, 512, 334, 145, 512, 204, 512, 512, 512, 512, 268, 485, 159, 145, 512, 334, 512, 87, 388, 512, 512, 121, 512, 366, 366, 334, 234, 512, 512, 125, 512, 453]
Target phrase lengths: [8, 4, 4, 8, 6, 8, 4, 7, 6, 6, 8, 5, 7, 8, 3, 6, 8, 6, 3, 5, 6, 6, 4, 5, 7, 8, 4, 4, 5, 6, 7, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.315, 0.617]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 64 | True: 64
Pred: 54 | True: 54
Pred: 56 | True: 53

Phrase Generation Sample:
Generated: [CLS] reopening the people ' [SEP] [SEP]
Target: [CLS] reopening the people ' [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 46.8421
Generation Loss: 0.5854
Total Loss: 47.4275
Topic Prediction Accuracy: 0.6875
Generation Perplexity: 1.7956
Train Epoch: 6 [0/334 (0%)] Loss: 47.427509
Train Epoch: 6 [64/334 (19%)] Loss: 38.861992
Train Epoch: 6 [128/334 (38%)] Loss: 56.235634
Train Epoch: 6 [192/334 (57%)] Loss: 59.467392
Train Epoch: 6 [256/334 (77%)] Loss: 51.011673
[2025-01-21 11:49:52] Starting validation for epoch: 6

Generation Samples:
Topic 68:
Generated: [CLS] wimbledon intelligence buddhist frey orlando monte amenities building [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] senators lied experimented astro orchestrated choices nazi execution [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] muscle machines eagles ivy job flowers z america [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 6 [0/10 (0%)] Loss: 38.682140

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 40, 41, 42, 43, 46, 47, 48, 50, 53, 54, 57, 60, 62, 63, 66, 67, 68, 69, 70, 71]
Input sequence lengths: [512, 204, 512, 87, 123, 512, 123, 512, 512, 512, 81, 512, 512, 125, 388, 512, 512, 512, 512, 512, 512, 485, 512, 512, 388, 334, 512, 512, 388, 236, 449, 512]
Target phrase lengths: [5, 5, 6, 6, 8, 4, 7, 5, 4, 6, 6, 6, 5, 6, 3, 5, 8, 6, 8, 4, 5, 5, 7, 6, 4, 4, 6, 4, 8, 6, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.349, 0.636]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 70 | True: 68
Pred: 69 | True: 67

Phrase Generation Sample:
Generated: [CLS] industry leading programs [SEP] [SEP] [SEP] [SEP] and
Target: [CLS] industry leading programs [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.9512
Generation Loss: 0.4309
Total Loss: 39.3821
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.5387
Train Epoch: 7 [0/334 (0%)] Loss: 39.382141
Train Epoch: 7 [64/334 (19%)] Loss: 41.546219
Train Epoch: 7 [128/334 (38%)] Loss: 52.583698
Train Epoch: 7 [192/334 (57%)] Loss: 38.156841
Train Epoch: 7 [256/334 (77%)] Loss: 57.328014
[2025-01-21 11:49:56] Starting validation for epoch: 7

Generation Samples:
Topic 59:
Generated: [CLS] developed words linux accepting league minnesota unanimously egypt [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 73:
Generated: [CLS] gifted property proponents permanent religion roman interpretations package [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] codes maryland loan moreno internal hindu proper hierarchy [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 7 [0/10 (0%)] Loss: 52.740108

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 51, 54, 55, 56, 59, 60, 61, 62, 63, 65, 68]
Input sequence lengths: [356, 453, 366, 512, 204, 121, 512, 512, 87, 356, 449, 512, 125, 512, 356, 145, 512, 234, 234, 512, 512, 512, 512, 453, 204, 78, 512, 159, 512, 512, 121, 81]
Target phrase lengths: [4, 7, 5, 5, 5, 4, 5, 6, 8, 4, 4, 6, 8, 6, 5, 8, 3, 4, 8, 6, 6, 6, 8, 8, 8, 7, 4, 4, 8, 7, 7, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.352, 0.707]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 55 | True: 55
Pred: 41 | True: 41
Pred: 53 | True: 59

Phrase Generation Sample:
Generated: [CLS] small business [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] small businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.9547
Generation Loss: 0.5716
Total Loss: 26.5263
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.7710
Train Epoch: 8 [0/334 (0%)] Loss: 26.526279
Train Epoch: 8 [64/334 (19%)] Loss: 38.565777
Train Epoch: 8 [128/334 (38%)] Loss: 36.344784
Train Epoch: 8 [192/334 (57%)] Loss: 26.480742
Train Epoch: 8 [256/334 (77%)] Loss: 46.924679
[2025-01-21 11:50:00] Starting validation for epoch: 8

Generation Samples:
Topic 38:
Generated: [CLS] rocket tainted travel advancing faith discreet framed wingspan [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] yen lineage mackay additions highness bryan rains bible [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] installed keys wrestling bible rich named politely math [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 8 [0/10 (0%)] Loss: 26.458223

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 40, 41, 42, 43, 44, 46, 49, 51, 53, 55, 59, 60, 62, 67, 68, 69, 70]
Input sequence lengths: [512, 334, 204, 512, 512, 512, 123, 512, 512, 512, 512, 236, 78, 356, 87, 512, 388, 125, 512, 512, 512, 121, 258, 125, 512, 512, 512, 121, 236, 366, 125, 356]
Target phrase lengths: [7, 8, 8, 5, 6, 8, 8, 5, 4, 4, 4, 8, 7, 5, 8, 5, 8, 6, 8, 5, 5, 4, 4, 4, 8, 5, 4, 5, 6, 7, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.360, 0.683]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 53 | True: 53
Pred: 73 | True: 68

Phrase Generation Sample:
Generated: [CLS] largest and most effective chamber [SEP] [SEP] [SEP]
Target: [CLS] largest and most effective chamber [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 40.6006
Generation Loss: 0.4416
Total Loss: 41.0422
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.5551
Train Epoch: 9 [0/334 (0%)] Loss: 41.042171
Train Epoch: 9 [64/334 (19%)] Loss: 30.764299
Train Epoch: 9 [128/334 (38%)] Loss: 34.404537
Train Epoch: 9 [192/334 (57%)] Loss: 43.228378
Train Epoch: 9 [256/334 (77%)] Loss: 32.633877
[2025-01-21 11:50:04] Starting validation for epoch: 9

Generation Samples:
Topic 41:
Generated: [CLS] grassy anything anti medicines language ears key adventure [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] wilkes unexpected myers offence sexually guilt santana electronics [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 45:
Generated: [CLS] deportation congress appropriated kraft administration warped regulates settle [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 9 [0/10 (0%)] Loss: 42.443668

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 41, 42, 43, 46, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 67, 68, 70, 71, 72]
Input sequence lengths: [512, 91, 366, 258, 453, 512, 204, 449, 512, 125, 512, 512, 234, 512, 512, 512, 512, 159, 123, 512, 125, 512, 449, 78, 204, 334, 92, 356, 512, 236, 159, 485]
Target phrase lengths: [8, 4, 5, 6, 6, 5, 8, 5, 8, 6, 6, 5, 4, 5, 4, 6, 8, 4, 7, 4, 5, 5, 4, 6, 4, 4, 5, 4, 5, 5, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.368, 0.699]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 67 | True: 67
Pred: 72 | True: 72
Pred: 59 | True: 59

Phrase Generation Sample:
Generated: [CLS] add $ 114 billion to the [SEP] [SEP]
Target: [CLS] add $ 114 billion to the [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 21.4187
Generation Loss: 0.2175
Total Loss: 21.6362
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.2430
Train Epoch: 10 [0/334 (0%)] Loss: 21.636213
Train Epoch: 10 [64/334 (19%)] Loss: 34.963665
Train Epoch: 10 [128/334 (38%)] Loss: 49.756321
Train Epoch: 10 [192/334 (57%)] Loss: 35.504269
Train Epoch: 10 [256/334 (77%)] Loss: 50.666458
[2025-01-21 11:50:08] Starting validation for epoch: 10

Generation Samples:
Topic 66:
Generated: [CLS] valor language subsidies citation hat sob mimi particles [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] wrestlers compressed utter nonstop sprung better latin windows [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] broncos ivy creativity brain fair box flynn decisions [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 10 [0/10 (0%)] Loss: 34.942272

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 41, 42, 43, 47, 48, 49, 51, 53, 54, 56, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72]
Input sequence lengths: [125, 388, 512, 121, 145, 512, 159, 92, 512, 258, 512, 512, 453, 449, 512, 81, 512, 236, 91, 204, 334, 512, 87, 123, 388, 512, 512, 512, 512, 512, 512, 453]
Target phrase lengths: [7, 4, 6, 5, 6, 4, 7, 5, 6, 4, 8, 6, 7, 5, 8, 6, 4, 5, 4, 8, 7, 4, 6, 7, 3, 5, 8, 6, 7, 4, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.347, 0.712]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 43
Pred: 69 | True: 69
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] speaker has not been elected [SEP] [SEP] and
Target: [CLS] speaker has not been elected [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.8279
Generation Loss: 0.1987
Total Loss: 31.0266
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.2198
Train Epoch: 11 [0/334 (0%)] Loss: 31.026590
Train Epoch: 11 [64/334 (19%)] Loss: 31.645582
Train Epoch: 11 [128/334 (38%)] Loss: 32.260414
Train Epoch: 11 [192/334 (57%)] Loss: 52.746567
Train Epoch: 11 [256/334 (77%)] Loss: 33.072731
[2025-01-21 11:50:17] Starting validation for epoch: 11

Generation Samples:
Topic 43:
Generated: [CLS] birds faction theories hungary wealth wi republicans bryson [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] ich pol natural molecule phil arbitrary mutant sol [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] interests foreigner brutal trouble placing saving eternal bryan [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 11 [0/10 (0%)] Loss: 24.522079

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 49, 51, 53, 54, 55, 57, 59, 61, 63, 64, 67, 69, 72]
Input sequence lengths: [485, 512, 512, 453, 234, 512, 512, 512, 388, 512, 258, 334, 91, 512, 512, 92, 512, 159, 512, 123, 125, 512, 512, 512, 64, 356, 78, 512, 78, 145, 512, 366]
Target phrase lengths: [7, 6, 7, 8, 7, 6, 4, 5, 4, 8, 4, 7, 4, 6, 4, 6, 4, 4, 4, 7, 4, 5, 5, 8, 8, 4, 5, 8, 7, 8, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.393, 0.741]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 57 | True: 57
Pred: 67 | True: 67
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] victory for the united states [SEP] [SEP] [SEP]
Target: [CLS] victory for the united states [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.1641
Generation Loss: 0.1340
Total Loss: 23.2981
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.1434
Train Epoch: 12 [0/334 (0%)] Loss: 23.298115
Train Epoch: 12 [64/334 (19%)] Loss: 29.519773
Train Epoch: 12 [128/334 (38%)] Loss: 25.823458
Train Epoch: 12 [192/334 (57%)] Loss: 33.565582
Train Epoch: 12 [256/334 (77%)] Loss: 22.571716
[2025-01-21 11:50:21] Starting validation for epoch: 12

Generation Samples:
Topic 40:
Generated: [CLS] corruption lgbt engineering type prostitution attic membership linguistic [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] static hat assign phil liberty astronaut modules none [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 73:
Generated: [CLS] jersey dances ill church solar committees languages planning [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 12 [0/10 (0%)] Loss: 47.274387

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 53, 54, 55, 59, 60, 61, 63, 65, 66, 69, 70, 71]
Input sequence lengths: [512, 512, 366, 512, 512, 334, 234, 145, 512, 356, 512, 449, 512, 512, 366, 258, 512, 512, 512, 159, 125, 121, 121, 512, 125, 388, 64, 236, 81, 123, 512, 268]
Target phrase lengths: [5, 6, 3, 6, 5, 4, 4, 7, 8, 4, 5, 6, 5, 8, 5, 4, 5, 8, 6, 4, 7, 7, 5, 5, 6, 3, 5, 5, 6, 8, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.415, 0.762]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 60 | True: 60
Pred: 59 | True: 59

Phrase Generation Sample:
Generated: [CLS] opportunity for all [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] opportunity for all [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 24.8329
Generation Loss: 0.1093
Total Loss: 24.9422
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.1155
Train Epoch: 13 [0/334 (0%)] Loss: 24.942184
Train Epoch: 13 [64/334 (19%)] Loss: 30.532454
Train Epoch: 13 [128/334 (38%)] Loss: 42.843765
Train Epoch: 13 [192/334 (57%)] Loss: 32.458641
Train Epoch: 13 [256/334 (77%)] Loss: 24.923111
[2025-01-21 11:50:25] Starting validation for epoch: 13

Generation Samples:
Topic 65:
Generated: [CLS] [unused766] aramaic naming painting championships tongues shankar linux [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 59:
Generated: [CLS] greek math explicit arbitrary monuments church grace ross [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] pass dealers bryan circling capitol isle gnu nominate [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Validation Epoch: 13 [0/10 (0%)] Loss: 41.706772

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 41, 42, 43, 44, 45, 48, 50, 52, 53, 55, 57, 62, 63, 65, 66, 69, 71, 72]
Input sequence lengths: [234, 334, 512, 512, 145, 449, 512, 512, 356, 512, 87, 512, 356, 512, 512, 453, 512, 512, 512, 388, 512, 512, 512, 512, 91, 512, 512, 356, 125, 485, 81, 512]
Target phrase lengths: [8, 8, 8, 8, 7, 4, 4, 6, 4, 6, 8, 4, 5, 8, 5, 8, 8, 7, 5, 8, 6, 5, 4, 6, 6, 5, 7, 4, 5, 7, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.390, 0.746]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 37 | True: 37
Pred: 53 | True: 53
Pred: 45 | True: 45

Phrase Generation Sample:
Generated: [CLS] john lewis voting rights advancement act [SEP] and
Target: [CLS] john lewis voting rights advancement act [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.4585
Generation Loss: 0.1182
Total Loss: 32.5768
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.1255
Train Epoch: 14 [0/334 (0%)] Loss: 32.576775
Train Epoch: 14 [64/334 (19%)] Loss: 39.177082
Train Epoch: 14 [128/334 (38%)] Loss: 30.467485
Train Epoch: 14 [192/334 (57%)] Loss: 28.146809
Train Epoch: 14 [256/334 (77%)] Loss: 58.851738
[2025-01-21 11:50:29] Starting validation for epoch: 14

Generation Samples:
Topic 47:
Generated: [CLS] deception robes card beans contract jill discipline loyalty [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 46:
Generated: [CLS] rosen liar translator democrat body inclusion category promotion [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] rebuilding wrestler budget prison regulator nov forms amendment [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 14 [0/10 (0%)] Loss: 34.289654

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 41, 42, 43, 46, 47, 48, 49, 51, 53, 54, 55, 56, 59, 60, 61, 63, 64, 65, 66, 67]
Input sequence lengths: [512, 334, 512, 356, 512, 449, 512, 512, 123, 125, 512, 81, 512, 512, 512, 512, 512, 512, 453, 512, 512, 366, 512, 453, 512, 159, 453, 512, 512, 125, 512, 78]
Target phrase lengths: [8, 6, 5, 5, 7, 5, 6, 4, 7, 6, 7, 6, 4, 6, 6, 7, 5, 6, 7, 5, 8, 3, 4, 7, 3, 4, 5, 4, 6, 4, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.419, 0.771]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 64 | True: 64
Pred: 56 | True: 53
Pred: 67 | True: 67

Phrase Generation Sample:
Generated: [CLS] reopening the people ' [SEP] [SEP]
Target: [CLS] reopening the people ' [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.5099
Generation Loss: 0.1076
Total Loss: 30.6174
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.1136
Train Epoch: 15 [0/334 (0%)] Loss: 30.617434
Train Epoch: 15 [64/334 (19%)] Loss: 30.870216
Train Epoch: 15 [128/334 (38%)] Loss: 26.388885
Train Epoch: 15 [192/334 (57%)] Loss: 34.908745
Train Epoch: 15 [256/334 (77%)] Loss: 25.901302
[2025-01-21 11:50:33] Starting validation for epoch: 15

Generation Samples:
Topic 73:
Generated: [CLS] kidding eu intelligent jeff gui crossings citation sega [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] voluntary aloud mat dunn rewarded terminal eagles exciting [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] charging card linguistic socialism specify chemical 802 telecommunications [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 15 [0/10 (0%)] Loss: 28.947817

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 39, 41, 43, 46, 47, 49, 53, 55, 56, 60, 61, 63, 66, 67, 70]
Input sequence lengths: [512, 512, 123, 512, 512, 64, 137, 356, 512, 234, 512, 159, 356, 512, 512, 121, 512, 512, 512, 453, 512, 125, 159, 512, 512, 449, 356, 512, 334, 159, 512, 236]
Target phrase lengths: [5, 8, 7, 6, 5, 5, 7, 4, 8, 8, 4, 5, 4, 5, 5, 4, 3, 5, 8, 7, 5, 4, 4, 8, 3, 4, 5, 8, 7, 4, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.427, 0.769]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 36
Pred: 41 | True: 41
Pred: 44 | True: 43

Phrase Generation Sample:
Generated: [CLS] nominate kevin mccarthy [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 51.1545
Generation Loss: 0.1263
Total Loss: 51.2808
Topic Prediction Accuracy: 0.6562
Generation Perplexity: 1.1346
Train Epoch: 16 [0/334 (0%)] Loss: 51.280758
Train Epoch: 16 [64/334 (19%)] Loss: 32.159733
Train Epoch: 16 [128/334 (38%)] Loss: 26.982771
Train Epoch: 16 [192/334 (57%)] Loss: 27.233316
Train Epoch: 16 [256/334 (77%)] Loss: 44.577587
[2025-01-21 11:50:42] Starting validation for epoch: 16

Generation Samples:
Topic 66:
Generated: [CLS] pledge commit outright sounds accessories common 269 committing [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] knicks pac gifted penitentiary maryland packing grew mack [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] amar situation options convention libertarian amendment named ring [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 16 [0/10 (0%)] Loss: 24.120712

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 39, 40, 41, 44, 47, 50, 51, 54, 55, 56, 59, 60, 66, 67, 69, 70, 71, 72]
Input sequence lengths: [512, 512, 512, 449, 512, 512, 512, 236, 236, 512, 512, 512, 512, 512, 145, 356, 121, 92, 512, 512, 512, 356, 366, 512, 91, 512, 388, 449, 512, 236, 512, 388]
Target phrase lengths: [4, 8, 4, 6, 5, 3, 8, 6, 8, 6, 5, 8, 5, 6, 7, 4, 5, 6, 8, 8, 8, 4, 5, 6, 4, 8, 4, 4, 5, 8, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.454, 0.829]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 67 | True: 67
Pred: 43 | True: 44

Phrase Generation Sample:
Generated: [CLS] douglass commonwealth [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] douglass commonwealth [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.3149
Generation Loss: 0.1189
Total Loss: 32.4338
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.1262
Train Epoch: 17 [0/334 (0%)] Loss: 32.433754
Train Epoch: 17 [64/334 (19%)] Loss: 47.916508
Train Epoch: 17 [128/334 (38%)] Loss: 38.783703
Train Epoch: 17 [192/334 (57%)] Loss: 36.424000
Train Epoch: 17 [256/334 (77%)] Loss: 33.295551
[2025-01-21 11:50:46] Starting validation for epoch: 17

Generation Samples:
Topic 65:
Generated: [CLS] brendan clever mouth hell bassist lexi help cabinets [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 38:
Generated: [CLS] shire system lou ko name nsa derivatives groningen [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] moral terminology decorations congress disney drugs russia general [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 17 [0/10 (0%)] Loss: 35.093796

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [39, 40, 41, 42, 43, 46, 47, 49, 50, 51, 52, 54, 55, 65, 66, 67, 68, 69, 70, 71]
Input sequence lengths: [449, 78, 512, 512, 512, 512, 512, 121, 512, 512, 123, 449, 512, 356, 512, 512, 356, 512, 512, 512, 512, 512, 236, 204, 512, 268, 512, 78, 236, 356, 388, 123]
Target phrase lengths: [6, 7, 8, 5, 8, 4, 4, 5, 6, 7, 8, 7, 5, 5, 8, 7, 5, 8, 5, 5, 8, 4, 8, 4, 6, 8, 4, 5, 8, 5, 3, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.468, 0.785]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 71 | True: 71
Pred: 51 | True: 51
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] fiscally responsible budget [SEP] [SEP] [SEP] [SEP]
Target: [CLS] fiscally responsible budget [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.6695
Generation Loss: 0.1198
Total Loss: 30.7893
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.1273
Train Epoch: 18 [0/334 (0%)] Loss: 30.789312
Train Epoch: 18 [64/334 (19%)] Loss: 34.169533
Train Epoch: 18 [128/334 (38%)] Loss: 21.639929
Train Epoch: 18 [192/334 (57%)] Loss: 22.818027
Train Epoch: 18 [256/334 (77%)] Loss: 45.217140
[2025-01-21 11:50:50] Starting validation for epoch: 18

Generation Samples:
Topic 36:
Generated: [CLS] teachers rhode ford ring orchestral lansing structurally code [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] ska liu tariff dax pablo conduct paso twitching [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] revised stupid organ barley drug mari turf ness [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 18 [0/10 (0%)] Loss: 42.835312

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 37, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 54, 58, 59, 60, 62, 65, 66, 68, 69, 71, 73]
Input sequence lengths: [512, 512, 512, 512, 121, 512, 78, 512, 512, 121, 512, 512, 388, 512, 145, 512, 366, 388, 512, 204, 512, 234, 512, 449, 512, 512, 87, 209, 366, 125, 512, 123]
Target phrase lengths: [4, 4, 6, 4, 5, 8, 5, 6, 5, 4, 4, 7, 4, 6, 8, 8, 7, 3, 6, 4, 8, 7, 6, 6, 6, 7, 6, 4, 3, 7, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.472, 0.820]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 45 | True: 45
Pred: 58 | True: 58
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] equal representation [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] equal representation [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.8068
Generation Loss: 0.0880
Total Loss: 26.8948
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0920
Train Epoch: 19 [0/334 (0%)] Loss: 26.894815
Train Epoch: 19 [64/334 (19%)] Loss: 32.272537
Train Epoch: 19 [128/334 (38%)] Loss: 54.075138
Train Epoch: 19 [192/334 (57%)] Loss: 27.907845
Train Epoch: 19 [256/334 (77%)] Loss: 35.501778
[2025-01-21 11:50:54] Starting validation for epoch: 19

Generation Samples:
Topic 38:
Generated: [CLS] electrical pistol de botanical jazz language answer musically [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 73:
Generated: [CLS] smallest ball dir mutually intelligence naming indefinite voice [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] wings outright telling republic object conduct immigration classes [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 19 [0/10 (0%)] Loss: 27.603781

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 39, 40, 41, 43, 44, 45, 47, 48, 52, 55, 58, 59, 60, 61, 63, 64, 65, 66, 68]
Input sequence lengths: [204, 204, 512, 145, 512, 125, 121, 125, 356, 356, 512, 512, 125, 512, 512, 366, 512, 512, 512, 123, 512, 512, 512, 81, 512, 366, 159, 512, 512, 512, 512, 512]
Target phrase lengths: [8, 8, 5, 8, 8, 5, 5, 6, 4, 4, 6, 6, 7, 6, 5, 6, 4, 4, 5, 8, 5, 7, 5, 6, 8, 7, 4, 8, 7, 8, 7, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.461, 0.821]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 68 | True: 68
Pred: 68 | True: 68
Pred: 47 | True: 47

Phrase Generation Sample:
Generated: [CLS] make decisions about their own bodies [SEP] [SEP]
Target: [CLS] make decisions about their own bodies [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.5255
Generation Loss: 0.0532
Total Loss: 33.5787
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0547
Train Epoch: 20 [0/334 (0%)] Loss: 33.578716
Train Epoch: 20 [64/334 (19%)] Loss: 28.275110
Train Epoch: 20 [128/334 (38%)] Loss: 37.610809
Train Epoch: 20 [192/334 (57%)] Loss: 48.165653
Train Epoch: 20 [256/334 (77%)] Loss: 36.477898
[2025-01-21 11:50:58] Starting validation for epoch: 20

Generation Samples:
Topic 66:
Generated: [CLS] algebra republic sorority peeking commissioners nazis mocking con [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] reckless contracts moves betrayal documentation hanover tb loan [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] shrubs foreign midland jet programming alternative axe boxing [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 20 [0/10 (0%)] Loss: 35.967873

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 40, 41, 43, 51, 52, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 71, 72]
Input sequence lengths: [512, 512, 449, 512, 512, 512, 512, 512, 159, 512, 356, 512, 512, 512, 258, 512, 91, 512, 123, 87, 123, 92, 449, 64, 512, 356, 125, 512, 159, 512, 258, 91]
Target phrase lengths: [4, 6, 7, 4, 4, 7, 5, 5, 4, 8, 4, 4, 5, 7, 6, 5, 4, 8, 8, 8, 7, 7, 4, 8, 4, 5, 7, 4, 7, 7, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.442, 0.869]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 65 | True: 65
Pred: 64 | True: 71

Phrase Generation Sample:
Generated: [CLS] democratic caucus [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] democratic caucus [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.1225
Generation Loss: 0.0737
Total Loss: 26.1961
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0764
Train Epoch: 21 [0/334 (0%)] Loss: 26.196135
Train Epoch: 21 [64/334 (19%)] Loss: 20.774738
Train Epoch: 21 [128/334 (38%)] Loss: 39.671848
Train Epoch: 21 [192/334 (57%)] Loss: 32.125107
Train Epoch: 21 [256/334 (77%)] Loss: 39.639977
[2025-01-21 11:51:07] Starting validation for epoch: 21

Generation Samples:
Topic 51:
Generated: [CLS] demo stole thrown card shoe glove alt joining [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 45:
Generated: [CLS] knicks indirectly costa shelby fleet shell administration conservative [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] remarried minor strangely glove dressed grammatical ceremonial chi [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 21 [0/10 (0%)] Loss: 35.676357

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 41, 42, 43, 44, 47, 49, 52, 53, 54, 55, 56, 62, 63, 64, 65, 66, 67, 69, 70]
Input sequence lengths: [234, 512, 512, 512, 512, 87, 334, 449, 512, 512, 236, 512, 512, 388, 334, 512, 125, 512, 123, 512, 356, 356, 512, 512, 512, 123, 512, 356, 512, 512, 64, 512]
Target phrase lengths: [4, 5, 6, 5, 5, 6, 7, 5, 6, 8, 6, 4, 7, 3, 4, 6, 7, 4, 7, 8, 4, 3, 7, 7, 8, 8, 7, 4, 7, 8, 7, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.463, 0.839]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 37 | True: 37
Pred: 41 | True: 41
Pred: 47 | True: 47

Phrase Generation Sample:
Generated: [CLS] expanding democracy [SEP] and and [SEP] [SEP] and
Target: [CLS] expanding democracy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.6852
Generation Loss: 0.1684
Total Loss: 31.8536
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.1834
Train Epoch: 22 [0/334 (0%)] Loss: 31.853567
Train Epoch: 22 [64/334 (19%)] Loss: 47.401867
Train Epoch: 22 [128/334 (38%)] Loss: 21.574953
Train Epoch: 22 [192/334 (57%)] Loss: 31.809717
Train Epoch: 22 [256/334 (77%)] Loss: 38.200321
[2025-01-21 11:51:11] Starting validation for epoch: 22

Generation Samples:
Topic 44:
Generated: [CLS] battery an happier constructed netting bash fictional surprising [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] rancho matthew organism mortally supplying goddamn shipping sioux [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] reassigned nintendo ring rings merged world ears nad [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 22 [0/10 (0%)] Loss: 40.056332

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 40, 41, 42, 43, 45, 49, 51, 52, 53, 54, 55, 56, 58, 60, 62, 65, 66, 67, 72, 73]
Input sequence lengths: [512, 234, 512, 92, 512, 91, 512, 512, 125, 512, 512, 512, 512, 512, 334, 512, 209, 512, 449, 145, 512, 512, 512, 356, 87, 91, 512, 512, 453, 92, 512, 512]
Target phrase lengths: [8, 8, 5, 7, 5, 4, 5, 6, 7, 7, 4, 6, 6, 6, 6, 8, 4, 5, 4, 7, 8, 5, 6, 5, 6, 4, 8, 4, 8, 5, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.485, 0.841]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 65 | True: 65
Pred: 37 | True: 37
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] gut the office of congressional ethics [SEP] [SEP]
Target: [CLS] gut the office of congressional ethics [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 12.6357
Generation Loss: 0.1288
Total Loss: 12.7645
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.1374
Train Epoch: 23 [0/334 (0%)] Loss: 12.764450
Train Epoch: 23 [64/334 (19%)] Loss: 27.048504
Train Epoch: 23 [128/334 (38%)] Loss: 33.180038
Train Epoch: 23 [192/334 (57%)] Loss: 31.547646
Train Epoch: 23 [256/334 (77%)] Loss: 49.009644
[2025-01-21 11:51:15] Starting validation for epoch: 23

Generation Samples:
Topic 59:
Generated: [CLS] kan celtic bryan shipped nee angry puget manages [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] stil ideas uk spoken republicans republican susquehanna wrestling [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] punches plastic think outskirts votes describing hands language [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 23 [0/10 (0%)] Loss: 26.017075

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 39, 40, 41, 43, 44, 45, 47, 48, 54, 56, 57, 58, 60, 62, 64, 66, 68, 70]
Input sequence lengths: [512, 512, 81, 512, 512, 449, 64, 453, 87, 123, 512, 512, 485, 512, 204, 449, 512, 145, 512, 236, 121, 512, 512, 123, 512, 512, 512, 125, 512, 512, 512, 123]
Target phrase lengths: [6, 4, 5, 6, 4, 4, 7, 6, 6, 8, 5, 6, 8, 5, 8, 5, 6, 7, 8, 8, 5, 3, 5, 8, 4, 7, 5, 8, 8, 4, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.471, 0.862]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 54 | True: 54
Pred: 34 | True: 48

Phrase Generation Sample:
Generated: [CLS] 5 - star accreditation [SEP] [SEP] [SEP] [SEP]
Target: [CLS] 5 - star accreditation [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.2891
Generation Loss: 0.0443
Total Loss: 31.3334
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0453
Train Epoch: 24 [0/334 (0%)] Loss: 31.333424
Train Epoch: 24 [64/334 (19%)] Loss: 50.401817
Train Epoch: 24 [128/334 (38%)] Loss: 47.575649
Train Epoch: 24 [192/334 (57%)] Loss: 40.418514
Train Epoch: 24 [256/334 (77%)] Loss: 39.279583
[2025-01-21 11:51:19] Starting validation for epoch: 24

Generation Samples:
Topic 51:
Generated: [CLS] unhappy implemented tried actually rushing murderer bike that [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 59:
Generated: [CLS] embraced is bmw andhra ruth hind phi talents [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] calmly government harper magic temple bryan empire sentences [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 24 [0/10 (0%)] Loss: 28.903582

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 40, 41, 42, 43, 47, 48, 49, 53, 54, 55, 56, 58, 59, 64, 66, 67, 69]
Input sequence lengths: [334, 125, 512, 512, 512, 512, 388, 512, 512, 512, 512, 125, 449, 512, 512, 512, 81, 512, 512, 512, 121, 356, 512, 512, 512, 137, 125, 512, 512, 512, 512, 366]
Target phrase lengths: [4, 6, 4, 5, 5, 6, 3, 6, 7, 6, 4, 5, 8, 6, 4, 6, 6, 8, 7, 6, 4, 5, 7, 5, 4, 7, 6, 8, 7, 8, 7, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.416, 0.849]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 59 | True: 53
Pred: 43 | True: 43
Pred: 49 | True: 49

Phrase Generation Sample:
Generated: [CLS] family values [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] family values [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 50.2617
Generation Loss: 0.1403
Total Loss: 50.4020
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.1506
Train Epoch: 25 [0/334 (0%)] Loss: 50.401974
Train Epoch: 25 [64/334 (19%)] Loss: 39.827976
Train Epoch: 25 [128/334 (38%)] Loss: 25.719494
Train Epoch: 25 [192/334 (57%)] Loss: 29.673061
Train Epoch: 25 [256/334 (77%)] Loss: 24.990135
[2025-01-21 11:51:23] Starting validation for epoch: 25

Generation Samples:
Topic 44:
Generated: [CLS] socialists disconnected ethics piled [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] wrestle electronic intention flies [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] conducts adjunct tak joshua [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 25 [0/10 (0%)] Loss: 26.893051

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 41, 42, 43, 44, 47, 49, 50, 54, 58, 59, 60, 61, 64, 66, 70, 72]
Input sequence lengths: [512, 512, 512, 512, 159, 125, 512, 512, 512, 512, 123, 512, 258, 137, 453, 512, 512, 512, 512, 512, 91, 512, 512, 512, 512, 366, 512, 512, 366, 236, 512, 512]
Target phrase lengths: [5, 6, 6, 4, 7, 4, 5, 6, 4, 4, 7, 5, 6, 7, 7, 4, 5, 4, 5, 8, 6, 6, 6, 8, 6, 5, 4, 8, 3, 8, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.450, 0.879]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 49 | True: 49
Pred: 47 | True: 47
Pred: 60 | True: 60

Phrase Generation Sample:
Generated: [CLS] american people first [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] american people first [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 44.8612
Generation Loss: 0.0542
Total Loss: 44.9154
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0557
Train Epoch: 26 [0/334 (0%)] Loss: 44.915417
Train Epoch: 26 [64/334 (19%)] Loss: 27.112324
Train Epoch: 26 [128/334 (38%)] Loss: 30.714272
Train Epoch: 26 [192/334 (57%)] Loss: 34.103573
Train Epoch: 26 [256/334 (77%)] Loss: 36.996975
[2025-01-21 11:51:32] Starting validation for epoch: 26

Generation Samples:
Topic 51:
Generated: [CLS] patriotic arm andrea wireless ears [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] berman forms options doing stirring [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 66:
Generated: [CLS] juan sen diego slave republicans [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 26 [0/10 (0%)] Loss: 38.571381

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 39, 41, 43, 44, 48, 52, 54, 55, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71]
Input sequence lengths: [121, 234, 366, 512, 512, 449, 81, 512, 512, 356, 512, 512, 512, 366, 123, 236, 512, 125, 356, 512, 159, 512, 512, 512, 388, 512, 512, 453, 512, 512, 512, 258]
Target phrase lengths: [7, 7, 5, 6, 5, 4, 8, 8, 8, 4, 5, 5, 8, 6, 4, 8, 4, 6, 4, 5, 4, 4, 8, 4, 8, 6, 5, 6, 4, 8, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.490, 0.897]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 39
Pred: 46 | True: 37
Pred: 59 | True: 59

Phrase Generation Sample:
Generated: [CLS] hakeem jeffries [SEP] those and
Target: [CLS] hakeem jeffries [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 19.3581
Generation Loss: 0.0507
Total Loss: 19.4088
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0520
Train Epoch: 27 [0/334 (0%)] Loss: 19.408768
Train Epoch: 27 [64/334 (19%)] Loss: 39.177948
Train Epoch: 27 [128/334 (38%)] Loss: 26.372416
Train Epoch: 27 [192/334 (57%)] Loss: 27.922586
Train Epoch: 27 [256/334 (77%)] Loss: 31.591337
[2025-01-21 11:51:36] Starting validation for epoch: 27

Generation Samples:
Topic 68:
Generated: [CLS] connection labels ah tanya [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] brass ser trouble jew [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] scandinavia madhya mysteriously flynn [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 27 [0/10 (0%)] Loss: 26.007107

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 40, 41, 43, 46, 49, 51, 53, 54, 55, 60, 61, 63, 64, 68, 70, 72]
Input sequence lengths: [453, 123, 159, 204, 512, 159, 453, 512, 78, 125, 512, 512, 78, 204, 512, 204, 512, 236, 512, 356, 334, 512, 512, 512, 334, 258, 512, 512, 159, 121, 91, 512]
Target phrase lengths: [8, 8, 7, 8, 8, 4, 6, 5, 7, 8, 6, 5, 5, 4, 7, 6, 5, 8, 8, 4, 4, 4, 4, 6, 6, 4, 6, 6, 4, 5, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.503, 0.930]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 43 | True: 43
Pred: 61 | True: 61

Phrase Generation Sample:
Generated: [CLS] elect a speaker who stands with [SEP] [SEP]
Target: [CLS] elect a speaker who stands with [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 42.5138
Generation Loss: 0.0469
Total Loss: 42.5607
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0480
Train Epoch: 28 [0/334 (0%)] Loss: 42.560707
Train Epoch: 28 [64/334 (19%)] Loss: 57.732738
Train Epoch: 28 [128/334 (38%)] Loss: 31.605352
Train Epoch: 28 [192/334 (57%)] Loss: 47.625000
Train Epoch: 28 [256/334 (77%)] Loss: 41.085716
[2025-01-21 11:51:39] Starting validation for epoch: 28

Generation Samples:
Topic 46:
Generated: [CLS] ale ks ankara space [SEP] [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] snort funky earthly paso fk [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] chamber cabbage legal bribery pact [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 28 [0/10 (0%)] Loss: 40.539417

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 38, 40, 41, 43, 45, 48, 51, 53, 54, 55, 56, 57, 60, 63, 64, 66, 72]
Input sequence lengths: [512, 145, 92, 512, 137, 512, 453, 512, 268, 512, 512, 91, 145, 453, 356, 512, 125, 449, 512, 512, 512, 485, 512, 512, 453, 512, 81, 334, 512, 92, 512, 512]
Target phrase lengths: [7, 7, 5, 8, 4, 8, 7, 8, 8, 5, 5, 4, 6, 7, 5, 5, 6, 5, 4, 8, 4, 8, 6, 5, 7, 4, 6, 6, 4, 5, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.425, 0.947]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 63 | True: 63
Pred: 35 | True: 35
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] committee authorization and oversight plans [SEP] [SEP] [SEP]
Target: [CLS] committee authorization and oversight plans [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.2235
Generation Loss: 0.0352
Total Loss: 31.2587
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0358
Train Epoch: 29 [0/334 (0%)] Loss: 31.258722
Train Epoch: 29 [64/334 (19%)] Loss: 37.288414
Train Epoch: 29 [128/334 (38%)] Loss: 31.416275
Train Epoch: 29 [192/334 (57%)] Loss: 20.411917
Train Epoch: 29 [256/334 (77%)] Loss: 28.082600
[2025-01-21 11:51:43] Starting validation for epoch: 29

Generation Samples:
Topic 44:
Generated: [CLS] creed mana q loans mono words believe mexico [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] sweden drugged hawk arbitrary flies hat stomped invitations [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] reopened rebranded serbia remembering nsw certain kyushu helping [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 29 [0/10 (0%)] Loss: 22.196190

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 39, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 64, 66, 67, 69]
Input sequence lengths: [512, 388, 78, 512, 512, 512, 512, 512, 366, 512, 512, 356, 512, 512, 512, 123, 512, 512, 512, 512, 334, 512, 121, 512, 258, 512, 512, 159, 234, 123, 512, 512]
Target phrase lengths: [4, 3, 5, 7, 6, 4, 6, 6, 5, 4, 7, 4, 4, 5, 4, 8, 8, 4, 8, 8, 6, 8, 5, 6, 6, 5, 8, 5, 4, 7, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.455, 0.914]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 69 | True: 69
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] douglass commonwealth [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] douglass commonwealth [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 24.5435
Generation Loss: 0.0247
Total Loss: 24.5682
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0250
Train Epoch: 30 [0/334 (0%)] Loss: 24.568161
Train Epoch: 30 [64/334 (19%)] Loss: 39.692593
Train Epoch: 30 [128/334 (38%)] Loss: 48.243156
Train Epoch: 30 [192/334 (57%)] Loss: 45.262421
Train Epoch: 30 [256/334 (77%)] Loss: 38.722950
[2025-01-21 11:51:47] Starting validation for epoch: 30

Generation Samples:
Topic 43:
Generated: [CLS] leasing citizenship fox torpedo peaceful [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] nonstop aeronautics parted germans rode [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] gift entity morals financing options [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 30 [0/10 (0%)] Loss: 41.480213

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 41, 42, 43, 45, 48, 51, 52, 53, 54, 55, 58, 59, 60, 63, 66, 67, 68, 72]
Input sequence lengths: [512, 92, 366, 512, 512, 512, 512, 512, 334, 258, 91, 356, 512, 512, 512, 512, 125, 81, 125, 123, 366, 204, 512, 356, 453, 512, 512, 512, 512, 366, 234, 512]
Target phrase lengths: [6, 5, 5, 7, 6, 4, 5, 6, 8, 6, 4, 4, 8, 4, 4, 6, 7, 5, 7, 8, 3, 8, 5, 4, 5, 5, 6, 6, 6, 5, 7, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.454, 0.915]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 63 | True: 63
Pred: 51 | True: 51
Pred: 59 | True: 59

Phrase Generation Sample:
Generated: [CLS] adoption of the rules [SEP] [SEP] [SEP] [SEP]
Target: [CLS] adoption of the rules [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.3039
Generation Loss: 0.0177
Total Loss: 25.3217
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0179
Train Epoch: 31 [0/334 (0%)] Loss: 25.321671
Train Epoch: 31 [64/334 (19%)] Loss: 43.559017
Train Epoch: 31 [128/334 (38%)] Loss: 23.898304
Train Epoch: 31 [192/334 (57%)] Loss: 43.001362
Train Epoch: 31 [256/334 (77%)] Loss: 44.025219
[2025-01-21 11:51:56] Starting validation for epoch: 31

Generation Samples:
Topic 58:
Generated: [CLS] reorganization franco celtic tickets tan buck corrupt tolkien [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] claire ether linux tossed planted pea kan greek [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 50:
Generated: [CLS] madman strict about mug levant subsidy strap budapest [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 31 [0/10 (0%)] Loss: 35.144630

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 39, 40, 41, 42, 43, 47, 48, 51, 53, 55, 59, 60, 61, 63, 64, 65, 67, 68, 69]
Input sequence lengths: [512, 512, 512, 512, 512, 512, 159, 512, 125, 78, 512, 512, 204, 121, 258, 512, 81, 512, 512, 512, 512, 512, 512, 334, 356, 512, 123, 512, 388, 366, 512, 64]
Target phrase lengths: [6, 4, 8, 7, 6, 5, 4, 5, 6, 7, 6, 8, 8, 4, 6, 6, 6, 8, 6, 6, 5, 6, 5, 7, 5, 8, 8, 8, 3, 3, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.512, 0.893]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 36 | True: 36
Pred: 54 | True: 63

Phrase Generation Sample:
Generated: [CLS] 5 - star accreditation [SEP] [SEP] and [SEP]
Target: [CLS] 5 - star accreditation [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 35.9693
Generation Loss: 0.0225
Total Loss: 35.9918
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0227
Train Epoch: 32 [0/334 (0%)] Loss: 35.991817
Train Epoch: 32 [64/334 (19%)] Loss: 38.166058
Train Epoch: 32 [128/334 (38%)] Loss: 30.960400
Train Epoch: 32 [192/334 (57%)] Loss: 44.344128
Train Epoch: 32 [256/334 (77%)] Loss: 38.804905
[2025-01-21 11:52:00] Starting validation for epoch: 32

Generation Samples:
Topic 41:
Generated: [CLS] purge reassigned philippines ios bike fcc hall myles [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] software drugged ultimatum diamond glove institutes ties rings [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] competes documentation programs winged cosmos leg words washington [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 32 [0/10 (0%)] Loss: 34.439167

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 40, 41, 42, 43, 45, 47, 48, 49, 51, 53, 54, 55, 58, 59, 62, 64, 65, 66, 68, 69, 70, 73]
Input sequence lengths: [512, 512, 125, 512, 512, 512, 125, 123, 356, 87, 512, 268, 512, 78, 81, 512, 209, 204, 236, 209, 512, 512, 512, 512, 512, 334, 366, 356, 388, 512, 512, 512]
Target phrase lengths: [5, 5, 4, 8, 4, 4, 7, 7, 4, 6, 8, 8, 6, 7, 8, 4, 4, 4, 8, 7, 6, 4, 7, 5, 8, 4, 5, 4, 4, 4, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.468, 0.904]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 64 | True: 64
Pred: 44 | True: 43

Phrase Generation Sample:
Generated: [CLS] nominate kevin mccarthy [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.1047
Generation Loss: 0.0148
Total Loss: 36.1195
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0149
Train Epoch: 33 [0/334 (0%)] Loss: 36.119453
Train Epoch: 33 [64/334 (19%)] Loss: 30.604055
Train Epoch: 33 [128/334 (38%)] Loss: 26.709463
Train Epoch: 33 [192/334 (57%)] Loss: 18.299004
Train Epoch: 33 [256/334 (77%)] Loss: 50.794945
[2025-01-21 11:52:04] Starting validation for epoch: 33

Generation Samples:
Topic 64:
Generated: [CLS] installed marketing ideas billed other deeds math saber [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 43:
Generated: [CLS] tyrant eta allegiance faerie castle locke constitution trapped [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] honesty decor cactus licenses mind hermes dialogue framework [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 33 [0/10 (0%)] Loss: 38.320469

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 41, 43, 44, 46, 49, 51, 52, 54, 56, 58, 59, 64, 67, 69, 70, 71]
Input sequence lengths: [78, 512, 512, 512, 512, 512, 125, 512, 512, 512, 512, 512, 125, 366, 258, 512, 512, 453, 78, 449, 512, 449, 258, 258, 125, 388, 449, 512, 453, 512, 366, 236]
Target phrase lengths: [7, 6, 6, 6, 3, 5, 7, 3, 4, 7, 6, 5, 8, 7, 4, 5, 4, 8, 7, 5, 6, 6, 6, 4, 6, 4, 4, 6, 7, 4, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.432, 0.927]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 58 | True: 58
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] flag of the united states [SEP] [SEP] [SEP]
Target: [CLS] flag of the united states [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 35.5926
Generation Loss: 0.0141
Total Loss: 35.6067
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0142
Train Epoch: 34 [0/334 (0%)] Loss: 35.606663
Train Epoch: 34 [64/334 (19%)] Loss: 56.072094
Train Epoch: 34 [128/334 (38%)] Loss: 26.653517
Train Epoch: 34 [192/334 (57%)] Loss: 20.103033
Train Epoch: 34 [256/334 (77%)] Loss: 39.302792
[2025-01-21 11:52:08] Starting validation for epoch: 34

Generation Samples:
Topic 52:
Generated: [CLS] elliot rejects romans box exciting intuitive creed xavier [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] gaming religions willard greece sees language phones drugs [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] planted goin formerly spaceship dimension greece anglia tribal [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 34 [0/10 (0%)] Loss: 30.839283

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 41, 43, 44, 45, 46, 47, 48, 53, 54, 55, 59, 60, 63, 64, 66, 68, 70, 71]
Input sequence lengths: [64, 512, 512, 512, 512, 125, 512, 236, 512, 512, 449, 512, 81, 512, 512, 123, 512, 366, 512, 334, 512, 204, 125, 356, 512, 512, 334, 512, 236, 512, 512, 512]
Target phrase lengths: [8, 4, 5, 6, 4, 7, 5, 8, 4, 5, 7, 8, 6, 5, 5, 8, 6, 5, 4, 4, 6, 4, 7, 4, 7, 7, 4, 7, 7, 3, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.451, 0.939]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 34
Pred: 46 | True: 46
Pred: 66 | True: 66

Phrase Generation Sample:
Generated: [CLS] join in the pledge of allegiance [SEP] [SEP]
Target: [CLS] join in the pledge of allegiance [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.8644
Generation Loss: 0.0224
Total Loss: 34.8869
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0227
Train Epoch: 35 [0/334 (0%)] Loss: 34.886856
Train Epoch: 35 [64/334 (19%)] Loss: 22.247396
Train Epoch: 35 [128/334 (38%)] Loss: 28.600620
Train Epoch: 35 [192/334 (57%)] Loss: 29.508535
Train Epoch: 35 [256/334 (77%)] Loss: 34.145485
[2025-01-21 11:52:12] Starting validation for epoch: 35

Generation Samples:
Topic 41:
Generated: [CLS] alfredo heel ik germany word bordered overboard shawn [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] armed inconsistent sovereignty migrant arms simplicity claus biologist [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] linux detached altering cyclic rome says interpreted shell [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 35 [0/10 (0%)] Loss: 24.918947

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 40, 41, 43, 44, 46, 48, 49, 51, 56, 57, 60, 61, 64, 65, 67, 68, 70, 73]
Input sequence lengths: [485, 512, 236, 268, 512, 92, 512, 78, 64, 512, 209, 204, 512, 512, 123, 81, 125, 512, 512, 159, 159, 209, 512, 512, 512, 449, 92, 145, 512, 453, 512, 512]
Target phrase lengths: [8, 5, 5, 8, 7, 5, 8, 7, 7, 6, 4, 5, 4, 6, 8, 8, 4, 6, 6, 5, 4, 4, 5, 4, 8, 5, 7, 8, 4, 8, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.463, 0.951]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 57 | True: 57
Pred: 46 | True: 46
Pred: 70 | True: 70

Phrase Generation Sample:
Generated: [CLS] united states sepak takra [SEP] and
Target: [CLS] united states sepak takra [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 18.9484
Generation Loss: 0.0125
Total Loss: 18.9608
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0125
Train Epoch: 36 [0/334 (0%)] Loss: 18.960846
Train Epoch: 36 [64/334 (19%)] Loss: 17.838730
Train Epoch: 36 [128/334 (38%)] Loss: 35.734955
Train Epoch: 36 [192/334 (57%)] Loss: 44.282429
Train Epoch: 36 [256/334 (77%)] Loss: 35.919285
[2025-01-21 11:52:21] Starting validation for epoch: 36

Generation Samples:
Topic 58:
Generated: [CLS] pont chicken translators weapons nationals horse hat cross [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 51:
Generated: [CLS] electronically fictional move condition cisco invading electricity formally [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 58:
Generated: [CLS] zen mouse clothing squirrel rib sane greek dunn [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 36 [0/10 (0%)] Loss: 23.071396

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 41, 44, 46, 47, 48, 49, 51, 53, 55, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 71, 72]
Input sequence lengths: [121, 512, 334, 512, 512, 453, 92, 366, 512, 388, 512, 159, 81, 356, 512, 121, 512, 512, 512, 512, 512, 449, 512, 512, 91, 87, 334, 512, 512, 204, 512, 512]
Target phrase lengths: [5, 6, 8, 4, 6, 8, 5, 5, 6, 3, 5, 5, 5, 4, 8, 4, 8, 7, 4, 7, 6, 4, 8, 5, 4, 8, 4, 6, 4, 8, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.473, 0.892]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 39
Pred: 36 | True: 36
Pred: 53 | True: 53

Phrase Generation Sample:
Generated: [CLS] speaker not elected [SEP] and and and and
Target: [CLS] speaker not elected [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 27.6396
Generation Loss: 0.0137
Total Loss: 27.6533
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0138
Train Epoch: 37 [0/334 (0%)] Loss: 27.653294
Train Epoch: 37 [64/334 (19%)] Loss: 41.574699
Train Epoch: 37 [128/334 (38%)] Loss: 25.203144
Train Epoch: 37 [192/334 (57%)] Loss: 37.942802
Train Epoch: 37 [256/334 (77%)] Loss: 33.216362
[2025-01-21 11:52:25] Starting validation for epoch: 37

Generation Samples:
Topic 73:
Generated: [CLS] cd wine tickets doubled oxygen languages wrestling translations [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] roster constitutional nomination mika hired bureaucracy housing harlem [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] clutching package broad bei phones penal rings cruiser [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 37 [0/10 (0%)] Loss: 37.559078

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 39, 40, 41, 42, 43, 47, 49, 51, 53, 54, 55, 56, 60, 62, 64, 65, 67, 68, 69, 70, 73]
Input sequence lengths: [512, 356, 512, 137, 512, 449, 234, 356, 209, 512, 512, 512, 512, 236, 512, 512, 356, 512, 388, 334, 512, 334, 204, 512, 512, 92, 512, 121, 512, 512, 87, 512]
Target phrase lengths: [6, 4, 5, 7, 5, 4, 4, 5, 7, 5, 6, 6, 8, 6, 4, 4, 4, 7, 3, 7, 5, 4, 8, 8, 7, 6, 5, 5, 5, 6, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.447, 0.912]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 49 | True: 49
Pred: 55 | True: 55
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] veterans ' accountability measures [SEP] [SEP] [SEP] and
Target: [CLS] veterans ' accountability measures [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.3769
Generation Loss: 0.0132
Total Loss: 30.3901
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0133
Train Epoch: 38 [0/334 (0%)] Loss: 30.390097
Train Epoch: 38 [64/334 (19%)] Loss: 36.019730
Train Epoch: 38 [128/334 (38%)] Loss: 31.622322
Train Epoch: 38 [192/334 (57%)] Loss: 38.149376
Train Epoch: 38 [256/334 (77%)] Loss: 42.060883
[2025-01-21 11:52:29] Starting validation for epoch: 38

Generation Samples:
Topic 65:
Generated: [CLS] parasites heads attire internally uttar stroked wearing rus [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 41:
Generated: [CLS] financed hurry guitar judaism proceeds substances chooses lied [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] learned mcbride lease guadalajara wizards orion gaius racial [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 38 [0/10 (0%)] Loss: 26.775576

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 41, 42, 43, 51, 52, 54, 56, 57, 59, 63, 64, 66, 68, 70]
Input sequence lengths: [512, 366, 512, 512, 92, 453, 512, 512, 449, 512, 512, 125, 512, 453, 512, 125, 204, 449, 137, 92, 512, 512, 258, 512, 485, 512, 453, 512, 236, 485, 512, 123]
Target phrase lengths: [5, 6, 8, 4, 7, 8, 4, 6, 4, 4, 6, 5, 8, 7, 8, 7, 8, 5, 7, 5, 5, 5, 6, 6, 5, 8, 5, 8, 8, 8, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.453, 0.891]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 52 | True: 52
Pred: 59 | True: 59
Pred: 66 | True: 66

Phrase Generation Sample:
Generated: [CLS] dedicated conservationist [SEP] positions [SEP] and and
Target: [CLS] dedicated conservationist [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 48.3522
Generation Loss: 0.0191
Total Loss: 48.3713
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0193
Train Epoch: 39 [0/334 (0%)] Loss: 48.371292
Train Epoch: 39 [64/334 (19%)] Loss: 46.884472
Train Epoch: 39 [128/334 (38%)] Loss: 27.335711
Train Epoch: 39 [192/334 (57%)] Loss: 23.515961
Train Epoch: 39 [256/334 (77%)] Loss: 30.048910
[2025-01-21 11:52:33] Starting validation for epoch: 39

Generation Samples:
Topic 61:
Generated: [CLS] playing function seneca straits jars collateral deal hitting [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] rowan dev appointing modules bargaining j symbol kant [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 66:
Generated: [CLS] interfering spaghetti representative deborah saber naming sees boyd [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 39 [0/10 (0%)] Loss: 26.726921

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 42, 44, 45, 47, 51, 52, 53, 54, 57, 59, 60, 64, 68, 69, 70, 71]
Input sequence lengths: [453, 388, 512, 512, 485, 512, 268, 512, 512, 236, 512, 366, 512, 512, 121, 512, 512, 512, 366, 512, 236, 512, 512, 204, 512, 334, 512, 78, 92, 449, 334, 453]
Target phrase lengths: [7, 3, 5, 7, 7, 6, 8, 4, 6, 5, 6, 3, 5, 6, 4, 3, 8, 6, 3, 5, 6, 8, 4, 8, 5, 7, 6, 7, 5, 4, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.453, 0.947]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 69 | True: 69
Pred: 40 | True: 40

Phrase Generation Sample:
Generated: [CLS] responsibility to serve our constituents [SEP] [SEP] [SEP]
Target: [CLS] responsibility to serve our constituents [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.4339
Generation Loss: 0.0107
Total Loss: 29.4446
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0107
Train Epoch: 40 [0/334 (0%)] Loss: 29.444597
Train Epoch: 40 [64/334 (19%)] Loss: 31.660801
Train Epoch: 40 [128/334 (38%)] Loss: 38.156765
Train Epoch: 40 [192/334 (57%)] Loss: 29.373213
Train Epoch: 40 [256/334 (77%)] Loss: 30.683510
[2025-01-21 11:52:37] Starting validation for epoch: 40

Generation Samples:
Topic 47:
Generated: [CLS] identities ska english violins ty stylistic moves aboard [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 58:
Generated: [CLS] consoles greece ross overhaul deal taiwan ding lego [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] doctrine dime weasel rap holland democrat ring english [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 40 [0/10 (0%)] Loss: 32.793518

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 38, 40, 41, 42, 47, 48, 53, 54, 55, 56, 57, 61, 63, 64, 65, 67, 69, 70]
Input sequence lengths: [512, 234, 485, 512, 512, 512, 512, 356, 512, 512, 64, 512, 159, 449, 388, 512, 145, 453, 81, 512, 453, 512, 236, 512, 512, 64, 334, 512, 453, 485, 356, 512]
Target phrase lengths: [5, 8, 5, 8, 8, 6, 5, 4, 4, 5, 5, 7, 4, 8, 4, 4, 7, 8, 5, 6, 7, 6, 8, 5, 5, 7, 6, 8, 7, 7, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.410, 0.933]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 47 | True: 47
Pred: 46 | True: 37
Pred: 57 | True: 57

Phrase Generation Sample:
Generated: [CLS] need a leader [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] need a leader [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 24.6476
Generation Loss: 0.0134
Total Loss: 24.6610
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0135
Train Epoch: 41 [0/334 (0%)] Loss: 24.660990
Train Epoch: 41 [64/334 (19%)] Loss: 23.691938
Train Epoch: 41 [128/334 (38%)] Loss: 25.746941
Train Epoch: 41 [192/334 (57%)] Loss: 41.859558
Train Epoch: 41 [256/334 (77%)] Loss: 53.700306
[2025-01-21 11:52:46] Starting validation for epoch: 41

Generation Samples:
Topic 66:
Generated: [CLS] [unused187] linear sexually inner religion [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] tang announced amend liar oppose [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] rebuilding sharon choreographed privatization morgan [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 41 [0/10 (0%)] Loss: 39.434597

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 44, 46, 49, 51, 53, 54, 56, 60, 61, 64, 65, 66, 69, 70, 73]
Input sequence lengths: [388, 123, 512, 512, 512, 449, 125, 209, 453, 512, 123, 512, 512, 236, 512, 512, 334, 121, 512, 78, 512, 512, 334, 512, 236, 512, 512, 512, 268, 512, 512, 159]
Target phrase lengths: [8, 8, 5, 5, 4, 7, 6, 7, 6, 6, 7, 6, 4, 7, 8, 8, 6, 6, 5, 5, 5, 6, 6, 8, 5, 8, 6, 8, 8, 6, 7, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.474, 0.970]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 69 | True: 69
Pred: 43 | True: 43
Pred: 46 | True: 46

Phrase Generation Sample:
Generated: [CLS] tax - and - spend politics [SEP] and
Target: [CLS] tax - and - spend politics [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 28.3837
Generation Loss: 0.0087
Total Loss: 28.3925
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0088
Train Epoch: 42 [0/334 (0%)] Loss: 28.392454
Train Epoch: 42 [64/334 (19%)] Loss: 35.352562
Train Epoch: 42 [128/334 (38%)] Loss: 39.299236
Train Epoch: 42 [192/334 (57%)] Loss: 45.035721
Train Epoch: 42 [256/334 (77%)] Loss: 39.218277
[2025-01-21 11:52:50] Starting validation for epoch: 42

Generation Samples:
Topic 38:
Generated: [CLS] plays knicks electronics mit way punches ammunition staggering [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] sword fee di walks claudio ter hat traded [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] commander cary pasha greek pow arms crap boxes [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 42 [0/10 (0%)] Loss: 55.983864

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 47, 48, 49, 55, 58, 59, 60, 64, 65, 66, 68]
Input sequence lengths: [366, 512, 512, 145, 512, 234, 512, 125, 512, 512, 204, 121, 123, 512, 512, 512, 512, 512, 512, 204, 512, 204, 258, 356, 64, 512, 512, 512, 512, 512, 81, 512]
Target phrase lengths: [3, 5, 6, 7, 5, 7, 5, 5, 4, 4, 8, 7, 8, 6, 4, 8, 3, 6, 6, 4, 7, 6, 4, 4, 8, 4, 4, 4, 4, 5, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.478, 0.948]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 59 | True: 59
Pred: 36 | True: 36
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] mentor [SEP] [SEP] [SEP] and and [SEP] and
Target: [CLS] mentor [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.8499
Generation Loss: 0.0078
Total Loss: 29.8577
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0078
Train Epoch: 43 [0/334 (0%)] Loss: 29.857691
Train Epoch: 43 [64/334 (19%)] Loss: 31.564270
Train Epoch: 43 [128/334 (38%)] Loss: 22.433655
Train Epoch: 43 [192/334 (57%)] Loss: 39.072338
Train Epoch: 43 [256/334 (77%)] Loss: 32.335846
[2025-01-21 11:52:54] Starting validation for epoch: 43

Generation Samples:
Topic 36:
Generated: [CLS] bombings eve christ nordic words fx jet aromatic [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] pharmaceuticals actions force anyone airplanes wat td ty [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] socialists mistaken linux foreign nile hurts flower fear [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 43 [0/10 (0%)] Loss: 24.351646

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 41, 43, 45, 46, 49, 50, 51, 53, 54, 55, 60, 63, 66, 67, 69, 71, 73]
Input sequence lengths: [512, 449, 258, 356, 209, 334, 512, 512, 512, 64, 512, 512, 453, 512, 512, 512, 512, 125, 512, 388, 512, 512, 512, 78, 512, 209, 512, 512, 512, 512, 356, 268]
Target phrase lengths: [4, 6, 6, 4, 4, 6, 6, 8, 4, 7, 4, 4, 6, 5, 5, 4, 4, 7, 6, 4, 6, 7, 5, 7, 6, 4, 5, 8, 7, 5, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.414, 0.977]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 69 | True: 71
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] effective advocate [SEP] [SEP] and and [SEP] and
Target: [CLS] effective advocate [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 27.9118
Generation Loss: 0.0092
Total Loss: 27.9210
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0092
Train Epoch: 44 [0/334 (0%)] Loss: 27.921011
Train Epoch: 44 [64/334 (19%)] Loss: 32.036873
Train Epoch: 44 [128/334 (38%)] Loss: 30.311277
Train Epoch: 44 [192/334 (57%)] Loss: 31.386089
Train Epoch: 44 [256/334 (77%)] Loss: 20.127144
[2025-01-21 11:52:58] Starting validation for epoch: 44

Generation Samples:
Topic 44:
Generated: [CLS] manipulate guadalajara cold india foreign [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] bargaining chaos systems caps thoughts [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] det ships insane answering postal [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 44 [0/10 (0%)] Loss: 41.796490

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 41, 42, 43, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 66, 69]
Input sequence lengths: [512, 449, 512, 512, 512, 125, 512, 92, 512, 268, 512, 512, 453, 388, 512, 449, 512, 512, 512, 512, 145, 64, 123, 512, 512, 512, 123, 366, 81, 512, 512, 92]
Target phrase lengths: [8, 4, 7, 5, 7, 7, 6, 7, 5, 8, 4, 4, 6, 4, 5, 5, 7, 6, 5, 6, 6, 7, 7, 5, 3, 5, 4, 5, 8, 8, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.461, 0.983]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 66
Pred: 56 | True: 56
Pred: 38 | True: 42

Phrase Generation Sample:
Generated: [CLS] out - of - control spending [SEP] [SEP]
Target: [CLS] out - of - control spending [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 42.1405
Generation Loss: 0.0080
Total Loss: 42.1485
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0080
Train Epoch: 45 [0/334 (0%)] Loss: 42.148518
Train Epoch: 45 [64/334 (19%)] Loss: 31.397688
Train Epoch: 45 [128/334 (38%)] Loss: 41.344448
Train Epoch: 45 [192/334 (57%)] Loss: 19.998339
Train Epoch: 45 [256/334 (77%)] Loss: 30.580362
[2025-01-21 11:53:02] Starting validation for epoch: 45

Generation Samples:
Topic 50:
Generated: [CLS] denied generalized clarify slave glove over crank news [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] nintendo beans joined ibm hungary spy deal medicare [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] settlers ships tay wheels authority connects woo merged [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 45 [0/10 (0%)] Loss: 26.487869

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54, 56, 58, 60, 61, 66, 67, 71]
Input sequence lengths: [125, 512, 159, 512, 512, 81, 512, 78, 512, 512, 512, 512, 512, 512, 258, 512, 512, 512, 125, 512, 449, 512, 449, 512, 512, 123, 449, 512, 512, 125, 234, 512]
Target phrase lengths: [5, 4, 7, 8, 4, 6, 6, 7, 6, 4, 5, 6, 5, 5, 6, 4, 8, 7, 7, 5, 4, 5, 5, 6, 5, 8, 4, 4, 8, 6, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.457, 0.974]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 66 | True: 66
Pred: 61 | True: 61

Phrase Generation Sample:
Generated: [CLS] kevin hern [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] kevin hern [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.5490
Generation Loss: 0.0104
Total Loss: 31.5594
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0104
Train Epoch: 46 [0/334 (0%)] Loss: 31.559378
Train Epoch: 46 [64/334 (19%)] Loss: 22.660530
Train Epoch: 46 [128/334 (38%)] Loss: 29.930662
Train Epoch: 46 [192/334 (57%)] Loss: 29.054108
Train Epoch: 46 [256/334 (77%)] Loss: 29.616638
[2025-01-21 11:53:16] Starting validation for epoch: 46

Generation Samples:
Topic 44:
Generated: [CLS] sentiment intrusion paved heck cabin pitch mind religions [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] turbulence dialogue finances lizard faso theological t tx [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] tribes snake funding crystalline swords louisville languages modules [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 46 [0/10 (0%)] Loss: 36.994263

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 49, 54, 55, 56, 59, 60, 64, 68, 69]
Input sequence lengths: [512, 356, 234, 512, 512, 449, 356, 512, 388, 512, 453, 512, 512, 512, 268, 512, 512, 512, 137, 356, 204, 145, 366, 125, 512, 512, 125, 512, 512, 121, 366, 512]
Target phrase lengths: [6, 5, 4, 5, 5, 8, 4, 5, 4, 8, 8, 5, 4, 6, 8, 8, 5, 5, 4, 4, 8, 6, 3, 7, 6, 5, 8, 8, 8, 7, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.470, 0.973]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 46 | True: 46
Pred: 55 | True: 55
Pred: 68 | True: 37

Phrase Generation Sample:
Generated: [CLS] single - subject legislation [SEP] [SEP] [SEP] [SEP]
Target: [CLS] single - subject legislation [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.7065
Generation Loss: 0.0111
Total Loss: 25.7176
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0112
Train Epoch: 47 [0/334 (0%)] Loss: 25.717579
Train Epoch: 47 [64/334 (19%)] Loss: 30.490942
Train Epoch: 47 [128/334 (38%)] Loss: 43.314053
Train Epoch: 47 [192/334 (57%)] Loss: 40.974937
Train Epoch: 47 [256/334 (77%)] Loss: 28.351187
[2025-01-21 11:53:20] Starting validation for epoch: 47

Generation Samples:
Topic 41:
Generated: [CLS] loans mono dual stunts downs acts liv living [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 50:
Generated: [CLS] soul clothes kingdoms headline skipped ties sends drugs [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] eureka boxing experimenting algebraic auditory wine docked complexes [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 47 [0/10 (0%)] Loss: 21.434683

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 39, 40, 42, 43, 44, 47, 49, 50, 51, 53, 54, 59, 60, 62, 63, 66, 67, 69, 70, 71, 72]
Input sequence lengths: [512, 87, 388, 512, 512, 334, 234, 366, 449, 512, 512, 91, 512, 92, 512, 512, 91, 512, 512, 236, 388, 512, 512, 512, 125, 121, 512, 512, 512, 236, 512, 512]
Target phrase lengths: [4, 6, 8, 4, 5, 6, 4, 5, 4, 4, 4, 4, 6, 6, 6, 5, 4, 6, 6, 7, 4, 5, 5, 4, 6, 5, 6, 4, 8, 8, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.447, 0.954]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 66
Pred: 71 | True: 62
Pred: 69 | True: 69

Phrase Generation Sample:
Generated: [CLS] house rules [SEP] [SEP] [PAD] [PAD] [SEP] [SEP]
Target: [CLS] house rules [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.8341
Generation Loss: 0.0100
Total Loss: 32.8441
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0100
Train Epoch: 48 [0/334 (0%)] Loss: 32.844109
Train Epoch: 48 [64/334 (19%)] Loss: 17.598555
Train Epoch: 48 [128/334 (38%)] Loss: 33.713955
Train Epoch: 48 [192/334 (57%)] Loss: 25.217508
Train Epoch: 48 [256/334 (77%)] Loss: 27.386862
[2025-01-21 11:53:24] Starting validation for epoch: 48

Generation Samples:
Topic 58:
Generated: [CLS] sergio mouse fritz devin strongly australian dragon bhutan [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] kant flies life america usa india doubt ring [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 38:
Generated: [CLS] sailor ich mathematician drag bombs hell rings ring [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 48 [0/10 (0%)] Loss: 30.234932

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 42, 49, 50, 51, 53, 54, 55, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71]
Input sequence lengths: [145, 92, 512, 512, 512, 512, 236, 512, 334, 512, 356, 512, 512, 512, 512, 512, 512, 512, 258, 512, 512, 512, 512, 449, 204, 453, 512, 512, 388, 159, 512, 268]
Target phrase lengths: [8, 5, 5, 4, 4, 6, 8, 5, 4, 8, 4, 4, 4, 6, 5, 8, 6, 4, 6, 8, 8, 5, 6, 4, 5, 6, 8, 5, 4, 5, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.442, 0.976]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 62 | True: 35
Pred: 51 | True: 51
Pred: 38 | True: 36

Phrase Generation Sample:
Generated: [CLS] respecting and upholding order and [SEP].
Target: [CLS] respecting and upholding order and [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 51.2977
Generation Loss: 0.0104
Total Loss: 51.3081
Topic Prediction Accuracy: 0.6250
Generation Perplexity: 1.0105
Train Epoch: 49 [0/334 (0%)] Loss: 51.308083
Train Epoch: 49 [64/334 (19%)] Loss: 24.530930
Train Epoch: 49 [128/334 (38%)] Loss: 33.056255
Train Epoch: 49 [192/334 (57%)] Loss: 34.484028
Train Epoch: 49 [256/334 (77%)] Loss: 37.973976
[2025-01-21 11:53:28] Starting validation for epoch: 49

Generation Samples:
Topic 44:
Generated: [CLS] membership aj renaming aura diabetes kant choice chaos [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] tang aztec most dealing mic kn argument paolo [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] controlled hindwings free innovation reorganization snake championships gong [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 49 [0/10 (0%)] Loss: 28.908287

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 42, 43, 44, 45, 46, 51, 54, 55, 56, 57, 62, 63, 65, 66, 67, 68, 70, 71, 72]
Input sequence lengths: [449, 512, 512, 512, 449, 356, 91, 258, 512, 485, 123, 512, 356, 92, 512, 512, 512, 512, 512, 87, 512, 204, 512, 512, 137, 512, 512, 258, 512, 356, 512, 236]
Target phrase lengths: [4, 4, 5, 4, 4, 5, 4, 4, 6, 8, 8, 4, 4, 5, 8, 5, 8, 6, 8, 6, 5, 5, 5, 7, 7, 6, 6, 6, 6, 4, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.471, 0.995]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 56 | True: 56
Pred: 66 | True: 66
Pred: 44 | True: 44

Phrase Generation Sample:
Generated: [CLS] greatest neighbor [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] greatest neighbor [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.0593
Generation Loss: 0.0083
Total Loss: 23.0676
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0083
Train Epoch: 50 [0/334 (0%)] Loss: 23.067553
Train Epoch: 50 [64/334 (19%)] Loss: 25.099306
Train Epoch: 50 [128/334 (38%)] Loss: 42.651569
Train Epoch: 50 [192/334 (57%)] Loss: 24.818613
Train Epoch: 50 [256/334 (77%)] Loss: 36.590908
[2025-01-21 11:53:32] Starting validation for epoch: 50

Generation Samples:
Topic 47:
Generated: [CLS] bangkok mls crossed backward design ideas gut ale [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 36:
Generated: [CLS] spontaneous loco sword shrugged commanders existent fictional dress [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] rust systems germany night timothy der answers disgusting [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 50 [0/10 (0%)] Loss: 22.943750

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 39, 41, 42, 43, 44, 46, 52, 54, 55, 59, 61, 63, 64, 66, 67, 68]
Input sequence lengths: [64, 512, 356, 512, 512, 512, 125, 512, 512, 512, 159, 512, 512, 145, 159, 234, 204, 366, 121, 512, 512, 512, 512, 356, 512, 512, 125, 512, 512, 512, 453, 512]
Target phrase lengths: [7, 6, 4, 5, 5, 4, 4, 6, 8, 8, 4, 5, 6, 8, 4, 4, 6, 7, 6, 5, 5, 3, 5, 5, 5, 5, 6, 7, 6, 5, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.462, 0.966]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 34 | True: 34
Pred: 71 | True: 63
Pred: 55 | True: 55

Phrase Generation Sample:
Generated: [CLS] led the pledge of allegiance [SEP] [SEP] [SEP]
Target: [CLS] led the pledge of allegiance [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.2368
Generation Loss: 0.0064
Total Loss: 23.2432
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0064
Train Epoch: 51 [0/334 (0%)] Loss: 23.243219
Train Epoch: 51 [64/334 (19%)] Loss: 18.187149
Train Epoch: 51 [128/334 (38%)] Loss: 47.740952
Train Epoch: 51 [192/334 (57%)] Loss: 20.482950
Train Epoch: 51 [256/334 (77%)] Loss: 21.326263
[2025-01-21 11:53:46] Starting validation for epoch: 51

Generation Samples:
Topic 41:
Generated: [CLS] ringing incomplete albanians electronics mb sabre aggression nate [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] matthews programming kidding fuck selective yep bolts robotics [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] potsdam voyage insults panama fern music abdul ring [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 51 [0/10 (0%)] Loss: 32.833199

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 42, 43, 44, 46, 47, 49, 50, 51, 53, 54, 55, 60, 63, 66, 68, 70, 71, 72, 73]
Input sequence lengths: [512, 512, 204, 512, 91, 512, 125, 512, 512, 512, 512, 512, 512, 512, 512, 123, 512, 512, 209, 91, 356, 334, 236, 512, 449, 512, 512, 512, 125, 512, 92, 356]
Target phrase lengths: [8, 6, 4, 6, 4, 3, 7, 5, 6, 4, 5, 6, 7, 5, 7, 7, 5, 8, 7, 4, 4, 7, 7, 5, 6, 8, 4, 4, 7, 8, 7, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.517, 0.979]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 66
Pred: 71 | True: 36
Pred: 68 | True: 68

Phrase Generation Sample:
Generated: [CLS] accountability for the biden administration [SEP] [SEP]
Target: [CLS] accountability for the biden administration [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 35.5811
Generation Loss: 0.0111
Total Loss: 35.5922
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0111
Train Epoch: 52 [0/334 (0%)] Loss: 35.592197
Train Epoch: 52 [64/334 (19%)] Loss: 23.820513
Train Epoch: 52 [128/334 (38%)] Loss: 25.173183
Train Epoch: 52 [192/334 (57%)] Loss: 27.461340
Train Epoch: 52 [256/334 (77%)] Loss: 33.352592
[2025-01-21 11:53:50] Starting validation for epoch: 52

Generation Samples:
Topic 73:
Generated: [CLS] constitutional words passport java finances creditors wright phil [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] lease wheeler monks isles valencia speaks mv hat [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] blink blizzard bei wilton choreographed refurbished theory scriptures [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 52 [0/10 (0%)] Loss: 32.792271

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 53, 54, 55, 56, 60, 61, 63, 66, 67, 68, 71]
Input sequence lengths: [204, 81, 512, 512, 453, 453, 512, 92, 137, 512, 449, 512, 512, 512, 125, 234, 512, 449, 512, 512, 449, 449, 512, 356, 159, 512, 512, 512, 512, 334, 512, 204]
Target phrase lengths: [4, 6, 5, 8, 6, 8, 8, 5, 4, 4, 4, 4, 5, 4, 5, 4, 8, 5, 6, 7, 4, 7, 7, 5, 4, 6, 4, 6, 6, 6, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.464, 0.974]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 73 | True: 68
Pred: 48 | True: 48
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] abortion rights [SEP] [SEP] [SEP] [SEP] and and
Target: [CLS] abortion rights [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.1146
Generation Loss: 0.0085
Total Loss: 38.1230
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0085
Train Epoch: 53 [0/334 (0%)] Loss: 38.123043
Train Epoch: 53 [64/334 (19%)] Loss: 44.640053
Train Epoch: 53 [128/334 (38%)] Loss: 25.669424
Train Epoch: 53 [192/334 (57%)] Loss: 30.212349
Train Epoch: 53 [256/334 (77%)] Loss: 38.838036
[2025-01-21 11:53:54] Starting validation for epoch: 53

Generation Samples:
Topic 52:
Generated: [CLS] [unused740] gundam atheist notation dual bryan organization renamed [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] hesitant peg wears jet phil modern gaming relocation [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] basque gleaming ross crossed yerevan amulet statements islam [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Validation Epoch: 53 [0/10 (0%)] Loss: 26.856169

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 40, 41, 42, 43, 46, 47, 49, 51, 53, 54, 55, 60, 61, 63, 64, 65, 67, 68, 71]
Input sequence lengths: [78, 159, 334, 512, 512, 512, 125, 512, 512, 512, 92, 512, 449, 234, 356, 512, 204, 356, 512, 512, 334, 123, 512, 512, 145, 92, 512, 512, 512, 356, 512, 512]
Target phrase lengths: [7, 4, 6, 7, 6, 7, 7, 8, 8, 8, 6, 5, 7, 7, 4, 8, 8, 4, 4, 6, 6, 7, 6, 5, 8, 5, 5, 7, 6, 4, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.505, 0.994]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 57 | True: 61
Pred: 53 | True: 53

Phrase Generation Sample:
Generated: [CLS] liberty and justice for all [SEP] and and
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 22.6511
Generation Loss: 0.0100
Total Loss: 22.6611
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0101
Train Epoch: 54 [0/334 (0%)] Loss: 22.661072
Train Epoch: 54 [64/334 (19%)] Loss: 25.546831
Train Epoch: 54 [128/334 (38%)] Loss: 29.194654
Train Epoch: 54 [192/334 (57%)] Loss: 27.711472
Train Epoch: 54 [256/334 (77%)] Loss: 29.235886
[2025-01-21 11:53:58] Starting validation for epoch: 54

Generation Samples:
Topic 50:
Generated: [CLS] beats tooth relate salazar tame witchcraft [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] ign pledged greek nordic swan dot [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] holdings roman darius changing steals dragon [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 54 [0/10 (0%)] Loss: 19.216988

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 39, 41, 42, 43, 46, 48, 49, 54, 55, 56, 59, 60, 61, 63, 64, 65, 66, 67, 68, 73]
Input sequence lengths: [512, 209, 125, 204, 512, 356, 512, 512, 366, 512, 64, 123, 512, 512, 145, 512, 123, 512, 453, 449, 121, 512, 512, 159, 512, 204, 81, 512, 512, 366, 512, 512]
Target phrase lengths: [6, 4, 4, 5, 4, 4, 6, 6, 5, 5, 8, 8, 4, 7, 8, 4, 4, 7, 6, 4, 7, 7, 7, 4, 6, 8, 5, 8, 6, 5, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.436, 0.992]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 42
Pred: 73 | True: 73
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] [SEP] and [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 45.8048
Generation Loss: 0.0077
Total Loss: 45.8125
Topic Prediction Accuracy: 0.6562
Generation Perplexity: 1.0077
Train Epoch: 55 [0/334 (0%)] Loss: 45.812485
Train Epoch: 55 [64/334 (19%)] Loss: 32.763653
Train Epoch: 55 [128/334 (38%)] Loss: 39.764950
Train Epoch: 55 [192/334 (57%)] Loss: 36.061466
Train Epoch: 55 [256/334 (77%)] Loss: 25.454855
[2025-01-21 11:54:02] Starting validation for epoch: 55

Generation Samples:
Topic 59:
Generated: [CLS] organs astro heck republished naming mitsubishi tangible franchise [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 73:
Generated: [CLS] natural constitutional romance fifth entrepreneur castle aviator tossed [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] shea libby zach cocaine sabre hotspur yen stupidity [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 55 [0/10 (0%)] Loss: 50.001839

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 41, 42, 43, 46, 51, 53, 54, 55, 56, 59, 63, 64, 65, 66, 72]
Input sequence lengths: [78, 512, 123, 512, 356, 512, 145, 78, 512, 125, 512, 78, 356, 64, 356, 268, 512, 366, 512, 91, 125, 512, 366, 334, 356, 91, 512, 137, 512, 258, 449, 366]
Target phrase lengths: [7, 3, 4, 8, 5, 5, 7, 6, 8, 6, 5, 7, 3, 7, 5, 8, 7, 7, 4, 6, 7, 7, 5, 4, 5, 4, 7, 4, 4, 6, 7, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.508, 0.959]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 52 | True: 41
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] liberty and justice for all [SEP] and and
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.7378
Generation Loss: 0.0078
Total Loss: 38.7456
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0078
Train Epoch: 56 [0/334 (0%)] Loss: 38.745556
Train Epoch: 56 [64/334 (19%)] Loss: 19.714592
Train Epoch: 56 [128/334 (38%)] Loss: 28.502655
Train Epoch: 56 [192/334 (57%)] Loss: 24.276751
Train Epoch: 56 [256/334 (77%)] Loss: 26.317684
[2025-01-21 11:54:11] Starting validation for epoch: 56

Generation Samples:
Topic 40:
Generated: [CLS] derivatives peerage mari borrow pea myth foundation christ [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] relic gorman hat glue loft dominion secrets racist [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] emblem 258 sac aliens rat formerly aboard lynch [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 56 [0/10 (0%)] Loss: 36.493172

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 41, 43, 44, 45, 47, 50, 51, 54, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 72]
Input sequence lengths: [512, 137, 91, 92, 125, 512, 512, 512, 512, 512, 137, 512, 512, 512, 92, 512, 512, 485, 512, 125, 449, 512, 204, 512, 512, 512, 512, 512, 204, 123, 512, 512]
Target phrase lengths: [6, 4, 4, 6, 7, 7, 5, 5, 6, 7, 7, 6, 5, 4, 5, 4, 8, 8, 5, 8, 4, 8, 8, 5, 8, 6, 4, 4, 8, 7, 8, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.484, 1.004]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 44 | True: 47
Pred: 43 | True: 43
Pred: 72 | True: 72

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] [SEP] [SEP] [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 43.1712
Generation Loss: 0.0114
Total Loss: 43.1826
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0115
Train Epoch: 57 [0/334 (0%)] Loss: 43.182648
Train Epoch: 57 [64/334 (19%)] Loss: 51.946762
Train Epoch: 57 [128/334 (38%)] Loss: 23.006554
Train Epoch: 57 [192/334 (57%)] Loss: 22.596266
Train Epoch: 57 [256/334 (77%)] Loss: 24.793045
[2025-01-21 11:54:15] Starting validation for epoch: 57

Generation Samples:
Topic 41:
Generated: [CLS] towed blessed mysterious mind carmen creative kevin framed [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] israelis neck saxons proteins orion beans salad annexation [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 50:
Generated: [CLS] nervous monterrey say savior midfielder sword ne democratic [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 57 [0/10 (0%)] Loss: 25.549595

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 39, 40, 41, 42, 43, 48, 51, 54, 55, 56, 57, 60, 63, 65, 66, 67, 68, 71]
Input sequence lengths: [512, 512, 512, 145, 512, 125, 512, 512, 512, 449, 268, 512, 512, 356, 125, 512, 512, 204, 81, 268, 512, 512, 449, 121, 78, 485, 204, 512, 234, 125, 145, 512]
Target phrase lengths: [7, 6, 7, 7, 8, 6, 4, 5, 8, 8, 8, 6, 8, 4, 7, 7, 5, 4, 8, 8, 4, 5, 4, 6, 7, 5, 6, 8, 4, 5, 7, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.454, 0.956]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 42 | True: 42
Pred: 42 | True: 42
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] nomination of byron donalds [SEP] [SEP] [SEP]
Target: [CLS] nomination of byron donalds [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.1391
Generation Loss: 0.0108
Total Loss: 32.1499
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0108
Train Epoch: 58 [0/334 (0%)] Loss: 32.149902
Train Epoch: 58 [64/334 (19%)] Loss: 33.974434
Train Epoch: 58 [128/334 (38%)] Loss: 36.674160
Train Epoch: 58 [192/334 (57%)] Loss: 38.955032
Train Epoch: 58 [256/334 (77%)] Loss: 28.599163
[2025-01-21 11:54:19] Starting validation for epoch: 58

Generation Samples:
Topic 41:
Generated: [CLS] liberals lease greeks slope forms administration arts ios [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 55:
Generated: [CLS] kappa iceland ports rosen cohen million rourke relocated [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] regulates package added nat accepting authority axe morgan [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 58 [0/10 (0%)] Loss: 40.973427

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 44, 46, 47, 53, 55, 60, 63, 65, 66, 67, 70]
Input sequence lengths: [512, 125, 512, 268, 236, 334, 356, 125, 121, 125, 512, 512, 356, 512, 512, 512, 334, 512, 512, 121, 512, 512, 512, 512, 512, 123, 236, 356, 125, 512, 512, 512]
Target phrase lengths: [8, 7, 8, 8, 6, 6, 5, 6, 6, 5, 7, 5, 4, 5, 4, 5, 4, 8, 8, 4, 6, 5, 6, 6, 5, 7, 8, 4, 7, 6, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.512, 0.984]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 44
Pred: 39 | True: 43
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] protect that speaker ' s gave [SEP] [SEP]
Target: [CLS] protect that speaker ' s gave [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 56.9418
Generation Loss: 0.0068
Total Loss: 56.9486
Topic Prediction Accuracy: 0.5938
Generation Perplexity: 1.0068
Train Epoch: 59 [0/334 (0%)] Loss: 56.948559
Train Epoch: 59 [64/334 (19%)] Loss: 49.734886
Train Epoch: 59 [128/334 (38%)] Loss: 34.046364
Train Epoch: 59 [192/334 (57%)] Loss: 38.548912
Train Epoch: 59 [256/334 (77%)] Loss: 50.239372
[2025-01-21 11:54:23] Starting validation for epoch: 59

Generation Samples:
Topic 44:
Generated: [CLS] nonlinear amend concessions seahawks foreign security cargo restructuring [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] upgrade bryan cords ko internal graffiti mets plant [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] rico delhi bryan turks whitman genera headed limbs [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Validation Epoch: 59 [0/10 (0%)] Loss: 33.585640

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 43, 44, 46, 53, 54, 55, 56, 60, 64, 66, 67, 68, 70, 72, 73]
Input sequence lengths: [512, 512, 512, 512, 512, 512, 512, 512, 209, 356, 512, 512, 512, 125, 512, 236, 204, 512, 512, 512, 453, 512, 356, 512, 121, 512, 91, 512, 334, 334, 236, 449]
Target phrase lengths: [4, 6, 4, 5, 6, 4, 8, 5, 4, 4, 5, 8, 5, 8, 8, 6, 6, 8, 6, 4, 7, 6, 4, 6, 6, 5, 6, 3, 6, 4, 8, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.458, 0.968]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 44 | True: 44
Pred: 60 | True: 60
Pred: 40 | True: 40

Phrase Generation Sample:
Generated: [CLS] overwhelming support [SEP]. and and purpose party
Target: [CLS] overwhelming support [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.5539
Generation Loss: 0.0341
Total Loss: 30.5880
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0347
Train Epoch: 60 [0/334 (0%)] Loss: 30.587955
Train Epoch: 60 [64/334 (19%)] Loss: 28.180777
Train Epoch: 60 [128/334 (38%)] Loss: 39.601948
Train Epoch: 60 [192/334 (57%)] Loss: 25.991005
Train Epoch: 60 [256/334 (77%)] Loss: 37.619839
[2025-01-21 11:54:27] Starting validation for epoch: 60

Generation Samples:
Topic 66:
Generated: [CLS] tai traders biology toss fang constitutional retribution agreements [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] humane privatization bargaining named mexican hell america drink [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] canonical authority varies opinions jaguars boxes implements spelling [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 60 [0/10 (0%)] Loss: 19.923330

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 39, 41, 42, 43, 44, 47, 54, 55, 57, 59, 60, 61, 62, 64, 65, 68]
Input sequence lengths: [512, 512, 512, 512, 366, 356, 512, 512, 512, 485, 512, 512, 512, 121, 159, 125, 87, 512, 145, 512, 512, 512, 204, 512, 87, 512, 512, 512, 137, 512, 125, 123]
Target phrase lengths: [6, 8, 5, 4, 5, 3, 4, 8, 5, 7, 5, 5, 7, 4, 4, 6, 6, 5, 8, 8, 4, 8, 4, 4, 8, 6, 8, 6, 7, 8, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.483, 0.956]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 47 | True: 47
Pred: 71 | True: 64
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] deliver on the promises [SEP] [SEP] and and
Target: [CLS] deliver on the promises [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.4166
Generation Loss: 0.0093
Total Loss: 33.4260
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0094
Train Epoch: 61 [0/334 (0%)] Loss: 33.425968
Train Epoch: 61 [64/334 (19%)] Loss: 19.417912
Train Epoch: 61 [128/334 (38%)] Loss: 43.523815
Train Epoch: 61 [192/334 (57%)] Loss: 38.398857
Train Epoch: 61 [256/334 (77%)] Loss: 18.843477
[2025-01-21 11:54:36] Starting validation for epoch: 61

Generation Samples:
Topic 59:
Generated: [CLS] stabilize joseph caught mild ludwig coined c excited [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] nomination crore boxes systems islander admit politically telling [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 36:
Generated: [CLS] iaaf nouveau pretend liar alphabet opinion reef language [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 61 [0/10 (0%)] Loss: 33.481152

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 41, 42, 43, 44, 46, 49, 52, 55, 60, 61, 63, 65, 66, 70, 73]
Input sequence lengths: [159, 209, 512, 512, 512, 512, 512, 512, 512, 236, 512, 512, 512, 512, 512, 125, 356, 512, 512, 512, 123, 512, 512, 512, 512, 512, 512, 125, 512, 512, 512, 512]
Target phrase lengths: [4, 4, 6, 6, 7, 5, 6, 8, 5, 7, 7, 5, 4, 7, 5, 6, 5, 8, 6, 6, 8, 4, 5, 5, 6, 5, 8, 5, 5, 5, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.472, 0.993]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 61 | True: 61
Pred: 73 | True: 73
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] public service [SEP] [SEP] [PAD] [SEP] [SEP] [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 37.2334
Generation Loss: 0.0074
Total Loss: 37.2408
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0075
Train Epoch: 62 [0/334 (0%)] Loss: 37.240822
Train Epoch: 62 [64/334 (19%)] Loss: 45.857197
Train Epoch: 62 [128/334 (38%)] Loss: 36.278831
Train Epoch: 62 [192/334 (57%)] Loss: 26.669014
Train Epoch: 62 [256/334 (77%)] Loss: 20.435690
[2025-01-21 11:54:40] Starting validation for epoch: 62

Generation Samples:
Topic 41:
Generated: [CLS] helmut fra abraham did borrowing watery versatile editing [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] parasitic hurry moves flies gypsy flying tension dragon [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 52:
Generated: [CLS] martial structurally fictional java soundtrack johansson sec mysteriously [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 62 [0/10 (0%)] Loss: 34.129501

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 39, 40, 41, 43, 44, 49, 51, 53, 57, 59, 60, 65, 66, 69, 70, 72]
Input sequence lengths: [512, 258, 512, 64, 453, 512, 512, 512, 268, 236, 485, 92, 512, 512, 334, 366, 512, 512, 512, 258, 121, 125, 512, 125, 78, 512, 388, 512, 91, 91, 512, 512]
Target phrase lengths: [4, 4, 6, 8, 7, 8, 4, 4, 8, 8, 8, 7, 8, 6, 6, 5, 5, 6, 8, 6, 7, 5, 7, 8, 7, 6, 3, 7, 4, 6, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.510, 0.974]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 40
Pred: 38 | True: 38
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] sacrificed for [SEP] and their and and and
Target: [CLS] sacrificed for [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.2060
Generation Loss: 0.0061
Total Loss: 33.2121
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0062
Train Epoch: 63 [0/334 (0%)] Loss: 33.212109
Train Epoch: 63 [64/334 (19%)] Loss: 31.103201
Train Epoch: 63 [128/334 (38%)] Loss: 38.309620
Train Epoch: 63 [192/334 (57%)] Loss: 31.495596
Train Epoch: 63 [256/334 (77%)] Loss: 35.199364
[2025-01-21 11:54:44] Starting validation for epoch: 63

Generation Samples:
Topic 46:
Generated: [CLS] fired kernel semantic choral language t lightning leafs [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] gemini keys jelly passage hopping anglia mohawk madhya [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] churches multi pearl permanent palm anarchy shell fk [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 63 [0/10 (0%)] Loss: 41.614220

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 41, 43, 44, 47, 50, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 70]
Input sequence lengths: [123, 123, 512, 512, 512, 485, 236, 449, 512, 512, 512, 204, 512, 512, 268, 512, 204, 512, 512, 512, 453, 236, 512, 512, 356, 512, 512, 512, 87, 234, 512, 485]
Target phrase lengths: [7, 8, 8, 8, 8, 8, 5, 5, 6, 6, 4, 8, 4, 6, 8, 4, 5, 8, 8, 8, 7, 8, 8, 6, 4, 6, 7, 4, 8, 7, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.533, 0.979]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 43 | True: 43
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] majority of the votes cast [SEP] [SEP] [SEP]
Target: [CLS] majority of the votes cast [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.4187
Generation Loss: 0.0091
Total Loss: 23.4278
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0092
Train Epoch: 64 [0/334 (0%)] Loss: 23.427814
Train Epoch: 64 [64/334 (19%)] Loss: 36.718105
Train Epoch: 64 [128/334 (38%)] Loss: 34.493759
Train Epoch: 64 [192/334 (57%)] Loss: 22.219530
Train Epoch: 64 [256/334 (77%)] Loss: 30.039713
[2025-01-21 11:54:48] Starting validation for epoch: 64

Generation Samples:
Topic 64:
Generated: [CLS] euroleague pandit hell drastic contractor def module chop [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 61:
Generated: [CLS] rosen java raft objections puppet rose sci 198 [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] bucks configured phil mundo ropes adler arrogant equipment [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 64 [0/10 (0%)] Loss: 26.646872

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 41, 42, 43, 46, 47, 49, 53, 55, 59, 60, 61, 62, 64, 66, 67, 69, 72]
Input sequence lengths: [512, 234, 258, 512, 512, 388, 512, 512, 512, 334, 512, 453, 512, 512, 366, 512, 159, 91, 512, 512, 453, 125, 512, 512, 87, 512, 388, 512, 512, 512, 356, 512]
Target phrase lengths: [6, 8, 4, 5, 8, 8, 8, 5, 5, 4, 6, 7, 6, 4, 6, 4, 5, 4, 7, 5, 8, 5, 7, 6, 6, 5, 4, 6, 8, 6, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.593, 0.959]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 68 | True: 37
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] and and [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.0732
Generation Loss: 0.0058
Total Loss: 32.0790
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0059
Train Epoch: 65 [0/334 (0%)] Loss: 32.079029
Train Epoch: 65 [64/334 (19%)] Loss: 26.228325
Train Epoch: 65 [128/334 (38%)] Loss: 31.546795
Train Epoch: 65 [192/334 (57%)] Loss: 21.883438
Train Epoch: 65 [256/334 (77%)] Loss: 30.915144
[2025-01-21 11:54:52] Starting validation for epoch: 65

Generation Samples:
Topic 41:
Generated: [CLS] hodgson flew fortune invited subway amendment [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] interpretations faction resources ideological commonplace order [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] rotherham amend nomination alejandro language official [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 65 [0/10 (0%)] Loss: 39.123116

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 47, 49, 50, 51, 55, 59, 60, 63, 65, 66, 67, 70, 73]
Input sequence lengths: [512, 512, 366, 512, 512, 512, 512, 512, 64, 512, 512, 512, 512, 366, 512, 123, 145, 356, 92, 209, 512, 512, 512, 125, 123, 236, 512, 512, 125, 121, 356, 512]
Target phrase lengths: [7, 5, 7, 6, 4, 7, 7, 8, 8, 5, 5, 5, 5, 6, 5, 7, 6, 4, 6, 4, 6, 8, 8, 6, 8, 8, 5, 3, 4, 6, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.575, 0.988]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 66
Pred: 49 | True: 49
Pred: 59 | True: 59

Phrase Generation Sample:
Generated: [CLS] return to normal operating procedures [SEP] [SEP] [SEP]
Target: [CLS] return to normal operating procedures [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 18.1850
Generation Loss: 0.0063
Total Loss: 18.1913
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0063
Train Epoch: 66 [0/334 (0%)] Loss: 18.191265
Train Epoch: 66 [64/334 (19%)] Loss: 36.609650
Train Epoch: 66 [128/334 (38%)] Loss: 50.377735
Train Epoch: 66 [192/334 (57%)] Loss: 18.064823
Train Epoch: 66 [256/334 (77%)] Loss: 27.257244
[2025-01-21 11:55:01] Starting validation for epoch: 66

Generation Samples:
Topic 51:
Generated: [CLS] invested passports uneasy seo steven music big system [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 61:
Generated: [CLS] minnesota rourke jet algebra itf concacaf invade bryan [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] substitution wingspan intend governmental gut nomination 1841 money [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 66 [0/10 (0%)] Loss: 58.363682

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 40, 41, 42, 43, 45, 46, 47, 49, 51, 53, 54, 55, 59, 60, 61, 62, 64, 65, 71, 72]
Input sequence lengths: [512, 449, 512, 512, 512, 512, 512, 453, 78, 512, 91, 125, 512, 159, 512, 87, 512, 334, 356, 512, 356, 234, 366, 512, 512, 512, 453, 512, 512, 512, 512, 512]
Target phrase lengths: [7, 4, 4, 6, 8, 5, 5, 7, 7, 8, 4, 6, 4, 5, 5, 8, 4, 6, 4, 8, 4, 4, 5, 5, 6, 8, 8, 8, 4, 7, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.551, 0.979]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 45 | True: 71
Pred: 45 | True: 45

Phrase Generation Sample:
Generated: [CLS] fight for the american dream [SEP] [SEP] [SEP]
Target: [CLS] fight for the american dream [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 42.5002
Generation Loss: 0.0065
Total Loss: 42.5066
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0065
Train Epoch: 67 [0/334 (0%)] Loss: 42.506630
Train Epoch: 67 [64/334 (19%)] Loss: 29.035912
Train Epoch: 67 [128/334 (38%)] Loss: 31.322199
Train Epoch: 67 [192/334 (57%)] Loss: 21.200342
Train Epoch: 67 [256/334 (77%)] Loss: 27.076706
[2025-01-21 11:55:05] Starting validation for epoch: 67

Generation Samples:
Topic 38:
Generated: [CLS] kern maryland hasty sue bayou subdivision furnishings dial [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] cages mexico reds bucks bottles clown card crossed [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] deborah swelling additions killer natural foreign dough kant [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 67 [0/10 (0%)] Loss: 40.849289

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 41, 43, 45, 48, 51, 53, 54, 56, 57, 58, 60, 63, 66, 67, 69, 73]
Input sequence lengths: [453, 268, 449, 125, 388, 512, 512, 512, 334, 209, 125, 512, 81, 123, 485, 145, 512, 512, 512, 512, 123, 512, 512, 512, 512, 92, 512, 485, 512, 512, 512, 512]
Target phrase lengths: [8, 8, 7, 5, 8, 7, 5, 5, 4, 7, 4, 7, 8, 8, 7, 8, 4, 6, 5, 4, 8, 8, 5, 8, 6, 6, 4, 5, 6, 6, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.487, 0.989]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 41 | True: 41
Pred: 56 | True: 56

Phrase Generation Sample:
Generated: [CLS] elect a speaker who stands with [SEP] [SEP]
Target: [CLS] elect a speaker who stands with [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 47.1442
Generation Loss: 0.0057
Total Loss: 47.1499
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0057
Train Epoch: 68 [0/334 (0%)] Loss: 47.149948
Train Epoch: 68 [64/334 (19%)] Loss: 45.621189
Train Epoch: 68 [128/334 (38%)] Loss: 37.707878
Train Epoch: 68 [192/334 (57%)] Loss: 19.391905
Train Epoch: 68 [256/334 (77%)] Loss: 32.786995
[2025-01-21 11:55:09] Starting validation for epoch: 68

Generation Samples:
Topic 43:
Generated: [CLS] alfredo fundamentally darius wore pitchers christians republican rules [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] libraries birmingham named isaac java bose cleveland avery [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] bucks nj textual chooses solved words naming wing [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 68 [0/10 (0%)] Loss: 36.925858

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 43, 44, 46, 50, 51, 54, 56, 57, 58, 59, 60, 65, 67, 68, 70, 71]
Input sequence lengths: [453, 512, 512, 236, 449, 236, 453, 125, 512, 204, 453, 512, 512, 512, 137, 512, 512, 121, 92, 449, 512, 366, 512, 512, 512, 512, 512, 137, 512, 125, 512, 485]
Target phrase lengths: [7, 6, 7, 5, 5, 7, 8, 6, 6, 8, 5, 6, 4, 4, 4, 4, 4, 5, 5, 4, 5, 3, 5, 5, 5, 4, 5, 7, 5, 5, 8, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.493, 0.981]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 46 | True: 46
Pred: 50 | True: 50

Phrase Generation Sample:
Generated: [CLS] house democrats will stand together [SEP] [SEP] [SEP]
Target: [CLS] house democrats will stand together [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.9593
Generation Loss: 0.0063
Total Loss: 25.9657
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0064
Train Epoch: 69 [0/334 (0%)] Loss: 25.965675
Train Epoch: 69 [64/334 (19%)] Loss: 32.495579
Train Epoch: 69 [128/334 (38%)] Loss: 32.596348
Train Epoch: 69 [192/334 (57%)] Loss: 46.391403
Train Epoch: 69 [256/334 (77%)] Loss: 33.275951
[2025-01-21 11:55:13] Starting validation for epoch: 69

Generation Samples:
Topic 59:
Generated: [CLS] yucatan dom puck handled kan intentionally oaxaca [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] stemming wants branches de dealing daniels aviv [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 46:
Generated: [CLS] joints suggest ale fra greek rings greet [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 69 [0/10 (0%)] Loss: 36.348896

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 42, 43, 44, 46, 51, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71]
Input sequence lengths: [512, 512, 512, 87, 512, 485, 125, 512, 512, 512, 121, 159, 512, 449, 366, 92, 512, 204, 512, 512, 512, 512, 512, 512, 453, 512, 449, 512, 268, 388, 512, 236]
Target phrase lengths: [8, 6, 7, 8, 8, 8, 6, 4, 5, 8, 7, 5, 5, 7, 5, 5, 5, 6, 8, 7, 6, 4, 5, 4, 5, 7, 4, 4, 8, 3, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.460, 1.024]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 65 | True: 65
Pred: 40 | True: 40
Pred: 42 | True: 42

Phrase Generation Sample:
Generated: [CLS] extremist maga faction [SEP] and
Target: [CLS] extremist maga faction [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.9020
Generation Loss: 0.0055
Total Loss: 29.9075
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0055
Train Epoch: 70 [0/334 (0%)] Loss: 29.907497
Train Epoch: 70 [64/334 (19%)] Loss: 34.475018
Train Epoch: 70 [128/334 (38%)] Loss: 21.890461
Train Epoch: 70 [192/334 (57%)] Loss: 48.211346
Train Epoch: 70 [256/334 (77%)] Loss: 27.728607
[2025-01-21 11:55:16] Starting validation for epoch: 70

Generation Samples:
Topic 58:
Generated: [CLS] workings pun minds agree wing zip hesse drug [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] serbia wyoming beats denies michigan empire republican lets [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] 1716 psychedelic pardon eccentric mathematician tradition wrexham jew [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 70 [0/10 (0%)] Loss: 44.624809

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 41, 42, 43, 44, 45, 46, 47, 53, 54, 58, 60, 62, 64, 65, 66, 67, 69, 70]
Input sequence lengths: [512, 512, 512, 512, 125, 512, 234, 236, 334, 388, 87, 512, 512, 512, 512, 512, 334, 125, 234, 512, 388, 512, 236, 512, 512, 512, 512, 334, 512, 512, 512, 512]
Target phrase lengths: [5, 4, 5, 8, 7, 7, 8, 8, 6, 4, 6, 4, 6, 5, 8, 8, 4, 6, 7, 6, 3, 5, 6, 8, 5, 5, 5, 6, 5, 7, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.518, 1.023]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 45 | True: 45
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] commitment to excellence [SEP] [SEP] [SEP] and [SEP]
Target: [CLS] commitment to excellence [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 18.1668
Generation Loss: 0.0051
Total Loss: 18.1719
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.0051
Train Epoch: 71 [0/334 (0%)] Loss: 18.171862
Train Epoch: 71 [64/334 (19%)] Loss: 35.922543
Train Epoch: 71 [128/334 (38%)] Loss: 32.701294
Train Epoch: 71 [192/334 (57%)] Loss: 26.104677
Train Epoch: 71 [256/334 (77%)] Loss: 48.020969
[2025-01-21 11:55:31] Starting validation for epoch: 71

Generation Samples:
Topic 73:
Generated: [CLS] india union christians cuban housing gorge abstracts nt [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] dictator radically bombings suffix transmitter torn edwin addicted [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] organs disgusted nielsen humor conjunction dakota joshi dot [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 71 [0/10 (0%)] Loss: 33.039845

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 41, 43, 44, 49, 50, 51, 54, 55, 60, 61, 62, 64, 66, 70]
Input sequence lengths: [356, 159, 258, 512, 78, 512, 512, 512, 512, 512, 145, 512, 268, 512, 453, 512, 512, 512, 512, 125, 125, 512, 512, 87, 512, 87, 512, 512, 512, 125, 236, 512]
Target phrase lengths: [5, 7, 4, 4, 5, 8, 8, 8, 6, 5, 7, 6, 8, 6, 7, 5, 8, 8, 6, 7, 6, 4, 5, 6, 6, 8, 4, 7, 8, 7, 8, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.463, 0.970]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 55 | True: 55
Pred: 61 | True: 61
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] local economic development [SEP] [SEP] and [SEP] [SEP]
Target: [CLS] local economic development [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.2465
Generation Loss: 0.0060
Total Loss: 34.2525
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0061
Train Epoch: 72 [0/334 (0%)] Loss: 34.252514
Train Epoch: 72 [64/334 (19%)] Loss: 24.462807
Train Epoch: 72 [128/334 (38%)] Loss: 31.976091
Train Epoch: 72 [192/334 (57%)] Loss: 35.900700
Train Epoch: 72 [256/334 (77%)] Loss: 29.098705
[2025-01-21 11:55:35] Starting validation for epoch: 72

Generation Samples:
Topic 61:
Generated: [CLS] czech founding jet peoples weapons breed labeled dna [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] churches phillies mint boxing greek clause india cohen [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] oppression democrat unconstitutional php mustafa republicans assigned karma [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Validation Epoch: 72 [0/10 (0%)] Loss: 26.152214

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 44, 46, 48, 49, 50, 51, 53, 54, 55, 58, 60, 64, 67, 68, 70, 73]
Input sequence lengths: [121, 125, 92, 512, 512, 121, 512, 125, 334, 258, 123, 209, 512, 512, 356, 512, 356, 512, 512, 236, 123, 512, 512, 512, 512, 125, 512, 512, 204, 356, 81, 268]
Target phrase lengths: [4, 6, 7, 5, 6, 5, 6, 6, 4, 6, 8, 7, 5, 8, 3, 6, 4, 8, 4, 8, 4, 4, 5, 3, 5, 6, 6, 8, 5, 5, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.490, 1.025]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 39
Pred: 43 | True: 43
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] votes cast [SEP] [SEP] [SEP] [SEP] and and
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 43.5140
Generation Loss: 0.0045
Total Loss: 43.5185
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0045
Train Epoch: 73 [0/334 (0%)] Loss: 43.518520
Train Epoch: 73 [64/334 (19%)] Loss: 30.548649
Train Epoch: 73 [128/334 (38%)] Loss: 36.612232
Train Epoch: 73 [192/334 (57%)] Loss: 33.811127
Train Epoch: 73 [256/334 (77%)] Loss: 30.139685
[2025-01-21 11:55:39] Starting validation for epoch: 73

Generation Samples:
Topic 52:
Generated: [CLS] graceful wildly atheist myers refining they philips def [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] knew autonomy connections linux formerly news spirituality missouri [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] county mlb musicians mis box settlers norse talents [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 73 [0/10 (0%)] Loss: 26.546345

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 43, 47, 48, 51, 52, 53, 54, 55, 57, 58, 60, 65, 66, 68, 73]
Input sequence lengths: [512, 512, 121, 512, 125, 512, 512, 485, 512, 81, 204, 512, 512, 123, 512, 334, 209, 356, 453, 356, 512, 512, 485, 512, 78, 512, 512, 512, 125, 512, 356, 258]
Target phrase lengths: [5, 6, 5, 4, 6, 5, 7, 5, 6, 5, 8, 8, 6, 7, 6, 7, 4, 4, 7, 4, 6, 8, 8, 4, 5, 8, 4, 5, 6, 6, 3, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.513, 1.035]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 52 | True: 52
Pred: 44 | True: 47
Pred: 39 | True: 39

Phrase Generation Sample:
Generated: [CLS] dedicated conservationist [SEP] [SEP] [SEP] [SEP] and
Target: [CLS] dedicated conservationist [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.4473
Generation Loss: 0.0053
Total Loss: 34.4526
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0053
Train Epoch: 74 [0/334 (0%)] Loss: 34.452583
Train Epoch: 74 [64/334 (19%)] Loss: 29.901970
Train Epoch: 74 [128/334 (38%)] Loss: 17.957777
Train Epoch: 74 [192/334 (57%)] Loss: 33.478016
Train Epoch: 74 [256/334 (77%)] Loss: 31.272430
[2025-01-21 11:55:43] Starting validation for epoch: 74

Generation Samples:
Topic 66:
Generated: [CLS] commanded transactions chambers spring a decisions industrialist card [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] rosen medicare phillies intentions friedrich soul contemplating independence [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] fleming keyboards ravi the the liv deal mills [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Validation Epoch: 74 [0/10 (0%)] Loss: 19.224949

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 41, 43, 45, 46, 47, 49, 51, 54, 60, 64, 65, 66, 67, 69, 70, 71, 72]
Input sequence lengths: [512, 512, 512, 91, 512, 512, 512, 512, 512, 512, 388, 449, 453, 512, 78, 512, 512, 236, 512, 64, 512, 512, 512, 512, 512, 268, 512, 512, 512, 449, 512, 137]
Target phrase lengths: [4, 8, 4, 4, 8, 4, 5, 8, 6, 6, 3, 7, 8, 5, 7, 7, 5, 8, 5, 8, 3, 6, 6, 8, 3, 8, 4, 6, 5, 4, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.496, 1.021]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 45 | True: 45
Pred: 60 | True: 60
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] equal representation [SEP] [SEP] [SEP] [SEP] and and
Target: [CLS] equal representation [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.3341
Generation Loss: 0.0060
Total Loss: 33.3401
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0060
Train Epoch: 75 [0/334 (0%)] Loss: 33.340054
Train Epoch: 75 [64/334 (19%)] Loss: 37.475060
Train Epoch: 75 [128/334 (38%)] Loss: 26.936628
Train Epoch: 75 [192/334 (57%)] Loss: 42.767128
Train Epoch: 75 [256/334 (77%)] Loss: 41.135674
[2025-01-21 11:55:47] Starting validation for epoch: 75

Generation Samples:
Topic 52:
Generated: [CLS] logistical cherokee herzegovina myers intentions transplant lightning serves [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] did money x j gig additional ny rand [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] xander weapon det and communist gun viking zen [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 75 [0/10 (0%)] Loss: 44.293034

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 41, 42, 43, 44, 47, 48, 50, 52, 53, 54, 55, 56, 58, 60, 61, 64, 67, 69]
Input sequence lengths: [512, 512, 453, 512, 159, 512, 512, 512, 125, 512, 512, 512, 512, 258, 512, 512, 388, 512, 258, 512, 512, 512, 512, 123, 81, 512, 512, 125, 356, 334, 512, 449]
Target phrase lengths: [6, 5, 5, 7, 4, 8, 8, 8, 5, 4, 6, 8, 6, 4, 4, 4, 8, 5, 4, 6, 6, 7, 6, 8, 6, 4, 5, 8, 4, 7, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.507, 1.012]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 40 | True: 40
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] republican commitment to america [SEP] [SEP] [SEP] and
Target: [CLS] republican commitment to america [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.1814
Generation Loss: 0.0056
Total Loss: 32.1870
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0056
Train Epoch: 76 [0/334 (0%)] Loss: 32.187023
Train Epoch: 76 [64/334 (19%)] Loss: 29.768095
Train Epoch: 76 [128/334 (38%)] Loss: 39.944473
Train Epoch: 76 [192/334 (57%)] Loss: 27.508821
Train Epoch: 76 [256/334 (77%)] Loss: 25.193905
[2025-01-21 11:55:56] Starting validation for epoch: 76

Generation Samples:
Topic 52:
Generated: [CLS] knowles classification allegiance goin constitution rim bryan [unused706] [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 64:
Generated: [CLS] funding affiliation mexico foliage phi plant truss electronics [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 55:
Generated: [CLS] mana membership acquiring accommodations shea kai vocabulary plant [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 76 [0/10 (0%)] Loss: 25.075491

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 37, 38, 40, 41, 43, 44, 45, 46, 49, 51, 53, 54, 55, 56, 59, 61, 62, 63, 64, 66, 67, 71, 73]
Input sequence lengths: [449, 512, 449, 258, 366, 512, 512, 145, 512, 512, 512, 512, 512, 512, 512, 512, 356, 87, 87, 512, 123, 209, 159, 234, 512, 145, 512, 512, 78, 512, 512, 334]
Target phrase lengths: [4, 5, 7, 6, 3, 4, 7, 8, 5, 4, 5, 4, 4, 7, 4, 4, 4, 6, 8, 6, 7, 7, 7, 4, 4, 8, 5, 6, 7, 8, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.506, 1.048]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 71 | True: 71
Pred: 64 | True: 66
Pred: 56 | True: 56

Phrase Generation Sample:
Generated: [CLS] legislative reform [SEP] [SEP] and [SEP] and and
Target: [CLS] legislative reform [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.7679
Generation Loss: 0.0046
Total Loss: 34.7725
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0047
Train Epoch: 77 [0/334 (0%)] Loss: 34.772495
Train Epoch: 77 [64/334 (19%)] Loss: 30.483482
Train Epoch: 77 [128/334 (38%)] Loss: 25.213995
Train Epoch: 77 [192/334 (57%)] Loss: 35.578514
Train Epoch: 77 [256/334 (77%)] Loss: 16.446428
[2025-01-21 11:56:00] Starting validation for epoch: 77

Generation Samples:
Topic 61:
Generated: [CLS] bulls computers freddie hall defines containers vikings organ [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] christ coli throat rayon monetary liquor hamlet guy [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 38:
Generated: [CLS] hack snuck christians ashok wedge speak gr republican [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 77 [0/10 (0%)] Loss: 24.724806

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 40, 41, 43, 45, 47, 50, 52, 53, 54, 55, 56, 59, 60, 63, 65, 67, 69]
Input sequence lengths: [512, 366, 123, 512, 388, 512, 123, 512, 512, 125, 512, 512, 512, 137, 356, 512, 356, 123, 512, 234, 512, 512, 449, 512, 512, 334, 512, 125, 512, 512, 512, 512]
Target phrase lengths: [7, 6, 4, 7, 8, 5, 8, 5, 4, 7, 8, 6, 4, 4, 4, 8, 5, 7, 6, 7, 5, 5, 4, 8, 8, 7, 5, 7, 8, 4, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.489, 1.038]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 67 | True: 67
Pred: 39 | True: 59
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] additional funding for administrative activities [SEP] [SEP] platform
Target: [CLS] additional funding for administrative activities [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.4534
Generation Loss: 0.0041
Total Loss: 38.4576
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0042
Train Epoch: 78 [0/334 (0%)] Loss: 38.457577
Train Epoch: 78 [64/334 (19%)] Loss: 24.337132
Train Epoch: 78 [128/334 (38%)] Loss: 32.329811
Train Epoch: 78 [192/334 (57%)] Loss: 27.527573
Train Epoch: 78 [256/334 (77%)] Loss: 37.528004
[2025-01-21 11:56:04] Starting validation for epoch: 78

Generation Samples:
Topic 73:
Generated: [CLS] guessing java name rings [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] ports sacrificed bismarck marrying [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] alcohol admit enterprise socially [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 78 [0/10 (0%)] Loss: 41.875847

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 59, 60, 65, 66, 67, 68, 69]
Input sequence lengths: [512, 121, 81, 512, 121, 512, 512, 366, 512, 512, 512, 334, 234, 512, 512, 512, 388, 512, 512, 204, 512, 512, 512, 512, 512, 453, 453, 512, 145, 512, 204, 123]
Target phrase lengths: [4, 4, 6, 6, 4, 8, 8, 7, 7, 4, 5, 8, 4, 7, 6, 5, 8, 8, 7, 8, 4, 5, 6, 6, 6, 5, 7, 6, 6, 5, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.497, 1.033]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 52 | True: 52
Pred: 39 | True: 39
Pred: 73 | True: 48

Phrase Generation Sample:
Generated: [CLS] exceptional service [SEP] [SEP] and and and [SEP]
Target: [CLS] exceptional service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 28.7879
Generation Loss: 0.0040
Total Loss: 28.7919
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0040
Train Epoch: 79 [0/334 (0%)] Loss: 28.791864
Train Epoch: 79 [64/334 (19%)] Loss: 35.512558
Train Epoch: 79 [128/334 (38%)] Loss: 23.815126
Train Epoch: 79 [192/334 (57%)] Loss: 37.596340
Train Epoch: 79 [256/334 (77%)] Loss: 33.627518
[2025-01-21 11:56:07] Starting validation for epoch: 79

Generation Samples:
Topic 44:
Generated: [CLS] republic torah butterfly mongolia raiders shipment genome republican [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] economical ties snake sentiment rossi monroe ether oak [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 45:
Generated: [CLS] uefa contiguous mainz slave and ministers stuffing bengals [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 79 [0/10 (0%)] Loss: 37.923191

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 40, 41, 43, 45, 47, 49, 51, 54, 55, 57, 58, 59, 60, 61, 66, 68, 69, 71, 73]
Input sequence lengths: [234, 512, 512, 204, 512, 366, 512, 512, 356, 78, 145, 453, 92, 512, 512, 512, 159, 512, 512, 366, 512, 512, 512, 356, 125, 449, 209, 388, 485, 234, 209, 512]
Target phrase lengths: [8, 4, 6, 8, 5, 5, 5, 5, 4, 6, 7, 7, 5, 3, 4, 8, 4, 6, 6, 3, 6, 4, 8, 4, 7, 4, 4, 4, 8, 7, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.474, 1.060]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 37 | True: 37
Pred: 66 | True: 66
Pred: 60 | True: 60

Phrase Generation Sample:
Generated: [CLS] john lewis voting rights advancement act [SEP] and
Target: [CLS] john lewis voting rights advancement act [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 20.6400
Generation Loss: 0.0042
Total Loss: 20.6442
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0042
Train Epoch: 80 [0/334 (0%)] Loss: 20.644213
Train Epoch: 80 [64/334 (19%)] Loss: 30.611357
Train Epoch: 80 [128/334 (38%)] Loss: 28.795828
Train Epoch: 80 [192/334 (57%)] Loss: 25.427149
Train Epoch: 80 [256/334 (77%)] Loss: 35.586777
[2025-01-21 11:56:11] Starting validation for epoch: 80

Generation Samples:
Topic 40:
Generated: [CLS] explorers aboard weasel wheels funding invitation wingspan spirituality [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] guiana oleg gregor denied funded wentworth snyder riches [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] whip accountability expands crippled holland daytona plans timing [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 80 [0/10 (0%)] Loss: 30.707069

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [38, 40, 41, 43, 44, 46, 49, 51, 52, 54, 55, 58, 60, 61, 62, 64, 65, 66, 69, 73]
Input sequence lengths: [123, 512, 512, 87, 92, 512, 512, 512, 125, 512, 512, 512, 209, 512, 78, 512, 388, 159, 159, 512, 512, 512, 159, 512, 356, 268, 512, 512, 512, 512, 512, 512]
Target phrase lengths: [8, 6, 7, 8, 5, 5, 5, 5, 5, 5, 6, 5, 4, 5, 6, 4, 3, 4, 5, 7, 5, 6, 4, 4, 4, 8, 6, 4, 4, 8, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.558, 1.038]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 65 | True: 65
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] byron donalds of the state [SEP] [SEP]
Target: [CLS] byron donalds of the state [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 28.0553
Generation Loss: 0.0045
Total Loss: 28.0597
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0045
Train Epoch: 81 [0/334 (0%)] Loss: 28.059750
Train Epoch: 81 [64/334 (19%)] Loss: 25.839510
Train Epoch: 81 [128/334 (38%)] Loss: 43.859711
Train Epoch: 81 [192/334 (57%)] Loss: 39.305878
Train Epoch: 81 [256/334 (77%)] Loss: 26.093746
[2025-01-21 11:56:21] Starting validation for epoch: 81

Generation Samples:
Topic 45:
Generated: [CLS] burned croatia derivatives brightened governments nomination fund developers [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] tak neutron bargaining ashok turtle airplane wings drummer [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] input michael mongolia authority sound chaos and morgan [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 81 [0/10 (0%)] Loss: 28.146652

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 60, 62, 65, 66, 67, 70]
Input sequence lengths: [512, 81, 512, 236, 512, 87, 512, 268, 92, 512, 512, 512, 512, 512, 512, 512, 512, 334, 512, 123, 125, 137, 512, 512, 125, 512, 512, 512, 512, 356, 125, 512]
Target phrase lengths: [4, 5, 6, 8, 5, 6, 4, 8, 5, 6, 7, 6, 5, 4, 5, 4, 5, 6, 8, 8, 7, 4, 7, 6, 7, 4, 6, 4, 4, 4, 5, 3]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.508, 1.018]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 46 | True: 46
Pred: 48 | True: 48
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] equal representation [SEP] [SEP] and [SEP] and [SEP]
Target: [CLS] equal representation [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 46.5945
Generation Loss: 0.0050
Total Loss: 46.5994
Topic Prediction Accuracy: 0.6875
Generation Perplexity: 1.0050
Train Epoch: 82 [0/334 (0%)] Loss: 46.599426
Train Epoch: 82 [64/334 (19%)] Loss: 42.152157
Train Epoch: 82 [128/334 (38%)] Loss: 38.178757
Train Epoch: 82 [192/334 (57%)] Loss: 17.603481
Train Epoch: 82 [256/334 (77%)] Loss: 30.859255
[2025-01-21 11:56:24] Starting validation for epoch: 82

Generation Samples:
Topic 36:
Generated: [CLS] masonic phil vegas tiberius garry alam caps unrelated [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] airplane equipment kidding stomped anders outfielder dodged splits [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] blizzard missiles unexpected oscar grace chi tomas sri [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 82 [0/10 (0%)] Loss: 28.892630

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [37, 38, 39, 40, 41, 43, 47, 49, 53, 55, 58, 59, 60, 62, 64, 66, 67, 69]
Input sequence lengths: [356, 512, 512, 512, 258, 512, 512, 388, 366, 453, 123, 512, 512, 87, 512, 512, 125, 512, 123, 512, 512, 258, 234, 87, 453, 512, 512, 121, 512, 356, 334, 512]
Target phrase lengths: [3, 8, 5, 5, 6, 4, 6, 4, 3, 5, 8, 8, 8, 8, 6, 4, 6, 7, 7, 8, 5, 4, 7, 6, 8, 7, 8, 6, 4, 4, 7, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.462, 1.034]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 67 | True: 55
Pred: 64 | True: 64
Pred: 49 | True: 49

Phrase Generation Sample:
Generated: [CLS] funding [SEP] [SEP]. [SEP] and and and
Target: [CLS] funding [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.1915
Generation Loss: 0.0050
Total Loss: 36.1966
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0051
Train Epoch: 83 [0/334 (0%)] Loss: 36.196568
Train Epoch: 83 [64/334 (19%)] Loss: 42.778099
Train Epoch: 83 [128/334 (38%)] Loss: 47.639664
Train Epoch: 83 [192/334 (57%)] Loss: 17.291731
Train Epoch: 83 [256/334 (77%)] Loss: 30.422522
[2025-01-21 11:56:28] Starting validation for epoch: 83

Generation Samples:
Topic 46:
Generated: [CLS] mundo rings naming acts admissions amadeus passing engineer [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] glove keys officially norse personalities authorization oleg j [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] programs disagreed knows words j heath england tom [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 83 [0/10 (0%)] Loss: 39.728577

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 41, 43, 44, 47, 51, 54, 56, 60, 61, 63, 64, 65, 66, 68, 69, 71, 72]
Input sequence lengths: [145, 512, 125, 512, 449, 512, 125, 512, 512, 512, 92, 258, 91, 512, 512, 512, 512, 512, 512, 449, 512, 453, 125, 204, 159, 159, 512, 512, 512, 204, 512, 388]
Target phrase lengths: [7, 6, 8, 8, 7, 5, 4, 6, 8, 5, 5, 4, 4, 8, 4, 8, 7, 6, 7, 5, 8, 7, 6, 5, 7, 5, 5, 6, 5, 8, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.495, 1.032]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 35 | True: 35
Pred: 36 | True: 36
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] preserve order and decorum [SEP] and and
Target: [CLS] preserve order and decorum [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 24.8872
Generation Loss: 0.0058
Total Loss: 24.8930
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0058
Train Epoch: 84 [0/334 (0%)] Loss: 24.893019
Train Epoch: 84 [64/334 (19%)] Loss: 23.185810
Train Epoch: 84 [128/334 (38%)] Loss: 30.568228
Train Epoch: 84 [192/334 (57%)] Loss: 26.642878
Train Epoch: 84 [256/334 (77%)] Loss: 30.750576
[2025-01-21 11:56:32] Starting validation for epoch: 84

Generation Samples:
Topic 44:
Generated: [CLS] algebraic abilities greece about [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] privatization broad magic licking [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] to fujian naming treasurer [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 84 [0/10 (0%)] Loss: 50.245480

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 39, 40, 41, 44, 45, 47, 52, 54, 56, 58, 59, 60, 63, 64, 68, 70]
Input sequence lengths: [234, 234, 512, 145, 512, 512, 512, 512, 512, 204, 512, 512, 366, 512, 121, 512, 512, 512, 512, 145, 512, 268, 449, 512, 236, 512, 121, 512, 512, 512, 512, 449]
Target phrase lengths: [7, 4, 4, 7, 4, 7, 3, 8, 5, 8, 6, 6, 5, 6, 5, 4, 5, 5, 8, 8, 4, 8, 4, 4, 8, 4, 4, 6, 5, 5, 3, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.565, 1.053]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 37 | True: 37
Pred: 37 | True: 37
Pred: 66 | True: 64

Phrase Generation Sample:
Generated: [CLS] protecting the right to vote [SEP] [SEP] [SEP]
Target: [CLS] protecting the right to vote [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 42.5606
Generation Loss: 0.0053
Total Loss: 42.5660
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0054
Train Epoch: 85 [0/334 (0%)] Loss: 42.565964
Train Epoch: 85 [64/334 (19%)] Loss: 36.154766
Train Epoch: 85 [128/334 (38%)] Loss: 35.695442
Train Epoch: 85 [192/334 (57%)] Loss: 33.641712
Train Epoch: 85 [256/334 (77%)] Loss: 31.229973
[2025-01-21 11:56:36] Starting validation for epoch: 85

Generation Samples:
Topic 55:
Generated: [CLS] freeing reservations statehood bryan intentionally lakes publishing headquartered [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] tariffs goethe gui helium rib tickets marc reasoning [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] congress delhi ellison handling move trusting unanimously packaged [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 85 [0/10 (0%)] Loss: 44.831264

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 41, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 59, 60, 61, 63, 64, 65, 66, 68, 69, 72, 73]
Input sequence lengths: [512, 512, 512, 512, 512, 366, 512, 512, 145, 334, 512, 512, 159, 125, 81, 81, 204, 512, 512, 512, 512, 512, 512, 125, 209, 356, 388, 512, 125, 512, 91, 512]
Target phrase lengths: [4, 4, 6, 5, 8, 3, 4, 6, 6, 8, 5, 3, 4, 6, 8, 6, 5, 5, 6, 4, 6, 7, 5, 5, 7, 4, 4, 8, 5, 5, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.499, 1.046]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 52 | True: 52
Pred: 60 | True: 60

Phrase Generation Sample:
Generated: [CLS] strong economy [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] strong economy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.5033
Generation Loss: 0.0045
Total Loss: 23.5078
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0045
Train Epoch: 86 [0/334 (0%)] Loss: 23.507833
Train Epoch: 86 [64/334 (19%)] Loss: 29.838108
Train Epoch: 86 [128/334 (38%)] Loss: 39.777596
Train Epoch: 86 [192/334 (57%)] Loss: 52.217167
Train Epoch: 86 [256/334 (77%)] Loss: 38.428783
[2025-01-21 11:56:45] Starting validation for epoch: 86

Generation Samples:
Topic 65:
Generated: [CLS] rene glove decorations greek missionaries havoc dragons phyllis [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 45:
Generated: [CLS] ale u merton eleanor merits medicare irregularities gaming [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] glamorgan rene aliens solve coinage [unused195] israel sleeps [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 86 [0/10 (0%)] Loss: 38.265465

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 39, 41, 43, 45, 46, 48, 54, 55, 59, 60, 61, 64, 65, 67, 69, 70]
Input sequence lengths: [121, 512, 388, 512, 512, 159, 512, 512, 512, 366, 512, 512, 236, 512, 125, 236, 121, 145, 125, 125, 356, 125, 145, 512, 512, 512, 81, 123, 125, 512, 453, 512]
Target phrase lengths: [4, 6, 8, 6, 6, 4, 8, 5, 6, 6, 8, 8, 8, 6, 5, 8, 4, 7, 7, 6, 4, 4, 8, 6, 7, 7, 8, 8, 6, 8, 7, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.497, 1.051]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 42 | True: 39
Pred: 64 | True: 46
Pred: 69 | True: 69

Phrase Generation Sample:
Generated: [CLS] votes cast [SEP] [SEP] [SEP] and [SEP] and
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 39.4533
Generation Loss: 0.0045
Total Loss: 39.4578
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0045
Train Epoch: 87 [0/334 (0%)] Loss: 39.457767
Train Epoch: 87 [64/334 (19%)] Loss: 32.246998
Train Epoch: 87 [128/334 (38%)] Loss: 25.957033
Train Epoch: 87 [192/334 (57%)] Loss: 28.165459
Train Epoch: 87 [256/334 (77%)] Loss: 36.331951
[2025-01-21 11:56:49] Starting validation for epoch: 87

Generation Samples:
Topic 73:
Generated: [CLS] creed static hands gaming state cell languages hands [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] nationalist creatures drunken phil behave fleming ty protestants [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] map socialists woodrow jong math passes hopes algebra [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 87 [0/10 (0%)] Loss: 33.469540

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 40, 41, 42, 43, 46, 47, 51, 52, 54, 55, 56, 59, 60, 65, 66, 71, 72]
Input sequence lengths: [449, 268, 512, 512, 356, 512, 449, 512, 91, 512, 512, 145, 125, 512, 449, 512, 512, 512, 512, 125, 512, 512, 512, 512, 512, 92, 64, 512, 268, 234, 366, 512]
Target phrase lengths: [5, 8, 4, 5, 3, 4, 4, 5, 4, 6, 8, 7, 8, 5, 8, 8, 6, 6, 5, 5, 4, 6, 4, 6, 4, 5, 7, 8, 8, 4, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.508, 1.061]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 56 | True: 56
Pred: 41 | True: 41
Pred: 40 | True: 40

Phrase Generation Sample:
Generated: [CLS] champion the cause [SEP] [SEP] and [SEP] and
Target: [CLS] champion the cause [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.8357
Generation Loss: 0.0037
Total Loss: 30.8395
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0037
Train Epoch: 88 [0/334 (0%)] Loss: 30.839474
Train Epoch: 88 [64/334 (19%)] Loss: 33.189602
Train Epoch: 88 [128/334 (38%)] Loss: 41.715771
Train Epoch: 88 [192/334 (57%)] Loss: 45.722122
Train Epoch: 88 [256/334 (77%)] Loss: 43.499458
[2025-01-21 11:56:53] Starting validation for epoch: 88

Generation Samples:
Topic 44:
Generated: [CLS] walks soul seat america realms does subdivision necks [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 73:
Generated: [CLS] think deal rule district england directory system k [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] mohawk hubbard premio td yu bb idiot chalk [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 88 [0/10 (0%)] Loss: 33.684219

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 39, 40, 41, 42, 43, 46, 47, 54, 55, 56, 57, 60, 64, 65, 66, 68, 70]
Input sequence lengths: [356, 356, 145, 121, 449, 356, 356, 453, 512, 485, 512, 145, 512, 512, 512, 512, 236, 512, 204, 512, 512, 512, 204, 485, 123, 512, 356, 512, 512, 512, 449, 512]
Target phrase lengths: [5, 4, 8, 5, 4, 4, 3, 5, 4, 7, 6, 6, 8, 6, 4, 4, 6, 5, 4, 6, 6, 5, 8, 5, 8, 4, 5, 6, 5, 7, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.519, 1.029]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 55 | True: 55
Pred: 55 | True: 55
Pred: 35 | True: 35

Phrase Generation Sample:
Generated: [CLS] planning and resources [SEP] and and and and
Target: [CLS] planning and resources [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.1567
Generation Loss: 0.0044
Total Loss: 25.1611
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0044
Train Epoch: 89 [0/334 (0%)] Loss: 25.161055
Train Epoch: 89 [64/334 (19%)] Loss: 24.656260
Train Epoch: 89 [128/334 (38%)] Loss: 44.804474
Train Epoch: 89 [192/334 (57%)] Loss: 25.384092
Train Epoch: 89 [256/334 (77%)] Loss: 33.495209
[2025-01-21 11:56:57] Starting validation for epoch: 89

Generation Samples:
Topic 59:
Generated: [CLS] buddhism kemp cobb bryan nielsen republicans publishes parasite [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] smoothly indigo claus tradition car nominations judgment ball [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] hindu rings of expands outspoken kevin magnesium nationalism [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 89 [0/10 (0%)] Loss: 45.106781

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 41, 43, 44, 45, 46, 51, 55, 58, 59, 60, 61, 63, 64, 66, 67, 68, 71]
Input sequence lengths: [512, 512, 512, 234, 356, 512, 356, 512, 449, 366, 512, 512, 512, 512, 512, 125, 512, 512, 92, 125, 159, 512, 145, 356, 356, 204, 234, 512, 512, 512, 356, 512]
Target phrase lengths: [8, 8, 8, 7, 4, 8, 4, 8, 6, 5, 7, 6, 5, 8, 8, 6, 7, 6, 7, 5, 5, 6, 7, 4, 4, 8, 4, 7, 4, 5, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.496, 1.076]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 45 | True: 45
Pred: 44 | True: 44
Pred: 8 | True: 67

Phrase Generation Sample:
Generated: [CLS] disintegration of relationships [SEP] [SEP]
Target: [CLS] disintegration of relationships [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.2747
Generation Loss: 0.0060
Total Loss: 26.2807
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0060
Train Epoch: 90 [0/334 (0%)] Loss: 26.280699
Train Epoch: 90 [64/334 (19%)] Loss: 27.680651
Train Epoch: 90 [128/334 (38%)] Loss: 42.115459
Train Epoch: 90 [192/334 (57%)] Loss: 29.201265
Train Epoch: 90 [256/334 (77%)] Loss: 26.045567
[2025-01-21 11:57:01] Starting validation for epoch: 90

Generation Samples:
Topic 36:
Generated: [CLS] disagreed popularized slovene ivanov kidding til hahn skipped [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 73:
Generated: [CLS] politically words allies housing highways mexico transportation endless [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] triad republican toy scientology cultures 1752 john blink [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 90 [0/10 (0%)] Loss: 26.948475

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 39, 41, 43, 44, 47, 49, 50, 51, 53, 56, 59, 60, 61, 63, 65, 66, 70, 73]
Input sequence lengths: [159, 512, 512, 64, 125, 366, 512, 453, 512, 512, 512, 145, 512, 512, 121, 512, 334, 209, 512, 512, 137, 125, 449, 512, 334, 78, 512, 512, 512, 236, 512, 512]
Target phrase lengths: [4, 6, 8, 7, 7, 7, 6, 8, 8, 8, 5, 8, 3, 6, 7, 7, 6, 7, 5, 6, 7, 7, 7, 5, 6, 7, 8, 5, 6, 8, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.520, 1.049]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 61 | True: 61
Pred: 65 | True: 65
Pred: 47 | True: 47

Phrase Generation Sample:
Generated: [CLS] officer morale [SEP] [SEP] [SEP] and [SEP] and
Target: [CLS] officer morale [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.5003
Generation Loss: 0.0051
Total Loss: 26.5054
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0052
Train Epoch: 91 [0/334 (0%)] Loss: 26.505436
Train Epoch: 91 [64/334 (19%)] Loss: 20.871906
Train Epoch: 91 [128/334 (38%)] Loss: 23.286716
Train Epoch: 91 [192/334 (57%)] Loss: 31.309664
Train Epoch: 91 [256/334 (77%)] Loss: 18.438721
[2025-01-21 11:57:10] Starting validation for epoch: 91

Generation Samples:
Topic 50:
Generated: [CLS] glove spark borders marek soul genetically works internal [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] espionage typing dime move expanding foreign cancel whistling [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] externally holmes colleges imports fundamentally containers joseph kant [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Validation Epoch: 91 [0/10 (0%)] Loss: 34.997929

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 40, 41, 43, 44, 49, 51, 52, 53, 55, 59, 60, 64, 65, 66, 67, 69]
Input sequence lengths: [366, 512, 512, 512, 453, 512, 92, 388, 512, 388, 78, 145, 512, 78, 92, 512, 512, 512, 356, 512, 512, 512, 366, 512, 334, 512, 512, 512, 334, 123, 145, 512]
Target phrase lengths: [7, 5, 5, 8, 5, 6, 6, 3, 4, 4, 7, 8, 8, 5, 5, 6, 6, 8, 5, 5, 5, 6, 5, 5, 6, 6, 6, 8, 7, 8, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.495, 1.078]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 59 | True: 59
Pred: 49 | True: 49
Pred: 52 | True: 52

Phrase Generation Sample:
Generated: [CLS] grew by thousands of members [SEP] [SEP] and
Target: [CLS] grew by thousands of members [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.3006
Generation Loss: 0.0040
Total Loss: 32.3047
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0041
Train Epoch: 92 [0/334 (0%)] Loss: 32.304684
Train Epoch: 92 [64/334 (19%)] Loss: 42.079357
Train Epoch: 92 [128/334 (38%)] Loss: 35.592945
Train Epoch: 92 [192/334 (57%)] Loss: 20.891176
Train Epoch: 92 [256/334 (77%)] Loss: 32.091625
[2025-01-21 11:57:14] Starting validation for epoch: 92

Generation Samples:
Topic 73:
Generated: [CLS] aura bihar sooner franchise dock numbers hockey vikings [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] nippon engineered aboard clever quantum uttar england flyers [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] globalization codex corporations contract brig knicks plans dictator [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 92 [0/10 (0%)] Loss: 43.610989

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 39, 41, 43, 45, 47, 49, 51, 53, 54, 55, 61, 64, 66, 68, 71]
Input sequence lengths: [159, 234, 334, 512, 356, 92, 78, 356, 512, 137, 121, 453, 125, 512, 512, 453, 453, 334, 512, 512, 512, 512, 512, 512, 512, 137, 512, 125, 512, 449, 204, 512]
Target phrase lengths: [4, 4, 6, 4, 5, 5, 6, 4, 5, 4, 4, 5, 5, 8, 5, 6, 7, 8, 6, 6, 4, 5, 5, 8, 5, 7, 4, 4, 4, 7, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.517, 1.090]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 61 | True: 61
Pred: 37 | True: 37
Pred: 53 | True: 53

Phrase Generation Sample:
Generated: [CLS] public service [SEP] [SEP] and and [SEP] [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.3633
Generation Loss: 0.0043
Total Loss: 36.3676
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0043
Train Epoch: 93 [0/334 (0%)] Loss: 36.367577
Train Epoch: 93 [64/334 (19%)] Loss: 19.781958
Train Epoch: 93 [128/334 (38%)] Loss: 38.223782
Train Epoch: 93 [192/334 (57%)] Loss: 23.805140
Train Epoch: 93 [256/334 (77%)] Loss: 27.628216
[2025-01-21 11:57:18] Starting validation for epoch: 93

Generation Samples:
Topic 50:
Generated: [CLS] privatization america language algebra problem serpent craft nervous [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] pod buddhist mets rex wandered loch clap netherlands [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 38:
Generated: [CLS] damned semantics saul none kevin fuck forcibly ron [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 93 [0/10 (0%)] Loss: 28.827044

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 40, 41, 43, 47, 49, 50, 51, 53, 54, 56, 60, 61, 62, 63, 64, 70, 71]
Input sequence lengths: [512, 512, 236, 512, 512, 512, 92, 87, 512, 449, 125, 512, 453, 87, 78, 334, 334, 512, 234, 145, 123, 512, 449, 125, 512, 512, 512, 512, 512, 512, 159, 512]
Target phrase lengths: [4, 4, 6, 7, 4, 5, 5, 6, 6, 7, 7, 5, 7, 6, 6, 4, 6, 4, 4, 8, 8, 7, 8, 5, 5, 8, 8, 6, 4, 6, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.554, 1.087]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 40
Pred: 60 | True: 60
Pred: 70 | True: 70

Phrase Generation Sample:
Generated: [CLS] my colleague [SEP] and and and and and
Target: [CLS] my colleague [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 19.8986
Generation Loss: 0.0046
Total Loss: 19.9032
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.0046
Train Epoch: 94 [0/334 (0%)] Loss: 19.903166
Train Epoch: 94 [64/334 (19%)] Loss: 39.503040
Train Epoch: 94 [128/334 (38%)] Loss: 40.781998
Train Epoch: 94 [192/334 (57%)] Loss: 37.083202
Train Epoch: 94 [256/334 (77%)] Loss: 33.311359
[2025-01-21 11:57:22] Starting validation for epoch: 94

Generation Samples:
Topic 59:
Generated: [CLS] administer timber ballroom handled republicans flies admitted colon [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] manhattan sophisticated mab decorative problem wing hercules splash [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] swami aligned td words nails innocent trap soul [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 94 [0/10 (0%)] Loss: 30.500481

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 40, 41, 42, 44, 45, 48, 49, 51, 54, 55, 56, 58, 60, 64, 67, 69, 70]
Input sequence lengths: [258, 512, 81, 64, 512, 512, 512, 512, 512, 64, 145, 449, 356, 512, 512, 512, 512, 512, 449, 512, 356, 236, 78, 512, 512, 512, 268, 388, 512, 512, 512, 512]
Target phrase lengths: [6, 6, 6, 7, 5, 4, 8, 4, 3, 5, 7, 5, 4, 6, 4, 5, 4, 6, 4, 6, 4, 8, 7, 5, 5, 4, 8, 4, 7, 5, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.496, 1.091]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 42 | True: 38
Pred: 42 | True: 38
Pred: 48 | True: 48

Phrase Generation Sample:
Generated: [CLS] nominate byron donalds [SEP] [SEP] [SEP] [SEP]
Target: [CLS] nominate byron donalds [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 55.4407
Generation Loss: 0.0030
Total Loss: 55.4437
Topic Prediction Accuracy: 0.5625
Generation Perplexity: 1.0030
Train Epoch: 95 [0/334 (0%)] Loss: 55.443699
Train Epoch: 95 [64/334 (19%)] Loss: 39.521095
Train Epoch: 95 [128/334 (38%)] Loss: 36.547054
Train Epoch: 95 [192/334 (57%)] Loss: 26.780647
Train Epoch: 95 [256/334 (77%)] Loss: 22.466393
[2025-01-21 11:57:26] Starting validation for epoch: 95

Generation Samples:
Topic 46:
Generated: [CLS] iss tumor shifted answer galaxies developers shoved label [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] moth agreements did ultimatum hickory inner organ aura [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 38:
Generated: [CLS] caught mage russell rings movement implements language definite [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 95 [0/10 (0%)] Loss: 34.092587

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 40, 41, 42, 43, 47, 53, 54, 55, 59, 60, 62, 64, 65, 66, 67, 70, 71]
Input sequence lengths: [449, 512, 512, 512, 512, 512, 512, 125, 356, 512, 512, 512, 512, 258, 453, 512, 512, 366, 512, 512, 125, 87, 512, 512, 512, 512, 234, 236, 334, 366, 512, 512]
Target phrase lengths: [6, 4, 7, 5, 7, 8, 5, 4, 5, 4, 5, 5, 5, 4, 8, 6, 8, 5, 5, 5, 6, 8, 7, 8, 6, 5, 7, 6, 7, 5, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.528, 1.046]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 57 | True: 71
Pred: 41 | True: 41
Pred: 66 | True: 66

Phrase Generation Sample:
Generated: [CLS] fiscally responsible budget [SEP] [SEP] [SEP] [SEP]
Target: [CLS] fiscally responsible budget [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 35.2039
Generation Loss: 0.0043
Total Loss: 35.2082
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0043
Train Epoch: 96 [0/334 (0%)] Loss: 35.208237
Train Epoch: 96 [64/334 (19%)] Loss: 20.367025
Train Epoch: 96 [128/334 (38%)] Loss: 22.063787
Train Epoch: 96 [192/334 (57%)] Loss: 30.517527
Train Epoch: 96 [256/334 (77%)] Loss: 36.721386
[2025-01-21 11:57:35] Starting validation for epoch: 96

Generation Samples:
Topic 58:
Generated: [CLS] contracts giants russell rib interpretation keyboardist hindu dragons [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] benjamin souls ley decorations fueled structurally common abolished [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 55:
Generated: [CLS] upstate leg hades riga 670 bubbling symbolic republicans [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 96 [0/10 (0%)] Loss: 45.617481

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 41, 43, 47, 48, 49, 51, 54, 55, 56, 60, 62, 63, 64, 65, 66, 68, 70, 71]
Input sequence lengths: [512, 512, 512, 512, 125, 449, 145, 512, 356, 449, 356, 449, 512, 512, 87, 512, 125, 512, 512, 512, 512, 81, 512, 204, 449, 512, 512, 92, 512, 145, 236, 123]
Target phrase lengths: [4, 5, 8, 8, 5, 4, 8, 4, 4, 8, 3, 4, 6, 5, 6, 5, 7, 8, 8, 7, 4, 8, 4, 8, 4, 6, 8, 5, 4, 8, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.526, 1.052]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 36 | True: 36
Pred: 39 | True: 60

Phrase Generation Sample:
Generated: [CLS] constitutional authority [SEP] [SEP] [SEP] [SEP] [SEP] and
Target: [CLS] constitutional authority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.5091
Generation Loss: 0.0045
Total Loss: 34.5135
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0045
Train Epoch: 97 [0/334 (0%)] Loss: 34.513542
Train Epoch: 97 [64/334 (19%)] Loss: 46.011517
Train Epoch: 97 [128/334 (38%)] Loss: 45.518353
Train Epoch: 97 [192/334 (57%)] Loss: 40.169670
Train Epoch: 97 [256/334 (77%)] Loss: 31.728701
[2025-01-21 11:57:39] Starting validation for epoch: 97

Generation Samples:
Topic 51:
Generated: [CLS] matched nomination nomination orton slick moved negotiated idea [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 47:
Generated: [CLS] tatar humane tattooed bjp loans connections dem roc [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 65:
Generated: [CLS] congress sacramento disgrace disguised enlarged clause delhi java [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Validation Epoch: 97 [0/10 (0%)] Loss: 34.339199

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 38, 39, 40, 41, 42, 43, 49, 54, 55, 56, 60, 61, 64, 66, 68, 70, 72]
Input sequence lengths: [121, 258, 204, 356, 512, 512, 512, 64, 512, 453, 512, 64, 512, 512, 512, 125, 512, 512, 356, 512, 449, 91, 268, 123, 121, 125, 159, 512, 449, 512, 453, 236]
Target phrase lengths: [5, 4, 8, 5, 3, 6, 4, 7, 5, 5, 5, 8, 4, 4, 3, 5, 6, 4, 4, 7, 8, 4, 8, 8, 5, 8, 7, 4, 5, 8, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.519, 1.031]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 39
Pred: 38 | True: 38
Pred: 68 | True: 68

Phrase Generation Sample:
Generated: [CLS] speaker not elected [SEP] which [SEP] and and
Target: [CLS] speaker not elected [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.8478
Generation Loss: 0.0033
Total Loss: 31.8511
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0033
Train Epoch: 98 [0/334 (0%)] Loss: 31.851126
Train Epoch: 98 [64/334 (19%)] Loss: 45.314133
Train Epoch: 98 [128/334 (38%)] Loss: 37.277596
Train Epoch: 98 [192/334 (57%)] Loss: 25.987621
Train Epoch: 98 [256/334 (77%)] Loss: 27.887238
[2025-01-21 11:57:43] Starting validation for epoch: 98

Generation Samples:
Topic 43:
Generated: [CLS] pledged powell implant fabrics give mana appeals sino [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] gundam denied administration rigged ties box authority liquor [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] 495 congress americas deal fee poly cross mutually [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 98 [0/10 (0%)] Loss: 32.880569

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 53, 54, 55, 58, 59, 60, 61, 63, 69, 70]
Input sequence lengths: [121, 123, 512, 388, 512, 512, 121, 512, 64, 334, 512, 159, 512, 356, 512, 512, 512, 236, 512, 512, 512, 512, 388, 236, 366, 512, 268, 366, 512, 512, 334, 125]
Target phrase lengths: [5, 7, 4, 4, 7, 4, 5, 6, 5, 4, 7, 4, 5, 4, 8, 5, 8, 8, 4, 5, 8, 6, 8, 5, 3, 6, 8, 3, 6, 5, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.522, 1.057]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 39
Pred: 43 | True: 43
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] speaker not elected [SEP] [SEP] [SEP] and and
Target: [CLS] speaker not elected [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.1912
Generation Loss: 0.0030
Total Loss: 25.1942
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0030
Train Epoch: 99 [0/334 (0%)] Loss: 25.194172
Train Epoch: 99 [64/334 (19%)] Loss: 32.593384
Train Epoch: 99 [128/334 (38%)] Loss: 38.941208
Train Epoch: 99 [192/334 (57%)] Loss: 33.812458
Train Epoch: 99 [256/334 (77%)] Loss: 32.497551
[2025-01-21 11:57:47] Starting validation for epoch: 99

Generation Samples:
Topic 73:
Generated: [CLS] liquidation buddhist christians living [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] mono pact rap affiliation [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] kant bargaining scotland toes [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 99 [0/10 (0%)] Loss: 35.901382

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 40, 41, 42, 43, 45, 47, 49, 53, 55, 61, 63, 66, 67, 69, 70, 71, 72]
Input sequence lengths: [512, 356, 512, 145, 512, 512, 453, 512, 512, 234, 512, 125, 91, 159, 512, 334, 512, 125, 236, 449, 388, 512, 512, 125, 512, 512, 512, 137, 512, 453, 137, 512]
Target phrase lengths: [6, 4, 5, 6, 7, 6, 7, 6, 5, 4, 4, 4, 6, 4, 5, 6, 5, 5, 8, 4, 4, 5, 8, 6, 8, 5, 5, 7, 5, 7, 7, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.503, 1.067]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 55 | True: 55
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] and [SEP] [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 35.7694
Generation Loss: 0.0030
Total Loss: 35.7724
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0030
Train Epoch: 100 [0/334 (0%)] Loss: 35.772404
Train Epoch: 100 [64/334 (19%)] Loss: 33.386112
Train Epoch: 100 [128/334 (38%)] Loss: 26.159876
Train Epoch: 100 [192/334 (57%)] Loss: 43.081757
Train Epoch: 100 [256/334 (77%)] Loss: 48.181110
[2025-01-21 11:57:51] Starting validation for epoch: 100

Generation Samples:
Topic 52:
Generated: [CLS] coordinating gui naga rafael randolph bomb formally rib [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] uncanny mendez fungi chickens westward bryan ios john [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] foreign nathan beech gui crossed shaken manhattan ferdinand [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 100 [0/10 (0%)] Loss: 41.672161

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 39, 40, 41, 42, 43, 45, 47, 49, 51, 54, 55, 57, 58, 60, 61, 62, 63, 70]
Input sequence lengths: [159, 236, 512, 512, 512, 512, 356, 268, 485, 92, 512, 512, 268, 512, 512, 123, 512, 512, 512, 485, 512, 512, 87, 121, 512, 512, 125, 87, 512, 64, 485, 512]
Target phrase lengths: [4, 8, 6, 4, 4, 5, 4, 8, 8, 5, 5, 5, 8, 4, 6, 8, 8, 4, 4, 8, 5, 8, 6, 5, 5, 4, 5, 8, 8, 5, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.502, 1.040]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 61 | True: 61
Pred: 70 | True: 70
Pred: 37 | True: 41

Phrase Generation Sample:
Generated: [CLS] officer morale [SEP] [SEP] and [SEP] and and
Target: [CLS] officer morale [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 41.4413
Generation Loss: 0.0039
Total Loss: 41.4452
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0039
Train Epoch: 101 [0/334 (0%)] Loss: 41.445232
Train Epoch: 101 [64/334 (19%)] Loss: 25.774189
Train Epoch: 101 [128/334 (38%)] Loss: 32.778263
Train Epoch: 101 [192/334 (57%)] Loss: 27.033533
Train Epoch: 101 [256/334 (77%)] Loss: 30.686432
[2025-01-21 11:58:05] Starting validation for epoch: 101

Generation Samples:
Topic 66:
Generated: [CLS] instincts horse [unused84] choice jimmy commits mainline fbi [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] piled davy baja receptor earrings innocence java damn [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 65:
Generated: [CLS] tex jurgen ether ling ji vijay jurgen phones [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Validation Epoch: 101 [0/10 (0%)] Loss: 51.791378

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 57, 59, 60, 65, 66, 67, 68, 70, 71]
Input sequence lengths: [366, 512, 92, 123, 356, 125, 512, 204, 512, 81, 512, 512, 125, 512, 236, 512, 453, 485, 512, 356, 123, 512, 512, 236, 512, 449, 234, 512, 356, 512, 512, 512]
Target phrase lengths: [6, 8, 5, 8, 5, 6, 5, 8, 5, 6, 4, 8, 7, 5, 6, 5, 8, 5, 4, 4, 7, 8, 6, 8, 6, 4, 4, 5, 4, 4, 8, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.574, 1.068]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 59 | True: 59
Pred: 65 | True: 65
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] legacy of faithful service [SEP] [PAD] [PAD] and
Target: [CLS] legacy of faithful service [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 15.1058
Generation Loss: 0.0040
Total Loss: 15.1098
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.0040
Train Epoch: 102 [0/334 (0%)] Loss: 15.109824
Train Epoch: 102 [64/334 (19%)] Loss: 31.421286
Train Epoch: 102 [128/334 (38%)] Loss: 53.180504
Train Epoch: 102 [192/334 (57%)] Loss: 23.428799
Train Epoch: 102 [256/334 (77%)] Loss: 31.446733
[2025-01-21 11:58:09] Starting validation for epoch: 102

Generation Samples:
Topic 65:
Generated: [CLS] nielsen devout thoughts ist inclusion ser cf puerto [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 38:
Generated: [CLS] pixels palms frustrated jobs practical medical nfl swedish [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] reorganization subdued disadvantaged brno trouble clue clause bryan [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 102 [0/10 (0%)] Loss: 44.769341

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 37, 40, 41, 43, 47, 48, 51, 52, 53, 54, 55, 56, 58, 59, 60, 64, 65, 66, 67, 68, 73]
Input sequence lengths: [356, 512, 512, 512, 512, 512, 512, 512, 512, 512, 204, 268, 366, 512, 125, 512, 334, 234, 449, 512, 145, 512, 512, 81, 512, 453, 209, 512, 356, 512, 512, 92]
Target phrase lengths: [5, 4, 8, 8, 4, 8, 6, 6, 8, 8, 8, 8, 3, 6, 6, 5, 4, 7, 5, 4, 8, 5, 6, 5, 7, 7, 4, 4, 4, 4, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.481, 1.058]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 55 | True: 55
Pred: 54 | True: 54
Pred: 69 | True: 65

Phrase Generation Sample:
Generated: [CLS] economic development committees [SEP] [SEP] and and [SEP]
Target: [CLS] economic development committees [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 28.4925
Generation Loss: 0.0030
Total Loss: 28.4955
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0030
Train Epoch: 103 [0/334 (0%)] Loss: 28.495504
Train Epoch: 103 [64/334 (19%)] Loss: 21.606846
Train Epoch: 103 [128/334 (38%)] Loss: 24.218937
Train Epoch: 103 [192/334 (57%)] Loss: 30.073204
Train Epoch: 103 [256/334 (77%)] Loss: 26.251402
[2025-01-21 11:58:13] Starting validation for epoch: 103

Generation Samples:
Topic 73:
Generated: [CLS] piper swiss flights flower name energy tear foreign [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] fang big changing cruz sneakers dragons schwartz american [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] manny commands josef events trying guitars name knicks [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 103 [0/10 (0%)] Loss: 25.013630

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 50, 54, 55, 59, 60, 66, 67, 68, 72]
Input sequence lengths: [512, 512, 512, 512, 121, 512, 356, 512, 453, 204, 268, 512, 356, 81, 512, 145, 123, 512, 125, 366, 512, 137, 512, 121, 512, 512, 258, 512, 366, 512, 91, 512]
Target phrase lengths: [7, 4, 6, 5, 4, 5, 5, 8, 7, 8, 8, 6, 3, 6, 5, 8, 8, 7, 6, 3, 4, 7, 5, 5, 4, 4, 6, 6, 7, 5, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.520, 1.050]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 45 | True: 45
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] largest and most effective chamber [SEP] [SEP] [SEP]
Target: [CLS] largest and most effective chamber [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.4566
Generation Loss: 0.0026
Total Loss: 29.4592
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0026
Train Epoch: 104 [0/334 (0%)] Loss: 29.459173
Train Epoch: 104 [64/334 (19%)] Loss: 29.417875
Train Epoch: 104 [128/334 (38%)] Loss: 34.947392
Train Epoch: 104 [192/334 (57%)] Loss: 39.449345
Train Epoch: 104 [256/334 (77%)] Loss: 24.083885
[2025-01-21 11:58:17] Starting validation for epoch: 104

Generation Samples:
Topic 58:
Generated: [CLS] naga union creative languages ship jammu zen structure [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 55:
Generated: [CLS] lexi caps lives leiden limbs runes sylvia 256 [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] headquartered sugarcane squinted missiles anything racism lied fragments [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Validation Epoch: 104 [0/10 (0%)] Loss: 49.673092

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 38, 39, 41, 42, 46, 48, 49, 52, 53, 54, 55, 60, 66, 69, 70, 71]
Input sequence lengths: [121, 512, 512, 512, 512, 453, 268, 388, 512, 145, 512, 512, 449, 356, 81, 512, 512, 512, 449, 512, 512, 356, 512, 236, 268, 512, 121, 64, 334, 512, 512, 512]
Target phrase lengths: [6, 5, 6, 5, 6, 8, 8, 8, 7, 7, 5, 4, 7, 3, 5, 7, 6, 4, 4, 6, 8, 4, 4, 8, 8, 4, 7, 7, 4, 5, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.480, 1.072]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 39
Pred: 66 | True: 66
Pred: 46 | True: 46

Phrase Generation Sample:
Generated: [CLS] donald j. trump [SEP] and and [SEP]
Target: [CLS] donald j. trump [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.8097
Generation Loss: 0.0024
Total Loss: 29.8121
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0024
Train Epoch: 105 [0/334 (0%)] Loss: 29.812132
Train Epoch: 105 [64/334 (19%)] Loss: 17.645576
Train Epoch: 105 [128/334 (38%)] Loss: 24.386923
Train Epoch: 105 [192/334 (57%)] Loss: 27.097073
Train Epoch: 105 [256/334 (77%)] Loss: 39.502907
[2025-01-21 11:58:21] Starting validation for epoch: 105

Generation Samples:
Topic 52:
Generated: [CLS] [unused661] bowie naga marin vaguely lexi horns johnstone [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] fabricated props devout real corporations deal dragon dunn [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 55:
Generated: [CLS] contract opinions northwest freiburg synod dot normally charters [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 105 [0/10 (0%)] Loss: 37.871105

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 44, 45, 47, 49, 51, 55, 58, 59, 61, 62, 63, 64, 65, 69, 70, 72, 73]
Input sequence lengths: [366, 512, 356, 388, 512, 268, 209, 512, 512, 236, 123, 512, 78, 512, 121, 91, 159, 512, 356, 258, 512, 512, 512, 512, 512, 512, 512, 512, 78, 356, 87, 512]
Target phrase lengths: [5, 6, 5, 3, 8, 8, 4, 5, 8, 5, 8, 4, 7, 6, 7, 4, 4, 4, 5, 6, 6, 5, 4, 6, 6, 5, 4, 6, 6, 5, 8, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.500, 1.065]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 59 | True: 59
Pred: 47 | True: 47
Pred: 55 | True: 55

Phrase Generation Sample:
Generated: [CLS] wise sayings [SEP] [SEP] [SEP] and and
Target: [CLS] wise sayings [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.6844
Generation Loss: 0.0022
Total Loss: 25.6866
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0023
Train Epoch: 106 [0/334 (0%)] Loss: 25.686647
Train Epoch: 106 [64/334 (19%)] Loss: 28.157064
Train Epoch: 106 [128/334 (38%)] Loss: 37.159348
Train Epoch: 106 [192/334 (57%)] Loss: 36.403687
Train Epoch: 106 [256/334 (77%)] Loss: 39.146088
[2025-01-21 11:58:30] Starting validation for epoch: 106

Generation Samples:
Topic 58:
Generated: [CLS] mage rib tasmanian weapon bomber personalities intuitive greeks [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] mika yuri bryan voices sounds hideous borrowed ale [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 55:
Generated: [CLS] naming nomination fielding pigeon downs tactics myers answers [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 106 [0/10 (0%)] Loss: 34.479046

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 40, 41, 42, 43, 44, 46, 47, 49, 54, 55, 56, 57, 61, 64, 65, 67, 68]
Input sequence lengths: [512, 512, 512, 512, 512, 234, 512, 449, 512, 512, 512, 512, 512, 512, 485, 159, 137, 512, 512, 512, 145, 512, 356, 512, 512, 204, 234, 512, 512, 356, 125, 356]
Target phrase lengths: [4, 7, 4, 5, 5, 7, 6, 8, 8, 8, 6, 5, 6, 6, 5, 4, 4, 5, 4, 8, 8, 5, 5, 4, 6, 8, 4, 7, 5, 3, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.537, 1.073]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 49 | True: 49
Pred: 67 | True: 67
Pred: 44 | True: 44

Phrase Generation Sample:
Generated: [CLS] confront china [SEP] and and [SEP] [SEP] and
Target: [CLS] confront china [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.1304
Generation Loss: 0.0030
Total Loss: 34.1334
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0030
Train Epoch: 107 [0/334 (0%)] Loss: 34.133446
Train Epoch: 107 [64/334 (19%)] Loss: 42.421711
Train Epoch: 107 [128/334 (38%)] Loss: 19.463005
Train Epoch: 107 [192/334 (57%)] Loss: 16.596495
Train Epoch: 107 [256/334 (77%)] Loss: 29.881491
[2025-01-21 11:58:34] Starting validation for epoch: 107

Generation Samples:
Topic 40:
Generated: [CLS] witty foreign silk muffled language faith offense wears [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] [unused80] bunk persian phi mint actions lease alistair [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] priesthood appointing scientology koch brandenburg transgender think aboard [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 107 [0/10 (0%)] Loss: 37.947269

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 39, 40, 41, 43, 44, 45, 49, 51, 55, 56, 58, 60, 62, 63, 64, 65, 66, 70, 71]
Input sequence lengths: [145, 64, 512, 125, 236, 512, 512, 449, 512, 356, 512, 121, 512, 512, 512, 512, 78, 512, 512, 512, 356, 512, 449, 512, 87, 512, 449, 512, 512, 512, 512, 64]
Target phrase lengths: [8, 7, 6, 5, 8, 8, 4, 4, 8, 4, 6, 4, 4, 5, 4, 8, 7, 5, 6, 4, 4, 8, 4, 6, 6, 4, 7, 6, 4, 5, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.526, 1.069]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 35 | True: 35
Pred: 34 | True: 34
Pred: 60 | True: 60

Phrase Generation Sample:
Generated: [CLS] address any remarks through the chair [SEP] and
Target: [CLS] address any remarks through the chair [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.5350
Generation Loss: 0.0023
Total Loss: 23.5374
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0023
Train Epoch: 108 [0/334 (0%)] Loss: 23.537382
Train Epoch: 108 [64/334 (19%)] Loss: 47.343361
Train Epoch: 108 [128/334 (38%)] Loss: 66.018166
Train Epoch: 108 [192/334 (57%)] Loss: 38.033535
Train Epoch: 108 [256/334 (77%)] Loss: 50.070648
[2025-01-21 11:58:38] Starting validation for epoch: 108

Generation Samples:
Topic 36:
Generated: [CLS] identities kellogg zu mit phased christ funding jet [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] remnant magic initials yu conduct kahn macedonian minerals [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 55:
Generated: [CLS] megan actions connecting truss constructions puppet rails axle [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 108 [0/10 (0%)] Loss: 35.449074

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 43, 44, 49, 50, 51, 52, 53, 55, 57, 59, 63, 64, 65, 66, 67, 69, 71]
Input sequence lengths: [512, 512, 125, 356, 512, 512, 512, 512, 512, 121, 78, 388, 512, 512, 512, 366, 512, 449, 485, 123, 334, 512, 512, 123, 137, 123, 512, 125, 334, 125, 512, 512]
Target phrase lengths: [5, 5, 7, 4, 5, 6, 5, 4, 8, 5, 7, 3, 4, 8, 7, 6, 8, 7, 7, 7, 7, 4, 7, 8, 7, 7, 5, 6, 6, 6, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.561, 1.090]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 64 | True: 64
Pred: 61 | True: 52
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] washington is broken [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] washington is broken [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 43.0119
Generation Loss: 0.0029
Total Loss: 43.0148
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0029
Train Epoch: 109 [0/334 (0%)] Loss: 43.014809
Train Epoch: 109 [64/334 (19%)] Loss: 21.347084
Train Epoch: 109 [128/334 (38%)] Loss: 35.300915
Train Epoch: 109 [192/334 (57%)] Loss: 30.312212
Train Epoch: 109 [256/334 (77%)] Loss: 21.397663
[2025-01-21 11:58:42] Starting validation for epoch: 109

Generation Samples:
Topic 44:
Generated: [CLS] homeless dictionary democracy command strings raft card [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] coherent grammar yang assign faith fox bei [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 44:
Generated: [CLS] canada identifiable reconcile prelate english symbolic unions [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 109 [0/10 (0%)] Loss: 32.351498

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 38, 39, 41, 46, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 64, 66, 67, 69, 70, 72]
Input sequence lengths: [512, 512, 234, 512, 388, 512, 159, 268, 453, 91, 512, 512, 356, 512, 121, 512, 334, 512, 258, 512, 236, 449, 234, 121, 236, 64, 512, 92, 512, 512, 87, 388]
Target phrase lengths: [7, 5, 4, 4, 3, 5, 4, 8, 8, 4, 4, 5, 4, 7, 6, 5, 7, 4, 6, 6, 8, 4, 7, 4, 7, 8, 5, 5, 6, 4, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.463, 1.125]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 63 | True: 63
Pred: 48 | True: 36
Pred: 37 | True: 37

Phrase Generation Sample:
Generated: [CLS] changes to the standing rules [SEP] [SEP] [SEP]
Target: [CLS] changes to the standing rules [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 21.4644
Generation Loss: 0.0027
Total Loss: 21.4671
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0027
Train Epoch: 110 [0/334 (0%)] Loss: 21.467104
Train Epoch: 110 [64/334 (19%)] Loss: 34.134327
Train Epoch: 110 [128/334 (38%)] Loss: 20.145113
Train Epoch: 110 [192/334 (57%)] Loss: 48.953102
Train Epoch: 110 [256/334 (77%)] Loss: 32.093716
[2025-01-21 11:58:46] Starting validation for epoch: 110

Generation Samples:
Topic 43:
Generated: [CLS] infinite catalina entities bargaining latvian negotiate branding vodka [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] parasitic dance leagues adamant aliens espionage global flourish [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] jailed tempting moves matteo emerald lightning documentation soul [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 110 [0/10 (0%)] Loss: 32.863739

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 39, 41, 43, 44, 48, 49, 57, 60, 61, 63, 65, 67, 68, 69, 71]
Input sequence lengths: [512, 204, 512, 512, 388, 512, 512, 159, 268, 121, 512, 512, 125, 121, 512, 485, 512, 512, 137, 449, 64, 512, 512, 512, 512, 512, 512, 512, 512, 512, 81, 204]
Target phrase lengths: [8, 8, 5, 5, 3, 5, 6, 5, 8, 6, 6, 8, 7, 5, 6, 8, 5, 6, 7, 6, 7, 6, 8, 6, 4, 8, 7, 8, 6, 8, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.543, 1.158]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 47 | True: 68
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] hakeem jeffries for [SEP] [PAD]
Target: [CLS] hakeem jeffries for [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 28.4088
Generation Loss: 0.0032
Total Loss: 28.4120
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0032
Train Epoch: 111 [0/334 (0%)] Loss: 28.411985
Train Epoch: 111 [64/334 (19%)] Loss: 38.187168
Train Epoch: 111 [128/334 (38%)] Loss: 24.573143
Train Epoch: 111 [192/334 (57%)] Loss: 27.682213
Train Epoch: 111 [256/334 (77%)] Loss: 24.437073
[2025-01-21 11:58:55] Starting validation for epoch: 111

Generation Samples:
Topic 66:
Generated: [CLS] tribes gases breathe sol covenant abbott nl autonomy [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] nationalism nomination eliot loan admit gas easier radically [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] guangdong axe leadership deal administration orthodox mace wil [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 111 [0/10 (0%)] Loss: 40.142265

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 39, 41, 42, 43, 45, 49, 51, 53, 54, 55, 59, 60, 61, 64, 67, 72]
Input sequence lengths: [258, 512, 78, 91, 512, 512, 356, 125, 78, 512, 334, 512, 512, 125, 512, 512, 512, 234, 234, 512, 91, 366, 512, 512, 121, 512, 121, 512, 159, 78, 356, 512]
Target phrase lengths: [4, 8, 7, 4, 6, 5, 3, 6, 5, 6, 6, 6, 6, 5, 8, 4, 5, 8, 4, 8, 4, 5, 5, 7, 5, 5, 7, 5, 7, 7, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.474, 1.004]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 48 | True: 38
Pred: 64 | True: 64
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] support him [SEP]. and and and [SEP]
Target: [CLS] support him [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 59.0825
Generation Loss: 0.0027
Total Loss: 59.0852
Topic Prediction Accuracy: 0.5938
Generation Perplexity: 1.0027
Train Epoch: 112 [0/334 (0%)] Loss: 59.085239
Train Epoch: 112 [64/334 (19%)] Loss: 37.925007
Train Epoch: 112 [128/334 (38%)] Loss: 35.054398
Train Epoch: 112 [192/334 (57%)] Loss: 19.360096
Train Epoch: 112 [256/334 (77%)] Loss: 44.184269
[2025-01-21 11:58:59] Starting validation for epoch: 112

Generation Samples:
Topic 59:
Generated: [CLS] barges lew delhi nintendo republican society skin overlap [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] morally cincinnati munoz agree shrugged not didn behaviors [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] benito tribe softly languages curtain advancement railways accepting [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 112 [0/10 (0%)] Loss: 30.529730

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 39, 41, 43, 47, 49, 54, 57, 59, 60, 61, 62, 64, 65, 67, 68, 70]
Input sequence lengths: [125, 366, 512, 236, 121, 512, 512, 125, 234, 512, 159, 125, 512, 512, 485, 512, 512, 485, 512, 512, 512, 512, 512, 512, 512, 512, 512, 366, 512, 204, 204, 87]
Target phrase lengths: [7, 7, 3, 8, 7, 5, 7, 5, 4, 8, 5, 8, 4, 5, 7, 4, 6, 8, 7, 8, 8, 4, 4, 6, 4, 6, 5, 3, 8, 8, 8, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.515, 1.062]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 59 | True: 59
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] speaker has not been elected [SEP] [SEP] [SEP]
Target: [CLS] speaker has not been elected [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 28.4629
Generation Loss: 0.0031
Total Loss: 28.4660
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0031
Train Epoch: 113 [0/334 (0%)] Loss: 28.465973
Train Epoch: 113 [64/334 (19%)] Loss: 30.478561
Train Epoch: 113 [128/334 (38%)] Loss: 45.509270
Train Epoch: 113 [192/334 (57%)] Loss: 30.595133
Train Epoch: 113 [256/334 (77%)] Loss: 24.573414
[2025-01-21 11:59:03] Starting validation for epoch: 113

Generation Samples:
Topic 59:
Generated: [CLS] pitchers usher intelligent nominate passes bonds spun say [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] tunnels bjp sioux governments hyundai sounding algebraic galley [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 52:
Generated: [CLS] gunnar pigment sino nl tickets controlled louder glove [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 113 [0/10 (0%)] Loss: 30.441053

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 40, 41, 43, 44, 45, 46, 47, 49, 54, 55, 56, 58, 61, 62, 65, 66, 68, 71, 73]
Input sequence lengths: [512, 512, 125, 512, 512, 234, 356, 209, 512, 512, 64, 512, 512, 512, 125, 87, 356, 512, 449, 449, 512, 512, 204, 512, 512, 512, 453, 145, 449, 512, 512, 159]
Target phrase lengths: [4, 4, 7, 6, 6, 4, 3, 4, 6, 8, 7, 4, 5, 8, 5, 8, 4, 6, 8, 6, 4, 4, 5, 8, 5, 6, 6, 8, 5, 5, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.519, 1.091]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 58 | True: 58
Pred: 69 | True: 66
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] public service [SEP] and and and [SEP] [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.4139
Generation Loss: 0.0021
Total Loss: 29.4160
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0021
Train Epoch: 114 [0/334 (0%)] Loss: 29.416016
Train Epoch: 114 [64/334 (19%)] Loss: 23.039705
Train Epoch: 114 [128/334 (38%)] Loss: 37.364956
Train Epoch: 114 [192/334 (57%)] Loss: 20.926773
Train Epoch: 114 [256/334 (77%)] Loss: 52.366543
[2025-01-21 11:59:07] Starting validation for epoch: 114

Generation Samples:
Topic 40:
Generated: [CLS] ships ax insider dod oppose synth multinational [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 51:
Generated: [CLS] surgery skull manages calculate flights ribs continuation [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] roland will sparrow kan delhi deals foreign [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 114 [0/10 (0%)] Loss: 35.598244

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 41, 42, 43, 45, 49, 53, 54, 60, 61, 65, 66, 68, 69, 70, 72, 73]
Input sequence lengths: [512, 512, 236, 137, 512, 268, 204, 334, 512, 258, 512, 388, 512, 125, 512, 209, 512, 512, 512, 159, 512, 137, 236, 512, 268, 91, 512, 512, 123, 512, 512, 512]
Target phrase lengths: [7, 5, 5, 4, 8, 8, 5, 6, 6, 4, 4, 3, 6, 5, 6, 7, 5, 4, 5, 4, 5, 7, 8, 6, 8, 4, 5, 5, 8, 5, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.552, 1.081]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 66 | True: 66
Pred: 70 | True: 70

Phrase Generation Sample:
Generated: [CLS] governing party in this chamber [SEP] [SEP] [SEP]
Target: [CLS] governing party in this chamber [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 27.8110
Generation Loss: 0.0023
Total Loss: 27.8133
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0023
Train Epoch: 115 [0/334 (0%)] Loss: 27.813311
Train Epoch: 115 [64/334 (19%)] Loss: 36.859310
Train Epoch: 115 [128/334 (38%)] Loss: 41.152573
Train Epoch: 115 [192/334 (57%)] Loss: 25.670553
Train Epoch: 115 [256/334 (77%)] Loss: 40.878338
[2025-01-21 11:59:11] Starting validation for epoch: 115

Generation Samples:
Topic 65:
Generated: [CLS] soul macquarie unix fellow john jar meredith govern [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 61:
Generated: [CLS] germanic sergio federally openly strings disturbing mills sci [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 55:
Generated: [CLS] flutes crossed yukon rayon ornate viking keys bites [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 115 [0/10 (0%)] Loss: 30.893127

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 41, 42, 43, 49, 51, 52, 54, 55, 58, 59, 60, 63, 64, 67, 69, 70]
Input sequence lengths: [512, 78, 512, 512, 366, 512, 145, 512, 512, 512, 512, 512, 453, 388, 512, 512, 236, 512, 512, 512, 512, 366, 92, 512, 123, 125, 512, 356, 125, 453, 512, 366]
Target phrase lengths: [4, 7, 4, 4, 3, 5, 7, 7, 4, 5, 8, 8, 7, 3, 5, 8, 5, 4, 4, 3, 6, 7, 5, 6, 7, 7, 4, 5, 7, 8, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.528, 1.072]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 64 | True: 64
Pred: 34 | True: 51
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] proxy voting [SEP] [SEP] [SEP] [SEP] and and
Target: [CLS] proxy voting [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 39.0256
Generation Loss: 0.0028
Total Loss: 39.0283
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0028
Train Epoch: 116 [0/334 (0%)] Loss: 39.028343
Train Epoch: 116 [64/334 (19%)] Loss: 41.485207
Train Epoch: 116 [128/334 (38%)] Loss: 41.769287
Train Epoch: 116 [192/334 (57%)] Loss: 26.138781
Train Epoch: 116 [256/334 (77%)] Loss: 25.109425
[2025-01-21 11:59:25] Starting validation for epoch: 116

Generation Samples:
Topic 44:
Generated: [CLS] insulted jailed committed choice box offer sweater admit [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] ranked hires republican aisles bolton judaism forgiven marcel [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 46:
Generated: [CLS] marc glove passes europe beats agree commit annexation [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 116 [0/10 (0%)] Loss: 32.967567

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 39, 41, 43, 44, 45, 47, 51, 52, 53, 54, 55, 56, 59, 60, 63, 64, 66, 67, 68]
Input sequence lengths: [449, 78, 334, 512, 64, 512, 453, 512, 123, 512, 268, 512, 204, 121, 512, 366, 512, 512, 449, 453, 121, 512, 512, 512, 453, 512, 512, 356, 512, 512, 512, 512]
Target phrase lengths: [5, 6, 4, 3, 5, 5, 6, 5, 8, 4, 8, 4, 5, 4, 4, 5, 5, 5, 4, 5, 5, 4, 4, 5, 8, 5, 8, 4, 8, 8, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.502, 1.063]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 56
Pred: 51 | True: 51
Pred: 49 | True: 53

Phrase Generation Sample:
Generated: [CLS] access to care [SEP] and and and and
Target: [CLS] access to care [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.1258
Generation Loss: 0.0025
Total Loss: 38.1283
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0025
Train Epoch: 117 [0/334 (0%)] Loss: 38.128258
Train Epoch: 117 [64/334 (19%)] Loss: 24.590219
Train Epoch: 117 [128/334 (38%)] Loss: 27.460758
Train Epoch: 117 [192/334 (57%)] Loss: 53.472145
Train Epoch: 117 [256/334 (77%)] Loss: 33.699772
[2025-01-21 11:59:29] Starting validation for epoch: 117

Generation Samples:
Topic 58:
Generated: [CLS] westchester li heck diamonds breathing hat winner bomb [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] defender trunks language murray translations astronomer ecuador harvey [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] lego novi glee ze deal dictator wrestling ja [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 117 [0/10 (0%)] Loss: 26.043266

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 39, 40, 41, 43, 44, 46, 48, 50, 52, 55, 56, 59, 60, 64, 65, 66, 67, 69, 70]
Input sequence lengths: [236, 512, 388, 512, 258, 388, 234, 512, 121, 145, 356, 366, 268, 512, 512, 123, 125, 512, 512, 512, 81, 512, 453, 512, 449, 512, 512, 512, 512, 453, 512, 512]
Target phrase lengths: [8, 8, 8, 8, 6, 4, 4, 4, 4, 7, 4, 3, 8, 6, 5, 8, 7, 6, 8, 5, 6, 4, 7, 5, 8, 6, 6, 5, 8, 8, 8, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.518, 1.073]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 47 | True: 70
Pred: 37 | True: 41
Pred: 66 | True: 69

Phrase Generation Sample:
Generated: [CLS] women ' s rights to reproductive [SEP] and
Target: [CLS] women ' s rights to reproductive [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 39.2294
Generation Loss: 0.0026
Total Loss: 39.2320
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0026
Train Epoch: 118 [0/334 (0%)] Loss: 39.231998
Train Epoch: 118 [64/334 (19%)] Loss: 30.695778
Train Epoch: 118 [128/334 (38%)] Loss: 43.747471
Train Epoch: 118 [192/334 (57%)] Loss: 28.284718
Train Epoch: 118 [256/334 (77%)] Loss: 34.480915
[2025-01-21 11:59:33] Starting validation for epoch: 118

Generation Samples:
Topic 41:
Generated: [CLS] tame skilled endowment kant elves twinkle roosevelt roman [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] beans loft natural malaysia floating gaming wat bart [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] chambers nucleus rustling changes toss idea republic colt [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 118 [0/10 (0%)] Loss: 35.810688

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 44, 48, 49, 50, 51, 56, 58, 60, 66, 67, 69, 70, 72]
Input sequence lengths: [512, 449, 123, 125, 512, 512, 512, 236, 512, 388, 388, 512, 268, 78, 512, 388, 92, 512, 512, 512, 512, 512, 512, 512, 512, 81, 512, 125, 512, 121, 512, 91]
Target phrase lengths: [4, 4, 7, 4, 8, 8, 4, 6, 6, 3, 3, 6, 8, 7, 4, 8, 6, 4, 8, 6, 8, 5, 5, 6, 6, 8, 7, 7, 8, 6, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.475, 1.081]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 58 | True: 58
Pred: 56 | True: 56
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] thoughtful dialogue [SEP] [SEP] myself [SEP] and [SEP]
Target: [CLS] thoughtful dialogue [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.0880
Generation Loss: 0.0037
Total Loss: 30.0917
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0037
Train Epoch: 119 [0/334 (0%)] Loss: 30.091705
Train Epoch: 119 [64/334 (19%)] Loss: 31.491125
Train Epoch: 119 [128/334 (38%)] Loss: 39.504841
Train Epoch: 119 [192/334 (57%)] Loss: 45.847401
Train Epoch: 119 [256/334 (77%)] Loss: 27.456402
[2025-01-21 11:59:37] Starting validation for epoch: 119

Generation Samples:
Topic 58:
Generated: [CLS] leasing government kant insane differ packed hopping birch [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] box words tomatoes simple caps gaming concerning doing [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] bargaining genetically hearts syn lux soul select hesitation [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 119 [0/10 (0%)] Loss: 38.753296

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 40, 41, 42, 45, 46, 49, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 70, 71]
Input sequence lengths: [512, 334, 512, 512, 234, 512, 236, 512, 512, 512, 366, 268, 334, 512, 268, 512, 78, 485, 512, 512, 512, 449, 87, 159, 453, 512, 512, 512, 449, 334, 512, 512]
Target phrase lengths: [6, 6, 6, 4, 7, 5, 8, 5, 8, 6, 5, 8, 4, 8, 8, 5, 7, 8, 8, 5, 4, 5, 8, 5, 7, 5, 5, 5, 4, 7, 6, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.448, 1.094]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 54
Pred: 53 | True: 53
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] taxed without representation [SEP] [SEP] [SEP] [SEP]
Target: [CLS] taxed without representation [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.1167
Generation Loss: 0.0031
Total Loss: 38.1198
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0031
Train Epoch: 120 [0/334 (0%)] Loss: 38.119770
Train Epoch: 120 [64/334 (19%)] Loss: 33.646339
Train Epoch: 120 [128/334 (38%)] Loss: 28.147024
Train Epoch: 120 [192/334 (57%)] Loss: 20.467152
Train Epoch: 120 [256/334 (77%)] Loss: 33.916275
[2025-01-21 11:59:41] Starting validation for epoch: 120

Generation Samples:
Topic 73:
Generated: [CLS] sabre governments citizenship organizational giro package gift bible [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] commit clause widespread fleeing attribute whisky morals republicans [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] syntax combined mutation hell greece lease metacritic skull [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 120 [0/10 (0%)] Loss: 30.267017

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 38, 39, 41, 43, 44, 45, 47, 49, 52, 54, 55, 58, 60, 61, 68, 69, 70, 71, 72]
Input sequence lengths: [453, 159, 512, 91, 512, 258, 388, 512, 121, 512, 449, 512, 268, 125, 512, 512, 512, 145, 512, 449, 512, 125, 204, 123, 512, 356, 145, 512, 145, 512, 512, 236]
Target phrase lengths: [5, 4, 8, 4, 6, 4, 3, 4, 4, 5, 4, 6, 8, 8, 4, 4, 5, 7, 4, 6, 5, 6, 8, 7, 4, 5, 8, 4, 6, 5, 3, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.488, 1.087]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 61 | True: 61
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] deliver basic services [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] deliver basic services [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 47.7959
Generation Loss: 0.0028
Total Loss: 47.7986
Topic Prediction Accuracy: 0.6875
Generation Perplexity: 1.0028
Train Epoch: 121 [0/334 (0%)] Loss: 47.798634
Train Epoch: 121 [64/334 (19%)] Loss: 20.633995
Train Epoch: 121 [128/334 (38%)] Loss: 21.777267
Train Epoch: 121 [192/334 (57%)] Loss: 17.097979
Train Epoch: 121 [256/334 (77%)] Loss: 45.031570
[2025-01-21 11:59:50] Starting validation for epoch: 121

Generation Samples:
Topic 46:
Generated: [CLS] wings mushrooms lied romans steer pine christians ham [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] howled wnba fades oak hamish gave nudged ideas [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] annexation averaging english owns accordion rowing musician initials [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 121 [0/10 (0%)] Loss: 26.552122

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 39, 41, 42, 46, 49, 51, 52, 55, 56, 58, 59, 60, 61, 63, 67, 68, 70]
Input sequence lengths: [234, 449, 512, 512, 356, 366, 512, 92, 234, 453, 121, 512, 512, 512, 512, 366, 512, 512, 512, 512, 512, 145, 92, 512, 236, 512, 356, 204, 512, 159, 234, 512]
Target phrase lengths: [8, 7, 4, 4, 5, 6, 8, 5, 7, 6, 4, 8, 8, 4, 4, 5, 6, 5, 7, 5, 5, 6, 7, 5, 8, 3, 3, 8, 6, 7, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.442, 1.072]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 37 | True: 37
Pred: 56 | True: 56
Pred: 58 | True: 58

Phrase Generation Sample:
Generated: [CLS] john lewis voting rights advancement act [SEP] and
Target: [CLS] john lewis voting rights advancement act [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 34.8880
Generation Loss: 0.0025
Total Loss: 34.8905
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0025
Train Epoch: 122 [0/334 (0%)] Loss: 34.890499
Train Epoch: 122 [64/334 (19%)] Loss: 21.736742
Train Epoch: 122 [128/334 (38%)] Loss: 39.210236
Train Epoch: 122 [192/334 (57%)] Loss: 35.908333
Train Epoch: 122 [256/334 (77%)] Loss: 30.861776
[2025-01-21 11:59:54] Starting validation for epoch: 122

Generation Samples:
Topic 41:
Generated: [CLS] [unused191] asteroid traded free dense wah brig postal [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] scandinavia sega liberals emmy algebra traders giro garrison [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 51:
Generated: [CLS] indie interactions commit newcomers system sentences seneca zip [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Validation Epoch: 122 [0/10 (0%)] Loss: 34.562038

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 39, 40, 41, 42, 43, 44, 46, 48, 54, 58, 60, 63, 65, 66, 69, 70, 72]
Input sequence lengths: [512, 512, 81, 512, 512, 125, 512, 453, 64, 137, 512, 512, 512, 512, 512, 512, 236, 388, 512, 453, 388, 121, 512, 125, 512, 512, 91, 512, 512, 512, 512, 453]
Target phrase lengths: [8, 6, 6, 5, 5, 7, 5, 8, 8, 7, 7, 4, 8, 8, 7, 7, 6, 4, 6, 7, 3, 4, 4, 5, 6, 4, 4, 4, 6, 4, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.499, 1.105]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 44 | True: 44
Pred: 65 | True: 65
Pred: 48 | True: 48

Phrase Generation Sample:
Generated: [CLS] motion to vacate the chair [SEP] and
Target: [CLS] motion to vacate the chair [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.6259
Generation Loss: 0.0022
Total Loss: 36.6280
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0022
Train Epoch: 123 [0/334 (0%)] Loss: 36.628048
Train Epoch: 123 [64/334 (19%)] Loss: 24.501186
Train Epoch: 123 [128/334 (38%)] Loss: 32.880394
Train Epoch: 123 [192/334 (57%)] Loss: 42.725971
Train Epoch: 123 [256/334 (77%)] Loss: 30.862314
[2025-01-21 11:59:58] Starting validation for epoch: 123

Generation Samples:
Topic 41:
Generated: [CLS] foreigner fk kn baseman xiao mit buddhism bei [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] judaism capitol module chickens kit sci botany umm [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 44:
Generated: [CLS] hilt doin chaired skull orchestras berlin mb cds [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 123 [0/10 (0%)] Loss: 35.892696

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 41, 43, 44, 45, 47, 48, 54, 55, 60, 61, 64, 66, 67, 69, 70, 72]
Input sequence lengths: [236, 236, 512, 512, 388, 123, 512, 145, 512, 81, 512, 234, 91, 512, 512, 512, 512, 159, 512, 512, 125, 512, 512, 388, 512, 512, 512, 512, 512, 356, 159, 512]
Target phrase lengths: [8, 8, 6, 8, 4, 4, 5, 6, 6, 6, 5, 4, 4, 5, 7, 4, 8, 7, 5, 8, 5, 8, 4, 3, 4, 4, 3, 8, 5, 4, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.513, 1.103]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 70 | True: 70
Pred: 70 | True: 70
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] women ' s rights to reproductive [SEP] [SEP]
Target: [CLS] women ' s rights to reproductive [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 45.2721
Generation Loss: 0.0027
Total Loss: 45.2748
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0027
Train Epoch: 124 [0/334 (0%)] Loss: 45.274849
Train Epoch: 124 [64/334 (19%)] Loss: 41.413994
Train Epoch: 124 [128/334 (38%)] Loss: 29.882397
Train Epoch: 124 [192/334 (57%)] Loss: 25.124657
Train Epoch: 124 [256/334 (77%)] Loss: 28.943207
[2025-01-21 12:00:02] Starting validation for epoch: 124

Generation Samples:
Topic 68:
Generated: [CLS] disciples ribbons midst live dam decision named union [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] lansing detainees vase passports potion religions violinist pasha [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] germain goethe greece euros doctrines institutions wings sweater [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 124 [0/10 (0%)] Loss: 47.972370

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 40, 41, 42, 43, 47, 49, 50, 52, 54, 57, 58, 60, 64, 66, 69, 70, 73]
Input sequence lengths: [125, 512, 512, 512, 209, 125, 236, 512, 125, 512, 512, 512, 453, 512, 512, 512, 512, 145, 512, 123, 234, 512, 388, 125, 145, 512, 512, 512, 512, 485, 512, 512]
Target phrase lengths: [4, 7, 4, 5, 7, 6, 8, 5, 7, 8, 6, 5, 7, 5, 6, 7, 5, 6, 5, 8, 4, 5, 3, 5, 8, 7, 5, 5, 4, 5, 5, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.560, 1.158]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 36 | True: 36
Pred: 58 | True: 58

Phrase Generation Sample:
Generated: [CLS] votes cast [SEP] and [SEP] [SEP] [SEP] and
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 27.0473
Generation Loss: 0.0024
Total Loss: 27.0497
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0024
Train Epoch: 125 [0/334 (0%)] Loss: 27.049706
Train Epoch: 125 [64/334 (19%)] Loss: 39.148636
Train Epoch: 125 [128/334 (38%)] Loss: 22.372871
Train Epoch: 125 [192/334 (57%)] Loss: 30.630777
Train Epoch: 125 [256/334 (77%)] Loss: 40.411625
[2025-01-21 12:00:06] Starting validation for epoch: 125

Generation Samples:
Topic 58:
Generated: [CLS] 1758 joseph reich wings ting say de bombs [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] jailed gift ethics n liberals budget dinosaur greece [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 38:
Generated: [CLS] hungary balkans defining vague chaos antiquities 1807 clarify [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 125 [0/10 (0%)] Loss: 25.499826

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 42, 43, 46, 48, 49, 50, 52, 54, 55, 58, 59, 60, 61, 63, 64, 65, 66, 67, 72]
Input sequence lengths: [512, 268, 512, 512, 81, 512, 366, 512, 512, 145, 512, 512, 159, 512, 512, 512, 512, 81, 356, 512, 512, 512, 512, 512, 512, 512, 91, 512, 356, 512, 125, 512]
Target phrase lengths: [6, 8, 7, 8, 6, 6, 5, 7, 4, 7, 8, 4, 4, 6, 6, 5, 4, 6, 5, 6, 6, 4, 4, 3, 5, 8, 6, 6, 4, 6, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.524, 1.122]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 58 | True: 58
Pred: 41 | True: 41
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] public service internships [SEP] [PAD] [SEP] [SEP]
Target: [CLS] public service internships [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 24.4424
Generation Loss: 0.0025
Total Loss: 24.4449
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0025
Train Epoch: 126 [0/334 (0%)] Loss: 24.444878
Train Epoch: 126 [64/334 (19%)] Loss: 27.254173
Train Epoch: 126 [128/334 (38%)] Loss: 44.344978
Train Epoch: 126 [192/334 (57%)] Loss: 54.245152
Train Epoch: 126 [256/334 (77%)] Loss: 25.610931
[2025-01-21 12:00:15] Starting validation for epoch: 126

Generation Samples:
Topic 64:
Generated: [CLS] specify intentions liv ticket lao democrat albania government [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 36:
Generated: [CLS] hess grant myspace modernization expanded giovanni john tak [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] chambers live shook ponce herrera saying klan religion [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 126 [0/10 (0%)] Loss: 31.780603

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 39, 40, 41, 43, 46, 50, 53, 54, 57, 59, 60, 61, 64, 66, 68, 69, 70, 73]
Input sequence lengths: [512, 366, 159, 512, 512, 204, 512, 512, 512, 512, 485, 236, 512, 125, 512, 334, 366, 512, 512, 209, 121, 512, 453, 209, 64, 204, 123, 512, 512, 123, 388, 236]
Target phrase lengths: [6, 3, 4, 5, 6, 8, 6, 6, 5, 4, 5, 8, 6, 7, 5, 4, 5, 4, 5, 4, 6, 6, 7, 4, 8, 8, 7, 5, 5, 7, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.508, 1.123]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 50 | True: 50
Pred: 59 | True: 59
Pred: 61 | True: 61

Phrase Generation Sample:
Generated: [CLS] selection of the speaker [SEP] [SEP] and [SEP]
Target: [CLS] selection of the speaker [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.3822
Generation Loss: 0.0022
Total Loss: 32.3844
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0022
Train Epoch: 127 [0/334 (0%)] Loss: 32.384411
Train Epoch: 127 [64/334 (19%)] Loss: 42.331665
Train Epoch: 127 [128/334 (38%)] Loss: 32.220604
Train Epoch: 127 [192/334 (57%)] Loss: 42.888470
Train Epoch: 127 [256/334 (77%)] Loss: 26.136824
[2025-01-21 12:00:19] Starting validation for epoch: 127

Generation Samples:
Topic 65:
Generated: [CLS] desirable declaring distributors ferns political jesuits greeks moderately [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 59:
Generated: [CLS] shipped settle think pigeon handled active lang convention [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] bargaining 126 world racist islam hearing english fun [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 127 [0/10 (0%)] Loss: 31.424131

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 40, 41, 42, 43, 47, 48, 49, 50, 55, 56, 58, 59, 60, 61, 65, 70, 72, 73]
Input sequence lengths: [453, 81, 145, 512, 366, 512, 209, 512, 512, 512, 123, 236, 356, 512, 81, 512, 512, 356, 512, 512, 356, 512, 512, 123, 159, 125, 512, 512, 449, 512, 91, 512]
Target phrase lengths: [7, 6, 6, 6, 3, 6, 4, 5, 5, 5, 8, 8, 5, 5, 5, 8, 4, 5, 5, 6, 4, 7, 4, 8, 7, 4, 5, 7, 4, 7, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.545, 1.059]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 48 | True: 48
Pred: 35 | True: 35

Phrase Generation Sample:
Generated: [CLS] responsibility to serve our constituents [SEP] [SEP] [SEP]
Target: [CLS] responsibility to serve our constituents [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.9941
Generation Loss: 0.0023
Total Loss: 38.9963
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0023
Train Epoch: 128 [0/334 (0%)] Loss: 38.996323
Train Epoch: 128 [64/334 (19%)] Loss: 40.974949
Train Epoch: 128 [128/334 (38%)] Loss: 43.059589
Train Epoch: 128 [192/334 (57%)] Loss: 44.188408
Train Epoch: 128 [256/334 (77%)] Loss: 42.896297
[2025-01-21 12:00:23] Starting validation for epoch: 128

Generation Samples:
Topic 38:
Generated: [CLS] subgenus arrests choking wheel blazing called blink card [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] doctrine composers negotiating rebuilding persian mind answer expand [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] foliage ty dem justice lei gaming ale fighter [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 128 [0/10 (0%)] Loss: 38.152443

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 40, 41, 43, 47, 49, 54, 55, 58, 59, 60, 61, 62, 65, 66, 67, 73]
Input sequence lengths: [159, 123, 87, 145, 512, 137, 125, 512, 512, 512, 512, 209, 512, 512, 125, 87, 512, 125, 512, 512, 512, 512, 512, 512, 512, 366, 145, 512, 356, 512, 512, 512]
Target phrase lengths: [4, 8, 6, 7, 5, 7, 5, 6, 8, 8, 6, 4, 6, 4, 6, 8, 7, 7, 5, 8, 8, 7, 8, 8, 8, 7, 8, 3, 4, 8, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.536, 1.082]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 61 | True: 61
Pred: 43 | True: 43
Pred: 62 | True: 62

Phrase Generation Sample:
Generated: [CLS] officer morale [SEP] [SEP] [SEP] and [SEP] and
Target: [CLS] officer morale [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 41.2516
Generation Loss: 0.0023
Total Loss: 41.2539
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0023
Train Epoch: 129 [0/334 (0%)] Loss: 41.253880
Train Epoch: 129 [64/334 (19%)] Loss: 41.929585
Train Epoch: 129 [128/334 (38%)] Loss: 30.355087
Train Epoch: 129 [192/334 (57%)] Loss: 43.046677
Train Epoch: 129 [256/334 (77%)] Loss: 26.838829
[2025-01-21 12:00:27] Starting validation for epoch: 129

Generation Samples:
Topic 73:
Generated: [CLS] leasing feng con new jar burying spain england [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] allergic cognition lightning ale repeatedly riga seat hindus [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] hearts hearts play immigrant shipping meet name bryan [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 129 [0/10 (0%)] Loss: 34.979500

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 39, 40, 41, 43, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 59, 60, 64, 66, 70]
Input sequence lengths: [64, 512, 512, 512, 512, 512, 449, 512, 121, 512, 453, 512, 334, 512, 236, 78, 81, 512, 512, 512, 125, 366, 125, 512, 356, 512, 512, 512, 512, 92, 123, 234]
Target phrase lengths: [5, 7, 4, 8, 8, 7, 4, 8, 5, 8, 7, 5, 4, 4, 8, 7, 5, 6, 5, 4, 7, 6, 7, 5, 4, 3, 5, 8, 7, 5, 7, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.516, 1.109]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 34 | True: 34
Pred: 36 | True: 36
Pred: 71 | True: 49

Phrase Generation Sample:
Generated: [CLS] pledge of allegiance [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] pledge of allegiance [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.3600
Generation Loss: 0.0022
Total Loss: 26.3621
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0022
Train Epoch: 130 [0/334 (0%)] Loss: 26.362144
Train Epoch: 130 [64/334 (19%)] Loss: 33.486046
Train Epoch: 130 [128/334 (38%)] Loss: 21.396994
Train Epoch: 130 [192/334 (57%)] Loss: 32.607311
Train Epoch: 130 [256/334 (77%)] Loss: 40.096172
[2025-01-21 12:00:31] Starting validation for epoch: 130

Generation Samples:
Topic 59:
Generated: [CLS] jewellery think lanka insider nazi nyc neuroscience officially [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] comfortably spitting kidney bryan muffled furnishings sets locke [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 38:
Generated: [CLS] treaties constitutional officially ave rome attic ibm pluto [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 130 [0/10 (0%)] Loss: 33.763580

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 40, 41, 42, 43, 44, 47, 49, 52, 54, 55, 60, 65, 67, 68, 69, 70, 72]
Input sequence lengths: [512, 356, 512, 512, 204, 204, 512, 268, 236, 512, 123, 512, 204, 512, 512, 512, 125, 64, 512, 388, 91, 512, 512, 512, 512, 512, 512, 356, 356, 453, 512, 512]
Target phrase lengths: [4, 4, 6, 5, 8, 5, 4, 8, 8, 4, 8, 8, 4, 5, 5, 5, 5, 7, 8, 3, 4, 6, 6, 6, 8, 6, 5, 4, 3, 8, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.528, 1.087]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 49 | True: 49
Pred: 33 | True: 55
Pred: 54 | True: 54

Phrase Generation Sample:
Generated: [CLS] trump presidency [SEP] [SEP] [PAD] [PAD] and [SEP]
Target: [CLS] trump presidency [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 38.6505
Generation Loss: 0.0026
Total Loss: 38.6530
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0026
Train Epoch: 131 [0/334 (0%)] Loss: 38.653034
Train Epoch: 131 [64/334 (19%)] Loss: 21.645233
Train Epoch: 131 [128/334 (38%)] Loss: 34.086258
Train Epoch: 131 [192/334 (57%)] Loss: 39.131813
Train Epoch: 131 [256/334 (77%)] Loss: 45.356071
[2025-01-21 12:00:40] Starting validation for epoch: 131

Generation Samples:
Topic 64:
Generated: [CLS] socialists hindu senators mathematics mandolin na religions intentions [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 41:
Generated: [CLS] netherlands mind forewings turks bowls millions colts linux [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] plata java into inner spanish helm once serves [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 131 [0/10 (0%)] Loss: 31.056065

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 41, 43, 44, 48, 52, 54, 55, 58, 60, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73]
Input sequence lengths: [236, 512, 512, 512, 356, 512, 512, 512, 125, 449, 512, 512, 512, 512, 209, 512, 356, 512, 137, 512, 512, 204, 512, 512, 453, 388, 356, 81, 512, 64, 91, 123]
Target phrase lengths: [6, 5, 5, 6, 4, 8, 4, 4, 7, 7, 4, 6, 5, 4, 7, 6, 4, 8, 7, 4, 8, 4, 5, 8, 5, 4, 5, 8, 4, 7, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.507, 1.111]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 47 | True: 70
Pred: 66 | True: 66
Pred: 66 | True: 66

Phrase Generation Sample:
Generated: [CLS] criminalize abortion care [SEP] and and and
Target: [CLS] criminalize abortion care [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.1662
Generation Loss: 0.0028
Total Loss: 36.1690
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0028
Train Epoch: 132 [0/334 (0%)] Loss: 36.169037
Train Epoch: 132 [64/334 (19%)] Loss: 38.444778
Train Epoch: 132 [128/334 (38%)] Loss: 26.878475
Train Epoch: 132 [192/334 (57%)] Loss: 24.336662
Train Epoch: 132 [256/334 (77%)] Loss: 32.874767
[2025-01-21 12:00:44] Starting validation for epoch: 132

Generation Samples:
Topic 41:
Generated: [CLS] taxa nordic storm scott collegiate daniels gillespie phil [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] [unused332] kant christmas guilt replacing temperament drugs politically [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] scope garbage timothy did anders diagnosed aura financially [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 132 [0/10 (0%)] Loss: 23.116737

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 41, 43, 44, 47, 49, 53, 54, 55, 60, 61, 63, 65, 68, 69, 71, 72, 73]
Input sequence lengths: [512, 145, 453, 512, 512, 512, 356, 512, 125, 91, 125, 388, 449, 356, 512, 512, 356, 512, 512, 512, 334, 204, 334, 512, 209, 512, 512, 388, 512, 121, 159, 204]
Target phrase lengths: [4, 8, 7, 4, 4, 4, 3, 5, 7, 4, 6, 8, 6, 5, 4, 8, 4, 8, 6, 7, 6, 8, 7, 5, 7, 6, 5, 4, 4, 7, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.514, 1.073]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 49 | True: 49
Pred: 35 | True: 35
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] confront china [SEP] and [SEP] and and and
Target: [CLS] confront china [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.8753
Generation Loss: 0.0026
Total Loss: 25.8779
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0026
Train Epoch: 133 [0/334 (0%)] Loss: 25.877851
Train Epoch: 133 [64/334 (19%)] Loss: 28.160524
Train Epoch: 133 [128/334 (38%)] Loss: 28.467649
Train Epoch: 133 [192/334 (57%)] Loss: 31.866852
Train Epoch: 133 [256/334 (77%)] Loss: 22.112841
[2025-01-21 12:00:48] Starting validation for epoch: 133

Generation Samples:
Topic 59:
Generated: [CLS] judas boat soccer flag shook pitch bryan juliet [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] passengers monkey architect brig walks play twitching borough [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 46:
Generated: [CLS] nikolai swore sanity convince deal admissions passage sets [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 133 [0/10 (0%)] Loss: 34.104862

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 37, 38, 39, 41, 42, 43, 48, 54, 56, 57, 59, 60, 63, 64, 65, 66, 68, 71]
Input sequence lengths: [512, 512, 204, 512, 512, 268, 234, 485, 449, 512, 121, 512, 453, 81, 512, 512, 125, 512, 512, 512, 512, 64, 366, 512, 145, 366, 449, 512, 512, 123, 512, 512]
Target phrase lengths: [6, 6, 5, 8, 7, 8, 8, 7, 4, 5, 5, 6, 5, 8, 6, 7, 7, 8, 6, 8, 7, 7, 3, 5, 6, 5, 4, 5, 6, 4, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.483, 1.139]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 41 | True: 41
Pred: 68 | True: 68

Phrase Generation Sample:
Generated: [CLS] taxed without representation [SEP] [SEP] [SEP].
Target: [CLS] taxed without representation [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.7670
Generation Loss: 0.0021
Total Loss: 32.7691
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0021
Train Epoch: 134 [0/334 (0%)] Loss: 32.769108
Train Epoch: 134 [64/334 (19%)] Loss: 22.529156
Train Epoch: 134 [128/334 (38%)] Loss: 30.528467
Train Epoch: 134 [192/334 (57%)] Loss: 41.195499
Train Epoch: 134 [256/334 (77%)] Loss: 24.244251
[2025-01-21 12:00:52] Starting validation for epoch: 134

Generation Samples:
Topic 68:
Generated: [CLS] expands sumo doorbell shout offer systemic truly explanation [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] plastic language rustling bryan titans altered trenton parasite [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] czech bucks randomly mongolian phillies indians pamphlet baseman [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 134 [0/10 (0%)] Loss: 23.999462

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 40, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 57, 58, 60, 63, 64, 68, 69, 70, 72]
Input sequence lengths: [204, 125, 334, 81, 512, 512, 512, 512, 512, 236, 512, 485, 512, 512, 91, 388, 81, 512, 512, 512, 268, 512, 268, 236, 512, 268, 512, 512, 512, 512, 512, 485]
Target phrase lengths: [6, 4, 8, 8, 6, 5, 8, 5, 4, 7, 5, 5, 5, 6, 4, 3, 5, 8, 4, 5, 8, 8, 8, 6, 5, 8, 4, 8, 5, 6, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.503, 1.103]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 66 | True: 68
Pred: 43 | True: 43
Pred: 53 | True: 53

Phrase Generation Sample:
Generated: [CLS] rights of every person [SEP] and [SEP] and
Target: [CLS] rights of every person [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 40.5920
Generation Loss: 0.0024
Total Loss: 40.5944
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0024
Train Epoch: 135 [0/334 (0%)] Loss: 40.594421
Train Epoch: 135 [64/334 (19%)] Loss: 25.196564
Train Epoch: 135 [128/334 (38%)] Loss: 24.302828
Train Epoch: 135 [192/334 (57%)] Loss: 26.982536
Train Epoch: 135 [256/334 (77%)] Loss: 29.668224
[2025-01-21 12:00:55] Starting validation for epoch: 135

Generation Samples:
Topic 36:
Generated: [CLS] sailors axle anything rule gaming ko arrow lease [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] gunnar det society cramer fungi christmas upgrade fortune [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] peptide medicare bayern gene relatively unnatural dj phil [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 135 [0/10 (0%)] Loss: 22.526436

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 43, 47, 49, 55, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 71]
Input sequence lengths: [512, 87, 366, 449, 449, 388, 512, 449, 512, 512, 123, 512, 388, 512, 512, 512, 485, 512, 123, 145, 512, 512, 512, 356, 512, 366, 512, 512, 356, 449, 512, 512]
Target phrase lengths: [6, 6, 5, 4, 7, 8, 8, 6, 5, 4, 4, 6, 3, 5, 8, 5, 7, 8, 8, 8, 5, 5, 6, 5, 4, 7, 5, 8, 4, 4, 7, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.517, 1.152]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 62 | True: 62
Pred: 59 | True: 59

Phrase Generation Sample:
Generated: [CLS] republican commitment to america [SEP] [SEP] [SEP] [SEP]
Target: [CLS] republican commitment to america [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.1576
Generation Loss: 0.0023
Total Loss: 31.1599
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0023
Train Epoch: 136 [0/334 (0%)] Loss: 31.159908
Train Epoch: 136 [64/334 (19%)] Loss: 26.138020
Train Epoch: 136 [128/334 (38%)] Loss: 40.304424
Train Epoch: 136 [192/334 (57%)] Loss: 36.068317
Train Epoch: 136 [256/334 (77%)] Loss: 32.951042
[2025-01-21 12:01:05] Starting validation for epoch: 136

Generation Samples:
Topic 73:
Generated: [CLS] tyrol database spatial finances leon [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] manfred kidding netherlands editors explosive [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] paso horatio uss bryan hat [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 136 [0/10 (0%)] Loss: 27.728256

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 41, 42, 43, 44, 45, 46, 48, 53, 54, 55, 57, 62, 64, 67, 71, 73]
Input sequence lengths: [485, 87, 512, 334, 512, 485, 512, 512, 125, 512, 449, 356, 512, 449, 512, 512, 334, 512, 145, 512, 512, 512, 512, 512, 258, 125, 81, 512, 81, 512, 209, 512]
Target phrase lengths: [8, 8, 8, 4, 4, 8, 5, 6, 6, 5, 4, 4, 4, 4, 6, 8, 4, 8, 6, 5, 3, 4, 5, 4, 4, 4, 5, 4, 8, 4, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.464, 1.088]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 57 | True: 57
Pred: 62 | True: 62
Pred: 45 | True: 45

Phrase Generation Sample:
Generated: [CLS] 2022 istaf world cup [SEP] and
Target: [CLS] 2022 istaf world cup [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 43.1420
Generation Loss: 0.0023
Total Loss: 43.1443
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0023
Train Epoch: 137 [0/334 (0%)] Loss: 43.144268
Train Epoch: 137 [64/334 (19%)] Loss: 21.328817
Train Epoch: 137 [128/334 (38%)] Loss: 20.973129
Train Epoch: 137 [192/334 (57%)] Loss: 25.965906
Train Epoch: 137 [256/334 (77%)] Loss: 41.254910
[2025-01-21 12:01:09] Starting validation for epoch: 137

Generation Samples:
Topic 40:
Generated: [CLS] puck skull fares thailand marlins erwin hume doors [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] relational punishment insider sides job proper bunny genetics [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] ricardo real cocaine redskins socialists dealings hands thing [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 137 [0/10 (0%)] Loss: 27.269205

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 41, 43, 47, 50, 51, 53, 54, 56, 58, 60, 66, 67, 68, 70, 71]
Input sequence lengths: [512, 512, 268, 78, 449, 334, 512, 512, 512, 334, 125, 92, 449, 204, 512, 512, 512, 204, 449, 512, 268, 268, 512, 236, 125, 453, 449, 512, 512, 512, 512, 123]
Target phrase lengths: [6, 7, 8, 7, 7, 6, 5, 4, 8, 4, 7, 6, 4, 8, 6, 7, 4, 4, 4, 4, 8, 8, 8, 8, 6, 5, 5, 4, 8, 6, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.542, 1.145]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 36
Pred: 67 | True: 67
Pred: 37 | True: 41

Phrase Generation Sample:
Generated: [CLS] future built on freedom [SEP] and [SEP] and
Target: [CLS] future built on freedom [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 52.1619
Generation Loss: 0.0019
Total Loss: 52.1637
Topic Prediction Accuracy: 0.6562
Generation Perplexity: 1.0019
Train Epoch: 138 [0/334 (0%)] Loss: 52.163731
Train Epoch: 138 [64/334 (19%)] Loss: 20.979118
Train Epoch: 138 [128/334 (38%)] Loss: 33.445961
Train Epoch: 138 [192/334 (57%)] Loss: 27.405979
Train Epoch: 138 [256/334 (77%)] Loss: 27.158476
[2025-01-21 12:01:12] Starting validation for epoch: 138

Generation Samples:
Topic 52:
Generated: [CLS] genetics codex messing card fisted vinci philosophical normal [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 59:
Generated: [CLS] united manning nee hartford sydney trunks hangs songwriter [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] guantanamo weapon cyber taught hands lips swore gee [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 138 [0/10 (0%)] Loss: 19.302563

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 40, 41, 43, 48, 49, 50, 51, 54, 55, 59, 60, 63, 64, 66, 70, 73]
Input sequence lengths: [512, 512, 356, 512, 512, 512, 512, 123, 512, 512, 512, 356, 366, 512, 512, 512, 145, 512, 356, 453, 92, 512, 236, 81, 64, 512, 512, 512, 512, 512, 145, 209]
Target phrase lengths: [5, 7, 4, 7, 5, 4, 5, 7, 5, 7, 4, 5, 5, 4, 7, 5, 6, 5, 4, 5, 6, 6, 6, 8, 5, 6, 8, 4, 4, 8, 7, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.535, 1.086]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 36
Pred: 41 | True: 41
Pred: 55 | True: 55

Phrase Generation Sample:
Generated: [CLS] opportunity for all [SEP] [SEP] [SEP] [SEP] [SEP]
Target: [CLS] opportunity for all [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 47.1878
Generation Loss: 0.0022
Total Loss: 47.1899
Topic Prediction Accuracy: 0.6562
Generation Perplexity: 1.0022
Train Epoch: 139 [0/334 (0%)] Loss: 47.189941
Train Epoch: 139 [64/334 (19%)] Loss: 35.742195
Train Epoch: 139 [128/334 (38%)] Loss: 27.092667
Train Epoch: 139 [192/334 (57%)] Loss: 35.521313
Train Epoch: 139 [256/334 (77%)] Loss: 41.654919
[2025-01-21 12:01:16] Starting validation for epoch: 139

Generation Samples:
Topic 59:
Generated: [CLS] subdued contracting astro greece bundled wings fate inter [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] splash institute abbot rings goin nomination dysfunction ether [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 40:
Generated: [CLS] fictional damned sino lattice linux foreign thoughtful hedge [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 139 [0/10 (0%)] Loss: 22.923326

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 39, 41, 43, 44, 45, 49, 51, 52, 54, 55, 56, 61, 64, 66, 70]
Input sequence lengths: [512, 512, 356, 512, 145, 125, 356, 236, 145, 159, 512, 512, 449, 512, 236, 125, 268, 123, 137, 125, 78, 512, 512, 236, 125, 512, 512, 121, 512, 123, 512, 268]
Target phrase lengths: [4, 5, 4, 6, 8, 5, 5, 8, 8, 7, 6, 8, 5, 7, 6, 7, 8, 8, 4, 4, 6, 5, 4, 8, 6, 8, 4, 4, 4, 7, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.565, 1.162]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 23 | True: 54
Pred: 52 | True: 52
Pred: 55 | True: 55

Phrase Generation Sample:
Generated: [CLS] douglass commonwealth [SEP] [SEP] and and and [SEP]
Target: [CLS] douglass commonwealth [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 44.9843
Generation Loss: 0.0023
Total Loss: 44.9866
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0023
Train Epoch: 140 [0/334 (0%)] Loss: 44.986622
Train Epoch: 140 [64/334 (19%)] Loss: 43.920597
Train Epoch: 140 [128/334 (38%)] Loss: 43.944508
Train Epoch: 140 [192/334 (57%)] Loss: 23.788092
Train Epoch: 140 [256/334 (77%)] Loss: 31.862129
[2025-01-21 12:01:20] Starting validation for epoch: 140

Generation Samples:
Topic 43:
Generated: [CLS] suffix nagar yankee managerial midfielder mcc [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 50:
Generated: [CLS] kgb brains shouldn trap normal gears [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] uefa hopped ballast knowledge box factual [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 140 [0/10 (0%)] Loss: 34.245861

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 40, 43, 44, 45, 47, 48, 51, 53, 54, 56, 57, 58, 60, 61, 64, 65, 66, 70, 72, 73]
Input sequence lengths: [91, 512, 512, 512, 234, 512, 209, 512, 236, 334, 81, 449, 512, 485, 512, 512, 512, 159, 137, 234, 258, 512, 92, 512, 91, 125, 512, 512, 123, 209, 512, 512]
Target phrase lengths: [4, 4, 8, 6, 4, 4, 4, 8, 7, 4, 6, 7, 8, 5, 6, 8, 4, 5, 7, 4, 6, 6, 5, 6, 4, 6, 5, 4, 7, 4, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.587, 1.191]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 72 | True: 72
Pred: 60 | True: 60
Pred: 38 | True: 45

Phrase Generation Sample:
Generated: [CLS] covid [SEP] [SEP] [SEP] [SEP] and and
Target: [CLS] covid [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 20.7127
Generation Loss: 0.0023
Total Loss: 20.7150
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0023
Train Epoch: 141 [0/334 (0%)] Loss: 20.715004
Train Epoch: 141 [64/334 (19%)] Loss: 33.732334
Train Epoch: 141 [128/334 (38%)] Loss: 46.028782
Train Epoch: 141 [192/334 (57%)] Loss: 41.180702
Train Epoch: 141 [256/334 (77%)] Loss: 39.378311
[2025-01-21 12:01:30] Starting validation for epoch: 141

Generation Samples:
Topic 58:
Generated: [CLS] renamed lake houses sony wry mutually leagues cutter [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] contract scientology leg wing dev sneaking heck mixing [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] camel arrests cheap officially endowment incorporated planning goin [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 141 [0/10 (0%)] Loss: 31.023203

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 39, 40, 41, 42, 43, 46, 48, 49, 53, 54, 55, 58, 60, 61, 62, 63, 65, 67, 70]
Input sequence lengths: [512, 512, 512, 64, 512, 334, 512, 159, 236, 512, 512, 512, 512, 512, 64, 145, 125, 81, 87, 512, 512, 137, 512, 123, 512, 512, 121, 512, 87, 356, 125, 512]
Target phrase lengths: [4, 4, 5, 5, 4, 4, 4, 4, 8, 8, 5, 4, 5, 6, 8, 8, 6, 8, 8, 4, 7, 4, 8, 4, 7, 6, 5, 5, 6, 5, 7, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.599, 1.079]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 38 | True: 54
Pred: 49 | True: 49
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] douglass commonwealth [SEP] and and and and and
Target: [CLS] douglass commonwealth [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.3687
Generation Loss: 0.0023
Total Loss: 31.3711
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0023
Train Epoch: 142 [0/334 (0%)] Loss: 31.371067
Train Epoch: 142 [64/334 (19%)] Loss: 23.818768
Train Epoch: 142 [128/334 (38%)] Loss: 34.347706
Train Epoch: 142 [192/334 (57%)] Loss: 22.300095
Train Epoch: 142 [256/334 (77%)] Loss: 30.645559
[2025-01-21 12:01:33] Starting validation for epoch: 142

Generation Samples:
Topic 41:
Generated: [CLS] timothy clemens sweetly truss adjoining vents paul barns [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] dev axe assign outright ching planes turks disgrace [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 58:
Generated: [CLS] accountability looting rapids translations seneca linguistic deal guitars [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 142 [0/10 (0%)] Loss: 29.391890

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 40, 41, 43, 46, 49, 50, 51, 54, 55, 56, 57, 60, 61, 63, 64, 73]
Input sequence lengths: [512, 356, 512, 453, 209, 512, 512, 512, 78, 356, 512, 512, 145, 449, 125, 512, 512, 159, 512, 64, 512, 512, 512, 512, 356, 512, 449, 512, 485, 485, 512, 512]
Target phrase lengths: [6, 4, 7, 7, 4, 5, 8, 6, 7, 3, 5, 4, 8, 5, 7, 3, 4, 4, 7, 5, 6, 4, 8, 5, 5, 8, 7, 4, 7, 5, 8, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.557, 1.104]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 49 | True: 49
Pred: 55 | True: 55
Pred: 63 | True: 63

Phrase Generation Sample:
Generated: [CLS] veterans ' accountability measures [SEP] [SEP] and and
Target: [CLS] veterans ' accountability measures [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 46.6387
Generation Loss: 0.0022
Total Loss: 46.6409
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0022
Train Epoch: 143 [0/334 (0%)] Loss: 46.640858
Train Epoch: 143 [64/334 (19%)] Loss: 40.556587
Train Epoch: 143 [128/334 (38%)] Loss: 37.597694
Train Epoch: 143 [192/334 (57%)] Loss: 33.364098
Train Epoch: 143 [256/334 (77%)] Loss: 32.879978
[2025-01-21 12:01:37] Starting validation for epoch: 143

Generation Samples:
Topic 43:
Generated: [CLS] plato bucks bundesliga midfielder letting sailed mccormick walls [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] redskins admit system dot grammar answers script clerical [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] [unused143] feudal gel bug inherited shan keyboard musica [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 143 [0/10 (0%)] Loss: 24.230345

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 41, 43, 44, 46, 48, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 66, 67, 69, 71]
Input sequence lengths: [81, 512, 512, 453, 78, 512, 449, 453, 512, 356, 123, 388, 366, 258, 449, 159, 334, 512, 125, 512, 512, 512, 512, 512, 356, 485, 512, 512, 356, 366, 512, 449]
Target phrase lengths: [6, 6, 6, 8, 7, 8, 5, 8, 8, 5, 8, 3, 3, 6, 4, 4, 8, 4, 8, 5, 8, 4, 8, 6, 4, 7, 7, 6, 3, 3, 4, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.547, 1.129]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 48 | True: 48
Pred: 60 | True: 60
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] nominate kevin hern [SEP] and [SEP] and
Target: [CLS] nominate kevin hern [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 25.9510
Generation Loss: 0.0014
Total Loss: 25.9524
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0014
Train Epoch: 144 [0/334 (0%)] Loss: 25.952372
Train Epoch: 144 [64/334 (19%)] Loss: 34.958267
Train Epoch: 144 [128/334 (38%)] Loss: 26.925137
Train Epoch: 144 [192/334 (57%)] Loss: 29.613892
Train Epoch: 144 [256/334 (77%)] Loss: 27.721594
[2025-01-21 12:01:41] Starting validation for epoch: 144

Generation Samples:
Topic 58:
Generated: [CLS] dresses greek dunn bryan texans ramon control foreign [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] alliances admit experimented math biography pts nomination shrimp [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] contractors furnishings finance witches organ electrically foreign varies [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 144 [0/10 (0%)] Loss: 37.190083

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 40, 41, 42, 43, 44, 45, 51, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69]
Input sequence lengths: [137, 512, 258, 512, 512, 512, 512, 123, 125, 453, 125, 92, 125, 512, 512, 388, 512, 512, 268, 123, 366, 159, 512, 512, 512, 512, 123, 204, 121, 512, 512, 512]
Target phrase lengths: [4, 8, 4, 3, 5, 8, 8, 8, 7, 8, 6, 5, 4, 5, 8, 3, 8, 4, 8, 7, 5, 4, 8, 5, 6, 6, 4, 6, 5, 6, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.520, 1.117]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 67 | True: 67
Pred: 42 | True: 38

Phrase Generation Sample:
Generated: [CLS] kevin mccarthy [SEP] and [SEP] [SEP] and and
Target: [CLS] kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.9194
Generation Loss: 0.0019
Total Loss: 32.9214
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0019
Train Epoch: 145 [0/334 (0%)] Loss: 32.921368
Train Epoch: 145 [64/334 (19%)] Loss: 13.780961
Train Epoch: 145 [128/334 (38%)] Loss: 30.404442
Train Epoch: 145 [192/334 (57%)] Loss: 43.978275
Train Epoch: 145 [256/334 (77%)] Loss: 19.068850
[2025-01-21 12:01:45] Starting validation for epoch: 145

Generation Samples:
Topic 66:
Generated: [CLS] escaping cheap unhappy det sen spirits earthly lopez [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] aerospace bangs receptor giants atom used shadowy sentences [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] gerhard crossed amber technically municipality leafs laurent boxed [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 145 [0/10 (0%)] Loss: 21.282187

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 41, 42, 43, 44, 48, 51, 52, 54, 55, 56, 59, 61, 66, 67, 68, 69, 73]
Input sequence lengths: [512, 125, 78, 356, 512, 512, 512, 512, 388, 512, 512, 258, 449, 123, 78, 209, 512, 92, 159, 78, 512, 366, 512, 512, 78, 512, 453, 512, 204, 81, 453, 512]
Target phrase lengths: [5, 7, 7, 4, 6, 8, 4, 8, 4, 8, 7, 4, 5, 8, 5, 4, 4, 6, 4, 7, 4, 5, 6, 4, 6, 4, 5, 4, 5, 6, 8, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.580, 1.177]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 52 | True: 52
Pred: 39 | True: 43
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] dedicated conservationist [SEP] [SEP] [SEP] [SEP] and
Target: [CLS] dedicated conservationist [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 47.4707
Generation Loss: 0.0014
Total Loss: 47.4721
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0014
Train Epoch: 146 [0/334 (0%)] Loss: 47.472134
Train Epoch: 146 [64/334 (19%)] Loss: 44.826675
Train Epoch: 146 [128/334 (38%)] Loss: 28.153271
Train Epoch: 146 [192/334 (57%)] Loss: 25.393803
Train Epoch: 146 [256/334 (77%)] Loss: 28.545465
[2025-01-21 12:01:54] Starting validation for epoch: 146

Generation Samples:
Topic 73:
Generated: [CLS] hemisphere billion league naming championship use spontaneous addition [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] phased modules greek aeronautics tak reputation states persians [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] marines to mutually bryan weapons define bryan elbow [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 146 [0/10 (0%)] Loss: 26.083740

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 42, 43, 47, 49, 55, 58, 61, 62, 63, 64, 65, 67, 68, 69, 71]
Input sequence lengths: [512, 204, 512, 512, 512, 512, 512, 125, 512, 512, 512, 204, 512, 449, 512, 137, 123, 512, 388, 125, 453, 512, 123, 123, 512, 159, 121, 512, 356, 512, 512, 87]
Target phrase lengths: [7, 8, 6, 6, 4, 6, 8, 7, 4, 8, 8, 6, 7, 6, 4, 4, 8, 5, 4, 4, 7, 4, 4, 7, 6, 4, 7, 6, 4, 4, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.580, 1.146]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 63 | True: 63
Pred: 68 | True: 68
Pred: 67 | True: 67

Phrase Generation Sample:
Generated: [CLS] committee authorization and oversight plans [SEP] and and
Target: [CLS] committee authorization and oversight plans [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.9849
Generation Loss: 0.0018
Total Loss: 33.9866
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0018
Train Epoch: 147 [0/334 (0%)] Loss: 33.986649
Train Epoch: 147 [64/334 (19%)] Loss: 25.130877
Train Epoch: 147 [128/334 (38%)] Loss: 28.675144
Train Epoch: 147 [192/334 (57%)] Loss: 38.698635
Train Epoch: 147 [256/334 (77%)] Loss: 32.436745
[2025-01-21 12:01:58] Starting validation for epoch: 147

Generation Samples:
Topic 40:
Generated: [CLS] belt nix blaming nominations kitchener letters jericho aliens [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 61:
Generated: [CLS] kiev bus board president jobs elm foreign hearts [SEP]
Target: [CLS] officer training [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] tanaka welles deutschland algebra delhi bryan biscuits midfielder [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 147 [0/10 (0%)] Loss: 32.738365

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [38, 39, 41, 42, 44, 49, 50, 53, 55, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73]
Input sequence lengths: [512, 209, 512, 449, 87, 512, 512, 512, 512, 512, 453, 453, 204, 121, 236, 366, 159, 512, 512, 512, 388, 159, 388, 512, 512, 258, 388, 334, 356, 512, 512, 512]
Target phrase lengths: [6, 7, 4, 6, 8, 7, 4, 7, 8, 8, 6, 8, 4, 4, 8, 3, 4, 6, 8, 7, 3, 4, 4, 4, 5, 4, 3, 4, 5, 6, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.544, 1.174]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 47 | True: 50
Pred: 73 | True: 73
Pred: 60 | True: 60

Phrase Generation Sample:
Generated: [CLS] selection of the speaker [SEP] and and [SEP]
Target: [CLS] selection of the speaker [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 39.6032
Generation Loss: 0.0016
Total Loss: 39.6048
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0016
Train Epoch: 148 [0/334 (0%)] Loss: 39.604797
Train Epoch: 148 [64/334 (19%)] Loss: 35.875454
Train Epoch: 148 [128/334 (38%)] Loss: 42.694004
Train Epoch: 148 [192/334 (57%)] Loss: 45.776047
Train Epoch: 148 [256/334 (77%)] Loss: 59.056576
[2025-01-21 12:02:02] Starting validation for epoch: 148

Generation Samples:
Topic 68:
Generated: [CLS] maximilian system scientology secrets hands peaceful dress [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] matthew gut weakening oversight innovation kant responds [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] boxed nuts overly labeled neuroscience analogue balloon [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 148 [0/10 (0%)] Loss: 29.811733

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 41, 42, 43, 45, 47, 48, 49, 51, 54, 57, 59, 60, 63, 64, 65, 66, 72]
Input sequence lengths: [453, 453, 268, 512, 512, 91, 78, 366, 512, 81, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 453, 512, 512, 512, 123, 485, 512, 512, 512, 145]
Target phrase lengths: [6, 8, 8, 6, 4, 4, 5, 5, 8, 8, 7, 6, 5, 6, 6, 8, 4, 8, 6, 4, 8, 5, 7, 8, 4, 4, 8, 7, 4, 5, 7, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.571, 1.188]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 41 | True: 41
Pred: 41 | True: 41
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] [SEP] [SEP] and
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.6279
Generation Loss: 0.0020
Total Loss: 36.6299
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0020
Train Epoch: 149 [0/334 (0%)] Loss: 36.629887
Train Epoch: 149 [64/334 (19%)] Loss: 23.520273
Train Epoch: 149 [128/334 (38%)] Loss: 31.422550
Train Epoch: 149 [192/334 (57%)] Loss: 27.409506
Train Epoch: 149 [256/334 (77%)] Loss: 26.741539
[2025-01-21 12:02:06] Starting validation for epoch: 149

Generation Samples:
Topic 51:
Generated: [CLS] bucks glove rn fee que murderer map kidding [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 43:
Generated: [CLS] contract eagles conceptual tomato mergers wooded spirits named [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] vested ross confuse say ride honesty foreign ball [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Validation Epoch: 149 [0/10 (0%)] Loss: 28.560781

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 39, 41, 42, 43, 45, 47, 51, 53, 54, 61, 64, 65, 67, 72]
Input sequence lengths: [512, 512, 159, 91, 512, 512, 512, 91, 512, 512, 453, 123, 512, 512, 137, 512, 512, 512, 512, 512, 334, 78, 512, 121, 512, 334, 512, 64, 512, 512, 512, 512]
Target phrase lengths: [4, 5, 4, 4, 7, 6, 6, 6, 7, 5, 5, 8, 7, 4, 7, 8, 6, 4, 6, 3, 6, 7, 4, 4, 6, 6, 6, 8, 6, 8, 7, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.571, 1.086]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 71 | True: 45
Pred: 36 | True: 36
Pred: 61 | True: 61

Phrase Generation Sample:
Generated: [CLS] control legislation [SEP] [SEP] and and and and
Target: [CLS] control legislation [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 62.6545
Generation Loss: 0.0020
Total Loss: 62.6565
Topic Prediction Accuracy: 0.6250
Generation Perplexity: 1.0020
Train Epoch: 150 [0/334 (0%)] Loss: 62.656548
Train Epoch: 150 [64/334 (19%)] Loss: 36.223297
Train Epoch: 150 [128/334 (38%)] Loss: 22.637403
Train Epoch: 150 [192/334 (57%)] Loss: 24.976299
Train Epoch: 150 [256/334 (77%)] Loss: 22.850105
[2025-01-21 12:02:10] Starting validation for epoch: 150

Generation Samples:
Topic 44:
Generated: [CLS] robe danish naturalist gnome socrates greece housing mint [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] capitals state dealings form fra hand mind netherlands [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] madman marcos unnecessary rex gear tentacles bryan winkler [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 150 [0/10 (0%)] Loss: 31.360113

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 38, 39, 41, 43, 44, 47, 49, 50, 51, 52, 54, 55, 56, 60, 63, 65, 71]
Input sequence lengths: [512, 449, 512, 512, 512, 92, 258, 123, 512, 512, 512, 234, 512, 512, 121, 512, 356, 356, 512, 512, 125, 512, 123, 449, 64, 512, 512, 512, 356, 512, 512, 512]
Target phrase lengths: [6, 7, 4, 7, 8, 7, 4, 4, 6, 5, 7, 8, 6, 4, 7, 8, 3, 4, 8, 5, 4, 6, 8, 4, 5, 4, 4, 6, 4, 8, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.550, 1.150]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 50 | True: 50
Pred: 71 | True: 71
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] people ' s representatives [SEP] [SEP] [SEP] [SEP]
Target: [CLS] people ' s representatives [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.1160
Generation Loss: 0.0016
Total Loss: 26.1176
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0016
Train Epoch: 151 [0/334 (0%)] Loss: 26.117590
Train Epoch: 151 [64/334 (19%)] Loss: 25.101000
Train Epoch: 151 [128/334 (38%)] Loss: 35.434010
Train Epoch: 151 [192/334 (57%)] Loss: 42.124176
Train Epoch: 151 [256/334 (77%)] Loss: 39.557728
[2025-01-21 12:02:19] Starting validation for epoch: 151

Generation Samples:
Topic 58:
Generated: [CLS] 231 demo structurally devices kan naming language else [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] greeks yep xiao morgan alphabet kurt macedonian declaration [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] adjutant noun betrayed nomination globally identifiable decidedly remixes [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 151 [0/10 (0%)] Loss: 33.705280

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 40, 41, 42, 43, 46, 49, 50, 53, 54, 55, 56, 60, 64, 65, 66, 67, 69, 70, 71]
Input sequence lengths: [512, 334, 258, 236, 512, 125, 512, 512, 388, 449, 512, 512, 449, 512, 268, 512, 512, 512, 137, 356, 512, 512, 512, 512, 512, 512, 512, 512, 512, 234, 125, 512]
Target phrase lengths: [6, 6, 4, 8, 8, 5, 6, 5, 3, 4, 6, 6, 5, 6, 8, 5, 3, 8, 7, 4, 8, 5, 5, 6, 7, 4, 6, 4, 5, 8, 7, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.539, 1.113]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 50 | True: 50
Pred: 53 | True: 53
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] selection of the speaker [SEP] [SEP] [SEP] [SEP]
Target: [CLS] selection of the speaker [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 16.5767
Generation Loss: 0.0015
Total Loss: 16.5781
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.0015
Train Epoch: 152 [0/334 (0%)] Loss: 16.578135
Train Epoch: 152 [64/334 (19%)] Loss: 23.832895
Train Epoch: 152 [128/334 (38%)] Loss: 45.493523
Train Epoch: 152 [192/334 (57%)] Loss: 44.151287
Train Epoch: 152 [256/334 (77%)] Loss: 26.899399
[2025-01-21 12:02:23] Starting validation for epoch: 152

Generation Samples:
Topic 46:
Generated: [CLS] states moves bases rule puget fairness heel choreographer [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] sovereignty idea phil qu discrete aura es love [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] commissions rex rudolph helping bern should conquered sexually [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Validation Epoch: 152 [0/10 (0%)] Loss: 56.957111

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 51, 54, 55, 56, 57, 60, 65, 67, 70]
Input sequence lengths: [356, 512, 453, 258, 512, 485, 485, 92, 512, 512, 449, 512, 236, 512, 512, 356, 356, 121, 268, 453, 512, 512, 512, 125, 512, 512, 512, 512, 512, 512, 512, 512]
Target phrase lengths: [5, 8, 8, 4, 8, 8, 5, 7, 5, 6, 5, 8, 7, 4, 4, 5, 5, 7, 8, 7, 8, 7, 6, 5, 8, 8, 3, 5, 5, 5, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.563, 1.142]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 55 | True: 55
Pred: 49 | True: 49
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] tools and guidance [SEP] and and and and
Target: [CLS] tools and guidance [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 17.9970
Generation Loss: 0.0019
Total Loss: 17.9989
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.0019
Train Epoch: 153 [0/334 (0%)] Loss: 17.998945
Train Epoch: 153 [64/334 (19%)] Loss: 24.711590
Train Epoch: 153 [128/334 (38%)] Loss: 14.269628
Train Epoch: 153 [192/334 (57%)] Loss: 37.614437
Train Epoch: 153 [256/334 (77%)] Loss: 22.929508
[2025-01-21 12:02:27] Starting validation for epoch: 153

Generation Samples:
Topic 59:
Generated: [CLS] integrating sweden howard airports sane currently injuring nicole [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] encoding republican over contract redskins democrat unix newt [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 44:
Generated: [CLS] tariff redskins nut djs casual truly geometry immune [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 153 [0/10 (0%)] Loss: 27.946579

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 40, 41, 43, 44, 45, 47, 49, 53, 54, 55, 58, 59, 62, 63, 65, 68, 69, 70, 71, 72, 73]
Input sequence lengths: [512, 512, 512, 512, 125, 91, 204, 512, 512, 512, 209, 512, 123, 512, 236, 87, 125, 366, 512, 512, 449, 334, 121, 512, 512, 512, 453, 512, 356, 512, 512, 388]
Target phrase lengths: [4, 3, 8, 7, 7, 4, 5, 6, 6, 5, 7, 7, 7, 6, 8, 6, 6, 5, 6, 5, 6, 7, 5, 6, 4, 6, 7, 4, 5, 5, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.530, 1.149]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 71 | True: 45
Pred: 54 | True: 54
Pred: 71 | True: 45

Phrase Generation Sample:
Generated: [CLS] control legislation [SEP] [SEP] and and and and
Target: [CLS] control legislation [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.8477
Generation Loss: 0.0018
Total Loss: 26.8495
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0018
Train Epoch: 154 [0/334 (0%)] Loss: 26.849522
Train Epoch: 154 [64/334 (19%)] Loss: 22.927446
Train Epoch: 154 [128/334 (38%)] Loss: 36.271206
Train Epoch: 154 [192/334 (57%)] Loss: 24.602888
Train Epoch: 154 [256/334 (77%)] Loss: 34.689480
[2025-01-21 12:02:31] Starting validation for epoch: 154

Generation Samples:
Topic 45:
Generated: [CLS] passport 1827 imperative in a mb founders borders [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] interior food airlines packaged bombings sugar homo nomination [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] boxing fingers loans languages republicans money j hat [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 154 [0/10 (0%)] Loss: 26.238565

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67]
Input sequence lengths: [512, 449, 512, 512, 123, 512, 125, 512, 366, 121, 512, 485, 512, 258, 512, 125, 512, 125, 512, 512, 512, 125, 512, 512, 512, 334, 512, 356, 87, 78, 512, 512]
Target phrase lengths: [5, 5, 4, 6, 4, 7, 4, 4, 5, 4, 6, 7, 5, 4, 8, 7, 4, 6, 4, 5, 8, 4, 5, 6, 6, 4, 6, 4, 6, 7, 8, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.515, 1.099]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 63 | True: 63
Pred: 56 | True: 56
Pred: 58 | True: 58

Phrase Generation Sample:
Generated: [CLS] two minute votes [SEP] [SEP] [PAD] [SEP] [SEP]
Target: [CLS] two minute votes [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 45.8367
Generation Loss: 0.0016
Total Loss: 45.8383
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0016
Train Epoch: 155 [0/334 (0%)] Loss: 45.838299
Train Epoch: 155 [64/334 (19%)] Loss: 34.908245
Train Epoch: 155 [128/334 (38%)] Loss: 23.679382
Train Epoch: 155 [192/334 (57%)] Loss: 39.361633
Train Epoch: 155 [256/334 (77%)] Loss: 28.784025
[2025-01-21 12:02:35] Starting validation for epoch: 155

Generation Samples:
Topic 58:
Generated: [CLS] sigismund homo dialect ideas words leafs calling keys [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] judo box digitally wheels superstar plague integer ska [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 68:
Generated: [CLS] corrections admissions roman arun cannabis feels sets bunny [SEP]
Target: [CLS] bodily autonomy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 155 [0/10 (0%)] Loss: 28.103716

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 54, 55, 56, 59, 60, 61, 63, 64, 65, 66, 69]
Input sequence lengths: [512, 512, 268, 512, 121, 78, 512, 512, 512, 512, 512, 512, 366, 388, 449, 512, 453, 366, 512, 512, 512, 512, 64, 512, 512, 512, 125, 159, 356, 234, 258, 92]
Target phrase lengths: [6, 4, 8, 7, 6, 7, 6, 4, 6, 6, 6, 5, 7, 8, 4, 8, 8, 3, 5, 7, 8, 4, 8, 8, 8, 7, 7, 4, 5, 4, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.537, 1.149]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 44 | True: 44
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] taxed without representation [SEP] [SEP] and [SEP]
Target: [CLS] taxed without representation [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 17.0459
Generation Loss: 0.0019
Total Loss: 17.0478
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0019
Train Epoch: 156 [0/334 (0%)] Loss: 17.047836
Train Epoch: 156 [64/334 (19%)] Loss: 39.225693
Train Epoch: 156 [128/334 (38%)] Loss: 45.353771
Train Epoch: 156 [192/334 (57%)] Loss: 29.602276
Train Epoch: 156 [256/334 (77%)] Loss: 61.867077
[2025-01-21 12:02:44] Starting validation for epoch: 156

Generation Samples:
Topic 51:
Generated: [CLS] romantic spielberg confusion linear foreign named linguistics hoc [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 66:
Generated: [CLS] wizards frank galveston mana planting delhi pry airways [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] turkic powell wrestlers grayson shack solved java syn [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 156 [0/10 (0%)] Loss: 33.768997

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 42, 43, 46, 47, 49, 54, 55, 59, 60, 61, 62, 65, 67, 68, 69, 70, 71]
Input sequence lengths: [512, 512, 512, 356, 512, 388, 512, 145, 512, 512, 512, 137, 512, 449, 512, 512, 512, 236, 512, 236, 512, 87, 512, 512, 512, 512, 159, 204, 453, 512, 512, 366]
Target phrase lengths: [4, 4, 5, 4, 4, 8, 8, 7, 5, 4, 6, 7, 6, 6, 6, 6, 6, 8, 6, 8, 6, 8, 7, 6, 3, 6, 4, 8, 5, 4, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.518, 1.144]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 46 | True: 46
Pred: 54 | True: 54
Pred: 44 | True: 40

Phrase Generation Sample:
Generated: [CLS] equal voice [SEP] [SEP] and [SEP] and [SEP]
Target: [CLS] equal voice [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 47.8346
Generation Loss: 0.0017
Total Loss: 47.8364
Topic Prediction Accuracy: 0.6562
Generation Perplexity: 1.0017
Train Epoch: 157 [0/334 (0%)] Loss: 47.836376
Train Epoch: 157 [64/334 (19%)] Loss: 46.913418
Train Epoch: 157 [128/334 (38%)] Loss: 37.796730
Train Epoch: 157 [192/334 (57%)] Loss: 19.202755
Train Epoch: 157 [256/334 (77%)] Loss: 27.994968
[2025-01-21 12:02:48] Starting validation for epoch: 157

Generation Samples:
Topic 46:
Generated: [CLS] giuseppe solve syntax ska clicked hoffmann package liar [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] myers cy constitutional caps taxpayers macedonia systematically words [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] military calderon identity assign contributing republican wing actions [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 157 [0/10 (0%)] Loss: 29.579834

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 49, 51, 54, 55, 56, 58, 60, 63, 64, 65, 66, 67, 71]
Input sequence lengths: [64, 449, 512, 512, 64, 449, 512, 512, 121, 512, 512, 512, 512, 449, 512, 512, 512, 512, 512, 512, 512, 234, 512, 356, 449, 78, 512, 512, 512, 512, 512, 512]
Target phrase lengths: [8, 4, 6, 5, 5, 5, 5, 8, 6, 8, 5, 8, 5, 4, 6, 8, 5, 4, 4, 6, 6, 7, 6, 5, 4, 7, 5, 6, 6, 6, 8, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.507, 1.157]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 34 | True: 34
Pred: 71 | True: 71
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] join in the pledge of allegiance [SEP] and
Target: [CLS] join in the pledge of allegiance [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.1794
Generation Loss: 0.0015
Total Loss: 36.1809
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0015
Train Epoch: 158 [0/334 (0%)] Loss: 36.180935
Train Epoch: 158 [64/334 (19%)] Loss: 25.751558
Train Epoch: 158 [128/334 (38%)] Loss: 26.162130
Train Epoch: 158 [192/334 (57%)] Loss: 31.078230
Train Epoch: 158 [256/334 (77%)] Loss: 35.564762
[2025-01-21 12:02:52] Starting validation for epoch: 158

Generation Samples:
Topic 65:
Generated: [CLS] midlands pak nl greek solving kurdish mets barbie [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 58:
Generated: [CLS] telecom bryan mumbled empire amend beaver bicycle question [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] settlement guitar kgb java structurally macintosh gifted ivanov [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 158 [0/10 (0%)] Loss: 32.336998

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [37, 39, 40, 41, 43, 45, 47, 49, 51, 52, 53, 54, 55, 60, 63, 64, 65, 66, 67, 71, 73]
Input sequence lengths: [512, 512, 512, 512, 334, 512, 209, 334, 512, 449, 334, 512, 334, 512, 334, 512, 512, 512, 512, 356, 512, 125, 234, 512, 78, 512, 512, 121, 92, 512, 512, 512]
Target phrase lengths: [8, 5, 4, 4, 6, 4, 7, 7, 6, 6, 4, 4, 6, 6, 4, 4, 6, 8, 7, 4, 8, 4, 8, 5, 7, 5, 8, 4, 5, 3, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.534, 1.136]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 65 | True: 65
Pred: 64 | True: 64
Pred: 49 | True: 49

Phrase Generation Sample:
Generated: [CLS] gut the office of congressional ethics [SEP] [SEP]
Target: [CLS] gut the office of congressional ethics [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.3443
Generation Loss: 0.0020
Total Loss: 33.3462
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0020
Train Epoch: 159 [0/334 (0%)] Loss: 33.346230
Train Epoch: 159 [64/334 (19%)] Loss: 45.622307
Train Epoch: 159 [128/334 (38%)] Loss: 23.290375
Train Epoch: 159 [192/334 (57%)] Loss: 25.764198
Train Epoch: 159 [256/334 (77%)] Loss: 18.940355
[2025-01-21 12:02:56] Starting validation for epoch: 159

Generation Samples:
Topic 59:
Generated: [CLS] kamen lease og options hearts millions throwing swansea [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 73:
Generated: [CLS] membership plant john politician nomination nothing moving partnerships [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] bribes thailand greek gerry j walking unpopular frankfurt [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 159 [0/10 (0%)] Loss: 49.482330

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 39, 40, 41, 43, 44, 49, 50, 53, 54, 55, 57, 58, 60, 63, 64, 67, 70]
Input sequence lengths: [512, 453, 356, 512, 356, 512, 236, 512, 121, 512, 512, 258, 121, 512, 512, 137, 512, 512, 453, 334, 236, 234, 334, 512, 512, 485, 512, 512, 512, 512, 512, 125]
Target phrase lengths: [7, 5, 4, 4, 4, 8, 8, 3, 4, 8, 8, 6, 5, 5, 4, 7, 5, 6, 7, 4, 7, 4, 4, 4, 6, 8, 5, 6, 5, 6, 6, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.542, 1.162]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 50 | True: 50
Pred: 41 | True: 41
Pred: 52 | True: 55

Phrase Generation Sample:
Generated: [CLS] placing a name in nomination [SEP] and [SEP]
Target: [CLS] placing a name in nomination [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.4847
Generation Loss: 0.0019
Total Loss: 33.4866
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0019
Train Epoch: 160 [0/334 (0%)] Loss: 33.486591
Train Epoch: 160 [64/334 (19%)] Loss: 19.701662
Train Epoch: 160 [128/334 (38%)] Loss: 32.320061
Train Epoch: 160 [192/334 (57%)] Loss: 32.901203
Train Epoch: 160 [256/334 (77%)] Loss: 52.643986
[2025-01-21 12:03:00] Starting validation for epoch: 160

Generation Samples:
Topic 45:
Generated: [CLS] missiles plans rebuild accreditation guild [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] nintendo musical border prisons ethics [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] yankee babe java soul j [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 160 [0/10 (0%)] Loss: 29.387560

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 40, 41, 43, 45, 47, 49, 51, 53, 54, 55, 59, 60, 64, 66, 70, 72, 73]
Input sequence lengths: [91, 512, 334, 125, 123, 209, 453, 512, 512, 356, 366, 121, 512, 334, 512, 236, 145, 512, 512, 453, 78, 512, 258, 512, 512, 366, 512, 125, 268, 512, 512, 366]
Target phrase lengths: [4, 4, 6, 7, 4, 4, 7, 8, 7, 4, 3, 5, 8, 4, 4, 8, 7, 4, 7, 5, 7, 4, 6, 4, 6, 6, 6, 5, 8, 4, 5, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.498, 1.141]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 72 | True: 72
Pred: 60 | True: 60
Pred: 50 | True: 53

Phrase Generation Sample:
Generated: [CLS] remote procedures [SEP] [SEP] [SEP] and and [SEP]
Target: [CLS] remote procedures [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.1644
Generation Loss: 0.0014
Total Loss: 30.1658
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0014
Train Epoch: 161 [0/334 (0%)] Loss: 30.165844
Train Epoch: 161 [64/334 (19%)] Loss: 35.544689
Train Epoch: 161 [128/334 (38%)] Loss: 31.363787
Train Epoch: 161 [192/334 (57%)] Loss: 38.519306
Train Epoch: 161 [256/334 (77%)] Loss: 19.689083
[2025-01-21 12:03:09] Starting validation for epoch: 161

Generation Samples:
Topic 47:
Generated: [CLS] derek speaks can mystical interested shouldn priesthood morgan [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 52:
Generated: [CLS] juris deserves believing cheering orbits tar java inventions [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] beers rings phillies swore moons stacks john bra [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 161 [0/10 (0%)] Loss: 47.325195

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 42, 43, 48, 49, 51, 53, 54, 55, 57, 61, 63, 64, 65, 66, 68]
Input sequence lengths: [512, 334, 78, 512, 453, 81, 512, 512, 512, 512, 159, 512, 512, 512, 512, 485, 512, 78, 145, 512, 125, 137, 356, 92, 512, 204, 512, 258, 512, 125, 78, 268]
Target phrase lengths: [4, 4, 5, 4, 8, 6, 4, 5, 8, 8, 7, 5, 7, 4, 4, 8, 8, 7, 8, 5, 7, 7, 5, 5, 5, 6, 3, 4, 5, 7, 7, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.519, 1.109]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 40
Pred: 59 | True: 53
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] my friend [SEP] and and and [SEP] and
Target: [CLS] my friend [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.9564
Generation Loss: 0.0012
Total Loss: 30.9576
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0012
Train Epoch: 162 [0/334 (0%)] Loss: 30.957626
Train Epoch: 162 [64/334 (19%)] Loss: 12.234290
Train Epoch: 162 [128/334 (38%)] Loss: 42.472942
Train Epoch: 162 [192/334 (57%)] Loss: 39.131435
Train Epoch: 162 [256/334 (77%)] Loss: 38.194893
[2025-01-21 12:03:13] Starting validation for epoch: 162

Generation Samples:
Topic 44:
Generated: [CLS] marcus constitution defined communications japanese constitution tu was [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] traditionally sentences mana morals equations languages invited yacht [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] twitching trump borrowing redesigned bricks j armed ne [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 162 [0/10 (0%)] Loss: 28.710869

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 40, 41, 42, 43, 48, 51, 54, 57, 64, 65, 66, 67, 70, 71]
Input sequence lengths: [137, 125, 78, 123, 512, 449, 512, 145, 512, 512, 512, 512, 512, 234, 512, 512, 512, 512, 234, 485, 512, 512, 512, 236, 512, 512, 125, 512, 512, 258, 81, 512]
Target phrase lengths: [7, 7, 7, 8, 5, 4, 8, 7, 4, 7, 4, 6, 8, 7, 5, 6, 6, 4, 4, 7, 7, 8, 5, 8, 4, 5, 6, 6, 5, 6, 8, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.543, 1.109]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 43 | True: 43
Pred: 34 | True: 51

Phrase Generation Sample:
Generated: [CLS] speaker has not been elected [SEP] [SEP] [SEP]
Target: [CLS] speaker has not been elected [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 56.3844
Generation Loss: 0.0016
Total Loss: 56.3860
Topic Prediction Accuracy: 0.6250
Generation Perplexity: 1.0016
Train Epoch: 163 [0/334 (0%)] Loss: 56.385998
Train Epoch: 163 [64/334 (19%)] Loss: 22.957911
Train Epoch: 163 [128/334 (38%)] Loss: 36.436245
Train Epoch: 163 [192/334 (57%)] Loss: 32.987400
Train Epoch: 163 [256/334 (77%)] Loss: 37.762550
[2025-01-21 12:03:17] Starting validation for epoch: 163

Generation Samples:
Topic 41:
Generated: [CLS] kaye blink bingham gina kn conduct scripts hat [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 40:
Generated: [CLS] enemies avant plant an commit aboard kentucky prosperous [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] unsigned midfielder play uniquely live believe organ communism [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 163 [0/10 (0%)] Loss: 29.944502

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 40, 41, 43, 48, 49, 50, 51, 53, 54, 55, 57, 58, 60, 61, 63, 64, 67, 69, 72, 73]
Input sequence lengths: [125, 388, 145, 512, 512, 512, 78, 91, 209, 512, 512, 512, 512, 334, 125, 81, 125, 159, 81, 512, 512, 512, 356, 512, 81, 485, 512, 64, 512, 512, 512, 512]
Target phrase lengths: [7, 4, 6, 8, 7, 6, 5, 4, 4, 4, 4, 4, 4, 8, 6, 8, 7, 5, 5, 4, 8, 8, 4, 8, 6, 5, 6, 8, 5, 6, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.523, 1.110]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 69 | True: 69
Pred: 35 | True: 35

Phrase Generation Sample:
Generated: [CLS] hakeem jeffries [SEP] and and
Target: [CLS] hakeem jeffries [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.3594
Generation Loss: 0.0017
Total Loss: 26.3611
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0017
Train Epoch: 164 [0/334 (0%)] Loss: 26.361124
Train Epoch: 164 [64/334 (19%)] Loss: 32.182991
Train Epoch: 164 [128/334 (38%)] Loss: 44.632862
Train Epoch: 164 [192/334 (57%)] Loss: 21.994003
Train Epoch: 164 [256/334 (77%)] Loss: 44.203152
[2025-01-21 12:03:21] Starting validation for epoch: 164

Generation Samples:
Topic 52:
Generated: [CLS] oblast robinson beale hearts gloucester internal bottle vocabulary [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] castes gwen yankee eastern free garage twins laurent [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 45:
Generated: [CLS] migrated punk foreign rings tombstone fundamentally agrees lease [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 164 [0/10 (0%)] Loss: 35.458725

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 37, 38, 39, 41, 43, 47, 49, 53, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70]
Input sequence lengths: [356, 121, 121, 204, 159, 366, 512, 236, 453, 512, 512, 512, 258, 388, 512, 234, 512, 64, 512, 512, 512, 512, 512, 366, 125, 334, 512, 204, 512, 87, 512, 366]
Target phrase lengths: [4, 5, 4, 8, 4, 7, 4, 8, 7, 6, 4, 7, 4, 4, 8, 7, 7, 7, 4, 8, 4, 6, 8, 5, 7, 8, 6, 8, 8, 6, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.553, 1.118]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 55 | True: 55
Pred: 39 | True: 39
Pred: 39 | True: 39

Phrase Generation Sample:
Generated: [CLS] economic driver [SEP] and and and and and
Target: [CLS] economic driver [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.4837
Generation Loss: 0.0019
Total Loss: 23.4856
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0019
Train Epoch: 165 [0/334 (0%)] Loss: 23.485559
Train Epoch: 165 [64/334 (19%)] Loss: 24.428013
Train Epoch: 165 [128/334 (38%)] Loss: 33.486298
Train Epoch: 165 [192/334 (57%)] Loss: 27.899630
Train Epoch: 165 [256/334 (77%)] Loss: 28.600254
[2025-01-21 12:03:25] Starting validation for epoch: 165

Generation Samples:
Topic 44:
Generated: [CLS] crimea heaven parasites filled brain plans government downloads [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] mentoring drawer contractor gui lamar inflammatory flows amend [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 52:
Generated: [CLS] cheney keyboard haunting answering intended mutually john peanuts [SEP]
Target: [CLS] commitment to public service [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 165 [0/10 (0%)] Loss: 22.828863

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 43, 44, 49, 51, 54, 55, 57, 58, 60, 61, 64, 66, 70, 72]
Input sequence lengths: [512, 92, 236, 512, 125, 512, 268, 512, 145, 512, 512, 485, 125, 356, 512, 356, 512, 91, 159, 78, 512, 512, 125, 512, 512, 512, 512, 236, 512, 512, 512, 145]
Target phrase lengths: [5, 5, 5, 6, 7, 7, 8, 5, 8, 5, 6, 8, 6, 4, 8, 4, 4, 4, 4, 7, 5, 6, 7, 8, 5, 4, 4, 8, 5, 4, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.500, 1.141]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 45 | True: 36
Pred: 44 | True: 51
Pred: 70 | True: 70

Phrase Generation Sample:
Generated: [CLS] nominate kevin mccarthy [SEP] [SEP] and and and
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.1388
Generation Loss: 0.0014
Total Loss: 31.1402
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0014
Train Epoch: 166 [0/334 (0%)] Loss: 31.140196
Train Epoch: 166 [64/334 (19%)] Loss: 32.630058
Train Epoch: 166 [128/334 (38%)] Loss: 30.222851
Train Epoch: 166 [192/334 (57%)] Loss: 27.900732
Train Epoch: 166 [256/334 (77%)] Loss: 23.732967
[2025-01-21 12:03:34] Starting validation for epoch: 166

Generation Samples:
Topic 41:
Generated: [CLS] unification apparatus nl levi refuse wing system amar [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] benito yugoslav nomination comets gaming lombard embedded saxe [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 44:
Generated: [CLS] scientology fide word chick eta choice punishment fee [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 166 [0/10 (0%)] Loss: 38.250305

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 35, 36, 41, 42, 43, 47, 51, 52, 54, 55, 56, 58, 60, 65, 66, 67, 68, 70]
Input sequence lengths: [512, 512, 512, 512, 512, 236, 512, 64, 512, 512, 512, 512, 92, 512, 145, 125, 512, 512, 512, 512, 356, 512, 92, 512, 78, 449, 512, 236, 512, 453, 512, 204]
Target phrase lengths: [4, 4, 6, 8, 6, 5, 8, 5, 6, 4, 8, 8, 7, 8, 8, 5, 6, 8, 5, 6, 5, 8, 5, 5, 5, 5, 5, 8, 5, 6, 3, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.544, 1.143]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 34 | True: 52
Pred: 36 | True: 36
Pred: 36 | True: 36

Phrase Generation Sample:
Generated: [CLS] exceptional service [SEP] and [PAD] and [SEP] and
Target: [CLS] exceptional service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 42.1318
Generation Loss: 0.0017
Total Loss: 42.1334
Topic Prediction Accuracy: 0.7500
Generation Perplexity: 1.0017
Train Epoch: 167 [0/334 (0%)] Loss: 42.133442
Train Epoch: 167 [64/334 (19%)] Loss: 38.534340
Train Epoch: 167 [128/334 (38%)] Loss: 37.538601
Train Epoch: 167 [192/334 (57%)] Loss: 28.020836
Train Epoch: 167 [256/334 (77%)] Loss: 18.385839
[2025-01-21 12:03:38] Starting validation for epoch: 167

Generation Samples:
Topic 47:
Generated: [CLS] greyhound fortune did michigan melody serves cutter bible [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 73:
Generated: [CLS] fidelity sergio weapons thompson citizen english hi declaration [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] weakly trenton cruz behalf midfielder pac biology inscribed [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 167 [0/10 (0%)] Loss: 17.822958

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 41, 42, 43, 46, 47, 48, 49, 51, 54, 55, 56, 59, 60, 66, 67, 69, 71, 72]
Input sequence lengths: [512, 258, 388, 356, 366, 512, 512, 81, 512, 512, 512, 91, 512, 512, 512, 512, 512, 512, 92, 512, 449, 268, 78, 512, 258, 512, 449, 121, 356, 512, 512, 123]
Target phrase lengths: [6, 4, 4, 4, 3, 4, 6, 5, 5, 6, 3, 4, 6, 5, 4, 6, 5, 4, 7, 8, 6, 8, 7, 5, 4, 4, 5, 5, 5, 7, 5, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.571, 1.187]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 42 | True: 42
Pred: 38 | True: 38
Pred: 69 | True: 69

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] [SEP] and [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 20.4502
Generation Loss: 0.0013
Total Loss: 20.4514
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0013
Train Epoch: 168 [0/334 (0%)] Loss: 20.451445
Train Epoch: 168 [64/334 (19%)] Loss: 35.252434
Train Epoch: 168 [128/334 (38%)] Loss: 40.571053
Train Epoch: 168 [192/334 (57%)] Loss: 25.299089
Train Epoch: 168 [256/334 (77%)] Loss: 23.874117
[2025-01-21 12:03:42] Starting validation for epoch: 168

Generation Samples:
Topic 44:
Generated: [CLS] mani saber shouldn newell jew dime system beans [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] dna hamas atomic griffin mil mana solve palatine [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] mace volunteers administering mb ui lawrence pact nsw [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Validation Epoch: 168 [0/10 (0%)] Loss: 39.326649

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 40, 41, 42, 43, 45, 47, 51, 54, 55, 58, 60, 61, 64, 65, 67, 69, 70, 71, 73]
Input sequence lengths: [92, 234, 123, 512, 512, 512, 512, 258, 258, 145, 159, 356, 512, 512, 512, 512, 449, 512, 209, 512, 125, 512, 388, 512, 512, 512, 512, 236, 512, 159, 512, 512]
Target phrase lengths: [7, 8, 8, 8, 4, 4, 8, 4, 6, 8, 4, 5, 7, 5, 8, 8, 4, 4, 4, 8, 5, 8, 3, 6, 4, 4, 8, 5, 5, 4, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.557, 1.159]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 37 | True: 37
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] flag of the united states [SEP] and and
Target: [CLS] flag of the united states [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.5305
Generation Loss: 0.0016
Total Loss: 33.5321
Topic Prediction Accuracy: 0.7812
Generation Perplexity: 1.0016
Train Epoch: 169 [0/334 (0%)] Loss: 33.532066
Train Epoch: 169 [64/334 (19%)] Loss: 32.867287
Train Epoch: 169 [128/334 (38%)] Loss: 32.278568
Train Epoch: 169 [192/334 (57%)] Loss: 33.189148
Train Epoch: 169 [256/334 (77%)] Loss: 49.278389
[2025-01-21 12:03:46] Starting validation for epoch: 169

Generation Samples:
Topic 51:
Generated: [CLS] mutations constitution baseball services volleyball kant [unused710] rings [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] chartered experimented allen steven irregularities clarity champagne ko [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] mani commit parasite cup confusion ticket grammar wat [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Validation Epoch: 169 [0/10 (0%)] Loss: 30.939724

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 42, 43, 44, 45, 47, 49, 54, 55, 60, 61, 62, 63, 65, 66, 67, 70, 71, 73]
Input sequence lengths: [512, 512, 145, 145, 512, 512, 512, 125, 449, 121, 512, 512, 512, 512, 512, 512, 512, 159, 512, 87, 236, 512, 356, 512, 209, 512, 125, 512, 512, 512, 512, 449]
Target phrase lengths: [6, 6, 8, 8, 5, 8, 4, 6, 4, 5, 6, 8, 6, 6, 8, 5, 3, 7, 6, 6, 8, 8, 3, 6, 4, 6, 6, 7, 5, 8, 6, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.571, 1.189]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 60 | True: 60
Pred: 35 | True: 35

Phrase Generation Sample:
Generated: [CLS] republican commitment to america [SEP] and and and
Target: [CLS] republican commitment to america [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 26.2869
Generation Loss: 0.0015
Total Loss: 26.2884
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0015
Train Epoch: 170 [0/334 (0%)] Loss: 26.288427
Train Epoch: 170 [64/334 (19%)] Loss: 34.615368
Train Epoch: 170 [128/334 (38%)] Loss: 31.076656
Train Epoch: 170 [192/334 (57%)] Loss: 25.487549
Train Epoch: 170 [256/334 (77%)] Loss: 43.560432
[2025-01-21 12:03:50] Starting validation for epoch: 170

Generation Samples:
Topic 43:
Generated: [CLS] luxury wired english solving wrestlers thrown [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] warped dakota unfair loud ol appointments [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Topic 58:
Generated: [CLS] ibm purple eu gina glove lunar [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 170 [0/10 (0%)] Loss: 26.633850

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 39, 40, 41, 43, 48, 49, 50, 52, 53, 54, 55, 57, 60, 61, 64, 65, 66, 70, 71]
Input sequence lengths: [449, 512, 512, 512, 512, 121, 512, 236, 485, 121, 512, 356, 258, 334, 125, 236, 512, 512, 512, 159, 123, 81, 512, 334, 512, 512, 453, 123, 512, 512, 512, 123]
Target phrase lengths: [4, 8, 6, 7, 6, 5, 8, 8, 7, 4, 4, 3, 6, 8, 6, 6, 6, 4, 5, 4, 7, 5, 5, 6, 5, 4, 7, 7, 4, 5, 4, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.548, 1.136]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 71 | True: 71
Pred: 41 | True: 41
Pred: 60 | True: 60

Phrase Generation Sample:
Generated: [CLS] transparent process [SEP] [SEP] [SEP] [SEP] and and
Target: [CLS] transparent process [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 43.2813
Generation Loss: 0.0016
Total Loss: 43.2829
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0016
Train Epoch: 171 [0/334 (0%)] Loss: 43.282913
Train Epoch: 171 [64/334 (19%)] Loss: 23.876493
Train Epoch: 171 [128/334 (38%)] Loss: 30.679991
Train Epoch: 171 [192/334 (57%)] Loss: 35.081512
Train Epoch: 171 [256/334 (77%)] Loss: 35.885891
[2025-01-21 12:03:59] Starting validation for epoch: 171

Generation Samples:
Topic 45:
Generated: [CLS] titans ko italians congress lgbt covent wimbledon brig [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] takahashi dot wing dunn epithet netherlands hydrogen medications [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] linking dean religions corrections constitution system of moons [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 171 [0/10 (0%)] Loss: 26.064953

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 41, 43, 45, 48, 51, 52, 54, 56, 57, 59, 60, 61, 63, 64, 67, 69, 70, 73]
Input sequence lengths: [137, 449, 81, 236, 512, 512, 512, 159, 388, 512, 512, 512, 512, 209, 366, 512, 258, 485, 123, 366, 512, 268, 512, 512, 123, 512, 78, 512, 512, 236, 258, 92]
Target phrase lengths: [7, 5, 8, 7, 5, 8, 8, 5, 4, 4, 6, 7, 4, 7, 5, 5, 4, 5, 8, 7, 8, 8, 6, 6, 7, 8, 7, 4, 5, 5, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.559, 1.159]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 56 | True: 56
Pred: 48 | True: 48

Phrase Generation Sample:
Generated: [CLS] speaker has not been elected [SEP] and its
Target: [CLS] speaker has not been elected [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 19.5113
Generation Loss: 0.0016
Total Loss: 19.5129
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0016
Train Epoch: 172 [0/334 (0%)] Loss: 19.512936
Train Epoch: 172 [64/334 (19%)] Loss: 33.282372
Train Epoch: 172 [128/334 (38%)] Loss: 29.600840
Train Epoch: 172 [192/334 (57%)] Loss: 21.774710
Train Epoch: 172 [256/334 (77%)] Loss: 36.394409
[2025-01-21 12:04:03] Starting validation for epoch: 172

Generation Samples:
Topic 50:
Generated: [CLS] emperor rules discuss phones [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] immigrant scare java gs [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] smoothly dakota gnome czech [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 172 [0/10 (0%)] Loss: 43.534767

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 39, 40, 41, 43, 45, 47, 49, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 70]
Input sequence lengths: [159, 121, 258, 356, 512, 512, 512, 356, 512, 512, 485, 512, 145, 449, 512, 121, 512, 453, 334, 512, 512, 512, 159, 236, 512, 512, 512, 512, 512, 87, 125, 512]
Target phrase lengths: [4, 7, 6, 4, 6, 4, 5, 4, 7, 3, 5, 6, 6, 8, 6, 6, 5, 6, 4, 5, 5, 4, 5, 7, 6, 5, 6, 6, 6, 6, 7, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.590, 1.158]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 61 | True: 61
Pred: 39 | True: 39
Pred: 38 | True: 38

Phrase Generation Sample:
Generated: [CLS] public safety [SEP] [SEP] [SEP] [PAD] [SEP] [SEP]
Target: [CLS] public safety [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.1136
Generation Loss: 0.0015
Total Loss: 36.1151
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0015
Train Epoch: 173 [0/334 (0%)] Loss: 36.115112
Train Epoch: 173 [64/334 (19%)] Loss: 40.040348
Train Epoch: 173 [128/334 (38%)] Loss: 39.319901
Train Epoch: 173 [192/334 (57%)] Loss: 34.968529
Train Epoch: 173 [256/334 (77%)] Loss: 44.504173
[2025-01-21 12:04:07] Starting validation for epoch: 173

Generation Samples:
Topic 65:
Generated: [CLS] faa overly way josef giants define drink heck [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 36:
Generated: [CLS] piano constructions schwartz knot lifelong founding infrastructure gaming [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] hat string blink conquest gu international finland det [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 173 [0/10 (0%)] Loss: 25.331568

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 40, 41, 42, 43, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 63, 65, 67, 68, 69]
Input sequence lengths: [78, 121, 204, 512, 512, 512, 512, 512, 356, 366, 512, 123, 512, 512, 512, 512, 512, 512, 512, 512, 512, 356, 449, 78, 512, 512, 512, 512, 388, 512, 512, 512]
Target phrase lengths: [7, 6, 8, 4, 6, 4, 8, 4, 4, 5, 5, 8, 5, 6, 5, 6, 8, 7, 6, 6, 8, 4, 5, 7, 5, 7, 4, 7, 4, 5, 8, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.623, 1.174]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 39 | True: 39
Pred: 68 | True: 68

Phrase Generation Sample:
Generated: [CLS] liberty and justice for all [SEP] [SEP] [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.7742
Generation Loss: 0.0015
Total Loss: 30.7757
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0015
Train Epoch: 174 [0/334 (0%)] Loss: 30.775663
Train Epoch: 174 [64/334 (19%)] Loss: 22.540180
Train Epoch: 174 [128/334 (38%)] Loss: 45.262802
Train Epoch: 174 [192/334 (57%)] Loss: 19.767067
Train Epoch: 174 [256/334 (77%)] Loss: 34.568073
[2025-01-21 12:04:10] Starting validation for epoch: 174

Generation Samples:
Topic 51:
Generated: [CLS] vague transgender whitehead dot playback medical bryan shale [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 41:
Generated: [CLS] buren swiss pants pursue laurence nl inception wing [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 73:
Generated: [CLS] identities romeo middletown nominations freedom organ tree patent [SEP]
Target: [CLS] criminalizes abortion [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 174 [0/10 (0%)] Loss: 35.906582

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 39, 41, 42, 43, 47, 48, 51, 52, 54, 55, 56, 59, 60, 61, 63, 65, 68]
Input sequence lengths: [512, 234, 125, 512, 512, 512, 81, 453, 512, 159, 204, 512, 78, 512, 123, 125, 137, 512, 258, 123, 512, 356, 512, 356, 512, 125, 449, 512, 512, 123, 121, 366]
Target phrase lengths: [6, 8, 4, 6, 8, 7, 5, 6, 6, 4, 6, 7, 7, 5, 8, 4, 7, 3, 4, 8, 6, 3, 5, 4, 4, 7, 8, 5, 6, 7, 6, 3]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.513, 1.129]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 42 | True: 42
Pred: 37 | True: 37
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] and [SEP] [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 42.9145
Generation Loss: 0.0010
Total Loss: 42.9155
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0010
Train Epoch: 175 [0/334 (0%)] Loss: 42.915512
Train Epoch: 175 [64/334 (19%)] Loss: 42.466068
Train Epoch: 175 [128/334 (38%)] Loss: 28.032492
Train Epoch: 175 [192/334 (57%)] Loss: 40.483963
Train Epoch: 175 [256/334 (77%)] Loss: 22.401011
[2025-01-21 12:04:14] Starting validation for epoch: 175

Generation Samples:
Topic 50:
Generated: [CLS] bran philosophical basic seeds privatization idea actions nerve [SEP]
Target: [CLS] position of the speaker [SEP] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] clue integer math instability fairies live wood prussia [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] diplomatic butterfly rational slavery bucks declaration ponce bloomfield [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 175 [0/10 (0%)] Loss: 25.743246

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 38, 40, 41, 42, 43, 45, 47, 51, 52, 54, 55, 56, 57, 60, 61, 62, 64, 66, 68, 73]
Input sequence lengths: [512, 512, 125, 449, 512, 512, 87, 512, 123, 512, 159, 356, 512, 159, 512, 204, 512, 512, 512, 125, 512, 512, 234, 125, 92, 125, 78, 209, 512, 512, 485, 87]
Target phrase lengths: [6, 5, 4, 4, 5, 8, 6, 3, 7, 8, 4, 4, 5, 7, 7, 6, 7, 4, 5, 7, 5, 5, 4, 6, 5, 7, 7, 7, 6, 4, 5, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.544, 1.149]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 36 | True: 36
Pred: 40 | True: 40
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] speaker of the house [SEP] [SEP] and and
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 27.4369
Generation Loss: 0.0013
Total Loss: 27.4382
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0013
Train Epoch: 176 [0/334 (0%)] Loss: 27.438166
Train Epoch: 176 [64/334 (19%)] Loss: 29.987608
Train Epoch: 176 [128/334 (38%)] Loss: 35.957520
Train Epoch: 176 [192/334 (57%)] Loss: 24.394400
Train Epoch: 176 [256/334 (77%)] Loss: 31.809137
[2025-01-21 12:04:29] Starting validation for epoch: 176

Generation Samples:
Topic 55:
Generated: [CLS] relic header neville netherlands express undergo toy goin [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 36:
Generated: [CLS] anger answers borders reprint orlando american pitcher say [SEP]
Target: [CLS] nation that is safe [SEP] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] converts pandit afford upbeat ron rudder mani axel [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 176 [0/10 (0%)] Loss: 24.450899

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 41, 43, 44, 46, 53, 54, 55, 58, 60, 61, 63, 65, 66, 68, 70]
Input sequence lengths: [512, 159, 512, 512, 512, 356, 512, 125, 512, 512, 125, 512, 204, 512, 512, 268, 512, 137, 204, 512, 512, 512, 512, 123, 453, 512, 512, 236, 512, 356, 512, 334]
Target phrase lengths: [8, 4, 4, 7, 6, 4, 8, 6, 8, 4, 7, 5, 8, 3, 4, 8, 8, 7, 5, 5, 6, 6, 8, 7, 7, 5, 7, 5, 6, 3, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.557, 1.151]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 61 | True: 61
Pred: 46 | True: 46

Phrase Generation Sample:
Generated: [CLS] d. c. residents voted [SEP] [SEP]
Target: [CLS] d. c. residents voted [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 39.9050
Generation Loss: 0.0012
Total Loss: 39.9062
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0012
Train Epoch: 177 [0/334 (0%)] Loss: 39.906242
Train Epoch: 177 [64/334 (19%)] Loss: 30.279919
Train Epoch: 177 [128/334 (38%)] Loss: 23.966566
Train Epoch: 177 [192/334 (57%)] Loss: 41.490379
Train Epoch: 177 [256/334 (77%)] Loss: 31.614672
[2025-01-21 12:04:33] Starting validation for epoch: 177

Generation Samples:
Topic 41:
Generated: [CLS] multicultural creativity mcpherson japan foreign blessed paxton timothy [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Topic 59:
Generated: [CLS] russia conduct norman pentagon wisconsin botany creed subdued [SEP]
Target: [CLS] massive impact [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 66:
Generated: [CLS] secession moral interested differ welles disagreed mani rag [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 177 [0/10 (0%)] Loss: 31.242220

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 48, 49, 50, 54, 57, 60, 64, 65, 67, 70, 73]
Input sequence lengths: [512, 209, 453, 512, 512, 81, 512, 123, 123, 234, 512, 453, 512, 512, 121, 512, 123, 512, 512, 512, 512, 512, 512, 512, 485, 512, 236, 512, 145, 512, 512, 512]
Target phrase lengths: [4, 7, 8, 4, 6, 6, 4, 7, 8, 4, 6, 7, 6, 6, 6, 8, 4, 6, 6, 8, 7, 6, 4, 7, 8, 6, 7, 5, 8, 4, 3, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.550, 1.166]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 46 | True: 46
Pred: 73 | True: 73
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] equal voice [SEP] [PAD] and and and and
Target: [CLS] equal voice [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 22.5261
Generation Loss: 0.0012
Total Loss: 22.5273
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0012
Train Epoch: 178 [0/334 (0%)] Loss: 22.527319
Train Epoch: 178 [64/334 (19%)] Loss: 24.058315
Train Epoch: 178 [128/334 (38%)] Loss: 22.220757
Train Epoch: 178 [192/334 (57%)] Loss: 25.846119
Train Epoch: 178 [256/334 (77%)] Loss: 32.318722
[2025-01-21 12:04:37] Starting validation for epoch: 178

Generation Samples:
Topic 44:
Generated: [CLS] linguistic languages lame lord religions money english madness [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] empire mit seville china mayfair transportation cfl midfielder [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] accountability marshall stanley bryan dragon rosen ascended chords [SEP]
Target: [CLS] lead vote - getter [SEP] [PAD] [PAD]

Validation Epoch: 178 [0/10 (0%)] Loss: 33.173779

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 38, 40, 41, 43, 45, 47, 49, 51, 53, 54, 55, 56, 60, 65, 66, 68, 69, 70, 73]
Input sequence lengths: [123, 64, 512, 512, 236, 258, 512, 236, 512, 356, 204, 512, 512, 78, 268, 512, 388, 356, 512, 512, 125, 209, 512, 512, 512, 334, 125, 512, 449, 356, 512, 334]
Target phrase lengths: [7, 7, 6, 6, 8, 6, 8, 6, 5, 5, 6, 5, 5, 7, 8, 4, 4, 4, 6, 6, 7, 7, 4, 4, 4, 4, 7, 8, 5, 4, 8, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.592, 1.197]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 34 | True: 34
Pred: 69 | True: 60

Phrase Generation Sample:
Generated: [CLS] speaker has not been elected [SEP] and [PAD]
Target: [CLS] speaker has not been elected [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 32.1342
Generation Loss: 0.0013
Total Loss: 32.1355
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0013
Train Epoch: 179 [0/334 (0%)] Loss: 32.135502
Train Epoch: 179 [64/334 (19%)] Loss: 45.318447
Train Epoch: 179 [128/334 (38%)] Loss: 23.679333
Train Epoch: 179 [192/334 (57%)] Loss: 26.756399
Train Epoch: 179 [256/334 (77%)] Loss: 33.055634
[2025-01-21 12:04:41] Starting validation for epoch: 179

Generation Samples:
Topic 36:
Generated: [CLS] linux afford algebraic merry redesigned government employ linguistic [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 47:
Generated: [CLS] deployment religions moving christians x sock be coherent [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 55:
Generated: [CLS] quebec casting fx inter bombing taste cater employs [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 179 [0/10 (0%)] Loss: 24.095367

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 37, 38, 39, 40, 41, 43, 44, 51, 53, 55, 63, 66, 68]
Input sequence lengths: [258, 204, 123, 234, 512, 145, 512, 334, 258, 512, 234, 334, 92, 512, 356, 125, 453, 512, 512, 334, 512, 512, 121, 78, 512, 334, 78, 512, 125, 121, 512, 268]
Target phrase lengths: [4, 8, 8, 4, 8, 8, 4, 4, 6, 7, 8, 6, 6, 4, 5, 7, 7, 8, 6, 6, 3, 4, 7, 6, 5, 4, 5, 6, 7, 5, 4, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.525, 1.155]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 38 | True: 38
Pred: 68 | True: 68
Pred: 43 | True: 43

Phrase Generation Sample:
Generated: [CLS] support him [SEP] and and [PAD] and [SEP]
Target: [CLS] support him [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 51.0992
Generation Loss: 0.0011
Total Loss: 51.1003
Topic Prediction Accuracy: 0.7188
Generation Perplexity: 1.0011
Train Epoch: 180 [0/334 (0%)] Loss: 51.100250
Train Epoch: 180 [64/334 (19%)] Loss: 47.728973
Train Epoch: 180 [128/334 (38%)] Loss: 20.692968
Train Epoch: 180 [192/334 (57%)] Loss: 19.835009
Train Epoch: 180 [256/334 (77%)] Loss: 18.960110
[2025-01-21 12:04:44] Starting validation for epoch: 180

Generation Samples:
Topic 51:
Generated: [CLS] leasing bribes trafficking renamed music freelance transformers [SEP]
Target: [CLS] liberty and justice for all [SEP] [PAD] [PAD]

Topic 36:
Generated: [CLS] tobias converse wight explicitly oppression wizards move [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 64:
Generated: [CLS] democracy calculus edwin shaping flawed vastly deny [SEP]
Target: [CLS] written in rooms behind closed doors [SEP] [PAD]

Validation Epoch: 180 [0/10 (0%)] Loss: 27.562059

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 41, 42, 43, 44, 47, 48, 49, 50, 51, 54, 55, 58, 60, 62, 63, 64, 65, 67, 70, 72]
Input sequence lengths: [125, 78, 512, 512, 512, 356, 236, 512, 512, 512, 512, 512, 512, 123, 512, 512, 236, 91, 512, 512, 512, 87, 92, 512, 512, 512, 125, 512, 512, 234, 81, 512]
Target phrase lengths: [5, 7, 8, 7, 6, 5, 7, 4, 6, 6, 8, 6, 3, 8, 4, 6, 8, 4, 4, 4, 5, 6, 6, 6, 5, 8, 4, 8, 8, 4, 6, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.515, 1.158]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 39 | True: 43
Pred: 51 | True: 51
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] honorable kevin mccarthy [SEP] [SEP] and and and
Target: [CLS] honorable kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 43.7609
Generation Loss: 0.0014
Total Loss: 43.7622
Topic Prediction Accuracy: 0.6875
Generation Perplexity: 1.0014
Train Epoch: 181 [0/334 (0%)] Loss: 43.762226
Train Epoch: 181 [64/334 (19%)] Loss: 39.072289
Train Epoch: 181 [128/334 (38%)] Loss: 35.267971
Train Epoch: 181 [192/334 (57%)] Loss: 37.793583
Train Epoch: 181 [256/334 (77%)] Loss: 33.193535
[2025-01-21 12:04:54] Starting validation for epoch: 181

Generation Samples:
Topic 44:
Generated: [CLS] admiral mormon reductions simple navy lakes rational anglo [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 59:
Generated: [CLS] restructuring redskins distribution signed hat belt oyster etymology [SEP]
Target: [CLS] spiritual guidance [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 52:
Generated: [CLS] keys hoop rings renamed tentacles dagger huffed verve [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Validation Epoch: 181 [0/10 (0%)] Loss: 29.668278

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 38, 40, 41, 47, 49, 51, 53, 54, 55, 59, 60, 63, 64, 65, 67, 68, 71, 73]
Input sequence lengths: [512, 512, 512, 78, 512, 512, 512, 512, 356, 356, 512, 512, 512, 512, 512, 204, 512, 512, 366, 512, 512, 512, 512, 145, 209, 512, 512, 268, 334, 512, 453, 449]
Target phrase lengths: [8, 6, 8, 6, 4, 8, 5, 4, 5, 4, 4, 4, 8, 8, 6, 8, 7, 8, 7, 6, 7, 5, 8, 6, 4, 5, 6, 8, 4, 5, 7, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.545, 1.142]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 64 | True: 64
Pred: 36 | True: 36
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] members of congress have to show [SEP] and
Target: [CLS] members of congress have to show [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.0405
Generation Loss: 0.0014
Total Loss: 30.0419
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0014
Train Epoch: 182 [0/334 (0%)] Loss: 30.041924
Train Epoch: 182 [64/334 (19%)] Loss: 45.411907
Train Epoch: 182 [128/334 (38%)] Loss: 25.481564
Train Epoch: 182 [192/334 (57%)] Loss: 20.661900
Train Epoch: 182 [256/334 (77%)] Loss: 46.805000
[2025-01-21 12:04:58] Starting validation for epoch: 182

Generation Samples:
Topic 52:
Generated: [CLS] settler experimenting pea lightning andhra owning funding barrie [SEP]
Target: [CLS] compassionate congressional caseworkers [SEP] [PAD] [PAD]

Topic 52:
Generated: [CLS] israelis beliefs joachim textbook nationalities parasitic minor songs [SEP]
Target: [CLS] public service [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] twisting gregorian li incentives honesty sanctions mistake goo [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 182 [0/10 (0%)] Loss: 21.652233

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 38, 40, 41, 43, 45, 49, 50, 54, 55, 57, 60, 61, 64, 66, 68, 70]
Input sequence lengths: [236, 512, 512, 125, 512, 512, 204, 268, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 485, 512, 159, 204, 512, 512, 356, 512, 123, 512, 125, 356, 512, 512]
Target phrase lengths: [5, 8, 4, 5, 8, 8, 4, 8, 5, 6, 3, 4, 4, 4, 5, 6, 4, 7, 5, 7, 4, 8, 4, 6, 4, 4, 8, 5, 5, 4, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.585, 1.192]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 70 | True: 70
Pred: 54 | True: 54
Pred: 49 | True: 49

Phrase Generation Sample:
Generated: [CLS] anti - choice [SEP] [SEP] [SEP] and [SEP]
Target: [CLS] anti - choice [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 31.8713
Generation Loss: 0.0010
Total Loss: 31.8723
Topic Prediction Accuracy: 0.9062
Generation Perplexity: 1.0010
Train Epoch: 183 [0/334 (0%)] Loss: 31.872314
Train Epoch: 183 [64/334 (19%)] Loss: 33.912018
Train Epoch: 183 [128/334 (38%)] Loss: 46.424454
Train Epoch: 183 [192/334 (57%)] Loss: 36.676933
Train Epoch: 183 [256/334 (77%)] Loss: 34.306362
[2025-01-21 12:05:01] Starting validation for epoch: 183

Generation Samples:
Topic 41:
Generated: [CLS] darren freddie battery limit hydro ryan horrific val [SEP]
Target: [CLS] democrats united [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 38:
Generated: [CLS] an boxes calderon too revolutionary mind midfielder shoe [SEP]
Target: [CLS] byron donalds [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 58:
Generated: [CLS] justine command germany capitals tree musicians watered flies [SEP]
Target: [CLS] civic engagement program [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 183 [0/10 (0%)] Loss: 28.583317

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 39, 41, 42, 43, 47, 48, 49, 51, 52, 54, 56, 58, 59, 60, 61, 63, 64, 65, 66, 71, 72]
Input sequence lengths: [125, 123, 453, 512, 78, 512, 512, 512, 125, 449, 512, 512, 91, 512, 512, 234, 512, 137, 512, 121, 449, 512, 366, 512, 512, 159, 512, 512, 512, 81, 366, 512]
Target phrase lengths: [4, 8, 7, 6, 7, 5, 6, 5, 7, 8, 6, 5, 4, 6, 7, 4, 6, 7, 5, 5, 4, 4, 3, 4, 5, 4, 4, 6, 7, 6, 3, 7]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.540, 1.165]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 43 | True: 43
Pred: 43 | True: 43
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] kevin mccarthy [SEP] [SEP] and and and and
Target: [CLS] kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 30.3709
Generation Loss: 0.0012
Total Loss: 30.3721
Topic Prediction Accuracy: 0.8438
Generation Perplexity: 1.0012
Train Epoch: 184 [0/334 (0%)] Loss: 30.372128
Train Epoch: 184 [64/334 (19%)] Loss: 26.902805
Train Epoch: 184 [128/334 (38%)] Loss: 56.767048
Train Epoch: 184 [192/334 (57%)] Loss: 33.207779
Train Epoch: 184 [256/334 (77%)] Loss: 19.226946
[2025-01-21 12:05:05] Starting validation for epoch: 184

Generation Samples:
Topic 36:
Generated: [CLS] believes binoculars assemble routing christians snake rhode jet [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] darius 18th wah electronics nomination relegation monkey borders [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] greeks angered fortune sentenced morals conduct charm god [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 184 [0/10 (0%)] Loss: 37.278030

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 41, 42, 43, 50, 51, 52, 55, 56, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71]
Input sequence lengths: [512, 388, 512, 512, 512, 512, 92, 449, 512, 512, 449, 512, 512, 512, 512, 453, 125, 512, 512, 512, 512, 512, 356, 512, 145, 512, 356, 145, 204, 512, 366, 453]
Target phrase lengths: [5, 8, 4, 5, 8, 5, 6, 4, 8, 5, 6, 6, 8, 6, 4, 7, 7, 8, 7, 4, 6, 5, 5, 6, 8, 6, 5, 7, 4, 8, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.556, 1.127]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 63 | True: 63
Pred: 69 | True: 69
Pred: 52 | True: 52

Phrase Generation Sample:
Generated: [CLS] two minute votes [SEP] [SEP] [SEP] and [SEP]
Target: [CLS] two minute votes [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 29.5475
Generation Loss: 0.0011
Total Loss: 29.5485
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0011
Train Epoch: 185 [0/334 (0%)] Loss: 29.548550
Train Epoch: 185 [64/334 (19%)] Loss: 21.594069
Train Epoch: 185 [128/334 (38%)] Loss: 21.141380
Train Epoch: 185 [192/334 (57%)] Loss: 38.476933
Train Epoch: 185 [256/334 (77%)] Loss: 29.277224
[2025-01-21 12:05:09] Starting validation for epoch: 185

Generation Samples:
Topic 58:
Generated: [CLS] brook ham mortgage caught systems marshal disputes completes [SEP]
Target: [CLS] political leaders [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] hutchinson lizard wah mari algebra inherited powell parasite [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Topic 46:
Generated: [CLS] leasing inheritance admit christi rig responsive responsible neil [SEP]
Target: [CLS] open rule process [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 185 [0/10 (0%)] Loss: 25.090286

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 38, 40, 41, 42, 43, 45, 47, 49, 51, 52, 54, 55, 56, 60, 61, 63, 66, 70]
Input sequence lengths: [78, 512, 512, 268, 512, 512, 512, 512, 449, 512, 512, 92, 453, 512, 512, 236, 125, 512, 123, 512, 512, 512, 64, 512, 258, 356, 512, 512, 512, 123, 159, 512]
Target phrase lengths: [7, 8, 5, 8, 3, 6, 6, 5, 5, 7, 8, 5, 7, 5, 4, 8, 5, 3, 8, 8, 8, 4, 7, 5, 6, 5, 8, 5, 5, 7, 7, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.562, 1.144]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 60 | True: 60
Pred: 50 | True: 42

Phrase Generation Sample:
Generated: [CLS] flag of the united states [SEP] [SEP] [SEP]
Target: [CLS] flag of the united states [SEP] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.6303
Generation Loss: 0.0011
Total Loss: 36.6314
Topic Prediction Accuracy: 0.8750
Generation Perplexity: 1.0011
Train Epoch: 186 [0/334 (0%)] Loss: 36.631413
Train Epoch: 186 [64/334 (19%)] Loss: 26.835550
Train Epoch: 186 [128/334 (38%)] Loss: 22.818354
Train Epoch: 186 [192/334 (57%)] Loss: 36.760201
Train Epoch: 186 [256/334 (77%)] Loss: 33.368099
[2025-01-21 12:05:19] Starting validation for epoch: 186

Generation Samples:
Topic 44:
Generated: [CLS] chaotic biology intentions protein wingspan primera alphabet named [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Topic 43:
Generated: [CLS] forbes celtics rails modular billion stole silk provision [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] axe convictions logic que hay winger cherry aztec [SEP]
Target: [CLS] republican majority [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 186 [0/10 (0%)] Loss: 47.120373

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [35, 36, 41, 43, 45, 46, 47, 48, 49, 51, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 71]
Input sequence lengths: [512, 125, 78, 366, 512, 512, 512, 449, 356, 145, 485, 268, 159, 366, 145, 512, 512, 512, 512, 123, 512, 92, 512, 512, 356, 137, 159, 81, 356, 512, 449, 512]
Target phrase lengths: [8, 6, 7, 6, 6, 5, 5, 4, 4, 7, 8, 8, 7, 5, 7, 8, 6, 8, 6, 8, 6, 7, 8, 4, 4, 4, 5, 8, 3, 5, 4, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.588, 1.142]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 60 | True: 60
Pred: 43 | True: 43
Pred: 51 | True: 51

Phrase Generation Sample:
Generated: [CLS] u. s. chamber of [SEP] [SEP]
Target: [CLS] u. s. chamber of [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.2083
Generation Loss: 0.0015
Total Loss: 23.2098
Topic Prediction Accuracy: 0.9375
Generation Perplexity: 1.0015
Train Epoch: 187 [0/334 (0%)] Loss: 23.209782
Train Epoch: 187 [64/334 (19%)] Loss: 33.707928
Train Epoch: 187 [128/334 (38%)] Loss: 36.398129
Train Epoch: 187 [192/334 (57%)] Loss: 37.250568
Train Epoch: 187 [256/334 (77%)] Loss: 44.620716
[2025-01-21 12:05:22] Starting validation for epoch: 187

Generation Samples:
Topic 47:
Generated: [CLS] overly political fraud singh j kant soul java [SEP]
Target: [CLS] nominate the gentleman from oklahoma [SEP] [PAD] [PAD]

Topic 44:
Generated: [CLS] pharmaceutical mind devout nerve licenses flags selecting news [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] homer trunks script ezra saul libel county spain [SEP]
Target: [CLS] speaker of the house [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 187 [0/10 (0%)] Loss: 40.328045

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 51, 55, 56, 60, 61, 65, 67, 69, 73]
Input sequence lengths: [512, 512, 512, 512, 512, 356, 512, 159, 512, 512, 388, 512, 234, 512, 512, 512, 512, 512, 78, 125, 449, 125, 512, 121, 512, 209, 453, 512, 512, 512, 512, 512]
Target phrase lengths: [6, 6, 8, 5, 4, 4, 5, 4, 8, 5, 3, 5, 7, 5, 4, 5, 7, 4, 5, 8, 5, 5, 5, 4, 6, 4, 7, 8, 5, 5, 6, 8]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.575, 1.153]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 40 | True: 40
Pred: 65 | True: 65
Pred: 65 | True: 65

Phrase Generation Sample:
Generated: [CLS] right the wrongs [SEP] [SEP] [SEP].
Target: [CLS] right the wrongs [SEP] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 23.9734
Generation Loss: 0.0011
Total Loss: 23.9744
Topic Prediction Accuracy: 0.9688
Generation Perplexity: 1.0011
Train Epoch: 188 [0/334 (0%)] Loss: 23.974442
Train Epoch: 188 [64/334 (19%)] Loss: 28.545731
Train Epoch: 188 [128/334 (38%)] Loss: 28.418316
Train Epoch: 188 [192/334 (57%)] Loss: 25.964285
Train Epoch: 188 [256/334 (77%)] Loss: 20.588707
[2025-01-21 12:05:26] Starting validation for epoch: 188

Generation Samples:
Topic 43:
Generated: [CLS] ottoman kazakh keel expanding constitutional restrictions guards [SEP]
Target: [CLS] votes cast [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] lebanese secession bordered bombs swamp congress tori [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 44:
Generated: [CLS] nevada affluent feather fai secrets macedonian verbs [SEP]
Target: [CLS] nominate kevin mccarthy [SEP] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 188 [0/10 (0%)] Loss: 36.045731

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 39, 43, 48, 49, 50, 53, 54, 55, 56, 58, 59, 63, 64, 65, 66, 67, 70, 71]
Input sequence lengths: [512, 512, 512, 512, 121, 121, 512, 356, 512, 334, 125, 81, 512, 366, 121, 512, 236, 512, 449, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 449, 356, 125]
Target phrase lengths: [8, 5, 7, 4, 4, 6, 8, 3, 6, 4, 5, 8, 4, 3, 5, 5, 8, 8, 4, 4, 4, 8, 5, 7, 6, 4, 5, 4, 5, 5, 4, 5]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.567, 1.138]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 67 | True: 67
Pred: 54 | True: 54
Pred: 66 | True: 66

Phrase Generation Sample:
Generated: [CLS] decrease outlays by $ [SEP] [SEP]
Target: [CLS] decrease outlays by $ [SEP] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 36.5014
Generation Loss: 0.0015
Total Loss: 36.5029
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0015
Train Epoch: 189 [0/334 (0%)] Loss: 36.502892
Train Epoch: 189 [64/334 (19%)] Loss: 26.748436
Train Epoch: 189 [128/334 (38%)] Loss: 35.533371
Train Epoch: 189 [192/334 (57%)] Loss: 30.506859
Train Epoch: 189 [256/334 (77%)] Loss: 28.225298
[2025-01-21 12:05:30] Starting validation for epoch: 189

Generation Samples:
Topic 66:
Generated: [CLS] digitally knicks rust hail gut algebra allergic words [SEP]
Target: [CLS] rules resolution [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 45:
Generated: [CLS] florian crab pepper bedrooms demonic leopard weapons beverage [SEP]
Target: [CLS] diminish voices [SEP] [PAD] [PAD] [PAD]

Topic 65:
Generated: [CLS] europa nl sweater metabolism ns nippon bonus gwen [SEP]
Target: [CLS] attack women ' s access to [SEP] [PAD]

Validation Epoch: 189 [0/10 (0%)] Loss: 47.654179

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [36, 37, 39, 40, 41, 43, 49, 52, 53, 54, 55, 59, 63, 64, 65, 66, 67, 69, 70, 71, 72]
Input sequence lengths: [512, 453, 268, 236, 512, 125, 512, 125, 121, 512, 512, 512, 356, 234, 512, 388, 512, 512, 388, 123, 512, 512, 356, 512, 512, 512, 366, 449, 334, 91, 512, 512]
Target phrase lengths: [4, 8, 8, 8, 4, 5, 4, 5, 4, 8, 5, 5, 4, 4, 8, 8, 5, 5, 4, 8, 5, 4, 5, 7, 7, 4, 5, 7, 6, 4, 5, 6]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.613, 1.182]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 54 | True: 54
Pred: 41 | True: 41
Pred: 41 | True: 41

Phrase Generation Sample:
Generated: [CLS] 23rd amendment [SEP] and and and and and
Target: [CLS] 23rd amendment [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 16.5495
Generation Loss: 0.0015
Total Loss: 16.5510
Topic Prediction Accuracy: 1.0000
Generation Perplexity: 1.0015
Train Epoch: 190 [0/334 (0%)] Loss: 16.550995
Train Epoch: 190 [64/334 (19%)] Loss: 51.266872
Train Epoch: 190 [128/334 (38%)] Loss: 39.799835
Train Epoch: 190 [192/334 (57%)] Loss: 26.585794
Train Epoch: 190 [256/334 (77%)] Loss: 56.579006
[2025-01-21 12:05:34] Starting validation for epoch: 190

Generation Samples:
Topic 36:
Generated: [CLS] arrondissement shook hell fly gesellschaft genera privatization consulting [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] crazed ruining borrow thames [unused630] crore sabre ira [SEP]
Target: [CLS] talented [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 55:
Generated: [CLS] liga shelton shatter kan frog lok philippines spend [SEP]
Target: [CLS] local businesses [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Validation Epoch: 190 [0/10 (0%)] Loss: 26.054768

[DEBUG] Batch Information:
Document IDs shape: torch.Size([32])
Topic IDs shape: torch.Size([32])
Unique topics in batch: [34, 36, 37, 39, 40, 41, 43, 46, 49, 50, 51, 53, 54, 56, 58, 60, 61, 63, 64, 65, 66, 68, 71]
Input sequence lengths: [78, 512, 449, 512, 512, 64, 123, 159, 78, 234, 125, 512, 512, 92, 512, 512, 512, 449, 512, 334, 512, 512, 512, 512, 512, 204, 121, 92, 64, 449, 512, 512]
Target phrase lengths: [5, 6, 4, 5, 5, 8, 8, 4, 6, 4, 5, 4, 4, 5, 4, 8, 7, 4, 4, 8, 6, 6, 4, 8, 4, 6, 5, 6, 5, 4, 8, 4]

[DEBUG] Model Outputs:
Similarity scores shape: torch.Size([32, 74])
Score range: [-0.564, 1.197]
Generation logits shape: torch.Size([32, 9, 30522])

Topic Prediction Sample:
Pred: 51 | True: 51
Pred: 50 | True: 50
Pred: 49 | True: 71

Phrase Generation Sample:
Generated: [CLS] pledge of allegiance [SEP] [SEP] [SEP] and [SEP]
Target: [CLS] pledge of allegiance [SEP] [PAD] [PAD] [PAD] [PAD]

[DEBUG] Loss Values:
Similarity Loss: 33.4775
Generation Loss: 0.0011
Total Loss: 33.4787
Topic Prediction Accuracy: 0.8125
Generation Perplexity: 1.0011
Train Epoch: 191 [0/334 (0%)] Loss: 33.478680
Train Epoch: 191 [64/334 (19%)] Loss: 40.908272
Train Epoch: 191 [128/334 (38%)] Loss: 26.477211
Train Epoch: 191 [192/334 (57%)] Loss: 13.293684
Train Epoch: 191 [256/334 (77%)] Loss: 34.216763
[2025-01-21 12:05:43] Starting validation for epoch: 191

Generation Samples:
Topic 36:
Generated: [CLS] istanbul christ system swap nomination structurally graf nomination [SEP]
Target: [CLS] government that is accountable [SEP] [PAD] [PAD] [PAD]

Topic 41:
Generated: [CLS] republican aqueduct hughes warship dans career arts to [SEP]
Target: [CLS] historic dysfunction [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]

Topic 46:
Generated: [CLS] affiliation mutter allergic deals ham kicks constitutional ballroom [SEP]
Target: [CLS] collaborate and craft legislation [SEP] [PAD] [PAD] [PAD]

Validation Epoch: 191 [0/10 (0%)] Loss: 29.703646
