2025-01-21 11:01:04,762 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:01:07,093 - trainer - INFO - ================================================================================
2025-01-21 11:01:07,093 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:01:07
2025-01-21 11:03:40,474 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:03:42,799 - trainer - INFO - ================================================================================
2025-01-21 11:03:42,799 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:03:42
2025-01-21 11:03:48,569 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:03:48
2025-01-21 11:03:48,570 - trainer - INFO -     epoch          : 1
2025-01-21 11:03:48,570 - trainer - INFO -     elapsed time   : 5.769897222518921
2025-01-21 11:03:48,570 - trainer - INFO -     loss           : 926.0519439697266
2025-01-21 11:03:48,570 - trainer - INFO -     sim_loss       : 80.15059967041016
2025-01-21 11:03:48,570 - trainer - INFO -     gen_loss       : 1288.581137084961
2025-01-21 11:03:48,570 - trainer - INFO -     val_loss       : 597.9047985076904
2025-01-21 11:03:48,570 - trainer - INFO -     val_sim_loss   : 30.897884368896484
2025-01-21 11:03:48,570 - trainer - INFO -     val_gen_loss   : 567.0069103240967
2025-01-21 11:03:48,570 - trainer - INFO -     val_perplexity : 34.28977584838867
2025-01-21 11:03:48,570 - trainer - INFO -     val_embedding_sim: 0.13666823506355286
2025-01-21 11:03:48,570 - trainer - INFO - ================================================================================
2025-01-21 11:03:48,570 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:03:48
2025-01-21 11:03:53,132 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:03:53
2025-01-21 11:03:53,132 - trainer - INFO -     epoch          : 2
2025-01-21 11:03:53,132 - trainer - INFO -     elapsed time   : 4.561354637145996
2025-01-21 11:03:53,132 - trainer - INFO -     loss           : 818.1401336669921
2025-01-21 11:03:53,132 - trainer - INFO -     sim_loss       : 44.15964412689209
2025-01-21 11:03:53,132 - trainer - INFO -     gen_loss       : 1149.8460571289063
2025-01-21 11:03:53,132 - trainer - INFO -     val_loss       : 568.61376953125
2025-01-21 11:03:53,132 - trainer - INFO -     val_sim_loss   : 25.156253814697266
2025-01-21 11:03:53,132 - trainer - INFO -     val_gen_loss   : 543.45751953125
2025-01-21 11:03:53,132 - trainer - INFO -     val_perplexity : 32.679656982421875
2025-01-21 11:03:53,132 - trainer - INFO -     val_embedding_sim: 0.12289004027843475
2025-01-21 11:03:53,132 - trainer - INFO - ================================================================================
2025-01-21 11:03:53,132 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:03:53
2025-01-21 11:03:57,703 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:03:57
2025-01-21 11:03:57,703 - trainer - INFO -     epoch          : 3
2025-01-21 11:03:57,703 - trainer - INFO -     elapsed time   : 4.5706470012664795
2025-01-21 11:03:57,703 - trainer - INFO -     loss           : 769.9964965820312
2025-01-21 11:03:57,703 - trainer - INFO -     sim_loss       : 31.62858376502991
2025-01-21 11:03:57,703 - trainer - INFO -     gen_loss       : 1086.4399047851562
2025-01-21 11:03:57,703 - trainer - INFO -     val_loss       : 539.9116134643555
2025-01-21 11:03:57,703 - trainer - INFO -     val_sim_loss   : 18.201324462890625
2025-01-21 11:03:57,703 - trainer - INFO -     val_gen_loss   : 521.7102890014648
2025-01-21 11:03:57,703 - trainer - INFO -     val_perplexity : 30.639623641967773
2025-01-21 11:03:57,703 - trainer - INFO -     val_embedding_sim: 0.12869185209274292
2025-01-21 11:03:57,703 - trainer - INFO - ================================================================================
2025-01-21 11:03:57,703 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:03:57
2025-01-21 11:04:02,280 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:04:02
2025-01-21 11:04:02,280 - trainer - INFO -     epoch          : 4
2025-01-21 11:04:02,280 - trainer - INFO -     elapsed time   : 4.576574325561523
2025-01-21 11:04:02,280 - trainer - INFO -     loss           : 725.3969787597656
2025-01-21 11:04:02,280 - trainer - INFO -     sim_loss       : 32.78736534118652
2025-01-21 11:04:02,280 - trainer - INFO -     gen_loss       : 1022.2296752929688
2025-01-21 11:04:02,280 - trainer - INFO -     val_loss       : 523.198091506958
2025-01-21 11:04:02,280 - trainer - INFO -     val_sim_loss   : 23.64540672302246
2025-01-21 11:04:02,280 - trainer - INFO -     val_gen_loss   : 499.5526752471924
2025-01-21 11:04:02,281 - trainer - INFO -     val_perplexity : 29.813417434692383
2025-01-21 11:04:02,281 - trainer - INFO -     val_embedding_sim: 0.12147559225559235
2025-01-21 11:04:02,281 - trainer - INFO - ================================================================================
2025-01-21 11:04:02,281 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:04:02
2025-01-21 11:04:06,842 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:04:06
2025-01-21 11:04:06,843 - trainer - INFO -     epoch          : 5
2025-01-21 11:04:06,843 - trainer - INFO -     elapsed time   : 4.561597585678101
2025-01-21 11:04:06,843 - trainer - INFO -     loss           : 679.582080078125
2025-01-21 11:04:06,843 - trainer - INFO -     sim_loss       : 34.431762504577634
2025-01-21 11:04:06,843 - trainer - INFO -     gen_loss       : 956.0750854492187
2025-01-21 11:04:06,843 - trainer - INFO -     val_loss       : 490.88640880584717
2025-01-21 11:04:06,843 - trainer - INFO -     val_sim_loss   : 16.582721710205078
2025-01-21 11:04:06,843 - trainer - INFO -     val_gen_loss   : 474.3036756515503
2025-01-21 11:04:06,843 - trainer - INFO -     val_perplexity : 28.8875675201416
2025-01-21 11:04:06,843 - trainer - INFO -     val_embedding_sim: 0.12403754889965057
2025-01-21 11:04:13,400 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:04:19,930 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:04:19,930 - trainer - INFO - ================================================================================
2025-01-21 11:04:19,930 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:04:19
2025-01-21 11:04:24,561 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:04:24
2025-01-21 11:04:24,562 - trainer - INFO -     epoch          : 6
2025-01-21 11:04:24,562 - trainer - INFO -     elapsed time   : 4.631126165390015
2025-01-21 11:04:24,562 - trainer - INFO -     loss           : 631.5764312744141
2025-01-21 11:04:24,562 - trainer - INFO -     sim_loss       : 34.07801918983459
2025-01-21 11:04:24,562 - trainer - INFO -     gen_loss       : 887.6471923828125
2025-01-21 11:04:24,562 - trainer - INFO -     val_loss       : 465.33051204681396
2025-01-21 11:04:24,562 - trainer - INFO -     val_sim_loss   : 12.27341079711914
2025-01-21 11:04:24,562 - trainer - INFO -     val_gen_loss   : 453.0571050643921
2025-01-21 11:04:24,562 - trainer - INFO -     val_perplexity : 27.352720260620117
2025-01-21 11:04:24,562 - trainer - INFO -     val_embedding_sim: 0.14163225889205933
2025-01-21 11:04:24,562 - trainer - INFO - ================================================================================
2025-01-21 11:04:24,562 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:04:24
2025-01-21 11:04:29,139 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:04:29
2025-01-21 11:04:29,139 - trainer - INFO -     epoch          : 7
2025-01-21 11:04:29,139 - trainer - INFO -     elapsed time   : 4.5769476890563965
2025-01-21 11:04:29,139 - trainer - INFO -     loss           : 589.1849075317383
2025-01-21 11:04:29,139 - trainer - INFO -     sim_loss       : 31.078872680664062
2025-01-21 11:04:29,139 - trainer - INFO -     gen_loss       : 828.3732299804688
2025-01-21 11:04:29,139 - trainer - INFO -     val_loss       : 450.8620386123657
2025-01-21 11:04:29,140 - trainer - INFO -     val_sim_loss   : 14.327374458312988
2025-01-21 11:04:29,140 - trainer - INFO -     val_gen_loss   : 436.53467655181885
2025-01-21 11:04:29,140 - trainer - INFO -     val_perplexity : 26.328960418701172
2025-01-21 11:04:29,140 - trainer - INFO -     val_embedding_sim: 0.12669633328914642
2025-01-21 11:04:29,140 - trainer - INFO - ================================================================================
2025-01-21 11:04:29,140 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:04:29
2025-01-21 11:04:33,707 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:04:33
2025-01-21 11:04:33,707 - trainer - INFO -     epoch          : 8
2025-01-21 11:04:33,708 - trainer - INFO -     elapsed time   : 4.567424297332764
2025-01-21 11:04:33,708 - trainer - INFO -     loss           : 554.25791015625
2025-01-21 11:04:33,708 - trainer - INFO -     sim_loss       : 29.116330003738405
2025-01-21 11:04:33,708 - trainer - INFO -     gen_loss       : 779.3186126708985
2025-01-21 11:04:33,708 - trainer - INFO -     val_loss       : 442.81386137008667
2025-01-21 11:04:33,708 - trainer - INFO -     val_sim_loss   : 16.141357421875
2025-01-21 11:04:33,708 - trainer - INFO -     val_gen_loss   : 426.67250394821167
2025-01-21 11:04:33,708 - trainer - INFO -     val_perplexity : 26.25133514404297
2025-01-21 11:04:33,708 - trainer - INFO -     val_embedding_sim: 0.1423085629940033
2025-01-21 11:04:33,708 - trainer - INFO - ================================================================================
2025-01-21 11:04:33,708 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:04:33
2025-01-21 11:04:38,278 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:04:38
2025-01-21 11:04:38,278 - trainer - INFO -     epoch          : 9
2025-01-21 11:04:38,278 - trainer - INFO -     elapsed time   : 4.5699896812438965
2025-01-21 11:04:38,278 - trainer - INFO -     loss           : 523.0952331542969
2025-01-21 11:04:38,278 - trainer - INFO -     sim_loss       : 33.39409275054932
2025-01-21 11:04:38,278 - trainer - INFO -     gen_loss       : 732.9671691894531
2025-01-21 11:04:38,278 - trainer - INFO -     val_loss       : 431.00056171417236
2025-01-21 11:04:38,278 - trainer - INFO -     val_sim_loss   : 13.267549514770508
2025-01-21 11:04:38,278 - trainer - INFO -     val_gen_loss   : 417.7330141067505
2025-01-21 11:04:38,279 - trainer - INFO -     val_perplexity : 25.40492820739746
2025-01-21 11:04:38,279 - trainer - INFO -     val_embedding_sim: 0.10869182646274567
2025-01-21 11:04:38,279 - trainer - INFO - ================================================================================
2025-01-21 11:04:38,279 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:04:38
2025-01-21 11:04:42,881 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:04:42
2025-01-21 11:04:42,881 - trainer - INFO -     epoch          : 10
2025-01-21 11:04:42,881 - trainer - INFO -     elapsed time   : 4.6018993854522705
2025-01-21 11:04:42,881 - trainer - INFO -     loss           : 491.5878143310547
2025-01-21 11:04:42,881 - trainer - INFO -     sim_loss       : 27.67424144744873
2025-01-21 11:04:42,881 - trainer - INFO -     gen_loss       : 690.407925415039
2025-01-21 11:04:42,881 - trainer - INFO -     val_loss       : 425.7060203552246
2025-01-21 11:04:42,881 - trainer - INFO -     val_sim_loss   : 17.344375610351562
2025-01-21 11:04:42,881 - trainer - INFO -     val_gen_loss   : 408.361629486084
2025-01-21 11:04:42,881 - trainer - INFO -     val_perplexity : 24.039384841918945
2025-01-21 11:04:42,881 - trainer - INFO -     val_embedding_sim: 0.09287156909704208
2025-01-21 11:04:49,408 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:04:55,988 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:04:55,989 - trainer - INFO - ================================================================================
2025-01-21 11:04:55,989 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:04:55
2025-01-21 11:05:00,669 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:05:00
2025-01-21 11:05:00,669 - trainer - INFO -     epoch          : 11
2025-01-21 11:05:00,669 - trainer - INFO -     elapsed time   : 4.67994236946106
2025-01-21 11:05:00,669 - trainer - INFO -     loss           : 464.9297836303711
2025-01-21 11:05:00,669 - trainer - INFO -     sim_loss       : 30.61037149429321
2025-01-21 11:05:00,669 - trainer - INFO -     gen_loss       : 651.0666900634766
2025-01-21 11:05:00,669 - trainer - INFO -     val_loss       : 418.3226079940796
2025-01-21 11:05:00,669 - trainer - INFO -     val_sim_loss   : 11.309075355529785
2025-01-21 11:05:00,669 - trainer - INFO -     val_gen_loss   : 407.0135259628296
2025-01-21 11:05:00,669 - trainer - INFO -     val_perplexity : 24.466413497924805
2025-01-21 11:05:00,669 - trainer - INFO -     val_embedding_sim: 0.09262049198150635
2025-01-21 11:05:00,669 - trainer - INFO - ================================================================================
2025-01-21 11:05:00,669 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:05:00
2025-01-21 11:05:05,255 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:05:05
2025-01-21 11:05:05,255 - trainer - INFO -     epoch          : 12
2025-01-21 11:05:05,255 - trainer - INFO -     elapsed time   : 4.5855443477630615
2025-01-21 11:05:05,255 - trainer - INFO -     loss           : 438.79956970214846
2025-01-21 11:05:05,255 - trainer - INFO -     sim_loss       : 29.593007850646973
2025-01-21 11:05:05,256 - trainer - INFO -     gen_loss       : 614.1738159179688
2025-01-21 11:05:05,256 - trainer - INFO -     val_loss       : 419.10369205474854
2025-01-21 11:05:05,256 - trainer - INFO -     val_sim_loss   : 22.183757781982422
2025-01-21 11:05:05,256 - trainer - INFO -     val_gen_loss   : 396.9199457168579
2025-01-21 11:05:05,256 - trainer - INFO -     val_perplexity : 23.82119369506836
2025-01-21 11:05:05,256 - trainer - INFO -     val_embedding_sim: 0.09391862154006958
2025-01-21 11:05:05,256 - trainer - INFO - ================================================================================
2025-01-21 11:05:05,256 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:05:05
2025-01-21 11:05:09,814 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:05:09
2025-01-21 11:05:09,814 - trainer - INFO -     epoch          : 13
2025-01-21 11:05:09,815 - trainer - INFO -     elapsed time   : 4.5583672523498535
2025-01-21 11:05:09,815 - trainer - INFO -     loss           : 418.70814056396483
2025-01-21 11:05:09,815 - trainer - INFO -     sim_loss       : 27.70587158203125
2025-01-21 11:05:09,815 - trainer - INFO -     gen_loss       : 586.2805480957031
2025-01-21 11:05:09,815 - trainer - INFO -     val_loss       : 410.1313934326172
2025-01-21 11:05:09,815 - trainer - INFO -     val_sim_loss   : 13.565485000610352
2025-01-21 11:05:09,815 - trainer - INFO -     val_gen_loss   : 396.56590270996094
2025-01-21 11:05:09,815 - trainer - INFO -     val_perplexity : 23.933002471923828
2025-01-21 11:05:09,815 - trainer - INFO -     val_embedding_sim: 0.11216865479946136
2025-01-21 11:05:09,815 - trainer - INFO - ================================================================================
2025-01-21 11:05:09,815 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:05:09
2025-01-21 11:05:14,429 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:05:14
2025-01-21 11:05:14,430 - trainer - INFO -     epoch          : 14
2025-01-21 11:05:14,430 - trainer - INFO -     elapsed time   : 4.614391088485718
2025-01-21 11:05:14,430 - trainer - INFO -     loss           : 398.6117248535156
2025-01-21 11:05:14,430 - trainer - INFO -     sim_loss       : 26.843203639984132
2025-01-21 11:05:14,430 - trainer - INFO -     gen_loss       : 557.9410949707031
2025-01-21 11:05:14,430 - trainer - INFO -     val_loss       : 403.31173038482666
2025-01-21 11:05:14,430 - trainer - INFO -     val_sim_loss   : 13.994431495666504
2025-01-21 11:05:14,430 - trainer - INFO -     val_gen_loss   : 389.3172845840454
2025-01-21 11:05:14,430 - trainer - INFO -     val_perplexity : 24.07252311706543
2025-01-21 11:05:14,430 - trainer - INFO -     val_embedding_sim: 0.10106629133224487
2025-01-21 11:05:14,430 - trainer - INFO - ================================================================================
2025-01-21 11:05:14,430 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:05:14
2025-01-21 11:05:19,004 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:05:19
2025-01-21 11:05:19,004 - trainer - INFO -     epoch          : 15
2025-01-21 11:05:19,004 - trainer - INFO -     elapsed time   : 4.573880910873413
2025-01-21 11:05:19,004 - trainer - INFO -     loss           : 379.553173828125
2025-01-21 11:05:19,004 - trainer - INFO -     sim_loss       : 29.399465084075928
2025-01-21 11:05:19,004 - trainer - INFO -     gen_loss       : 529.6190628051758
2025-01-21 11:05:19,004 - trainer - INFO -     val_loss       : 400.81122493743896
2025-01-21 11:05:19,004 - trainer - INFO -     val_sim_loss   : 11.285567283630371
2025-01-21 11:05:19,004 - trainer - INFO -     val_gen_loss   : 389.52567195892334
2025-01-21 11:05:19,004 - trainer - INFO -     val_perplexity : 23.721189498901367
2025-01-21 11:05:19,004 - trainer - INFO -     val_embedding_sim: 0.14927928149700165
2025-01-21 11:05:25,562 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:05:25,562 - trainer - INFO - ================================================================================
2025-01-21 11:05:25,563 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:05:25
2025-01-21 11:05:30,154 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:05:30
2025-01-21 11:05:30,154 - trainer - INFO -     epoch          : 16
2025-01-21 11:05:30,154 - trainer - INFO -     elapsed time   : 4.591327667236328
2025-01-21 11:05:30,154 - trainer - INFO -     loss           : 362.56701507568357
2025-01-21 11:05:30,154 - trainer - INFO -     sim_loss       : 28.248128271102907
2025-01-21 11:05:30,154 - trainer - INFO -     gen_loss       : 505.8465515136719
2025-01-21 11:05:30,154 - trainer - INFO -     val_loss       : 410.37131357192993
2025-01-21 11:05:30,154 - trainer - INFO -     val_sim_loss   : 22.40926170349121
2025-01-21 11:05:30,154 - trainer - INFO -     val_gen_loss   : 387.96204233169556
2025-01-21 11:05:30,155 - trainer - INFO -     val_perplexity : 23.8521728515625
2025-01-21 11:05:30,155 - trainer - INFO -     val_embedding_sim: 0.11508586257696152
2025-01-21 11:05:30,155 - trainer - INFO - ================================================================================
2025-01-21 11:05:30,155 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:05:30
2025-01-21 11:05:34,716 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:05:34
2025-01-21 11:05:34,716 - trainer - INFO -     epoch          : 17
2025-01-21 11:05:34,716 - trainer - INFO -     elapsed time   : 4.561405181884766
2025-01-21 11:05:34,716 - trainer - INFO -     loss           : 348.59795532226565
2025-01-21 11:05:34,716 - trainer - INFO -     sim_loss       : 31.981904792785645
2025-01-21 11:05:34,716 - trainer - INFO -     gen_loss       : 484.2905471801758
2025-01-21 11:05:34,716 - trainer - INFO -     val_loss       : 392.96069717407227
2025-01-21 11:05:34,716 - trainer - INFO -     val_sim_loss   : 11.984954833984375
2025-01-21 11:05:34,716 - trainer - INFO -     val_gen_loss   : 380.9757423400879
2025-01-21 11:05:34,717 - trainer - INFO -     val_perplexity : 22.341129302978516
2025-01-21 11:05:34,717 - trainer - INFO -     val_embedding_sim: 0.13425487279891968
2025-01-21 11:05:34,717 - trainer - INFO - ================================================================================
2025-01-21 11:05:34,717 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:05:34
2025-01-21 11:05:39,288 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:05:39
2025-01-21 11:05:39,288 - trainer - INFO -     epoch          : 18
2025-01-21 11:05:39,288 - trainer - INFO -     elapsed time   : 4.571536064147949
2025-01-21 11:05:39,289 - trainer - INFO -     loss           : 332.93125
2025-01-21 11:05:39,289 - trainer - INFO -     sim_loss       : 30.995863723754884
2025-01-21 11:05:39,289 - trainer - INFO -     gen_loss       : 462.33212890625
2025-01-21 11:05:39,289 - trainer - INFO -     val_loss       : 395.7828621864319
2025-01-21 11:05:39,289 - trainer - INFO -     val_sim_loss   : 14.72945785522461
2025-01-21 11:05:39,289 - trainer - INFO -     val_gen_loss   : 381.05340051651
2025-01-21 11:05:39,289 - trainer - INFO -     val_perplexity : 23.6783390045166
2025-01-21 11:05:39,289 - trainer - INFO -     val_embedding_sim: 0.12871184945106506
2025-01-21 11:05:39,289 - trainer - INFO - ================================================================================
2025-01-21 11:05:39,289 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:05:39
2025-01-21 11:05:43,858 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:05:43
2025-01-21 11:05:43,858 - trainer - INFO -     epoch          : 19
2025-01-21 11:05:43,858 - trainer - INFO -     elapsed time   : 4.568909168243408
2025-01-21 11:05:43,858 - trainer - INFO -     loss           : 317.53098449707034
2025-01-21 11:05:43,858 - trainer - INFO -     sim_loss       : 26.617593193054198
2025-01-21 11:05:43,858 - trainer - INFO -     gen_loss       : 442.20815124511716
2025-01-21 11:05:43,858 - trainer - INFO -     val_loss       : 400.50645446777344
2025-01-21 11:05:43,858 - trainer - INFO -     val_sim_loss   : 16.905010223388672
2025-01-21 11:05:43,858 - trainer - INFO -     val_gen_loss   : 383.60145568847656
2025-01-21 11:05:43,858 - trainer - INFO -     val_perplexity : 21.875045776367188
2025-01-21 11:05:43,858 - trainer - INFO -     val_embedding_sim: 0.12683440744876862
2025-01-21 11:05:43,858 - trainer - INFO - ================================================================================
2025-01-21 11:05:43,859 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:05:43
2025-01-21 11:05:48,475 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:05:48
2025-01-21 11:05:48,475 - trainer - INFO -     epoch          : 20
2025-01-21 11:05:48,475 - trainer - INFO -     elapsed time   : 4.616438627243042
2025-01-21 11:05:48,475 - trainer - INFO -     loss           : 304.07374267578126
2025-01-21 11:05:48,475 - trainer - INFO -     sim_loss       : 26.845297050476074
2025-01-21 11:05:48,475 - trainer - INFO -     gen_loss       : 422.88594512939454
2025-01-21 11:05:48,475 - trainer - INFO -     val_loss       : 396.75442457199097
2025-01-21 11:05:48,475 - trainer - INFO -     val_sim_loss   : 13.29230785369873
2025-01-21 11:05:48,476 - trainer - INFO -     val_gen_loss   : 383.4621272087097
2025-01-21 11:05:48,476 - trainer - INFO -     val_perplexity : 23.7319393157959
2025-01-21 11:05:48,476 - trainer - INFO -     val_embedding_sim: 0.12024622410535812
2025-01-21 11:05:55,016 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:05:55,016 - trainer - INFO - ================================================================================
2025-01-21 11:05:55,016 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:05:55
2025-01-21 11:05:59,628 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:05:59
2025-01-21 11:05:59,628 - trainer - INFO -     epoch          : 21
2025-01-21 11:05:59,628 - trainer - INFO -     elapsed time   : 4.611464262008667
2025-01-21 11:05:59,628 - trainer - INFO -     loss           : 289.8626235961914
2025-01-21 11:05:59,628 - trainer - INFO -     sim_loss       : 26.495360946655275
2025-01-21 11:05:59,628 - trainer - INFO -     gen_loss       : 402.73431701660155
2025-01-21 11:05:59,628 - trainer - INFO -     val_loss       : 404.3116569519043
2025-01-21 11:05:59,628 - trainer - INFO -     val_sim_loss   : 20.561983108520508
2025-01-21 11:05:59,628 - trainer - INFO -     val_gen_loss   : 383.7496757507324
2025-01-21 11:05:59,628 - trainer - INFO -     val_perplexity : 22.541950225830078
2025-01-21 11:05:59,628 - trainer - INFO -     val_embedding_sim: 0.13378143310546875
2025-01-21 11:05:59,628 - trainer - INFO - ================================================================================
2025-01-21 11:05:59,628 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:05:59
2025-01-21 11:06:04,212 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:06:04
2025-01-21 11:06:04,212 - trainer - INFO -     epoch          : 22
2025-01-21 11:06:04,212 - trainer - INFO -     elapsed time   : 4.583429574966431
2025-01-21 11:06:04,212 - trainer - INFO -     loss           : 278.73849029541014
2025-01-21 11:06:04,212 - trainer - INFO -     sim_loss       : 28.3484069455415
2025-01-21 11:06:04,212 - trainer - INFO -     gen_loss       : 386.04854278564454
2025-01-21 11:06:04,212 - trainer - INFO -     val_loss       : 401.3933849334717
2025-01-21 11:06:04,212 - trainer - INFO -     val_sim_loss   : 21.331533432006836
2025-01-21 11:06:04,212 - trainer - INFO -     val_gen_loss   : 380.0618419647217
2025-01-21 11:06:04,212 - trainer - INFO -     val_perplexity : 22.21444320678711
2025-01-21 11:06:04,212 - trainer - INFO -     val_embedding_sim: 0.0923214852809906
2025-01-21 11:06:04,212 - trainer - INFO - ================================================================================
2025-01-21 11:06:04,212 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:06:04
2025-01-21 11:06:08,796 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:06:08
2025-01-21 11:06:08,796 - trainer - INFO -     epoch          : 23
2025-01-21 11:06:08,796 - trainer - INFO -     elapsed time   : 4.583087205886841
2025-01-21 11:06:08,796 - trainer - INFO -     loss           : 267.6239471435547
2025-01-21 11:06:08,796 - trainer - INFO -     sim_loss       : 26.38816108703613
2025-01-21 11:06:08,796 - trainer - INFO -     gen_loss       : 371.0107162475586
2025-01-21 11:06:08,796 - trainer - INFO -     val_loss       : 394.9864454269409
2025-01-21 11:06:08,796 - trainer - INFO -     val_sim_loss   : 13.367634773254395
2025-01-21 11:06:08,796 - trainer - INFO -     val_gen_loss   : 381.61880016326904
2025-01-21 11:06:08,796 - trainer - INFO -     val_perplexity : 23.28582763671875
2025-01-21 11:06:08,796 - trainer - INFO -     val_embedding_sim: 0.13532155752182007
2025-01-21 11:06:08,796 - trainer - INFO - ================================================================================
2025-01-21 11:06:08,796 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:06:08
2025-01-21 11:06:13,378 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:06:13
2025-01-21 11:06:13,378 - trainer - INFO -     epoch          : 24
2025-01-21 11:06:13,378 - trainer - INFO -     elapsed time   : 4.5814478397369385
2025-01-21 11:06:13,378 - trainer - INFO -     loss           : 256.7323974609375
2025-01-21 11:06:13,378 - trainer - INFO -     sim_loss       : 29.187371730804443
2025-01-21 11:06:13,378 - trainer - INFO -     gen_loss       : 354.25169982910154
2025-01-21 11:06:13,378 - trainer - INFO -     val_loss       : 394.3366184234619
2025-01-21 11:06:13,378 - trainer - INFO -     val_sim_loss   : 12.41535472869873
2025-01-21 11:06:13,378 - trainer - INFO -     val_gen_loss   : 381.92127418518066
2025-01-21 11:06:13,378 - trainer - INFO -     val_perplexity : 22.326684951782227
2025-01-21 11:06:13,378 - trainer - INFO -     val_embedding_sim: 0.13327088952064514
2025-01-21 11:06:13,378 - trainer - INFO - ================================================================================
2025-01-21 11:06:13,378 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:06:13
2025-01-21 11:06:17,939 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:06:17
2025-01-21 11:06:17,939 - trainer - INFO -     epoch          : 25
2025-01-21 11:06:17,939 - trainer - INFO -     elapsed time   : 4.560091018676758
2025-01-21 11:06:17,939 - trainer - INFO -     loss           : 247.40595245361328
2025-01-21 11:06:17,939 - trainer - INFO -     sim_loss       : 32.51254043579102
2025-01-21 11:06:17,939 - trainer - INFO -     gen_loss       : 339.5031280517578
2025-01-21 11:06:17,939 - trainer - INFO -     val_loss       : 402.5485563278198
2025-01-21 11:06:17,939 - trainer - INFO -     val_sim_loss   : 19.839874267578125
2025-01-21 11:06:17,939 - trainer - INFO -     val_gen_loss   : 382.7086820602417
2025-01-21 11:06:17,939 - trainer - INFO -     val_perplexity : 23.071298599243164
2025-01-21 11:06:17,939 - trainer - INFO -     val_embedding_sim: 0.12485183030366898
2025-01-21 11:06:24,481 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:06:24,481 - trainer - INFO - ================================================================================
2025-01-21 11:06:24,481 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:06:24
2025-01-21 11:06:29,118 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:06:29
2025-01-21 11:06:29,118 - trainer - INFO -     epoch          : 26
2025-01-21 11:06:29,118 - trainer - INFO -     elapsed time   : 4.63640022277832
2025-01-21 11:06:29,118 - trainer - INFO -     loss           : 237.32769165039062
2025-01-21 11:06:29,118 - trainer - INFO -     sim_loss       : 30.976594734191895
2025-01-21 11:06:29,118 - trainer - INFO -     gen_loss       : 325.7638824462891
2025-01-21 11:06:29,118 - trainer - INFO -     val_loss       : 398.11186027526855
2025-01-21 11:06:29,118 - trainer - INFO -     val_sim_loss   : 16.67139434814453
2025-01-21 11:06:29,118 - trainer - INFO -     val_gen_loss   : 381.44047355651855
2025-01-21 11:06:29,118 - trainer - INFO -     val_perplexity : 23.701885223388672
2025-01-21 11:06:29,118 - trainer - INFO -     val_embedding_sim: 0.13946932554244995
2025-01-21 11:06:29,118 - trainer - INFO - ================================================================================
2025-01-21 11:06:29,118 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:06:29
2025-01-21 11:06:33,698 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:06:33
2025-01-21 11:06:33,698 - trainer - INFO -     epoch          : 27
2025-01-21 11:06:33,698 - trainer - INFO -     elapsed time   : 4.579484701156616
2025-01-21 11:06:33,698 - trainer - INFO -     loss           : 225.3188934326172
2025-01-21 11:06:33,698 - trainer - INFO -     sim_loss       : 28.23128433227539
2025-01-21 11:06:33,698 - trainer - INFO -     gen_loss       : 309.7850227355957
2025-01-21 11:06:33,698 - trainer - INFO -     val_loss       : 394.7086944580078
2025-01-21 11:06:33,698 - trainer - INFO -     val_sim_loss   : 12.547508239746094
2025-01-21 11:06:33,698 - trainer - INFO -     val_gen_loss   : 382.1611785888672
2025-01-21 11:06:33,698 - trainer - INFO -     val_perplexity : 23.72279930114746
2025-01-21 11:06:33,698 - trainer - INFO -     val_embedding_sim: 0.11035062372684479
2025-01-21 11:06:33,698 - trainer - INFO - ================================================================================
2025-01-21 11:06:33,698 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:06:33
2025-01-21 11:06:38,261 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:06:38
2025-01-21 11:06:38,261 - trainer - INFO -     epoch          : 28
2025-01-21 11:06:38,262 - trainer - INFO -     elapsed time   : 4.562955141067505
2025-01-21 11:06:38,262 - trainer - INFO -     loss           : 219.90910949707032
2025-01-21 11:06:38,262 - trainer - INFO -     sim_loss       : 35.44960741996765
2025-01-21 11:06:38,262 - trainer - INFO -     gen_loss       : 298.9631881713867
2025-01-21 11:06:38,262 - trainer - INFO -     val_loss       : 395.7241415977478
2025-01-21 11:06:38,262 - trainer - INFO -     val_sim_loss   : 16.152671813964844
2025-01-21 11:06:38,262 - trainer - INFO -     val_gen_loss   : 379.5714621543884
2025-01-21 11:06:38,262 - trainer - INFO -     val_perplexity : 23.45545768737793
2025-01-21 11:06:38,262 - trainer - INFO -     val_embedding_sim: 0.12125259637832642
2025-01-21 11:06:38,262 - trainer - INFO - ================================================================================
2025-01-21 11:06:38,262 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:06:38
2025-01-21 11:06:42,834 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:06:42
2025-01-21 11:06:42,834 - trainer - INFO -     epoch          : 29
2025-01-21 11:06:42,834 - trainer - INFO -     elapsed time   : 4.57200026512146
2025-01-21 11:06:42,834 - trainer - INFO -     loss           : 209.67716369628906
2025-01-21 11:06:42,834 - trainer - INFO -     sim_loss       : 32.89674882888794
2025-01-21 11:06:42,834 - trainer - INFO -     gen_loss       : 285.4402053833008
2025-01-21 11:06:42,834 - trainer - INFO -     val_loss       : 389.5766201019287
2025-01-21 11:06:42,834 - trainer - INFO -     val_sim_loss   : 9.445537567138672
2025-01-21 11:06:42,834 - trainer - INFO -     val_gen_loss   : 380.13109397888184
2025-01-21 11:06:42,835 - trainer - INFO -     val_perplexity : 23.628822326660156
2025-01-21 11:06:42,835 - trainer - INFO -     val_embedding_sim: 0.15667513012886047
2025-01-21 11:06:42,835 - trainer - INFO - ================================================================================
2025-01-21 11:06:42,835 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:06:42
2025-01-21 11:06:47,409 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:06:47
2025-01-21 11:06:47,409 - trainer - INFO -     epoch          : 30
2025-01-21 11:06:47,409 - trainer - INFO -     elapsed time   : 4.57393217086792
2025-01-21 11:06:47,409 - trainer - INFO -     loss           : 198.5173599243164
2025-01-21 11:06:47,409 - trainer - INFO -     sim_loss       : 30.605120277404787
2025-01-21 11:06:47,409 - trainer - INFO -     gen_loss       : 270.4797523498535
2025-01-21 11:06:47,409 - trainer - INFO -     val_loss       : 399.3052816390991
2025-01-21 11:06:47,409 - trainer - INFO -     val_sim_loss   : 19.226608276367188
2025-01-21 11:06:47,409 - trainer - INFO -     val_gen_loss   : 380.078688621521
2025-01-21 11:06:47,409 - trainer - INFO -     val_perplexity : 22.93596076965332
2025-01-21 11:06:47,409 - trainer - INFO -     val_embedding_sim: 0.1265895962715149
2025-01-21 11:06:53,954 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:06:53,955 - trainer - INFO - ================================================================================
2025-01-21 11:06:53,955 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:06:53
2025-01-21 11:06:58,559 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:06:58
2025-01-21 11:06:58,559 - trainer - INFO -     epoch          : 31
2025-01-21 11:06:58,559 - trainer - INFO -     elapsed time   : 4.603986740112305
2025-01-21 11:06:58,559 - trainer - INFO -     loss           : 192.83720855712892
2025-01-21 11:06:58,559 - trainer - INFO -     sim_loss       : 32.622314453125
2025-01-21 11:06:58,559 - trainer - INFO -     gen_loss       : 261.50073394775393
2025-01-21 11:06:58,559 - trainer - INFO -     val_loss       : 395.8862247467041
2025-01-21 11:06:58,559 - trainer - INFO -     val_sim_loss   : 18.706209182739258
2025-01-21 11:06:58,559 - trainer - INFO -     val_gen_loss   : 377.1800174713135
2025-01-21 11:06:58,559 - trainer - INFO -     val_perplexity : 23.001020431518555
2025-01-21 11:06:58,560 - trainer - INFO -     val_embedding_sim: 0.14227081835269928
2025-01-21 11:06:58,560 - trainer - INFO - ================================================================================
2025-01-21 11:06:58,560 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:06:58
2025-01-21 11:07:03,136 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:07:03
2025-01-21 11:07:03,136 - trainer - INFO -     epoch          : 32
2025-01-21 11:07:03,136 - trainer - INFO -     elapsed time   : 4.575792074203491
2025-01-21 11:07:03,136 - trainer - INFO -     loss           : 185.6061584472656
2025-01-21 11:07:03,136 - trainer - INFO -     sim_loss       : 32.09314727783203
2025-01-21 11:07:03,136 - trainer - INFO -     gen_loss       : 251.3974494934082
2025-01-21 11:07:03,136 - trainer - INFO -     val_loss       : 396.84227871894836
2025-01-21 11:07:03,136 - trainer - INFO -     val_sim_loss   : 17.165834426879883
2025-01-21 11:07:03,136 - trainer - INFO -     val_gen_loss   : 379.6764461994171
2025-01-21 11:07:03,136 - trainer - INFO -     val_perplexity : 23.615575790405273
2025-01-21 11:07:03,136 - trainer - INFO -     val_embedding_sim: 0.1305200159549713
2025-01-21 11:07:03,136 - trainer - INFO - ================================================================================
2025-01-21 11:07:03,136 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:07:03
2025-01-21 11:07:07,700 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:07:07
2025-01-21 11:07:07,701 - trainer - INFO -     epoch          : 33
2025-01-21 11:07:07,701 - trainer - INFO -     elapsed time   : 4.564084529876709
2025-01-21 11:07:07,701 - trainer - INFO -     loss           : 177.87935256958008
2025-01-21 11:07:07,701 - trainer - INFO -     sim_loss       : 31.279668617248536
2025-01-21 11:07:07,701 - trainer - INFO -     gen_loss       : 240.70779037475586
2025-01-21 11:07:07,701 - trainer - INFO -     val_loss       : 397.1735324859619
2025-01-21 11:07:07,701 - trainer - INFO -     val_sim_loss   : 19.88849639892578
2025-01-21 11:07:07,701 - trainer - INFO -     val_gen_loss   : 377.28504371643066
2025-01-21 11:07:07,701 - trainer - INFO -     val_perplexity : 22.446870803833008
2025-01-21 11:07:07,701 - trainer - INFO -     val_embedding_sim: 0.14647454023361206
2025-01-21 11:07:07,701 - trainer - INFO - ================================================================================
2025-01-21 11:07:07,701 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:07:07
2025-01-21 11:07:12,269 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:07:12
2025-01-21 11:07:12,270 - trainer - INFO -     epoch          : 34
2025-01-21 11:07:12,270 - trainer - INFO -     elapsed time   : 4.568286895751953
2025-01-21 11:07:12,270 - trainer - INFO -     loss           : 172.16134872436524
2025-01-21 11:07:12,270 - trainer - INFO -     sim_loss       : 35.688871192932126
2025-01-21 11:07:12,270 - trainer - INFO -     gen_loss       : 230.6495590209961
2025-01-21 11:07:12,270 - trainer - INFO -     val_loss       : 398.82242584228516
2025-01-21 11:07:12,270 - trainer - INFO -     val_sim_loss   : 22.559608459472656
2025-01-21 11:07:12,270 - trainer - INFO -     val_gen_loss   : 376.26282501220703
2025-01-21 11:07:12,270 - trainer - INFO -     val_perplexity : 22.672943115234375
2025-01-21 11:07:12,270 - trainer - INFO -     val_embedding_sim: 0.10685752332210541
2025-01-21 11:07:12,270 - trainer - INFO - ================================================================================
2025-01-21 11:07:12,270 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:07:12
2025-01-21 11:07:16,841 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:07:16
2025-01-21 11:07:16,841 - trainer - INFO -     epoch          : 35
2025-01-21 11:07:16,841 - trainer - INFO -     elapsed time   : 4.570559740066528
2025-01-21 11:07:16,841 - trainer - INFO -     loss           : 164.98186340332032
2025-01-21 11:07:16,841 - trainer - INFO -     sim_loss       : 35.72227935791015
2025-01-21 11:07:16,841 - trainer - INFO -     gen_loss       : 220.3788284301758
2025-01-21 11:07:16,841 - trainer - INFO -     val_loss       : 392.46038150787354
2025-01-21 11:07:16,841 - trainer - INFO -     val_sim_loss   : 15.513741493225098
2025-01-21 11:07:16,841 - trainer - INFO -     val_gen_loss   : 376.9466485977173
2025-01-21 11:07:16,841 - trainer - INFO -     val_perplexity : 22.735275268554688
2025-01-21 11:07:16,841 - trainer - INFO -     val_embedding_sim: 0.11791209876537323
2025-01-21 11:07:23,385 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:07:23,385 - trainer - INFO - ================================================================================
2025-01-21 11:07:23,386 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:07:23
2025-01-21 11:07:28,010 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:07:28
2025-01-21 11:07:28,010 - trainer - INFO -     epoch          : 36
2025-01-21 11:07:28,010 - trainer - INFO -     elapsed time   : 4.624375581741333
2025-01-21 11:07:28,010 - trainer - INFO -     loss           : 160.03375091552735
2025-01-21 11:07:28,010 - trainer - INFO -     sim_loss       : 36.06581039428711
2025-01-21 11:07:28,010 - trainer - INFO -     gen_loss       : 213.1628730773926
2025-01-21 11:07:28,010 - trainer - INFO -     val_loss       : 399.7429094314575
2025-01-21 11:07:28,010 - trainer - INFO -     val_sim_loss   : 23.07292938232422
2025-01-21 11:07:28,010 - trainer - INFO -     val_gen_loss   : 376.66997241973877
2025-01-21 11:07:28,011 - trainer - INFO -     val_perplexity : 23.340465545654297
2025-01-21 11:07:28,011 - trainer - INFO -     val_embedding_sim: 0.11261183023452759
2025-01-21 11:07:28,011 - trainer - INFO - ================================================================================
2025-01-21 11:07:28,011 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:07:28
2025-01-21 11:07:32,674 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:07:32
2025-01-21 11:07:32,675 - trainer - INFO -     epoch          : 37
2025-01-21 11:07:32,675 - trainer - INFO -     elapsed time   : 4.663675308227539
2025-01-21 11:07:32,675 - trainer - INFO -     loss           : 152.88824577331542
2025-01-21 11:07:32,675 - trainer - INFO -     sim_loss       : 34.17824096679688
2025-01-21 11:07:32,675 - trainer - INFO -     gen_loss       : 203.76396636962892
2025-01-21 11:07:32,675 - trainer - INFO -     val_loss       : 399.6528694629669
2025-01-21 11:07:32,675 - trainer - INFO -     val_sim_loss   : 22.959774017333984
2025-01-21 11:07:32,675 - trainer - INFO -     val_gen_loss   : 376.69309163093567
2025-01-21 11:07:32,675 - trainer - INFO -     val_perplexity : 23.43353271484375
2025-01-21 11:07:32,675 - trainer - INFO -     val_embedding_sim: 0.12836489081382751
2025-01-21 11:07:32,675 - trainer - INFO - ================================================================================
2025-01-21 11:07:32,675 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:07:32
2025-01-21 11:07:37,240 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:07:37
2025-01-21 11:07:37,240 - trainer - INFO -     epoch          : 38
2025-01-21 11:07:37,240 - trainer - INFO -     elapsed time   : 4.564334392547607
2025-01-21 11:07:37,240 - trainer - INFO -     loss           : 142.66408462524413
2025-01-21 11:07:37,240 - trainer - INFO -     sim_loss       : 29.484304869174956
2025-01-21 11:07:37,240 - trainer - INFO -     gen_loss       : 191.16970291137696
2025-01-21 11:07:37,240 - trainer - INFO -     val_loss       : 392.1994709968567
2025-01-21 11:07:37,240 - trainer - INFO -     val_sim_loss   : 14.515802383422852
2025-01-21 11:07:37,240 - trainer - INFO -     val_gen_loss   : 377.68366289138794
2025-01-21 11:07:37,240 - trainer - INFO -     val_perplexity : 23.521451950073242
2025-01-21 11:07:37,240 - trainer - INFO -     val_embedding_sim: 0.12678614258766174
2025-01-21 11:07:37,240 - trainer - INFO - ================================================================================
2025-01-21 11:07:37,240 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:07:37
2025-01-21 11:07:41,805 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:07:41
2025-01-21 11:07:41,805 - trainer - INFO -     epoch          : 39
2025-01-21 11:07:41,806 - trainer - INFO -     elapsed time   : 4.565058708190918
2025-01-21 11:07:41,806 - trainer - INFO -     loss           : 137.12266731262207
2025-01-21 11:07:41,806 - trainer - INFO -     sim_loss       : 33.069167137145996
2025-01-21 11:07:41,806 - trainer - INFO -     gen_loss       : 181.71702880859374
2025-01-21 11:07:41,806 - trainer - INFO -     val_loss       : 401.5969982147217
2025-01-21 11:07:41,806 - trainer - INFO -     val_sim_loss   : 19.5091552734375
2025-01-21 11:07:41,806 - trainer - INFO -     val_gen_loss   : 382.0878429412842
2025-01-21 11:07:41,806 - trainer - INFO -     val_perplexity : 23.13101577758789
2025-01-21 11:07:41,806 - trainer - INFO -     val_embedding_sim: 0.1344166249036789
2025-01-21 11:07:41,806 - trainer - INFO - ================================================================================
2025-01-21 11:07:41,806 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:07:41
2025-01-21 11:07:46,387 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:07:46
2025-01-21 11:07:46,387 - trainer - INFO -     epoch          : 40
2025-01-21 11:07:46,387 - trainer - INFO -     elapsed time   : 4.58116888999939
2025-01-21 11:07:46,387 - trainer - INFO -     loss           : 132.0966640472412
2025-01-21 11:07:46,387 - trainer - INFO -     sim_loss       : 33.135322380065915
2025-01-21 11:07:46,388 - trainer - INFO -     gen_loss       : 174.5086685180664
2025-01-21 11:07:46,388 - trainer - INFO -     val_loss       : 391.88061714172363
2025-01-21 11:07:46,388 - trainer - INFO -     val_sim_loss   : 16.57118034362793
2025-01-21 11:07:46,388 - trainer - INFO -     val_gen_loss   : 375.30945014953613
2025-01-21 11:07:46,388 - trainer - INFO -     val_perplexity : 21.921201705932617
2025-01-21 11:07:46,388 - trainer - INFO -     val_embedding_sim: 0.1477673202753067
2025-01-21 11:07:52,932 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:07:59,599 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:07:59,599 - trainer - INFO - ================================================================================
2025-01-21 11:07:59,599 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:07:59
2025-01-21 11:08:04,222 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:08:04
2025-01-21 11:08:04,222 - trainer - INFO -     epoch          : 41
2025-01-21 11:08:04,222 - trainer - INFO -     elapsed time   : 4.622908115386963
2025-01-21 11:08:04,222 - trainer - INFO -     loss           : 125.65115585327149
2025-01-21 11:08:04,222 - trainer - INFO -     sim_loss       : 28.30113353729248
2025-01-21 11:08:04,222 - trainer - INFO -     gen_loss       : 167.37259979248046
2025-01-21 11:08:04,222 - trainer - INFO -     val_loss       : 396.57395219802856
2025-01-21 11:08:04,222 - trainer - INFO -     val_sim_loss   : 13.655406951904297
2025-01-21 11:08:04,222 - trainer - INFO -     val_gen_loss   : 382.91855669021606
2025-01-21 11:08:04,223 - trainer - INFO -     val_perplexity : 23.848617553710938
2025-01-21 11:08:04,223 - trainer - INFO -     val_embedding_sim: 0.14294463396072388
2025-01-21 11:08:04,223 - trainer - INFO - ================================================================================
2025-01-21 11:08:04,223 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:08:04
2025-01-21 11:08:08,793 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:08:08
2025-01-21 11:08:08,793 - trainer - INFO -     epoch          : 42
2025-01-21 11:08:08,793 - trainer - INFO -     elapsed time   : 4.56999397277832
2025-01-21 11:08:08,793 - trainer - INFO -     loss           : 121.72511367797851
2025-01-21 11:08:08,793 - trainer - INFO -     sim_loss       : 31.011959409713747
2025-01-21 11:08:08,793 - trainer - INFO -     gen_loss       : 160.6021842956543
2025-01-21 11:08:08,793 - trainer - INFO -     val_loss       : 406.6568946838379
2025-01-21 11:08:08,793 - trainer - INFO -     val_sim_loss   : 25.481201171875
2025-01-21 11:08:08,793 - trainer - INFO -     val_gen_loss   : 381.1756935119629
2025-01-21 11:08:08,793 - trainer - INFO -     val_perplexity : 22.3211727142334
2025-01-21 11:08:08,793 - trainer - INFO -     val_embedding_sim: 0.1632392406463623
2025-01-21 11:08:08,793 - trainer - INFO - ================================================================================
2025-01-21 11:08:08,793 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:08:08
2025-01-21 11:10:49,041 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:10:51,357 - trainer - INFO - ================================================================================
2025-01-21 11:10:51,357 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:10:51
2025-01-21 11:10:57,127 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:10:57
2025-01-21 11:10:57,127 - trainer - INFO -     epoch          : 1
2025-01-21 11:10:57,127 - trainer - INFO -     elapsed time   : 5.769922733306885
2025-01-21 11:10:57,127 - trainer - INFO -     loss           : 926.0518676757813
2025-01-21 11:10:57,127 - trainer - INFO -     sim_loss       : 80.15060462951661
2025-01-21 11:10:57,127 - trainer - INFO -     gen_loss       : 1288.581021118164
2025-01-21 11:10:57,127 - trainer - INFO -     val_loss       : 597.9046440124512
2025-01-21 11:10:57,127 - trainer - INFO -     val_sim_loss   : 30.897905349731445
2025-01-21 11:10:57,127 - trainer - INFO -     val_gen_loss   : 567.0067558288574
2025-01-21 11:10:57,127 - trainer - INFO -     val_perplexity : 34.28976821899414
2025-01-21 11:10:57,128 - trainer - INFO -     val_embedding_sim: 0.13666823506355286
2025-01-21 11:10:57,128 - trainer - INFO - ================================================================================
2025-01-21 11:10:57,128 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:10:57
2025-01-21 11:11:01,685 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:11:01
2025-01-21 11:11:01,685 - trainer - INFO -     epoch          : 2
2025-01-21 11:11:01,685 - trainer - INFO -     elapsed time   : 4.556779861450195
2025-01-21 11:11:01,685 - trainer - INFO -     loss           : 818.138818359375
2025-01-21 11:11:01,685 - trainer - INFO -     sim_loss       : 44.15967655181885
2025-01-21 11:11:01,685 - trainer - INFO -     gen_loss       : 1149.8442016601562
2025-01-21 11:11:01,685 - trainer - INFO -     val_loss       : 568.6213397979736
2025-01-21 11:11:01,685 - trainer - INFO -     val_sim_loss   : 25.156375885009766
2025-01-21 11:11:01,685 - trainer - INFO -     val_gen_loss   : 543.4649677276611
2025-01-21 11:11:01,685 - trainer - INFO -     val_perplexity : 32.68014144897461
2025-01-21 11:11:01,685 - trainer - INFO -     val_embedding_sim: 0.12105973064899445
2025-01-21 11:11:01,685 - trainer - INFO - ================================================================================
2025-01-21 11:11:01,685 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:11:01
2025-01-21 11:11:06,248 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:11:06
2025-01-21 11:11:06,248 - trainer - INFO -     epoch          : 3
2025-01-21 11:11:06,249 - trainer - INFO -     elapsed time   : 4.563124179840088
2025-01-21 11:11:06,249 - trainer - INFO -     loss           : 769.9986541748046
2025-01-21 11:11:06,249 - trainer - INFO -     sim_loss       : 31.62845907211304
2025-01-21 11:11:06,249 - trainer - INFO -     gen_loss       : 1086.443032836914
2025-01-21 11:11:06,249 - trainer - INFO -     val_loss       : 539.9182319641113
2025-01-21 11:11:06,249 - trainer - INFO -     val_sim_loss   : 18.201953887939453
2025-01-21 11:11:06,249 - trainer - INFO -     val_gen_loss   : 521.7162666320801
2025-01-21 11:11:06,249 - trainer - INFO -     val_perplexity : 30.639976501464844
2025-01-21 11:11:06,249 - trainer - INFO -     val_embedding_sim: 0.12869185209274292
2025-01-21 11:11:06,249 - trainer - INFO - ================================================================================
2025-01-21 11:11:06,249 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:11:06
2025-01-21 11:11:10,808 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:11:10
2025-01-21 11:11:10,808 - trainer - INFO -     epoch          : 4
2025-01-21 11:11:10,808 - trainer - INFO -     elapsed time   : 4.559024810791016
2025-01-21 11:11:10,808 - trainer - INFO -     loss           : 725.4052124023438
2025-01-21 11:11:10,808 - trainer - INFO -     sim_loss       : 32.788217544555664
2025-01-21 11:11:10,808 - trainer - INFO -     gen_loss       : 1022.2411071777344
2025-01-21 11:11:10,808 - trainer - INFO -     val_loss       : 523.2192535400391
2025-01-21 11:11:10,808 - trainer - INFO -     val_sim_loss   : 23.645509719848633
2025-01-21 11:11:10,808 - trainer - INFO -     val_gen_loss   : 499.57374572753906
2025-01-21 11:11:10,809 - trainer - INFO -     val_perplexity : 29.814695358276367
2025-01-21 11:11:10,809 - trainer - INFO -     val_embedding_sim: 0.12242409586906433
2025-01-21 11:11:10,809 - trainer - INFO - ================================================================================
2025-01-21 11:11:10,809 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:11:10
2025-01-21 11:11:15,368 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:11:15
2025-01-21 11:11:15,368 - trainer - INFO -     epoch          : 5
2025-01-21 11:11:15,368 - trainer - INFO -     elapsed time   : 4.558699607849121
2025-01-21 11:11:15,368 - trainer - INFO -     loss           : 679.5910797119141
2025-01-21 11:11:15,368 - trainer - INFO -     sim_loss       : 34.43480815887451
2025-01-21 11:11:15,368 - trainer - INFO -     gen_loss       : 956.0866394042969
2025-01-21 11:11:15,368 - trainer - INFO -     val_loss       : 490.8685760498047
2025-01-21 11:11:15,368 - trainer - INFO -     val_sim_loss   : 16.582136154174805
2025-01-21 11:11:15,368 - trainer - INFO -     val_gen_loss   : 474.2864532470703
2025-01-21 11:11:15,368 - trainer - INFO -     val_perplexity : 28.886428833007812
2025-01-21 11:11:15,368 - trainer - INFO -     val_embedding_sim: 0.12403754889965057
2025-01-21 11:11:22,839 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:11:29,413 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:11:29,414 - trainer - INFO - ================================================================================
2025-01-21 11:11:29,414 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:11:29
2025-01-21 11:11:34,012 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:11:34
2025-01-21 11:11:34,012 - trainer - INFO -     epoch          : 6
2025-01-21 11:11:34,012 - trainer - INFO -     elapsed time   : 4.598479270935059
2025-01-21 11:11:34,012 - trainer - INFO -     loss           : 631.5791168212891
2025-01-21 11:11:34,012 - trainer - INFO -     sim_loss       : 34.07434663772583
2025-01-21 11:11:34,013 - trainer - INFO -     gen_loss       : 887.6526000976562
2025-01-21 11:11:34,013 - trainer - INFO -     val_loss       : 465.3702869415283
2025-01-21 11:11:34,013 - trainer - INFO -     val_sim_loss   : 12.26746940612793
2025-01-21 11:11:34,013 - trainer - INFO -     val_gen_loss   : 453.1028308868408
2025-01-21 11:11:34,013 - trainer - INFO -     val_perplexity : 27.35556983947754
2025-01-21 11:11:34,013 - trainer - INFO -     val_embedding_sim: 0.14163225889205933
2025-01-21 11:11:34,013 - trainer - INFO - ================================================================================
2025-01-21 11:11:34,013 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:11:34
2025-01-21 11:11:38,583 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:11:38
2025-01-21 11:11:38,584 - trainer - INFO -     epoch          : 7
2025-01-21 11:11:38,584 - trainer - INFO -     elapsed time   : 4.570445537567139
2025-01-21 11:11:38,584 - trainer - INFO -     loss           : 589.1755661010742
2025-01-21 11:11:38,584 - trainer - INFO -     sim_loss       : 31.072006034851075
2025-01-21 11:11:38,584 - trainer - INFO -     gen_loss       : 828.3628082275391
2025-01-21 11:11:38,584 - trainer - INFO -     val_loss       : 450.8003463745117
2025-01-21 11:11:38,584 - trainer - INFO -     val_sim_loss   : 14.321913719177246
2025-01-21 11:11:38,584 - trainer - INFO -     val_gen_loss   : 436.4784469604492
2025-01-21 11:11:38,584 - trainer - INFO -     val_perplexity : 26.324954986572266
2025-01-21 11:11:38,584 - trainer - INFO -     val_embedding_sim: 0.125660240650177
2025-01-21 11:11:38,584 - trainer - INFO - ================================================================================
2025-01-21 11:11:38,584 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:11:38
2025-01-21 11:11:43,143 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:11:43
2025-01-21 11:11:43,143 - trainer - INFO -     epoch          : 8
2025-01-21 11:11:43,143 - trainer - INFO -     elapsed time   : 4.558593511581421
2025-01-21 11:11:43,143 - trainer - INFO -     loss           : 554.0099960327149
2025-01-21 11:11:43,143 - trainer - INFO -     sim_loss       : 29.116068983078
2025-01-21 11:11:43,143 - trainer - INFO -     gen_loss       : 778.9645477294922
2025-01-21 11:11:43,143 - trainer - INFO -     val_loss       : 442.2682161331177
2025-01-21 11:11:43,143 - trainer - INFO -     val_sim_loss   : 16.102643966674805
2025-01-21 11:11:43,143 - trainer - INFO -     val_gen_loss   : 426.1655855178833
2025-01-21 11:11:43,143 - trainer - INFO -     val_perplexity : 26.222999572753906
2025-01-21 11:11:43,143 - trainer - INFO -     val_embedding_sim: 0.14288844168186188
2025-01-21 11:11:43,143 - trainer - INFO - ================================================================================
2025-01-21 11:11:43,143 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:11:43
2025-01-21 11:11:47,716 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:11:47
2025-01-21 11:11:47,716 - trainer - INFO -     epoch          : 9
2025-01-21 11:11:47,717 - trainer - INFO -     elapsed time   : 4.572819948196411
2025-01-21 11:11:47,717 - trainer - INFO -     loss           : 522.4518264770508
2025-01-21 11:11:47,717 - trainer - INFO -     sim_loss       : 33.35802459716797
2025-01-21 11:11:47,717 - trainer - INFO -     gen_loss       : 732.0634735107421
2025-01-21 11:11:47,717 - trainer - INFO -     val_loss       : 430.36391735076904
2025-01-21 11:11:47,717 - trainer - INFO -     val_sim_loss   : 13.264713287353516
2025-01-21 11:11:47,717 - trainer - INFO -     val_gen_loss   : 417.0992078781128
2025-01-21 11:11:47,717 - trainer - INFO -     val_perplexity : 25.366470336914062
2025-01-21 11:11:47,717 - trainer - INFO -     val_embedding_sim: 0.10869182646274567
2025-01-21 11:11:47,717 - trainer - INFO - ================================================================================
2025-01-21 11:11:47,717 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:11:47
2025-01-21 11:11:52,304 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:11:52
2025-01-21 11:11:52,304 - trainer - INFO -     epoch          : 10
2025-01-21 11:11:52,304 - trainer - INFO -     elapsed time   : 4.587069988250732
2025-01-21 11:11:52,304 - trainer - INFO -     loss           : 490.16400756835935
2025-01-21 11:11:52,304 - trainer - INFO -     sim_loss       : 27.644661140441894
2025-01-21 11:11:52,304 - trainer - INFO -     gen_loss       : 688.3865966796875
2025-01-21 11:11:52,304 - trainer - INFO -     val_loss       : 424.83731842041016
2025-01-21 11:11:52,304 - trainer - INFO -     val_sim_loss   : 17.34536361694336
2025-01-21 11:11:52,305 - trainer - INFO -     val_gen_loss   : 407.49195098876953
2025-01-21 11:11:52,305 - trainer - INFO -     val_perplexity : 23.99220085144043
2025-01-21 11:11:52,305 - trainer - INFO -     val_embedding_sim: 0.0920289009809494
2025-01-21 11:11:58,896 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:12:05,470 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:12:05,471 - trainer - INFO - ================================================================================
2025-01-21 11:12:05,471 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:12:05
2025-01-21 11:12:10,108 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:12:10
2025-01-21 11:12:10,108 - trainer - INFO -     epoch          : 11
2025-01-21 11:12:10,108 - trainer - INFO -     elapsed time   : 4.6370322704315186
2025-01-21 11:12:10,108 - trainer - INFO -     loss           : 463.3146041870117
2025-01-21 11:12:10,108 - trainer - INFO -     sim_loss       : 30.59953498840332
2025-01-21 11:12:10,108 - trainer - INFO -     gen_loss       : 648.7639343261719
2025-01-21 11:12:10,108 - trainer - INFO -     val_loss       : 418.480845451355
2025-01-21 11:12:10,108 - trainer - INFO -     val_sim_loss   : 11.31159782409668
2025-01-21 11:12:10,108 - trainer - INFO -     val_gen_loss   : 407.16926097869873
2025-01-21 11:12:10,109 - trainer - INFO -     val_perplexity : 24.4727840423584
2025-01-21 11:12:10,109 - trainer - INFO -     val_embedding_sim: 0.10701514035463333
2025-01-21 11:12:10,109 - trainer - INFO - ================================================================================
2025-01-21 11:12:10,109 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:12:10
2025-01-21 11:12:14,687 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:12:14
2025-01-21 11:12:14,687 - trainer - INFO -     epoch          : 12
2025-01-21 11:12:14,687 - trainer - INFO -     elapsed time   : 4.577651262283325
2025-01-21 11:12:14,687 - trainer - INFO -     loss           : 440.5827133178711
2025-01-21 11:12:14,687 - trainer - INFO -     sim_loss       : 33.56797342300415
2025-01-21 11:12:14,687 - trainer - INFO -     gen_loss       : 615.0176086425781
2025-01-21 11:12:14,687 - trainer - INFO -     val_loss       : 409.22182178497314
2025-01-21 11:12:14,687 - trainer - INFO -     val_sim_loss   : 12.84035873413086
2025-01-21 11:12:14,687 - trainer - INFO -     val_gen_loss   : 396.381459236145
2025-01-21 11:12:14,687 - trainer - INFO -     val_perplexity : 23.77855682373047
2025-01-21 11:12:14,687 - trainer - INFO -     val_embedding_sim: 0.13282810151576996
2025-01-21 11:12:14,687 - trainer - INFO - ================================================================================
2025-01-21 11:12:14,687 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:12:14
2025-01-21 11:12:19,246 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:12:19
2025-01-21 11:12:19,246 - trainer - INFO -     epoch          : 13
2025-01-21 11:12:19,246 - trainer - INFO -     elapsed time   : 4.558616876602173
2025-01-21 11:12:19,246 - trainer - INFO -     loss           : 417.52635650634767
2025-01-21 11:12:19,246 - trainer - INFO -     sim_loss       : 28.900172328948976
2025-01-21 11:12:19,246 - trainer - INFO -     gen_loss       : 584.0804397583008
2025-01-21 11:12:19,246 - trainer - INFO -     val_loss       : 416.8297452926636
2025-01-21 11:12:19,246 - trainer - INFO -     val_sim_loss   : 20.79948616027832
2025-01-21 11:12:19,246 - trainer - INFO -     val_gen_loss   : 396.0302457809448
2025-01-21 11:12:19,246 - trainer - INFO -     val_perplexity : 23.89650535583496
2025-01-21 11:12:19,246 - trainer - INFO -     val_embedding_sim: 0.119126096367836
2025-01-21 11:12:19,246 - trainer - INFO - ================================================================================
2025-01-21 11:12:19,246 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:12:19
2025-01-21 11:12:23,805 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:12:23
2025-01-21 11:12:23,805 - trainer - INFO -     epoch          : 14
2025-01-21 11:12:23,805 - trainer - INFO -     elapsed time   : 4.558057069778442
2025-01-21 11:12:23,805 - trainer - INFO -     loss           : 399.51070404052734
2025-01-21 11:12:23,805 - trainer - INFO -     sim_loss       : 32.1328628540039
2025-01-21 11:12:23,805 - trainer - INFO -     gen_loss       : 556.9583557128906
2025-01-21 11:12:23,805 - trainer - INFO -     val_loss       : 404.58380031585693
2025-01-21 11:12:23,805 - trainer - INFO -     val_sim_loss   : 14.572610855102539
2025-01-21 11:12:23,805 - trainer - INFO -     val_gen_loss   : 390.01119899749756
2025-01-21 11:12:23,805 - trainer - INFO -     val_perplexity : 24.117431640625
2025-01-21 11:12:23,805 - trainer - INFO -     val_embedding_sim: 0.12609568238258362
2025-01-21 11:12:23,805 - trainer - INFO - ================================================================================
2025-01-21 11:12:23,805 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:12:23
2025-01-21 11:12:28,396 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:12:28
2025-01-21 11:12:28,396 - trainer - INFO -     epoch          : 15
2025-01-21 11:12:28,396 - trainer - INFO -     elapsed time   : 4.590826511383057
2025-01-21 11:12:28,397 - trainer - INFO -     loss           : 379.20598754882815
2025-01-21 11:12:28,397 - trainer - INFO -     sim_loss       : 27.439306449890136
2025-01-21 11:12:28,397 - trainer - INFO -     gen_loss       : 529.9631469726562
2025-01-21 11:12:28,397 - trainer - INFO -     val_loss       : 404.70003604888916
2025-01-21 11:12:28,397 - trainer - INFO -     val_sim_loss   : 17.96949005126953
2025-01-21 11:12:28,397 - trainer - INFO -     val_gen_loss   : 386.73055362701416
2025-01-21 11:12:28,397 - trainer - INFO -     val_perplexity : 23.550884246826172
2025-01-21 11:12:28,397 - trainer - INFO -     val_embedding_sim: 0.09444363415241241
2025-01-21 11:12:35,008 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:12:41,596 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:12:41,596 - trainer - INFO - ================================================================================
2025-01-21 11:12:41,596 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:12:41
2025-01-21 11:12:46,219 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:12:46
2025-01-21 11:12:46,219 - trainer - INFO -     epoch          : 16
2025-01-21 11:12:46,219 - trainer - INFO -     elapsed time   : 4.622684001922607
2025-01-21 11:12:46,219 - trainer - INFO -     loss           : 363.85071868896483
2025-01-21 11:12:46,219 - trainer - INFO -     sim_loss       : 29.843349075317384
2025-01-21 11:12:46,219 - trainer - INFO -     gen_loss       : 506.9967346191406
2025-01-21 11:12:46,219 - trainer - INFO -     val_loss       : 402.61656618118286
2025-01-21 11:12:46,219 - trainer - INFO -     val_sim_loss   : 18.385377883911133
2025-01-21 11:12:46,219 - trainer - INFO -     val_gen_loss   : 384.23119020462036
2025-01-21 11:12:46,219 - trainer - INFO -     val_perplexity : 23.620330810546875
2025-01-21 11:12:46,219 - trainer - INFO -     val_embedding_sim: 0.11372670531272888
2025-01-21 11:12:46,219 - trainer - INFO - ================================================================================
2025-01-21 11:12:46,219 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:12:46
2025-01-21 11:12:50,836 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:12:50
2025-01-21 11:12:50,836 - trainer - INFO -     epoch          : 17
2025-01-21 11:12:50,836 - trainer - INFO -     elapsed time   : 4.616598606109619
2025-01-21 11:12:50,836 - trainer - INFO -     loss           : 349.4650512695313
2025-01-21 11:12:50,836 - trainer - INFO -     sim_loss       : 35.022897481918335
2025-01-21 11:12:50,836 - trainer - INFO -     gen_loss       : 484.2259780883789
2025-01-21 11:12:50,837 - trainer - INFO -     val_loss       : 398.7251491546631
2025-01-21 11:12:50,837 - trainer - INFO -     val_sim_loss   : 15.306532859802246
2025-01-21 11:12:50,837 - trainer - INFO -     val_gen_loss   : 383.4186305999756
2025-01-21 11:12:50,837 - trainer - INFO -     val_perplexity : 22.437435150146484
2025-01-21 11:12:50,837 - trainer - INFO -     val_embedding_sim: 0.09559085965156555
2025-01-21 11:12:50,837 - trainer - INFO - ================================================================================
2025-01-21 11:12:50,837 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:12:50
2025-01-21 11:12:55,425 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:12:55
2025-01-21 11:12:55,426 - trainer - INFO -     epoch          : 18
2025-01-21 11:12:55,426 - trainer - INFO -     elapsed time   : 4.588460683822632
2025-01-21 11:12:55,426 - trainer - INFO -     loss           : 333.12967987060546
2025-01-21 11:12:55,426 - trainer - INFO -     sim_loss       : 30.36341276168823
2025-01-21 11:12:55,426 - trainer - INFO -     gen_loss       : 462.88665771484375
2025-01-21 11:12:55,426 - trainer - INFO -     val_loss       : 402.95659041404724
2025-01-21 11:12:55,426 - trainer - INFO -     val_sim_loss   : 19.028987884521484
2025-01-21 11:12:55,426 - trainer - INFO -     val_gen_loss   : 383.9275987148285
2025-01-21 11:12:55,426 - trainer - INFO -     val_perplexity : 23.852079391479492
2025-01-21 11:12:55,426 - trainer - INFO -     val_embedding_sim: 0.1106276884675026
2025-01-21 11:12:55,426 - trainer - INFO - ================================================================================
2025-01-21 11:12:55,426 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:12:55
2025-01-21 11:13:00,000 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:12:59
2025-01-21 11:13:00,000 - trainer - INFO -     epoch          : 19
2025-01-21 11:13:00,000 - trainer - INFO -     elapsed time   : 4.573617219924927
2025-01-21 11:13:00,000 - trainer - INFO -     loss           : 319.1216094970703
2025-01-21 11:13:00,000 - trainer - INFO -     sim_loss       : 26.764625072479248
2025-01-21 11:13:00,000 - trainer - INFO -     gen_loss       : 444.41746673583987
2025-01-21 11:13:00,000 - trainer - INFO -     val_loss       : 399.3265686035156
2025-01-21 11:13:00,000 - trainer - INFO -     val_sim_loss   : 16.95846176147461
2025-01-21 11:13:00,000 - trainer - INFO -     val_gen_loss   : 382.36810302734375
2025-01-21 11:13:00,000 - trainer - INFO -     val_perplexity : 21.784212112426758
2025-01-21 11:13:00,000 - trainer - INFO -     val_embedding_sim: 0.1155744194984436
2025-01-21 11:13:00,000 - trainer - INFO - ================================================================================
2025-01-21 11:13:00,000 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:12:59
2025-01-21 11:13:04,611 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:13:04
2025-01-21 11:13:04,611 - trainer - INFO -     epoch          : 20
2025-01-21 11:13:04,611 - trainer - INFO -     elapsed time   : 4.610732555389404
2025-01-21 11:13:04,611 - trainer - INFO -     loss           : 304.28799591064455
2025-01-21 11:13:04,612 - trainer - INFO -     sim_loss       : 26.882752561569212
2025-01-21 11:13:04,612 - trainer - INFO -     gen_loss       : 423.17596740722655
2025-01-21 11:13:04,612 - trainer - INFO -     val_loss       : 396.1400799751282
2025-01-21 11:13:04,612 - trainer - INFO -     val_sim_loss   : 13.122339248657227
2025-01-21 11:13:04,612 - trainer - INFO -     val_gen_loss   : 383.01773500442505
2025-01-21 11:13:04,612 - trainer - INFO -     val_perplexity : 23.735416412353516
2025-01-21 11:13:04,612 - trainer - INFO -     val_embedding_sim: 0.12525571882724762
2025-01-21 11:13:11,210 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:13:11,210 - trainer - INFO - ================================================================================
2025-01-21 11:13:11,210 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:13:11
2025-01-21 11:13:15,858 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:13:15
2025-01-21 11:13:15,858 - trainer - INFO -     epoch          : 21
2025-01-21 11:13:15,858 - trainer - INFO -     elapsed time   : 4.64765191078186
2025-01-21 11:13:15,858 - trainer - INFO -     loss           : 290.88708267211916
2025-01-21 11:13:15,858 - trainer - INFO -     sim_loss       : 26.345297813415527
2025-01-21 11:13:15,858 - trainer - INFO -     gen_loss       : 404.2621444702148
2025-01-21 11:13:15,858 - trainer - INFO -     val_loss       : 404.9458999633789
2025-01-21 11:13:15,858 - trainer - INFO -     val_sim_loss   : 20.545747756958008
2025-01-21 11:13:15,858 - trainer - INFO -     val_gen_loss   : 384.40015411376953
2025-01-21 11:13:15,858 - trainer - INFO -     val_perplexity : 22.58405876159668
2025-01-21 11:13:15,858 - trainer - INFO -     val_embedding_sim: 0.12570777535438538
2025-01-21 11:13:15,858 - trainer - INFO - ================================================================================
2025-01-21 11:13:15,858 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:13:15
2025-01-21 11:13:20,432 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:13:20
2025-01-21 11:13:20,432 - trainer - INFO -     epoch          : 22
2025-01-21 11:13:20,432 - trainer - INFO -     elapsed time   : 4.573112487792969
2025-01-21 11:13:20,432 - trainer - INFO -     loss           : 282.0966735839844
2025-01-21 11:13:20,432 - trainer - INFO -     sim_loss       : 31.92654094696045
2025-01-21 11:13:20,432 - trainer - INFO -     gen_loss       : 389.3124572753906
2025-01-21 11:13:20,432 - trainer - INFO -     val_loss       : 397.00964546203613
2025-01-21 11:13:20,432 - trainer - INFO -     val_sim_loss   : 19.007495880126953
2025-01-21 11:13:20,432 - trainer - INFO -     val_gen_loss   : 378.0021381378174
2025-01-21 11:13:20,432 - trainer - INFO -     val_perplexity : 22.10340118408203
2025-01-21 11:13:20,432 - trainer - INFO -     val_embedding_sim: 0.12426705658435822
2025-01-21 11:13:20,432 - trainer - INFO - ================================================================================
2025-01-21 11:13:20,432 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:13:20
2025-01-21 11:13:24,993 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:13:24
2025-01-21 11:13:24,993 - trainer - INFO -     epoch          : 23
2025-01-21 11:13:24,994 - trainer - INFO -     elapsed time   : 4.561020135879517
2025-01-21 11:13:24,994 - trainer - INFO -     loss           : 269.63953857421876
2025-01-21 11:13:24,994 - trainer - INFO -     sim_loss       : 26.177098178863524
2025-01-21 11:13:24,994 - trainer - INFO -     gen_loss       : 373.9805908203125
2025-01-21 11:13:24,994 - trainer - INFO -     val_loss       : 393.6212100982666
2025-01-21 11:13:24,994 - trainer - INFO -     val_sim_loss   : 13.56025218963623
2025-01-21 11:13:24,994 - trainer - INFO -     val_gen_loss   : 380.06096839904785
2025-01-21 11:13:24,994 - trainer - INFO -     val_perplexity : 23.169965744018555
2025-01-21 11:13:24,994 - trainer - INFO -     val_embedding_sim: 0.13340717554092407
2025-01-21 11:13:24,994 - trainer - INFO - ================================================================================
2025-01-21 11:13:24,994 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:13:24
2025-01-21 11:13:29,552 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:13:29
2025-01-21 11:13:29,552 - trainer - INFO -     epoch          : 24
2025-01-21 11:13:29,552 - trainer - INFO -     elapsed time   : 4.5580055713653564
2025-01-21 11:13:29,552 - trainer - INFO -     loss           : 260.23777160644534
2025-01-21 11:13:29,552 - trainer - INFO -     sim_loss       : 29.470584630966187
2025-01-21 11:13:29,552 - trainer - INFO -     gen_loss       : 359.138005065918
2025-01-21 11:13:29,552 - trainer - INFO -     val_loss       : 395.44878005981445
2025-01-21 11:13:29,552 - trainer - INFO -     val_sim_loss   : 13.713739395141602
2025-01-21 11:13:29,552 - trainer - INFO -     val_gen_loss   : 381.73503494262695
2025-01-21 11:13:29,552 - trainer - INFO -     val_perplexity : 22.305845260620117
2025-01-21 11:13:29,553 - trainer - INFO -     val_embedding_sim: 0.13657024502754211
2025-01-21 11:13:29,553 - trainer - INFO - ================================================================================
2025-01-21 11:13:29,553 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:13:29
2025-01-21 11:13:34,109 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:13:34
2025-01-21 11:13:34,109 - trainer - INFO -     epoch          : 25
2025-01-21 11:13:34,109 - trainer - INFO -     elapsed time   : 4.555946111679077
2025-01-21 11:13:34,109 - trainer - INFO -     loss           : 250.63036575317383
2025-01-21 11:13:34,109 - trainer - INFO -     sim_loss       : 33.2254695892334
2025-01-21 11:13:34,109 - trainer - INFO -     gen_loss       : 343.8039016723633
2025-01-21 11:13:34,109 - trainer - INFO -     val_loss       : 399.9349250793457
2025-01-21 11:13:34,109 - trainer - INFO -     val_sim_loss   : 20.086755752563477
2025-01-21 11:13:34,109 - trainer - INFO -     val_gen_loss   : 379.8481636047363
2025-01-21 11:13:34,109 - trainer - INFO -     val_perplexity : 22.888904571533203
2025-01-21 11:13:34,109 - trainer - INFO -     val_embedding_sim: 0.1259290874004364
2025-01-21 11:13:40,707 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:13:40,707 - trainer - INFO - ================================================================================
2025-01-21 11:13:40,707 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:13:40
2025-01-21 11:13:45,326 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:13:45
2025-01-21 11:13:45,326 - trainer - INFO -     epoch          : 26
2025-01-21 11:13:45,326 - trainer - INFO -     elapsed time   : 4.618361711502075
2025-01-21 11:13:45,326 - trainer - INFO -     loss           : 241.240877532959
2025-01-21 11:13:45,326 - trainer - INFO -     sim_loss       : 31.417033195495605
2025-01-21 11:13:45,326 - trainer - INFO -     gen_loss       : 331.1653793334961
2025-01-21 11:13:45,326 - trainer - INFO -     val_loss       : 396.8886260986328
2025-01-21 11:13:45,326 - trainer - INFO -     val_sim_loss   : 16.99313735961914
2025-01-21 11:13:45,326 - trainer - INFO -     val_gen_loss   : 379.89549255371094
2025-01-21 11:13:45,326 - trainer - INFO -     val_perplexity : 23.603532791137695
2025-01-21 11:13:45,326 - trainer - INFO -     val_embedding_sim: 0.10897404700517654
2025-01-21 11:13:45,326 - trainer - INFO - ================================================================================
2025-01-21 11:13:45,326 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:13:45
2025-01-21 11:13:49,891 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:13:49
2025-01-21 11:13:49,891 - trainer - INFO -     epoch          : 27
2025-01-21 11:13:49,891 - trainer - INFO -     elapsed time   : 4.564455986022949
2025-01-21 11:13:49,891 - trainer - INFO -     loss           : 230.89159545898437
2025-01-21 11:13:49,891 - trainer - INFO -     sim_loss       : 30.764977788925172
2025-01-21 11:13:49,891 - trainer - INFO -     gen_loss       : 316.66014404296874
2025-01-21 11:13:49,891 - trainer - INFO -     val_loss       : 399.89412665367126
2025-01-21 11:13:49,891 - trainer - INFO -     val_sim_loss   : 18.296344757080078
2025-01-21 11:13:49,891 - trainer - INFO -     val_gen_loss   : 381.5977704524994
2025-01-21 11:13:49,891 - trainer - INFO -     val_perplexity : 23.667680740356445
2025-01-21 11:13:49,892 - trainer - INFO -     val_embedding_sim: 0.12040188163518906
2025-01-21 11:13:49,892 - trainer - INFO - ================================================================================
2025-01-21 11:13:49,892 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:13:49
2025-01-21 11:13:54,454 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:13:54
2025-01-21 11:13:54,454 - trainer - INFO -     epoch          : 28
2025-01-21 11:13:54,454 - trainer - INFO -     elapsed time   : 4.562309503555298
2025-01-21 11:13:54,454 - trainer - INFO -     loss           : 222.8546127319336
2025-01-21 11:13:54,454 - trainer - INFO -     sim_loss       : 33.23492383956909
2025-01-21 11:13:54,454 - trainer - INFO -     gen_loss       : 304.12020416259764
2025-01-21 11:13:54,454 - trainer - INFO -     val_loss       : 391.73510789871216
2025-01-21 11:13:54,454 - trainer - INFO -     val_sim_loss   : 15.501502990722656
2025-01-21 11:13:54,454 - trainer - INFO -     val_gen_loss   : 376.23361253738403
2025-01-21 11:13:54,455 - trainer - INFO -     val_perplexity : 23.231229782104492
2025-01-21 11:13:54,455 - trainer - INFO -     val_embedding_sim: 0.12449227273464203
2025-01-21 11:13:54,455 - trainer - INFO - ================================================================================
2025-01-21 11:13:54,455 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:13:54
2025-01-21 11:13:59,018 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:13:59
2025-01-21 11:13:59,018 - trainer - INFO -     epoch          : 29
2025-01-21 11:13:59,018 - trainer - INFO -     elapsed time   : 4.562906742095947
2025-01-21 11:13:59,018 - trainer - INFO -     loss           : 213.8287139892578
2025-01-21 11:13:59,018 - trainer - INFO -     sim_loss       : 29.46741352081299
2025-01-21 11:13:59,018 - trainer - INFO -     gen_loss       : 292.8407012939453
2025-01-21 11:13:59,018 - trainer - INFO -     val_loss       : 397.1207696199417
2025-01-21 11:13:59,018 - trainer - INFO -     val_sim_loss   : 21.591894149780273
2025-01-21 11:13:59,018 - trainer - INFO -     val_gen_loss   : 375.52888119220734
2025-01-21 11:13:59,018 - trainer - INFO -     val_perplexity : 23.353351593017578
2025-01-21 11:13:59,018 - trainer - INFO -     val_embedding_sim: 0.1492529809474945
2025-01-21 11:13:59,018 - trainer - INFO - ================================================================================
2025-01-21 11:13:59,018 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:13:59
2025-01-21 11:14:03,583 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:14:03
2025-01-21 11:14:03,583 - trainer - INFO -     epoch          : 30
2025-01-21 11:14:03,583 - trainer - INFO -     elapsed time   : 4.564481258392334
2025-01-21 11:14:03,583 - trainer - INFO -     loss           : 206.67319030761718
2025-01-21 11:14:03,583 - trainer - INFO -     sim_loss       : 36.619928169250485
2025-01-21 11:14:03,583 - trainer - INFO -     gen_loss       : 279.55316772460935
2025-01-21 11:14:03,583 - trainer - INFO -     val_loss       : 402.1353015899658
2025-01-21 11:14:03,583 - trainer - INFO -     val_sim_loss   : 25.790145874023438
2025-01-21 11:14:03,583 - trainer - INFO -     val_gen_loss   : 376.34517097473145
2025-01-21 11:14:03,583 - trainer - INFO -     val_perplexity : 22.717466354370117
2025-01-21 11:14:03,583 - trainer - INFO -     val_embedding_sim: 0.13846993446350098
2025-01-21 11:14:10,189 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:14:10,190 - trainer - INFO - ================================================================================
2025-01-21 11:14:10,190 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:14:10
2025-01-21 11:14:14,804 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:14:14
2025-01-21 11:14:14,804 - trainer - INFO -     epoch          : 31
2025-01-21 11:14:14,804 - trainer - INFO -     elapsed time   : 4.613956689834595
2025-01-21 11:14:14,804 - trainer - INFO -     loss           : 194.52911758422852
2025-01-21 11:14:14,804 - trainer - INFO -     sim_loss       : 29.904891538619996
2025-01-21 11:14:14,804 - trainer - INFO -     gen_loss       : 265.0823600769043
2025-01-21 11:14:14,804 - trainer - INFO -     val_loss       : 396.39954662323
2025-01-21 11:14:14,804 - trainer - INFO -     val_sim_loss   : 17.623252868652344
2025-01-21 11:14:14,804 - trainer - INFO -     val_gen_loss   : 378.7762861251831
2025-01-21 11:14:14,805 - trainer - INFO -     val_perplexity : 23.107919692993164
2025-01-21 11:14:14,805 - trainer - INFO -     val_embedding_sim: 0.17073889076709747
2025-01-21 11:14:14,805 - trainer - INFO - ================================================================================
2025-01-21 11:14:14,805 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:14:14
2025-01-21 11:14:19,369 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:14:19
2025-01-21 11:14:19,370 - trainer - INFO -     epoch          : 32
2025-01-21 11:14:19,370 - trainer - INFO -     elapsed time   : 4.56469464302063
2025-01-21 11:14:19,370 - trainer - INFO -     loss           : 189.03326568603515
2025-01-21 11:14:19,370 - trainer - INFO -     sim_loss       : 31.68226718902588
2025-01-21 11:14:19,370 - trainer - INFO -     gen_loss       : 256.469416809082
2025-01-21 11:14:19,370 - trainer - INFO -     val_loss       : 403.6430250406265
2025-01-21 11:14:19,370 - trainer - INFO -     val_sim_loss   : 21.165815353393555
2025-01-21 11:14:19,370 - trainer - INFO -     val_gen_loss   : 382.4772230386734
2025-01-21 11:14:19,370 - trainer - INFO -     val_perplexity : 23.788434982299805
2025-01-21 11:14:19,370 - trainer - INFO -     val_embedding_sim: 0.1371602863073349
2025-01-21 11:14:19,370 - trainer - INFO - ================================================================================
2025-01-21 11:14:19,370 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:14:19
2025-01-21 11:14:23,934 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:14:23
2025-01-21 11:14:23,934 - trainer - INFO -     epoch          : 33
2025-01-21 11:14:23,934 - trainer - INFO -     elapsed time   : 4.5640482902526855
2025-01-21 11:14:23,934 - trainer - INFO -     loss           : 177.63856506347656
2025-01-21 11:14:23,935 - trainer - INFO -     sim_loss       : 27.81475439071655
2025-01-21 11:14:23,935 - trainer - INFO -     gen_loss       : 241.84877166748046
2025-01-21 11:14:23,935 - trainer - INFO -     val_loss       : 391.63689613342285
2025-01-21 11:14:23,935 - trainer - INFO -     val_sim_loss   : 13.929226875305176
2025-01-21 11:14:23,935 - trainer - INFO -     val_gen_loss   : 377.7076663970947
2025-01-21 11:14:23,935 - trainer - INFO -     val_perplexity : 22.54424476623535
2025-01-21 11:14:23,935 - trainer - INFO -     val_embedding_sim: 0.11543358117341995
2025-01-21 11:14:23,935 - trainer - INFO - ================================================================================
2025-01-21 11:14:23,935 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:14:23
2025-01-21 11:14:28,503 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:14:28
2025-01-21 11:14:28,503 - trainer - INFO -     epoch          : 34
2025-01-21 11:14:28,503 - trainer - INFO -     elapsed time   : 4.567615985870361
2025-01-21 11:14:28,503 - trainer - INFO -     loss           : 173.56130828857422
2025-01-21 11:14:28,503 - trainer - INFO -     sim_loss       : 33.98968234062195
2025-01-21 11:14:28,503 - trainer - INFO -     gen_loss       : 233.3777229309082
2025-01-21 11:14:28,503 - trainer - INFO -     val_loss       : 401.06562328338623
2025-01-21 11:14:28,503 - trainer - INFO -     val_sim_loss   : 27.426424026489258
2025-01-21 11:14:28,503 - trainer - INFO -     val_gen_loss   : 373.6392011642456
2025-01-21 11:14:28,503 - trainer - INFO -     val_perplexity : 22.516321182250977
2025-01-21 11:14:28,503 - trainer - INFO -     val_embedding_sim: 0.12199679762125015
2025-01-21 11:14:28,503 - trainer - INFO - ================================================================================
2025-01-21 11:14:28,503 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:14:28
2025-01-21 11:14:33,066 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:14:33
2025-01-21 11:14:33,067 - trainer - INFO -     epoch          : 35
2025-01-21 11:14:33,067 - trainer - INFO -     elapsed time   : 4.562997579574585
2025-01-21 11:14:33,067 - trainer - INFO -     loss           : 163.6370948791504
2025-01-21 11:14:33,067 - trainer - INFO -     sim_loss       : 27.893446063995363
2025-01-21 11:14:33,067 - trainer - INFO -     gen_loss       : 221.8129455566406
2025-01-21 11:14:33,067 - trainer - INFO -     val_loss       : 395.5744094848633
2025-01-21 11:14:33,067 - trainer - INFO -     val_sim_loss   : 21.004871368408203
2025-01-21 11:14:33,067 - trainer - INFO -     val_gen_loss   : 374.5695266723633
2025-01-21 11:14:33,067 - trainer - INFO -     val_perplexity : 22.5820255279541
2025-01-21 11:14:33,067 - trainer - INFO -     val_embedding_sim: 0.1348343938589096
2025-01-21 11:14:39,683 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:14:39,683 - trainer - INFO - ================================================================================
2025-01-21 11:14:39,684 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:14:39
2025-01-21 11:14:44,303 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:14:44
2025-01-21 11:14:44,303 - trainer - INFO -     epoch          : 36
2025-01-21 11:14:44,303 - trainer - INFO -     elapsed time   : 4.618896484375
2025-01-21 11:14:44,303 - trainer - INFO -     loss           : 160.2550277709961
2025-01-21 11:14:44,303 - trainer - INFO -     sim_loss       : 33.60226168632507
2025-01-21 11:14:44,303 - trainer - INFO -     gen_loss       : 214.5347915649414
2025-01-21 11:14:44,303 - trainer - INFO -     val_loss       : 386.07683539390564
2025-01-21 11:14:44,303 - trainer - INFO -     val_sim_loss   : 13.428598403930664
2025-01-21 11:14:44,303 - trainer - INFO -     val_gen_loss   : 372.64824652671814
2025-01-21 11:14:44,303 - trainer - INFO -     val_perplexity : 23.08075714111328
2025-01-21 11:14:44,303 - trainer - INFO -     val_embedding_sim: 0.11242779344320297
2025-01-21 11:14:44,303 - trainer - INFO - ================================================================================
2025-01-21 11:14:44,303 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:14:44
2025-01-21 11:14:48,870 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:14:48
2025-01-21 11:14:48,870 - trainer - INFO -     epoch          : 37
2025-01-21 11:14:48,870 - trainer - INFO -     elapsed time   : 4.566609859466553
2025-01-21 11:14:48,870 - trainer - INFO -     loss           : 148.95243492126465
2025-01-21 11:14:48,870 - trainer - INFO -     sim_loss       : 25.449046206474303
2025-01-21 11:14:48,870 - trainer - INFO -     gen_loss       : 201.88246002197266
2025-01-21 11:14:48,870 - trainer - INFO -     val_loss       : 392.71287536621094
2025-01-21 11:14:48,870 - trainer - INFO -     val_sim_loss   : 20.097923278808594
2025-01-21 11:14:48,870 - trainer - INFO -     val_gen_loss   : 372.6149444580078
2025-01-21 11:14:48,870 - trainer - INFO -     val_perplexity : 23.152469635009766
2025-01-21 11:14:48,870 - trainer - INFO -     val_embedding_sim: 0.1461917757987976
2025-01-21 11:14:48,871 - trainer - INFO - ================================================================================
2025-01-21 11:14:48,871 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:14:48
2025-01-21 11:14:53,430 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:14:53
2025-01-21 11:14:53,430 - trainer - INFO -     epoch          : 38
2025-01-21 11:14:53,430 - trainer - INFO -     elapsed time   : 4.559458017349243
2025-01-21 11:14:53,430 - trainer - INFO -     loss           : 146.4779281616211
2025-01-21 11:14:53,430 - trainer - INFO -     sim_loss       : 31.697963523864747
2025-01-21 11:14:53,430 - trainer - INFO -     gen_loss       : 195.6693473815918
2025-01-21 11:14:53,430 - trainer - INFO -     val_loss       : 389.6636233329773
2025-01-21 11:14:53,431 - trainer - INFO -     val_sim_loss   : 13.5949125289917
2025-01-21 11:14:53,431 - trainer - INFO -     val_gen_loss   : 376.06871366500854
2025-01-21 11:14:53,431 - trainer - INFO -     val_perplexity : 23.394367218017578
2025-01-21 11:14:53,431 - trainer - INFO -     val_embedding_sim: 0.12763938307762146
2025-01-21 11:14:53,431 - trainer - INFO - ================================================================================
2025-01-21 11:14:53,431 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:14:53
2025-01-21 11:14:57,989 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:14:57
2025-01-21 11:14:57,989 - trainer - INFO -     epoch          : 39
2025-01-21 11:14:57,989 - trainer - INFO -     elapsed time   : 4.558018207550049
2025-01-21 11:14:57,989 - trainer - INFO -     loss           : 140.51460914611818
2025-01-21 11:14:57,989 - trainer - INFO -     sim_loss       : 33.50286521911621
2025-01-21 11:14:57,989 - trainer - INFO -     gen_loss       : 186.3767868041992
2025-01-21 11:14:57,989 - trainer - INFO -     val_loss       : 399.5722465515137
2025-01-21 11:14:57,989 - trainer - INFO -     val_sim_loss   : 23.41248893737793
2025-01-21 11:14:57,989 - trainer - INFO -     val_gen_loss   : 376.1597709655762
2025-01-21 11:14:57,989 - trainer - INFO -     val_perplexity : 22.79643440246582
2025-01-21 11:14:57,989 - trainer - INFO -     val_embedding_sim: 0.13913622498512268
2025-01-21 11:14:57,989 - trainer - INFO - ================================================================================
2025-01-21 11:14:57,989 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:14:57
2025-01-21 11:15:02,555 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:15:02
2025-01-21 11:15:02,555 - trainer - INFO -     epoch          : 40
2025-01-21 11:15:02,555 - trainer - INFO -     elapsed time   : 4.565335035324097
2025-01-21 11:15:02,555 - trainer - INFO -     loss           : 136.96771850585938
2025-01-21 11:15:02,555 - trainer - INFO -     sim_loss       : 37.29016489982605
2025-01-21 11:15:02,555 - trainer - INFO -     gen_loss       : 179.6866714477539
2025-01-21 11:15:02,555 - trainer - INFO -     val_loss       : 399.78668785095215
2025-01-21 11:15:02,555 - trainer - INFO -     val_sim_loss   : 24.747440338134766
2025-01-21 11:15:02,555 - trainer - INFO -     val_gen_loss   : 375.03925132751465
2025-01-21 11:15:02,555 - trainer - INFO -     val_perplexity : 21.91678237915039
2025-01-21 11:15:02,555 - trainer - INFO -     val_embedding_sim: 0.13902541995048523
2025-01-21 11:15:09,187 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:15:09,187 - trainer - INFO - ================================================================================
2025-01-21 11:15:09,187 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:15:09
2025-01-21 11:15:13,784 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:15:13
2025-01-21 11:15:13,785 - trainer - INFO -     epoch          : 41
2025-01-21 11:15:13,785 - trainer - INFO -     elapsed time   : 4.597129821777344
2025-01-21 11:15:13,785 - trainer - INFO -     loss           : 128.76530685424805
2025-01-21 11:15:13,785 - trainer - INFO -     sim_loss       : 31.25827827453613
2025-01-21 11:15:13,785 - trainer - INFO -     gen_loss       : 170.5540344238281
2025-01-21 11:15:13,785 - trainer - INFO -     val_loss       : 395.3981956243515
2025-01-21 11:15:13,785 - trainer - INFO -     val_sim_loss   : 18.321426391601562
2025-01-21 11:15:13,785 - trainer - INFO -     val_gen_loss   : 377.076784491539
2025-01-21 11:15:13,785 - trainer - INFO -     val_perplexity : 23.451610565185547
2025-01-21 11:15:13,785 - trainer - INFO -     val_embedding_sim: 0.12217862904071808
2025-01-21 11:15:13,785 - trainer - INFO - ================================================================================
2025-01-21 11:15:13,785 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:15:13
2025-01-21 11:15:18,355 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:15:18
2025-01-21 11:15:18,356 - trainer - INFO -     epoch          : 42
2025-01-21 11:15:18,356 - trainer - INFO -     elapsed time   : 4.570374488830566
2025-01-21 11:15:18,356 - trainer - INFO -     loss           : 123.39893035888672
2025-01-21 11:15:18,356 - trainer - INFO -     sim_loss       : 32.087532711029056
2025-01-21 11:15:18,356 - trainer - INFO -     gen_loss       : 162.5323860168457
2025-01-21 11:15:18,356 - trainer - INFO -     val_loss       : 404.6431770324707
2025-01-21 11:15:18,356 - trainer - INFO -     val_sim_loss   : 25.69782257080078
2025-01-21 11:15:18,356 - trainer - INFO -     val_gen_loss   : 378.94536209106445
2025-01-21 11:15:18,356 - trainer - INFO -     val_perplexity : 22.27101707458496
2025-01-21 11:15:18,356 - trainer - INFO -     val_embedding_sim: 0.1523265838623047
2025-01-21 11:15:18,356 - trainer - INFO - ================================================================================
2025-01-21 11:15:18,356 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:15:18
2025-01-21 11:15:22,932 - trainer - INFO - Epoch 43 completed at 2025-01-21 11:15:22
2025-01-21 11:15:22,932 - trainer - INFO -     epoch          : 43
2025-01-21 11:15:22,932 - trainer - INFO -     elapsed time   : 4.575412273406982
2025-01-21 11:15:22,932 - trainer - INFO -     loss           : 118.55370712280273
2025-01-21 11:15:22,932 - trainer - INFO -     sim_loss       : 30.27674217224121
2025-01-21 11:15:22,932 - trainer - INFO -     gen_loss       : 156.3866958618164
2025-01-21 11:15:22,932 - trainer - INFO -     val_loss       : 391.01464080810547
2025-01-21 11:15:22,932 - trainer - INFO -     val_sim_loss   : 13.437350273132324
2025-01-21 11:15:22,932 - trainer - INFO -     val_gen_loss   : 377.5772933959961
2025-01-21 11:15:22,932 - trainer - INFO -     val_perplexity : 21.341527938842773
2025-01-21 11:15:22,932 - trainer - INFO -     val_embedding_sim: 0.13483595848083496
2025-01-21 11:15:22,932 - trainer - INFO - ================================================================================
2025-01-21 11:15:22,932 - trainer - INFO - Starting epoch 44 at 2025-01-21 11:15:22
2025-01-21 11:15:27,495 - trainer - INFO - Epoch 44 completed at 2025-01-21 11:15:27
2025-01-21 11:15:27,495 - trainer - INFO -     epoch          : 44
2025-01-21 11:15:27,495 - trainer - INFO -     elapsed time   : 4.562167644500732
2025-01-21 11:15:27,495 - trainer - INFO -     loss           : 115.43269653320313
2025-01-21 11:15:27,495 - trainer - INFO -     sim_loss       : 32.80137710571289
2025-01-21 11:15:27,495 - trainer - INFO -     gen_loss       : 150.84612045288085
2025-01-21 11:15:27,495 - trainer - INFO -     val_loss       : 403.5951051712036
2025-01-21 11:15:27,495 - trainer - INFO -     val_sim_loss   : 22.4921817779541
2025-01-21 11:15:27,495 - trainer - INFO -     val_gen_loss   : 381.1029176712036
2025-01-21 11:15:27,495 - trainer - INFO -     val_perplexity : 23.727270126342773
2025-01-21 11:15:27,495 - trainer - INFO -     val_embedding_sim: 0.13543830811977386
2025-01-21 11:15:27,495 - trainer - INFO - ================================================================================
2025-01-21 11:15:27,495 - trainer - INFO - Starting epoch 45 at 2025-01-21 11:15:27
2025-01-21 11:15:32,062 - trainer - INFO - Epoch 45 completed at 2025-01-21 11:15:32
2025-01-21 11:15:32,062 - trainer - INFO -     epoch          : 45
2025-01-21 11:15:32,062 - trainer - INFO -     elapsed time   : 4.567048072814941
2025-01-21 11:15:32,063 - trainer - INFO -     loss           : 110.06602363586425
2025-01-21 11:15:32,063 - trainer - INFO -     sim_loss       : 34.917249584198
2025-01-21 11:15:32,063 - trainer - INFO -     gen_loss       : 142.27264137268065
2025-01-21 11:15:32,063 - trainer - INFO -     val_loss       : 398.8674466609955
2025-01-21 11:15:32,063 - trainer - INFO -     val_sim_loss   : 20.368663787841797
2025-01-21 11:15:32,063 - trainer - INFO -     val_gen_loss   : 378.4987943172455
2025-01-21 11:15:32,063 - trainer - INFO -     val_perplexity : 23.4541072845459
2025-01-21 11:15:32,063 - trainer - INFO -     val_embedding_sim: 0.1700267344713211
2025-01-21 11:15:38,588 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 11:15:38,589 - trainer - INFO - ================================================================================
2025-01-21 11:15:38,589 - trainer - INFO - Starting epoch 46 at 2025-01-21 11:15:38
2025-01-21 11:15:43,204 - trainer - INFO - Epoch 46 completed at 2025-01-21 11:15:43
2025-01-21 11:15:43,204 - trainer - INFO -     epoch          : 46
2025-01-21 11:15:43,204 - trainer - INFO -     elapsed time   : 4.614623546600342
2025-01-21 11:15:43,204 - trainer - INFO -     loss           : 105.03941535949707
2025-01-21 11:15:43,204 - trainer - INFO -     sim_loss       : 35.648542165756226
2025-01-21 11:15:43,204 - trainer - INFO -     gen_loss       : 134.77836494445802
2025-01-21 11:15:43,204 - trainer - INFO -     val_loss       : 395.583779335022
2025-01-21 11:15:43,204 - trainer - INFO -     val_sim_loss   : 16.659791946411133
2025-01-21 11:15:43,204 - trainer - INFO -     val_gen_loss   : 378.9239892959595
2025-01-21 11:15:43,204 - trainer - INFO -     val_perplexity : 23.02998161315918
2025-01-21 11:15:43,204 - trainer - INFO -     val_embedding_sim: 0.14400175213813782
2025-01-21 11:15:43,204 - trainer - INFO - ================================================================================
2025-01-21 11:15:43,204 - trainer - INFO - Starting epoch 47 at 2025-01-21 11:15:43
2025-01-21 11:15:47,772 - trainer - INFO - Epoch 47 completed at 2025-01-21 11:15:47
2025-01-21 11:15:47,772 - trainer - INFO -     epoch          : 47
2025-01-21 11:15:47,772 - trainer - INFO -     elapsed time   : 4.5675928592681885
2025-01-21 11:15:47,772 - trainer - INFO -     loss           : 98.83382110595703
2025-01-21 11:15:47,772 - trainer - INFO -     sim_loss       : 35.197865104675294
2025-01-21 11:15:47,772 - trainer - INFO -     gen_loss       : 126.10637245178222
2025-01-21 11:15:47,772 - trainer - INFO -     val_loss       : 403.45317459106445
2025-01-21 11:15:47,772 - trainer - INFO -     val_sim_loss   : 21.208770751953125
2025-01-21 11:15:47,772 - trainer - INFO -     val_gen_loss   : 382.2444038391113
2025-01-21 11:15:47,772 - trainer - INFO -     val_perplexity : 22.829626083374023
2025-01-21 11:15:47,773 - trainer - INFO -     val_embedding_sim: 0.1363617479801178
2025-01-21 11:15:47,773 - trainer - INFO - ================================================================================
2025-01-21 11:15:47,773 - trainer - INFO - Starting epoch 48 at 2025-01-21 11:15:47
2025-01-21 11:15:52,330 - trainer - INFO - Epoch 48 completed at 2025-01-21 11:15:52
2025-01-21 11:15:52,330 - trainer - INFO -     epoch          : 48
2025-01-21 11:15:52,330 - trainer - INFO -     elapsed time   : 4.5571489334106445
2025-01-21 11:15:52,330 - trainer - INFO -     loss           : 97.1100009918213
2025-01-21 11:15:52,330 - trainer - INFO -     sim_loss       : 36.725960397720335
2025-01-21 11:15:52,330 - trainer - INFO -     gen_loss       : 122.98887672424317
2025-01-21 11:15:52,330 - trainer - INFO -     val_loss       : 395.4956430196762
2025-01-21 11:15:52,330 - trainer - INFO -     val_sim_loss   : 16.857568740844727
2025-01-21 11:15:52,330 - trainer - INFO -     val_gen_loss   : 378.6380685567856
2025-01-21 11:15:52,330 - trainer - INFO -     val_perplexity : 23.586864471435547
2025-01-21 11:15:52,330 - trainer - INFO -     val_embedding_sim: 0.14440932869911194
2025-01-21 11:15:52,330 - trainer - INFO - ================================================================================
2025-01-21 11:15:52,330 - trainer - INFO - Starting epoch 49 at 2025-01-21 11:15:52
2025-01-21 11:15:56,901 - trainer - INFO - Epoch 49 completed at 2025-01-21 11:15:56
2025-01-21 11:15:56,902 - trainer - INFO -     epoch          : 49
2025-01-21 11:15:56,902 - trainer - INFO -     elapsed time   : 4.57081151008606
2025-01-21 11:15:56,902 - trainer - INFO -     loss           : 93.32399291992188
2025-01-21 11:15:56,902 - trainer - INFO -     sim_loss       : 36.04694185256958
2025-01-21 11:15:56,902 - trainer - INFO -     gen_loss       : 117.8713005065918
2025-01-21 11:15:56,902 - trainer - INFO -     val_loss       : 393.8632539510727
2025-01-21 11:15:56,902 - trainer - INFO -     val_sim_loss   : 15.062725067138672
2025-01-21 11:15:56,902 - trainer - INFO -     val_gen_loss   : 378.8005403280258
2025-01-21 11:15:56,902 - trainer - INFO -     val_perplexity : 23.550308227539062
2025-01-21 11:15:56,902 - trainer - INFO -     val_embedding_sim: 0.13131709396839142
2025-01-21 11:15:56,902 - trainer - INFO - ================================================================================
2025-01-21 11:15:56,902 - trainer - INFO - Starting epoch 50 at 2025-01-21 11:15:56
2025-01-21 11:16:01,465 - trainer - INFO - Epoch 50 completed at 2025-01-21 11:16:01
2025-01-21 11:16:01,465 - trainer - INFO -     epoch          : 50
2025-01-21 11:16:01,465 - trainer - INFO -     elapsed time   : 4.562373638153076
2025-01-21 11:16:01,465 - trainer - INFO -     loss           : 88.36971130371094
2025-01-21 11:16:01,465 - trainer - INFO -     sim_loss       : 32.55777258872986
2025-01-21 11:16:01,465 - trainer - INFO -     gen_loss       : 112.28911323547364
2025-01-21 11:16:01,465 - trainer - INFO -     val_loss       : 394.0857892036438
2025-01-21 11:16:01,465 - trainer - INFO -     val_sim_loss   : 11.313129425048828
2025-01-21 11:16:01,465 - trainer - INFO -     val_gen_loss   : 382.7726483345032
2025-01-21 11:16:01,465 - trainer - INFO -     val_perplexity : 23.731475830078125
2025-01-21 11:16:01,465 - trainer - INFO -     val_embedding_sim: 0.1426618993282318
2025-01-21 11:16:07,995 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 11:16:07,995 - trainer - INFO - ================================================================================
2025-01-21 11:16:07,995 - trainer - INFO - Starting epoch 51 at 2025-01-21 11:16:07
2025-01-21 11:16:12,598 - trainer - INFO - Epoch 51 completed at 2025-01-21 11:16:12
2025-01-21 11:16:12,598 - trainer - INFO -     epoch          : 51
2025-01-21 11:16:12,598 - trainer - INFO -     elapsed time   : 4.601958274841309
2025-01-21 11:16:12,598 - trainer - INFO -     loss           : 85.95858802795411
2025-01-21 11:16:12,598 - trainer - INFO -     sim_loss       : 35.77648487091064
2025-01-21 11:16:12,598 - trainer - INFO -     gen_loss       : 107.46520614624023
2025-01-21 11:16:12,598 - trainer - INFO -     val_loss       : 406.21192741394043
2025-01-21 11:16:12,598 - trainer - INFO -     val_sim_loss   : 16.51332664489746
2025-01-21 11:16:12,598 - trainer - INFO -     val_gen_loss   : 389.6985912322998
2025-01-21 11:16:12,598 - trainer - INFO -     val_perplexity : 22.792062759399414
2025-01-21 11:16:12,598 - trainer - INFO -     val_embedding_sim: 0.14329802989959717
2025-01-21 11:16:12,598 - trainer - INFO - ================================================================================
2025-01-21 11:16:12,598 - trainer - INFO - Starting epoch 52 at 2025-01-21 11:16:12
2025-01-21 11:16:17,157 - trainer - INFO - Epoch 52 completed at 2025-01-21 11:16:17
2025-01-21 11:16:17,158 - trainer - INFO -     epoch          : 52
2025-01-21 11:16:17,158 - trainer - INFO -     elapsed time   : 4.559184789657593
2025-01-21 11:16:17,158 - trainer - INFO -     loss           : 82.31015815734864
2025-01-21 11:16:17,158 - trainer - INFO -     sim_loss       : 29.756574440002442
2025-01-21 11:16:17,158 - trainer - INFO -     gen_loss       : 104.83312339782715
2025-01-21 11:16:17,158 - trainer - INFO -     val_loss       : 399.3372573852539
2025-01-21 11:16:17,158 - trainer - INFO -     val_sim_loss   : 16.068708419799805
2025-01-21 11:16:17,158 - trainer - INFO -     val_gen_loss   : 383.26856231689453
2025-01-21 11:16:17,158 - trainer - INFO -     val_perplexity : 21.720365524291992
2025-01-21 11:16:17,158 - trainer - INFO -     val_embedding_sim: 0.13712874054908752
2025-01-21 11:16:17,158 - trainer - INFO - ================================================================================
2025-01-21 11:16:17,158 - trainer - INFO - Starting epoch 53 at 2025-01-21 11:16:17
2025-01-21 11:16:21,729 - trainer - INFO - Epoch 53 completed at 2025-01-21 11:16:21
2025-01-21 11:16:21,730 - trainer - INFO -     epoch          : 53
2025-01-21 11:16:21,730 - trainer - INFO -     elapsed time   : 4.571425914764404
2025-01-21 11:16:21,730 - trainer - INFO -     loss           : 81.50887565612793
2025-01-21 11:16:21,730 - trainer - INFO -     sim_loss       : 32.04063081741333
2025-01-21 11:16:21,730 - trainer - INFO -     gen_loss       : 102.70955200195313
2025-01-21 11:16:21,730 - trainer - INFO -     val_loss       : 409.5026388168335
2025-01-21 11:16:21,730 - trainer - INFO -     val_sim_loss   : 18.835834503173828
2025-01-21 11:16:21,730 - trainer - INFO -     val_gen_loss   : 390.66679286956787
2025-01-21 11:16:21,730 - trainer - INFO -     val_perplexity : 23.63766860961914
2025-01-21 11:16:21,730 - trainer - INFO -     val_embedding_sim: 0.1520335078239441
2025-01-21 11:16:21,730 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
