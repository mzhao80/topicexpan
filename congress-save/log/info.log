2025-01-21 11:01:04,762 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:01:07,093 - trainer - INFO - ================================================================================
2025-01-21 11:01:07,093 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:01:07
2025-01-21 11:03:40,474 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:03:42,799 - trainer - INFO - ================================================================================
2025-01-21 11:03:42,799 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:03:42
2025-01-21 11:03:48,569 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:03:48
2025-01-21 11:03:48,570 - trainer - INFO -     epoch          : 1
2025-01-21 11:03:48,570 - trainer - INFO -     elapsed time   : 5.769897222518921
2025-01-21 11:03:48,570 - trainer - INFO -     loss           : 926.0519439697266
2025-01-21 11:03:48,570 - trainer - INFO -     sim_loss       : 80.15059967041016
2025-01-21 11:03:48,570 - trainer - INFO -     gen_loss       : 1288.581137084961
2025-01-21 11:03:48,570 - trainer - INFO -     val_loss       : 597.9047985076904
2025-01-21 11:03:48,570 - trainer - INFO -     val_sim_loss   : 30.897884368896484
2025-01-21 11:03:48,570 - trainer - INFO -     val_gen_loss   : 567.0069103240967
2025-01-21 11:03:48,570 - trainer - INFO -     val_perplexity : 34.28977584838867
2025-01-21 11:03:48,570 - trainer - INFO -     val_embedding_sim: 0.13666823506355286
2025-01-21 11:03:48,570 - trainer - INFO - ================================================================================
2025-01-21 11:03:48,570 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:03:48
2025-01-21 11:03:53,132 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:03:53
2025-01-21 11:03:53,132 - trainer - INFO -     epoch          : 2
2025-01-21 11:03:53,132 - trainer - INFO -     elapsed time   : 4.561354637145996
2025-01-21 11:03:53,132 - trainer - INFO -     loss           : 818.1401336669921
2025-01-21 11:03:53,132 - trainer - INFO -     sim_loss       : 44.15964412689209
2025-01-21 11:03:53,132 - trainer - INFO -     gen_loss       : 1149.8460571289063
2025-01-21 11:03:53,132 - trainer - INFO -     val_loss       : 568.61376953125
2025-01-21 11:03:53,132 - trainer - INFO -     val_sim_loss   : 25.156253814697266
2025-01-21 11:03:53,132 - trainer - INFO -     val_gen_loss   : 543.45751953125
2025-01-21 11:03:53,132 - trainer - INFO -     val_perplexity : 32.679656982421875
2025-01-21 11:03:53,132 - trainer - INFO -     val_embedding_sim: 0.12289004027843475
2025-01-21 11:03:53,132 - trainer - INFO - ================================================================================
2025-01-21 11:03:53,132 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:03:53
2025-01-21 11:03:57,703 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:03:57
2025-01-21 11:03:57,703 - trainer - INFO -     epoch          : 3
2025-01-21 11:03:57,703 - trainer - INFO -     elapsed time   : 4.5706470012664795
2025-01-21 11:03:57,703 - trainer - INFO -     loss           : 769.9964965820312
2025-01-21 11:03:57,703 - trainer - INFO -     sim_loss       : 31.62858376502991
2025-01-21 11:03:57,703 - trainer - INFO -     gen_loss       : 1086.4399047851562
2025-01-21 11:03:57,703 - trainer - INFO -     val_loss       : 539.9116134643555
2025-01-21 11:03:57,703 - trainer - INFO -     val_sim_loss   : 18.201324462890625
2025-01-21 11:03:57,703 - trainer - INFO -     val_gen_loss   : 521.7102890014648
2025-01-21 11:03:57,703 - trainer - INFO -     val_perplexity : 30.639623641967773
2025-01-21 11:03:57,703 - trainer - INFO -     val_embedding_sim: 0.12869185209274292
2025-01-21 11:03:57,703 - trainer - INFO - ================================================================================
2025-01-21 11:03:57,703 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:03:57
2025-01-21 11:04:02,280 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:04:02
2025-01-21 11:04:02,280 - trainer - INFO -     epoch          : 4
2025-01-21 11:04:02,280 - trainer - INFO -     elapsed time   : 4.576574325561523
2025-01-21 11:04:02,280 - trainer - INFO -     loss           : 725.3969787597656
2025-01-21 11:04:02,280 - trainer - INFO -     sim_loss       : 32.78736534118652
2025-01-21 11:04:02,280 - trainer - INFO -     gen_loss       : 1022.2296752929688
2025-01-21 11:04:02,280 - trainer - INFO -     val_loss       : 523.198091506958
2025-01-21 11:04:02,280 - trainer - INFO -     val_sim_loss   : 23.64540672302246
2025-01-21 11:04:02,280 - trainer - INFO -     val_gen_loss   : 499.5526752471924
2025-01-21 11:04:02,281 - trainer - INFO -     val_perplexity : 29.813417434692383
2025-01-21 11:04:02,281 - trainer - INFO -     val_embedding_sim: 0.12147559225559235
2025-01-21 11:04:02,281 - trainer - INFO - ================================================================================
2025-01-21 11:04:02,281 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:04:02
2025-01-21 11:04:06,842 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:04:06
2025-01-21 11:04:06,843 - trainer - INFO -     epoch          : 5
2025-01-21 11:04:06,843 - trainer - INFO -     elapsed time   : 4.561597585678101
2025-01-21 11:04:06,843 - trainer - INFO -     loss           : 679.582080078125
2025-01-21 11:04:06,843 - trainer - INFO -     sim_loss       : 34.431762504577634
2025-01-21 11:04:06,843 - trainer - INFO -     gen_loss       : 956.0750854492187
2025-01-21 11:04:06,843 - trainer - INFO -     val_loss       : 490.88640880584717
2025-01-21 11:04:06,843 - trainer - INFO -     val_sim_loss   : 16.582721710205078
2025-01-21 11:04:06,843 - trainer - INFO -     val_gen_loss   : 474.3036756515503
2025-01-21 11:04:06,843 - trainer - INFO -     val_perplexity : 28.8875675201416
2025-01-21 11:04:06,843 - trainer - INFO -     val_embedding_sim: 0.12403754889965057
2025-01-21 11:04:13,400 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:04:19,930 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:04:19,930 - trainer - INFO - ================================================================================
2025-01-21 11:04:19,930 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:04:19
2025-01-21 11:04:24,561 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:04:24
2025-01-21 11:04:24,562 - trainer - INFO -     epoch          : 6
2025-01-21 11:04:24,562 - trainer - INFO -     elapsed time   : 4.631126165390015
2025-01-21 11:04:24,562 - trainer - INFO -     loss           : 631.5764312744141
2025-01-21 11:04:24,562 - trainer - INFO -     sim_loss       : 34.07801918983459
2025-01-21 11:04:24,562 - trainer - INFO -     gen_loss       : 887.6471923828125
2025-01-21 11:04:24,562 - trainer - INFO -     val_loss       : 465.33051204681396
2025-01-21 11:04:24,562 - trainer - INFO -     val_sim_loss   : 12.27341079711914
2025-01-21 11:04:24,562 - trainer - INFO -     val_gen_loss   : 453.0571050643921
2025-01-21 11:04:24,562 - trainer - INFO -     val_perplexity : 27.352720260620117
2025-01-21 11:04:24,562 - trainer - INFO -     val_embedding_sim: 0.14163225889205933
2025-01-21 11:04:24,562 - trainer - INFO - ================================================================================
2025-01-21 11:04:24,562 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:04:24
2025-01-21 11:04:29,139 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:04:29
2025-01-21 11:04:29,139 - trainer - INFO -     epoch          : 7
2025-01-21 11:04:29,139 - trainer - INFO -     elapsed time   : 4.5769476890563965
2025-01-21 11:04:29,139 - trainer - INFO -     loss           : 589.1849075317383
2025-01-21 11:04:29,139 - trainer - INFO -     sim_loss       : 31.078872680664062
2025-01-21 11:04:29,139 - trainer - INFO -     gen_loss       : 828.3732299804688
2025-01-21 11:04:29,139 - trainer - INFO -     val_loss       : 450.8620386123657
2025-01-21 11:04:29,140 - trainer - INFO -     val_sim_loss   : 14.327374458312988
2025-01-21 11:04:29,140 - trainer - INFO -     val_gen_loss   : 436.53467655181885
2025-01-21 11:04:29,140 - trainer - INFO -     val_perplexity : 26.328960418701172
2025-01-21 11:04:29,140 - trainer - INFO -     val_embedding_sim: 0.12669633328914642
2025-01-21 11:04:29,140 - trainer - INFO - ================================================================================
2025-01-21 11:04:29,140 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:04:29
2025-01-21 11:04:33,707 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:04:33
2025-01-21 11:04:33,707 - trainer - INFO -     epoch          : 8
2025-01-21 11:04:33,708 - trainer - INFO -     elapsed time   : 4.567424297332764
2025-01-21 11:04:33,708 - trainer - INFO -     loss           : 554.25791015625
2025-01-21 11:04:33,708 - trainer - INFO -     sim_loss       : 29.116330003738405
2025-01-21 11:04:33,708 - trainer - INFO -     gen_loss       : 779.3186126708985
2025-01-21 11:04:33,708 - trainer - INFO -     val_loss       : 442.81386137008667
2025-01-21 11:04:33,708 - trainer - INFO -     val_sim_loss   : 16.141357421875
2025-01-21 11:04:33,708 - trainer - INFO -     val_gen_loss   : 426.67250394821167
2025-01-21 11:04:33,708 - trainer - INFO -     val_perplexity : 26.25133514404297
2025-01-21 11:04:33,708 - trainer - INFO -     val_embedding_sim: 0.1423085629940033
2025-01-21 11:04:33,708 - trainer - INFO - ================================================================================
2025-01-21 11:04:33,708 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:04:33
2025-01-21 11:04:38,278 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:04:38
2025-01-21 11:04:38,278 - trainer - INFO -     epoch          : 9
2025-01-21 11:04:38,278 - trainer - INFO -     elapsed time   : 4.5699896812438965
2025-01-21 11:04:38,278 - trainer - INFO -     loss           : 523.0952331542969
2025-01-21 11:04:38,278 - trainer - INFO -     sim_loss       : 33.39409275054932
2025-01-21 11:04:38,278 - trainer - INFO -     gen_loss       : 732.9671691894531
2025-01-21 11:04:38,278 - trainer - INFO -     val_loss       : 431.00056171417236
2025-01-21 11:04:38,278 - trainer - INFO -     val_sim_loss   : 13.267549514770508
2025-01-21 11:04:38,278 - trainer - INFO -     val_gen_loss   : 417.7330141067505
2025-01-21 11:04:38,279 - trainer - INFO -     val_perplexity : 25.40492820739746
2025-01-21 11:04:38,279 - trainer - INFO -     val_embedding_sim: 0.10869182646274567
2025-01-21 11:04:38,279 - trainer - INFO - ================================================================================
2025-01-21 11:04:38,279 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:04:38
2025-01-21 11:04:42,881 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:04:42
2025-01-21 11:04:42,881 - trainer - INFO -     epoch          : 10
2025-01-21 11:04:42,881 - trainer - INFO -     elapsed time   : 4.6018993854522705
2025-01-21 11:04:42,881 - trainer - INFO -     loss           : 491.5878143310547
2025-01-21 11:04:42,881 - trainer - INFO -     sim_loss       : 27.67424144744873
2025-01-21 11:04:42,881 - trainer - INFO -     gen_loss       : 690.407925415039
2025-01-21 11:04:42,881 - trainer - INFO -     val_loss       : 425.7060203552246
2025-01-21 11:04:42,881 - trainer - INFO -     val_sim_loss   : 17.344375610351562
2025-01-21 11:04:42,881 - trainer - INFO -     val_gen_loss   : 408.361629486084
2025-01-21 11:04:42,881 - trainer - INFO -     val_perplexity : 24.039384841918945
2025-01-21 11:04:42,881 - trainer - INFO -     val_embedding_sim: 0.09287156909704208
2025-01-21 11:04:49,408 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:04:55,988 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:04:55,989 - trainer - INFO - ================================================================================
2025-01-21 11:04:55,989 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:04:55
2025-01-21 11:05:00,669 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:05:00
2025-01-21 11:05:00,669 - trainer - INFO -     epoch          : 11
2025-01-21 11:05:00,669 - trainer - INFO -     elapsed time   : 4.67994236946106
2025-01-21 11:05:00,669 - trainer - INFO -     loss           : 464.9297836303711
2025-01-21 11:05:00,669 - trainer - INFO -     sim_loss       : 30.61037149429321
2025-01-21 11:05:00,669 - trainer - INFO -     gen_loss       : 651.0666900634766
2025-01-21 11:05:00,669 - trainer - INFO -     val_loss       : 418.3226079940796
2025-01-21 11:05:00,669 - trainer - INFO -     val_sim_loss   : 11.309075355529785
2025-01-21 11:05:00,669 - trainer - INFO -     val_gen_loss   : 407.0135259628296
2025-01-21 11:05:00,669 - trainer - INFO -     val_perplexity : 24.466413497924805
2025-01-21 11:05:00,669 - trainer - INFO -     val_embedding_sim: 0.09262049198150635
2025-01-21 11:05:00,669 - trainer - INFO - ================================================================================
2025-01-21 11:05:00,669 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:05:00
2025-01-21 11:05:05,255 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:05:05
2025-01-21 11:05:05,255 - trainer - INFO -     epoch          : 12
2025-01-21 11:05:05,255 - trainer - INFO -     elapsed time   : 4.5855443477630615
2025-01-21 11:05:05,255 - trainer - INFO -     loss           : 438.79956970214846
2025-01-21 11:05:05,255 - trainer - INFO -     sim_loss       : 29.593007850646973
2025-01-21 11:05:05,256 - trainer - INFO -     gen_loss       : 614.1738159179688
2025-01-21 11:05:05,256 - trainer - INFO -     val_loss       : 419.10369205474854
2025-01-21 11:05:05,256 - trainer - INFO -     val_sim_loss   : 22.183757781982422
2025-01-21 11:05:05,256 - trainer - INFO -     val_gen_loss   : 396.9199457168579
2025-01-21 11:05:05,256 - trainer - INFO -     val_perplexity : 23.82119369506836
2025-01-21 11:05:05,256 - trainer - INFO -     val_embedding_sim: 0.09391862154006958
2025-01-21 11:05:05,256 - trainer - INFO - ================================================================================
2025-01-21 11:05:05,256 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:05:05
2025-01-21 11:05:09,814 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:05:09
2025-01-21 11:05:09,814 - trainer - INFO -     epoch          : 13
2025-01-21 11:05:09,815 - trainer - INFO -     elapsed time   : 4.5583672523498535
2025-01-21 11:05:09,815 - trainer - INFO -     loss           : 418.70814056396483
2025-01-21 11:05:09,815 - trainer - INFO -     sim_loss       : 27.70587158203125
2025-01-21 11:05:09,815 - trainer - INFO -     gen_loss       : 586.2805480957031
2025-01-21 11:05:09,815 - trainer - INFO -     val_loss       : 410.1313934326172
2025-01-21 11:05:09,815 - trainer - INFO -     val_sim_loss   : 13.565485000610352
2025-01-21 11:05:09,815 - trainer - INFO -     val_gen_loss   : 396.56590270996094
2025-01-21 11:05:09,815 - trainer - INFO -     val_perplexity : 23.933002471923828
2025-01-21 11:05:09,815 - trainer - INFO -     val_embedding_sim: 0.11216865479946136
2025-01-21 11:05:09,815 - trainer - INFO - ================================================================================
2025-01-21 11:05:09,815 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:05:09
2025-01-21 11:05:14,429 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:05:14
2025-01-21 11:05:14,430 - trainer - INFO -     epoch          : 14
2025-01-21 11:05:14,430 - trainer - INFO -     elapsed time   : 4.614391088485718
2025-01-21 11:05:14,430 - trainer - INFO -     loss           : 398.6117248535156
2025-01-21 11:05:14,430 - trainer - INFO -     sim_loss       : 26.843203639984132
2025-01-21 11:05:14,430 - trainer - INFO -     gen_loss       : 557.9410949707031
2025-01-21 11:05:14,430 - trainer - INFO -     val_loss       : 403.31173038482666
2025-01-21 11:05:14,430 - trainer - INFO -     val_sim_loss   : 13.994431495666504
2025-01-21 11:05:14,430 - trainer - INFO -     val_gen_loss   : 389.3172845840454
2025-01-21 11:05:14,430 - trainer - INFO -     val_perplexity : 24.07252311706543
2025-01-21 11:05:14,430 - trainer - INFO -     val_embedding_sim: 0.10106629133224487
2025-01-21 11:05:14,430 - trainer - INFO - ================================================================================
2025-01-21 11:05:14,430 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:05:14
2025-01-21 11:05:19,004 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:05:19
2025-01-21 11:05:19,004 - trainer - INFO -     epoch          : 15
2025-01-21 11:05:19,004 - trainer - INFO -     elapsed time   : 4.573880910873413
2025-01-21 11:05:19,004 - trainer - INFO -     loss           : 379.553173828125
2025-01-21 11:05:19,004 - trainer - INFO -     sim_loss       : 29.399465084075928
2025-01-21 11:05:19,004 - trainer - INFO -     gen_loss       : 529.6190628051758
2025-01-21 11:05:19,004 - trainer - INFO -     val_loss       : 400.81122493743896
2025-01-21 11:05:19,004 - trainer - INFO -     val_sim_loss   : 11.285567283630371
2025-01-21 11:05:19,004 - trainer - INFO -     val_gen_loss   : 389.52567195892334
2025-01-21 11:05:19,004 - trainer - INFO -     val_perplexity : 23.721189498901367
2025-01-21 11:05:19,004 - trainer - INFO -     val_embedding_sim: 0.14927928149700165
2025-01-21 11:05:25,562 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:05:25,562 - trainer - INFO - ================================================================================
2025-01-21 11:05:25,563 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:05:25
2025-01-21 11:05:30,154 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:05:30
2025-01-21 11:05:30,154 - trainer - INFO -     epoch          : 16
2025-01-21 11:05:30,154 - trainer - INFO -     elapsed time   : 4.591327667236328
2025-01-21 11:05:30,154 - trainer - INFO -     loss           : 362.56701507568357
2025-01-21 11:05:30,154 - trainer - INFO -     sim_loss       : 28.248128271102907
2025-01-21 11:05:30,154 - trainer - INFO -     gen_loss       : 505.8465515136719
2025-01-21 11:05:30,154 - trainer - INFO -     val_loss       : 410.37131357192993
2025-01-21 11:05:30,154 - trainer - INFO -     val_sim_loss   : 22.40926170349121
2025-01-21 11:05:30,154 - trainer - INFO -     val_gen_loss   : 387.96204233169556
2025-01-21 11:05:30,155 - trainer - INFO -     val_perplexity : 23.8521728515625
2025-01-21 11:05:30,155 - trainer - INFO -     val_embedding_sim: 0.11508586257696152
2025-01-21 11:05:30,155 - trainer - INFO - ================================================================================
2025-01-21 11:05:30,155 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:05:30
2025-01-21 11:05:34,716 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:05:34
2025-01-21 11:05:34,716 - trainer - INFO -     epoch          : 17
2025-01-21 11:05:34,716 - trainer - INFO -     elapsed time   : 4.561405181884766
2025-01-21 11:05:34,716 - trainer - INFO -     loss           : 348.59795532226565
2025-01-21 11:05:34,716 - trainer - INFO -     sim_loss       : 31.981904792785645
2025-01-21 11:05:34,716 - trainer - INFO -     gen_loss       : 484.2905471801758
2025-01-21 11:05:34,716 - trainer - INFO -     val_loss       : 392.96069717407227
2025-01-21 11:05:34,716 - trainer - INFO -     val_sim_loss   : 11.984954833984375
2025-01-21 11:05:34,716 - trainer - INFO -     val_gen_loss   : 380.9757423400879
2025-01-21 11:05:34,717 - trainer - INFO -     val_perplexity : 22.341129302978516
2025-01-21 11:05:34,717 - trainer - INFO -     val_embedding_sim: 0.13425487279891968
2025-01-21 11:05:34,717 - trainer - INFO - ================================================================================
2025-01-21 11:05:34,717 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:05:34
2025-01-21 11:05:39,288 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:05:39
2025-01-21 11:05:39,288 - trainer - INFO -     epoch          : 18
2025-01-21 11:05:39,288 - trainer - INFO -     elapsed time   : 4.571536064147949
2025-01-21 11:05:39,289 - trainer - INFO -     loss           : 332.93125
2025-01-21 11:05:39,289 - trainer - INFO -     sim_loss       : 30.995863723754884
2025-01-21 11:05:39,289 - trainer - INFO -     gen_loss       : 462.33212890625
2025-01-21 11:05:39,289 - trainer - INFO -     val_loss       : 395.7828621864319
2025-01-21 11:05:39,289 - trainer - INFO -     val_sim_loss   : 14.72945785522461
2025-01-21 11:05:39,289 - trainer - INFO -     val_gen_loss   : 381.05340051651
2025-01-21 11:05:39,289 - trainer - INFO -     val_perplexity : 23.6783390045166
2025-01-21 11:05:39,289 - trainer - INFO -     val_embedding_sim: 0.12871184945106506
2025-01-21 11:05:39,289 - trainer - INFO - ================================================================================
2025-01-21 11:05:39,289 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:05:39
2025-01-21 11:05:43,858 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:05:43
2025-01-21 11:05:43,858 - trainer - INFO -     epoch          : 19
2025-01-21 11:05:43,858 - trainer - INFO -     elapsed time   : 4.568909168243408
2025-01-21 11:05:43,858 - trainer - INFO -     loss           : 317.53098449707034
2025-01-21 11:05:43,858 - trainer - INFO -     sim_loss       : 26.617593193054198
2025-01-21 11:05:43,858 - trainer - INFO -     gen_loss       : 442.20815124511716
2025-01-21 11:05:43,858 - trainer - INFO -     val_loss       : 400.50645446777344
2025-01-21 11:05:43,858 - trainer - INFO -     val_sim_loss   : 16.905010223388672
2025-01-21 11:05:43,858 - trainer - INFO -     val_gen_loss   : 383.60145568847656
2025-01-21 11:05:43,858 - trainer - INFO -     val_perplexity : 21.875045776367188
2025-01-21 11:05:43,858 - trainer - INFO -     val_embedding_sim: 0.12683440744876862
2025-01-21 11:05:43,858 - trainer - INFO - ================================================================================
2025-01-21 11:05:43,859 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:05:43
2025-01-21 11:05:48,475 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:05:48
2025-01-21 11:05:48,475 - trainer - INFO -     epoch          : 20
2025-01-21 11:05:48,475 - trainer - INFO -     elapsed time   : 4.616438627243042
2025-01-21 11:05:48,475 - trainer - INFO -     loss           : 304.07374267578126
2025-01-21 11:05:48,475 - trainer - INFO -     sim_loss       : 26.845297050476074
2025-01-21 11:05:48,475 - trainer - INFO -     gen_loss       : 422.88594512939454
2025-01-21 11:05:48,475 - trainer - INFO -     val_loss       : 396.75442457199097
2025-01-21 11:05:48,475 - trainer - INFO -     val_sim_loss   : 13.29230785369873
2025-01-21 11:05:48,476 - trainer - INFO -     val_gen_loss   : 383.4621272087097
2025-01-21 11:05:48,476 - trainer - INFO -     val_perplexity : 23.7319393157959
2025-01-21 11:05:48,476 - trainer - INFO -     val_embedding_sim: 0.12024622410535812
2025-01-21 11:05:55,016 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:05:55,016 - trainer - INFO - ================================================================================
2025-01-21 11:05:55,016 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:05:55
2025-01-21 11:05:59,628 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:05:59
2025-01-21 11:05:59,628 - trainer - INFO -     epoch          : 21
2025-01-21 11:05:59,628 - trainer - INFO -     elapsed time   : 4.611464262008667
2025-01-21 11:05:59,628 - trainer - INFO -     loss           : 289.8626235961914
2025-01-21 11:05:59,628 - trainer - INFO -     sim_loss       : 26.495360946655275
2025-01-21 11:05:59,628 - trainer - INFO -     gen_loss       : 402.73431701660155
2025-01-21 11:05:59,628 - trainer - INFO -     val_loss       : 404.3116569519043
2025-01-21 11:05:59,628 - trainer - INFO -     val_sim_loss   : 20.561983108520508
2025-01-21 11:05:59,628 - trainer - INFO -     val_gen_loss   : 383.7496757507324
2025-01-21 11:05:59,628 - trainer - INFO -     val_perplexity : 22.541950225830078
2025-01-21 11:05:59,628 - trainer - INFO -     val_embedding_sim: 0.13378143310546875
2025-01-21 11:05:59,628 - trainer - INFO - ================================================================================
2025-01-21 11:05:59,628 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:05:59
2025-01-21 11:06:04,212 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:06:04
2025-01-21 11:06:04,212 - trainer - INFO -     epoch          : 22
2025-01-21 11:06:04,212 - trainer - INFO -     elapsed time   : 4.583429574966431
2025-01-21 11:06:04,212 - trainer - INFO -     loss           : 278.73849029541014
2025-01-21 11:06:04,212 - trainer - INFO -     sim_loss       : 28.3484069455415
2025-01-21 11:06:04,212 - trainer - INFO -     gen_loss       : 386.04854278564454
2025-01-21 11:06:04,212 - trainer - INFO -     val_loss       : 401.3933849334717
2025-01-21 11:06:04,212 - trainer - INFO -     val_sim_loss   : 21.331533432006836
2025-01-21 11:06:04,212 - trainer - INFO -     val_gen_loss   : 380.0618419647217
2025-01-21 11:06:04,212 - trainer - INFO -     val_perplexity : 22.21444320678711
2025-01-21 11:06:04,212 - trainer - INFO -     val_embedding_sim: 0.0923214852809906
2025-01-21 11:06:04,212 - trainer - INFO - ================================================================================
2025-01-21 11:06:04,212 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:06:04
2025-01-21 11:06:08,796 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:06:08
2025-01-21 11:06:08,796 - trainer - INFO -     epoch          : 23
2025-01-21 11:06:08,796 - trainer - INFO -     elapsed time   : 4.583087205886841
2025-01-21 11:06:08,796 - trainer - INFO -     loss           : 267.6239471435547
2025-01-21 11:06:08,796 - trainer - INFO -     sim_loss       : 26.38816108703613
2025-01-21 11:06:08,796 - trainer - INFO -     gen_loss       : 371.0107162475586
2025-01-21 11:06:08,796 - trainer - INFO -     val_loss       : 394.9864454269409
2025-01-21 11:06:08,796 - trainer - INFO -     val_sim_loss   : 13.367634773254395
2025-01-21 11:06:08,796 - trainer - INFO -     val_gen_loss   : 381.61880016326904
2025-01-21 11:06:08,796 - trainer - INFO -     val_perplexity : 23.28582763671875
2025-01-21 11:06:08,796 - trainer - INFO -     val_embedding_sim: 0.13532155752182007
2025-01-21 11:06:08,796 - trainer - INFO - ================================================================================
2025-01-21 11:06:08,796 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:06:08
2025-01-21 11:06:13,378 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:06:13
2025-01-21 11:06:13,378 - trainer - INFO -     epoch          : 24
2025-01-21 11:06:13,378 - trainer - INFO -     elapsed time   : 4.5814478397369385
2025-01-21 11:06:13,378 - trainer - INFO -     loss           : 256.7323974609375
2025-01-21 11:06:13,378 - trainer - INFO -     sim_loss       : 29.187371730804443
2025-01-21 11:06:13,378 - trainer - INFO -     gen_loss       : 354.25169982910154
2025-01-21 11:06:13,378 - trainer - INFO -     val_loss       : 394.3366184234619
2025-01-21 11:06:13,378 - trainer - INFO -     val_sim_loss   : 12.41535472869873
2025-01-21 11:06:13,378 - trainer - INFO -     val_gen_loss   : 381.92127418518066
2025-01-21 11:06:13,378 - trainer - INFO -     val_perplexity : 22.326684951782227
2025-01-21 11:06:13,378 - trainer - INFO -     val_embedding_sim: 0.13327088952064514
2025-01-21 11:06:13,378 - trainer - INFO - ================================================================================
2025-01-21 11:06:13,378 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:06:13
2025-01-21 11:06:17,939 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:06:17
2025-01-21 11:06:17,939 - trainer - INFO -     epoch          : 25
2025-01-21 11:06:17,939 - trainer - INFO -     elapsed time   : 4.560091018676758
2025-01-21 11:06:17,939 - trainer - INFO -     loss           : 247.40595245361328
2025-01-21 11:06:17,939 - trainer - INFO -     sim_loss       : 32.51254043579102
2025-01-21 11:06:17,939 - trainer - INFO -     gen_loss       : 339.5031280517578
2025-01-21 11:06:17,939 - trainer - INFO -     val_loss       : 402.5485563278198
2025-01-21 11:06:17,939 - trainer - INFO -     val_sim_loss   : 19.839874267578125
2025-01-21 11:06:17,939 - trainer - INFO -     val_gen_loss   : 382.7086820602417
2025-01-21 11:06:17,939 - trainer - INFO -     val_perplexity : 23.071298599243164
2025-01-21 11:06:17,939 - trainer - INFO -     val_embedding_sim: 0.12485183030366898
2025-01-21 11:06:24,481 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:06:24,481 - trainer - INFO - ================================================================================
2025-01-21 11:06:24,481 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:06:24
2025-01-21 11:06:29,118 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:06:29
2025-01-21 11:06:29,118 - trainer - INFO -     epoch          : 26
2025-01-21 11:06:29,118 - trainer - INFO -     elapsed time   : 4.63640022277832
2025-01-21 11:06:29,118 - trainer - INFO -     loss           : 237.32769165039062
2025-01-21 11:06:29,118 - trainer - INFO -     sim_loss       : 30.976594734191895
2025-01-21 11:06:29,118 - trainer - INFO -     gen_loss       : 325.7638824462891
2025-01-21 11:06:29,118 - trainer - INFO -     val_loss       : 398.11186027526855
2025-01-21 11:06:29,118 - trainer - INFO -     val_sim_loss   : 16.67139434814453
2025-01-21 11:06:29,118 - trainer - INFO -     val_gen_loss   : 381.44047355651855
2025-01-21 11:06:29,118 - trainer - INFO -     val_perplexity : 23.701885223388672
2025-01-21 11:06:29,118 - trainer - INFO -     val_embedding_sim: 0.13946932554244995
2025-01-21 11:06:29,118 - trainer - INFO - ================================================================================
2025-01-21 11:06:29,118 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:06:29
2025-01-21 11:06:33,698 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:06:33
2025-01-21 11:06:33,698 - trainer - INFO -     epoch          : 27
2025-01-21 11:06:33,698 - trainer - INFO -     elapsed time   : 4.579484701156616
2025-01-21 11:06:33,698 - trainer - INFO -     loss           : 225.3188934326172
2025-01-21 11:06:33,698 - trainer - INFO -     sim_loss       : 28.23128433227539
2025-01-21 11:06:33,698 - trainer - INFO -     gen_loss       : 309.7850227355957
2025-01-21 11:06:33,698 - trainer - INFO -     val_loss       : 394.7086944580078
2025-01-21 11:06:33,698 - trainer - INFO -     val_sim_loss   : 12.547508239746094
2025-01-21 11:06:33,698 - trainer - INFO -     val_gen_loss   : 382.1611785888672
2025-01-21 11:06:33,698 - trainer - INFO -     val_perplexity : 23.72279930114746
2025-01-21 11:06:33,698 - trainer - INFO -     val_embedding_sim: 0.11035062372684479
2025-01-21 11:06:33,698 - trainer - INFO - ================================================================================
2025-01-21 11:06:33,698 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:06:33
2025-01-21 11:06:38,261 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:06:38
2025-01-21 11:06:38,261 - trainer - INFO -     epoch          : 28
2025-01-21 11:06:38,262 - trainer - INFO -     elapsed time   : 4.562955141067505
2025-01-21 11:06:38,262 - trainer - INFO -     loss           : 219.90910949707032
2025-01-21 11:06:38,262 - trainer - INFO -     sim_loss       : 35.44960741996765
2025-01-21 11:06:38,262 - trainer - INFO -     gen_loss       : 298.9631881713867
2025-01-21 11:06:38,262 - trainer - INFO -     val_loss       : 395.7241415977478
2025-01-21 11:06:38,262 - trainer - INFO -     val_sim_loss   : 16.152671813964844
2025-01-21 11:06:38,262 - trainer - INFO -     val_gen_loss   : 379.5714621543884
2025-01-21 11:06:38,262 - trainer - INFO -     val_perplexity : 23.45545768737793
2025-01-21 11:06:38,262 - trainer - INFO -     val_embedding_sim: 0.12125259637832642
2025-01-21 11:06:38,262 - trainer - INFO - ================================================================================
2025-01-21 11:06:38,262 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:06:38
2025-01-21 11:06:42,834 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:06:42
2025-01-21 11:06:42,834 - trainer - INFO -     epoch          : 29
2025-01-21 11:06:42,834 - trainer - INFO -     elapsed time   : 4.57200026512146
2025-01-21 11:06:42,834 - trainer - INFO -     loss           : 209.67716369628906
2025-01-21 11:06:42,834 - trainer - INFO -     sim_loss       : 32.89674882888794
2025-01-21 11:06:42,834 - trainer - INFO -     gen_loss       : 285.4402053833008
2025-01-21 11:06:42,834 - trainer - INFO -     val_loss       : 389.5766201019287
2025-01-21 11:06:42,834 - trainer - INFO -     val_sim_loss   : 9.445537567138672
2025-01-21 11:06:42,834 - trainer - INFO -     val_gen_loss   : 380.13109397888184
2025-01-21 11:06:42,835 - trainer - INFO -     val_perplexity : 23.628822326660156
2025-01-21 11:06:42,835 - trainer - INFO -     val_embedding_sim: 0.15667513012886047
2025-01-21 11:06:42,835 - trainer - INFO - ================================================================================
2025-01-21 11:06:42,835 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:06:42
2025-01-21 11:06:47,409 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:06:47
2025-01-21 11:06:47,409 - trainer - INFO -     epoch          : 30
2025-01-21 11:06:47,409 - trainer - INFO -     elapsed time   : 4.57393217086792
2025-01-21 11:06:47,409 - trainer - INFO -     loss           : 198.5173599243164
2025-01-21 11:06:47,409 - trainer - INFO -     sim_loss       : 30.605120277404787
2025-01-21 11:06:47,409 - trainer - INFO -     gen_loss       : 270.4797523498535
2025-01-21 11:06:47,409 - trainer - INFO -     val_loss       : 399.3052816390991
2025-01-21 11:06:47,409 - trainer - INFO -     val_sim_loss   : 19.226608276367188
2025-01-21 11:06:47,409 - trainer - INFO -     val_gen_loss   : 380.078688621521
2025-01-21 11:06:47,409 - trainer - INFO -     val_perplexity : 22.93596076965332
2025-01-21 11:06:47,409 - trainer - INFO -     val_embedding_sim: 0.1265895962715149
2025-01-21 11:06:53,954 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:06:53,955 - trainer - INFO - ================================================================================
2025-01-21 11:06:53,955 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:06:53
2025-01-21 11:06:58,559 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:06:58
2025-01-21 11:06:58,559 - trainer - INFO -     epoch          : 31
2025-01-21 11:06:58,559 - trainer - INFO -     elapsed time   : 4.603986740112305
2025-01-21 11:06:58,559 - trainer - INFO -     loss           : 192.83720855712892
2025-01-21 11:06:58,559 - trainer - INFO -     sim_loss       : 32.622314453125
2025-01-21 11:06:58,559 - trainer - INFO -     gen_loss       : 261.50073394775393
2025-01-21 11:06:58,559 - trainer - INFO -     val_loss       : 395.8862247467041
2025-01-21 11:06:58,559 - trainer - INFO -     val_sim_loss   : 18.706209182739258
2025-01-21 11:06:58,559 - trainer - INFO -     val_gen_loss   : 377.1800174713135
2025-01-21 11:06:58,559 - trainer - INFO -     val_perplexity : 23.001020431518555
2025-01-21 11:06:58,560 - trainer - INFO -     val_embedding_sim: 0.14227081835269928
2025-01-21 11:06:58,560 - trainer - INFO - ================================================================================
2025-01-21 11:06:58,560 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:06:58
2025-01-21 11:07:03,136 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:07:03
2025-01-21 11:07:03,136 - trainer - INFO -     epoch          : 32
2025-01-21 11:07:03,136 - trainer - INFO -     elapsed time   : 4.575792074203491
2025-01-21 11:07:03,136 - trainer - INFO -     loss           : 185.6061584472656
2025-01-21 11:07:03,136 - trainer - INFO -     sim_loss       : 32.09314727783203
2025-01-21 11:07:03,136 - trainer - INFO -     gen_loss       : 251.3974494934082
2025-01-21 11:07:03,136 - trainer - INFO -     val_loss       : 396.84227871894836
2025-01-21 11:07:03,136 - trainer - INFO -     val_sim_loss   : 17.165834426879883
2025-01-21 11:07:03,136 - trainer - INFO -     val_gen_loss   : 379.6764461994171
2025-01-21 11:07:03,136 - trainer - INFO -     val_perplexity : 23.615575790405273
2025-01-21 11:07:03,136 - trainer - INFO -     val_embedding_sim: 0.1305200159549713
2025-01-21 11:07:03,136 - trainer - INFO - ================================================================================
2025-01-21 11:07:03,136 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:07:03
2025-01-21 11:07:07,700 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:07:07
2025-01-21 11:07:07,701 - trainer - INFO -     epoch          : 33
2025-01-21 11:07:07,701 - trainer - INFO -     elapsed time   : 4.564084529876709
2025-01-21 11:07:07,701 - trainer - INFO -     loss           : 177.87935256958008
2025-01-21 11:07:07,701 - trainer - INFO -     sim_loss       : 31.279668617248536
2025-01-21 11:07:07,701 - trainer - INFO -     gen_loss       : 240.70779037475586
2025-01-21 11:07:07,701 - trainer - INFO -     val_loss       : 397.1735324859619
2025-01-21 11:07:07,701 - trainer - INFO -     val_sim_loss   : 19.88849639892578
2025-01-21 11:07:07,701 - trainer - INFO -     val_gen_loss   : 377.28504371643066
2025-01-21 11:07:07,701 - trainer - INFO -     val_perplexity : 22.446870803833008
2025-01-21 11:07:07,701 - trainer - INFO -     val_embedding_sim: 0.14647454023361206
2025-01-21 11:07:07,701 - trainer - INFO - ================================================================================
2025-01-21 11:07:07,701 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:07:07
2025-01-21 11:07:12,269 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:07:12
2025-01-21 11:07:12,270 - trainer - INFO -     epoch          : 34
2025-01-21 11:07:12,270 - trainer - INFO -     elapsed time   : 4.568286895751953
2025-01-21 11:07:12,270 - trainer - INFO -     loss           : 172.16134872436524
2025-01-21 11:07:12,270 - trainer - INFO -     sim_loss       : 35.688871192932126
2025-01-21 11:07:12,270 - trainer - INFO -     gen_loss       : 230.6495590209961
2025-01-21 11:07:12,270 - trainer - INFO -     val_loss       : 398.82242584228516
2025-01-21 11:07:12,270 - trainer - INFO -     val_sim_loss   : 22.559608459472656
2025-01-21 11:07:12,270 - trainer - INFO -     val_gen_loss   : 376.26282501220703
2025-01-21 11:07:12,270 - trainer - INFO -     val_perplexity : 22.672943115234375
2025-01-21 11:07:12,270 - trainer - INFO -     val_embedding_sim: 0.10685752332210541
2025-01-21 11:07:12,270 - trainer - INFO - ================================================================================
2025-01-21 11:07:12,270 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:07:12
2025-01-21 11:07:16,841 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:07:16
2025-01-21 11:07:16,841 - trainer - INFO -     epoch          : 35
2025-01-21 11:07:16,841 - trainer - INFO -     elapsed time   : 4.570559740066528
2025-01-21 11:07:16,841 - trainer - INFO -     loss           : 164.98186340332032
2025-01-21 11:07:16,841 - trainer - INFO -     sim_loss       : 35.72227935791015
2025-01-21 11:07:16,841 - trainer - INFO -     gen_loss       : 220.3788284301758
2025-01-21 11:07:16,841 - trainer - INFO -     val_loss       : 392.46038150787354
2025-01-21 11:07:16,841 - trainer - INFO -     val_sim_loss   : 15.513741493225098
2025-01-21 11:07:16,841 - trainer - INFO -     val_gen_loss   : 376.9466485977173
2025-01-21 11:07:16,841 - trainer - INFO -     val_perplexity : 22.735275268554688
2025-01-21 11:07:16,841 - trainer - INFO -     val_embedding_sim: 0.11791209876537323
2025-01-21 11:07:23,385 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:07:23,385 - trainer - INFO - ================================================================================
2025-01-21 11:07:23,386 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:07:23
2025-01-21 11:07:28,010 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:07:28
2025-01-21 11:07:28,010 - trainer - INFO -     epoch          : 36
2025-01-21 11:07:28,010 - trainer - INFO -     elapsed time   : 4.624375581741333
2025-01-21 11:07:28,010 - trainer - INFO -     loss           : 160.03375091552735
2025-01-21 11:07:28,010 - trainer - INFO -     sim_loss       : 36.06581039428711
2025-01-21 11:07:28,010 - trainer - INFO -     gen_loss       : 213.1628730773926
2025-01-21 11:07:28,010 - trainer - INFO -     val_loss       : 399.7429094314575
2025-01-21 11:07:28,010 - trainer - INFO -     val_sim_loss   : 23.07292938232422
2025-01-21 11:07:28,010 - trainer - INFO -     val_gen_loss   : 376.66997241973877
2025-01-21 11:07:28,011 - trainer - INFO -     val_perplexity : 23.340465545654297
2025-01-21 11:07:28,011 - trainer - INFO -     val_embedding_sim: 0.11261183023452759
2025-01-21 11:07:28,011 - trainer - INFO - ================================================================================
2025-01-21 11:07:28,011 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:07:28
2025-01-21 11:07:32,674 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:07:32
2025-01-21 11:07:32,675 - trainer - INFO -     epoch          : 37
2025-01-21 11:07:32,675 - trainer - INFO -     elapsed time   : 4.663675308227539
2025-01-21 11:07:32,675 - trainer - INFO -     loss           : 152.88824577331542
2025-01-21 11:07:32,675 - trainer - INFO -     sim_loss       : 34.17824096679688
2025-01-21 11:07:32,675 - trainer - INFO -     gen_loss       : 203.76396636962892
2025-01-21 11:07:32,675 - trainer - INFO -     val_loss       : 399.6528694629669
2025-01-21 11:07:32,675 - trainer - INFO -     val_sim_loss   : 22.959774017333984
2025-01-21 11:07:32,675 - trainer - INFO -     val_gen_loss   : 376.69309163093567
2025-01-21 11:07:32,675 - trainer - INFO -     val_perplexity : 23.43353271484375
2025-01-21 11:07:32,675 - trainer - INFO -     val_embedding_sim: 0.12836489081382751
2025-01-21 11:07:32,675 - trainer - INFO - ================================================================================
2025-01-21 11:07:32,675 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:07:32
2025-01-21 11:07:37,240 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:07:37
2025-01-21 11:07:37,240 - trainer - INFO -     epoch          : 38
2025-01-21 11:07:37,240 - trainer - INFO -     elapsed time   : 4.564334392547607
2025-01-21 11:07:37,240 - trainer - INFO -     loss           : 142.66408462524413
2025-01-21 11:07:37,240 - trainer - INFO -     sim_loss       : 29.484304869174956
2025-01-21 11:07:37,240 - trainer - INFO -     gen_loss       : 191.16970291137696
2025-01-21 11:07:37,240 - trainer - INFO -     val_loss       : 392.1994709968567
2025-01-21 11:07:37,240 - trainer - INFO -     val_sim_loss   : 14.515802383422852
2025-01-21 11:07:37,240 - trainer - INFO -     val_gen_loss   : 377.68366289138794
2025-01-21 11:07:37,240 - trainer - INFO -     val_perplexity : 23.521451950073242
2025-01-21 11:07:37,240 - trainer - INFO -     val_embedding_sim: 0.12678614258766174
2025-01-21 11:07:37,240 - trainer - INFO - ================================================================================
2025-01-21 11:07:37,240 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:07:37
2025-01-21 11:07:41,805 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:07:41
2025-01-21 11:07:41,805 - trainer - INFO -     epoch          : 39
2025-01-21 11:07:41,806 - trainer - INFO -     elapsed time   : 4.565058708190918
2025-01-21 11:07:41,806 - trainer - INFO -     loss           : 137.12266731262207
2025-01-21 11:07:41,806 - trainer - INFO -     sim_loss       : 33.069167137145996
2025-01-21 11:07:41,806 - trainer - INFO -     gen_loss       : 181.71702880859374
2025-01-21 11:07:41,806 - trainer - INFO -     val_loss       : 401.5969982147217
2025-01-21 11:07:41,806 - trainer - INFO -     val_sim_loss   : 19.5091552734375
2025-01-21 11:07:41,806 - trainer - INFO -     val_gen_loss   : 382.0878429412842
2025-01-21 11:07:41,806 - trainer - INFO -     val_perplexity : 23.13101577758789
2025-01-21 11:07:41,806 - trainer - INFO -     val_embedding_sim: 0.1344166249036789
2025-01-21 11:07:41,806 - trainer - INFO - ================================================================================
2025-01-21 11:07:41,806 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:07:41
2025-01-21 11:07:46,387 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:07:46
2025-01-21 11:07:46,387 - trainer - INFO -     epoch          : 40
2025-01-21 11:07:46,387 - trainer - INFO -     elapsed time   : 4.58116888999939
2025-01-21 11:07:46,387 - trainer - INFO -     loss           : 132.0966640472412
2025-01-21 11:07:46,387 - trainer - INFO -     sim_loss       : 33.135322380065915
2025-01-21 11:07:46,388 - trainer - INFO -     gen_loss       : 174.5086685180664
2025-01-21 11:07:46,388 - trainer - INFO -     val_loss       : 391.88061714172363
2025-01-21 11:07:46,388 - trainer - INFO -     val_sim_loss   : 16.57118034362793
2025-01-21 11:07:46,388 - trainer - INFO -     val_gen_loss   : 375.30945014953613
2025-01-21 11:07:46,388 - trainer - INFO -     val_perplexity : 21.921201705932617
2025-01-21 11:07:46,388 - trainer - INFO -     val_embedding_sim: 0.1477673202753067
2025-01-21 11:07:52,932 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:07:59,599 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:07:59,599 - trainer - INFO - ================================================================================
2025-01-21 11:07:59,599 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:07:59
2025-01-21 11:08:04,222 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:08:04
2025-01-21 11:08:04,222 - trainer - INFO -     epoch          : 41
2025-01-21 11:08:04,222 - trainer - INFO -     elapsed time   : 4.622908115386963
2025-01-21 11:08:04,222 - trainer - INFO -     loss           : 125.65115585327149
2025-01-21 11:08:04,222 - trainer - INFO -     sim_loss       : 28.30113353729248
2025-01-21 11:08:04,222 - trainer - INFO -     gen_loss       : 167.37259979248046
2025-01-21 11:08:04,222 - trainer - INFO -     val_loss       : 396.57395219802856
2025-01-21 11:08:04,222 - trainer - INFO -     val_sim_loss   : 13.655406951904297
2025-01-21 11:08:04,222 - trainer - INFO -     val_gen_loss   : 382.91855669021606
2025-01-21 11:08:04,223 - trainer - INFO -     val_perplexity : 23.848617553710938
2025-01-21 11:08:04,223 - trainer - INFO -     val_embedding_sim: 0.14294463396072388
2025-01-21 11:08:04,223 - trainer - INFO - ================================================================================
2025-01-21 11:08:04,223 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:08:04
2025-01-21 11:08:08,793 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:08:08
2025-01-21 11:08:08,793 - trainer - INFO -     epoch          : 42
2025-01-21 11:08:08,793 - trainer - INFO -     elapsed time   : 4.56999397277832
2025-01-21 11:08:08,793 - trainer - INFO -     loss           : 121.72511367797851
2025-01-21 11:08:08,793 - trainer - INFO -     sim_loss       : 31.011959409713747
2025-01-21 11:08:08,793 - trainer - INFO -     gen_loss       : 160.6021842956543
2025-01-21 11:08:08,793 - trainer - INFO -     val_loss       : 406.6568946838379
2025-01-21 11:08:08,793 - trainer - INFO -     val_sim_loss   : 25.481201171875
2025-01-21 11:08:08,793 - trainer - INFO -     val_gen_loss   : 381.1756935119629
2025-01-21 11:08:08,793 - trainer - INFO -     val_perplexity : 22.3211727142334
2025-01-21 11:08:08,793 - trainer - INFO -     val_embedding_sim: 0.1632392406463623
2025-01-21 11:08:08,793 - trainer - INFO - ================================================================================
2025-01-21 11:08:08,793 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:08:08
2025-01-21 11:10:49,041 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:10:51,357 - trainer - INFO - ================================================================================
2025-01-21 11:10:51,357 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:10:51
2025-01-21 11:10:57,127 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:10:57
2025-01-21 11:10:57,127 - trainer - INFO -     epoch          : 1
2025-01-21 11:10:57,127 - trainer - INFO -     elapsed time   : 5.769922733306885
2025-01-21 11:10:57,127 - trainer - INFO -     loss           : 926.0518676757813
2025-01-21 11:10:57,127 - trainer - INFO -     sim_loss       : 80.15060462951661
2025-01-21 11:10:57,127 - trainer - INFO -     gen_loss       : 1288.581021118164
2025-01-21 11:10:57,127 - trainer - INFO -     val_loss       : 597.9046440124512
2025-01-21 11:10:57,127 - trainer - INFO -     val_sim_loss   : 30.897905349731445
2025-01-21 11:10:57,127 - trainer - INFO -     val_gen_loss   : 567.0067558288574
2025-01-21 11:10:57,127 - trainer - INFO -     val_perplexity : 34.28976821899414
2025-01-21 11:10:57,128 - trainer - INFO -     val_embedding_sim: 0.13666823506355286
2025-01-21 11:10:57,128 - trainer - INFO - ================================================================================
2025-01-21 11:10:57,128 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:10:57
2025-01-21 11:11:01,685 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:11:01
2025-01-21 11:11:01,685 - trainer - INFO -     epoch          : 2
2025-01-21 11:11:01,685 - trainer - INFO -     elapsed time   : 4.556779861450195
2025-01-21 11:11:01,685 - trainer - INFO -     loss           : 818.138818359375
2025-01-21 11:11:01,685 - trainer - INFO -     sim_loss       : 44.15967655181885
2025-01-21 11:11:01,685 - trainer - INFO -     gen_loss       : 1149.8442016601562
2025-01-21 11:11:01,685 - trainer - INFO -     val_loss       : 568.6213397979736
2025-01-21 11:11:01,685 - trainer - INFO -     val_sim_loss   : 25.156375885009766
2025-01-21 11:11:01,685 - trainer - INFO -     val_gen_loss   : 543.4649677276611
2025-01-21 11:11:01,685 - trainer - INFO -     val_perplexity : 32.68014144897461
2025-01-21 11:11:01,685 - trainer - INFO -     val_embedding_sim: 0.12105973064899445
2025-01-21 11:11:01,685 - trainer - INFO - ================================================================================
2025-01-21 11:11:01,685 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:11:01
2025-01-21 11:11:06,248 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:11:06
2025-01-21 11:11:06,248 - trainer - INFO -     epoch          : 3
2025-01-21 11:11:06,249 - trainer - INFO -     elapsed time   : 4.563124179840088
2025-01-21 11:11:06,249 - trainer - INFO -     loss           : 769.9986541748046
2025-01-21 11:11:06,249 - trainer - INFO -     sim_loss       : 31.62845907211304
2025-01-21 11:11:06,249 - trainer - INFO -     gen_loss       : 1086.443032836914
2025-01-21 11:11:06,249 - trainer - INFO -     val_loss       : 539.9182319641113
2025-01-21 11:11:06,249 - trainer - INFO -     val_sim_loss   : 18.201953887939453
2025-01-21 11:11:06,249 - trainer - INFO -     val_gen_loss   : 521.7162666320801
2025-01-21 11:11:06,249 - trainer - INFO -     val_perplexity : 30.639976501464844
2025-01-21 11:11:06,249 - trainer - INFO -     val_embedding_sim: 0.12869185209274292
2025-01-21 11:11:06,249 - trainer - INFO - ================================================================================
2025-01-21 11:11:06,249 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:11:06
2025-01-21 11:11:10,808 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:11:10
2025-01-21 11:11:10,808 - trainer - INFO -     epoch          : 4
2025-01-21 11:11:10,808 - trainer - INFO -     elapsed time   : 4.559024810791016
2025-01-21 11:11:10,808 - trainer - INFO -     loss           : 725.4052124023438
2025-01-21 11:11:10,808 - trainer - INFO -     sim_loss       : 32.788217544555664
2025-01-21 11:11:10,808 - trainer - INFO -     gen_loss       : 1022.2411071777344
2025-01-21 11:11:10,808 - trainer - INFO -     val_loss       : 523.2192535400391
2025-01-21 11:11:10,808 - trainer - INFO -     val_sim_loss   : 23.645509719848633
2025-01-21 11:11:10,808 - trainer - INFO -     val_gen_loss   : 499.57374572753906
2025-01-21 11:11:10,809 - trainer - INFO -     val_perplexity : 29.814695358276367
2025-01-21 11:11:10,809 - trainer - INFO -     val_embedding_sim: 0.12242409586906433
2025-01-21 11:11:10,809 - trainer - INFO - ================================================================================
2025-01-21 11:11:10,809 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:11:10
2025-01-21 11:11:15,368 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:11:15
2025-01-21 11:11:15,368 - trainer - INFO -     epoch          : 5
2025-01-21 11:11:15,368 - trainer - INFO -     elapsed time   : 4.558699607849121
2025-01-21 11:11:15,368 - trainer - INFO -     loss           : 679.5910797119141
2025-01-21 11:11:15,368 - trainer - INFO -     sim_loss       : 34.43480815887451
2025-01-21 11:11:15,368 - trainer - INFO -     gen_loss       : 956.0866394042969
2025-01-21 11:11:15,368 - trainer - INFO -     val_loss       : 490.8685760498047
2025-01-21 11:11:15,368 - trainer - INFO -     val_sim_loss   : 16.582136154174805
2025-01-21 11:11:15,368 - trainer - INFO -     val_gen_loss   : 474.2864532470703
2025-01-21 11:11:15,368 - trainer - INFO -     val_perplexity : 28.886428833007812
2025-01-21 11:11:15,368 - trainer - INFO -     val_embedding_sim: 0.12403754889965057
2025-01-21 11:11:22,839 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:11:29,413 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:11:29,414 - trainer - INFO - ================================================================================
2025-01-21 11:11:29,414 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:11:29
2025-01-21 11:11:34,012 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:11:34
2025-01-21 11:11:34,012 - trainer - INFO -     epoch          : 6
2025-01-21 11:11:34,012 - trainer - INFO -     elapsed time   : 4.598479270935059
2025-01-21 11:11:34,012 - trainer - INFO -     loss           : 631.5791168212891
2025-01-21 11:11:34,012 - trainer - INFO -     sim_loss       : 34.07434663772583
2025-01-21 11:11:34,013 - trainer - INFO -     gen_loss       : 887.6526000976562
2025-01-21 11:11:34,013 - trainer - INFO -     val_loss       : 465.3702869415283
2025-01-21 11:11:34,013 - trainer - INFO -     val_sim_loss   : 12.26746940612793
2025-01-21 11:11:34,013 - trainer - INFO -     val_gen_loss   : 453.1028308868408
2025-01-21 11:11:34,013 - trainer - INFO -     val_perplexity : 27.35556983947754
2025-01-21 11:11:34,013 - trainer - INFO -     val_embedding_sim: 0.14163225889205933
2025-01-21 11:11:34,013 - trainer - INFO - ================================================================================
2025-01-21 11:11:34,013 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:11:34
2025-01-21 11:11:38,583 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:11:38
2025-01-21 11:11:38,584 - trainer - INFO -     epoch          : 7
2025-01-21 11:11:38,584 - trainer - INFO -     elapsed time   : 4.570445537567139
2025-01-21 11:11:38,584 - trainer - INFO -     loss           : 589.1755661010742
2025-01-21 11:11:38,584 - trainer - INFO -     sim_loss       : 31.072006034851075
2025-01-21 11:11:38,584 - trainer - INFO -     gen_loss       : 828.3628082275391
2025-01-21 11:11:38,584 - trainer - INFO -     val_loss       : 450.8003463745117
2025-01-21 11:11:38,584 - trainer - INFO -     val_sim_loss   : 14.321913719177246
2025-01-21 11:11:38,584 - trainer - INFO -     val_gen_loss   : 436.4784469604492
2025-01-21 11:11:38,584 - trainer - INFO -     val_perplexity : 26.324954986572266
2025-01-21 11:11:38,584 - trainer - INFO -     val_embedding_sim: 0.125660240650177
2025-01-21 11:11:38,584 - trainer - INFO - ================================================================================
2025-01-21 11:11:38,584 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:11:38
2025-01-21 11:11:43,143 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:11:43
2025-01-21 11:11:43,143 - trainer - INFO -     epoch          : 8
2025-01-21 11:11:43,143 - trainer - INFO -     elapsed time   : 4.558593511581421
2025-01-21 11:11:43,143 - trainer - INFO -     loss           : 554.0099960327149
2025-01-21 11:11:43,143 - trainer - INFO -     sim_loss       : 29.116068983078
2025-01-21 11:11:43,143 - trainer - INFO -     gen_loss       : 778.9645477294922
2025-01-21 11:11:43,143 - trainer - INFO -     val_loss       : 442.2682161331177
2025-01-21 11:11:43,143 - trainer - INFO -     val_sim_loss   : 16.102643966674805
2025-01-21 11:11:43,143 - trainer - INFO -     val_gen_loss   : 426.1655855178833
2025-01-21 11:11:43,143 - trainer - INFO -     val_perplexity : 26.222999572753906
2025-01-21 11:11:43,143 - trainer - INFO -     val_embedding_sim: 0.14288844168186188
2025-01-21 11:11:43,143 - trainer - INFO - ================================================================================
2025-01-21 11:11:43,143 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:11:43
2025-01-21 11:11:47,716 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:11:47
2025-01-21 11:11:47,716 - trainer - INFO -     epoch          : 9
2025-01-21 11:11:47,717 - trainer - INFO -     elapsed time   : 4.572819948196411
2025-01-21 11:11:47,717 - trainer - INFO -     loss           : 522.4518264770508
2025-01-21 11:11:47,717 - trainer - INFO -     sim_loss       : 33.35802459716797
2025-01-21 11:11:47,717 - trainer - INFO -     gen_loss       : 732.0634735107421
2025-01-21 11:11:47,717 - trainer - INFO -     val_loss       : 430.36391735076904
2025-01-21 11:11:47,717 - trainer - INFO -     val_sim_loss   : 13.264713287353516
2025-01-21 11:11:47,717 - trainer - INFO -     val_gen_loss   : 417.0992078781128
2025-01-21 11:11:47,717 - trainer - INFO -     val_perplexity : 25.366470336914062
2025-01-21 11:11:47,717 - trainer - INFO -     val_embedding_sim: 0.10869182646274567
2025-01-21 11:11:47,717 - trainer - INFO - ================================================================================
2025-01-21 11:11:47,717 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:11:47
2025-01-21 11:11:52,304 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:11:52
2025-01-21 11:11:52,304 - trainer - INFO -     epoch          : 10
2025-01-21 11:11:52,304 - trainer - INFO -     elapsed time   : 4.587069988250732
2025-01-21 11:11:52,304 - trainer - INFO -     loss           : 490.16400756835935
2025-01-21 11:11:52,304 - trainer - INFO -     sim_loss       : 27.644661140441894
2025-01-21 11:11:52,304 - trainer - INFO -     gen_loss       : 688.3865966796875
2025-01-21 11:11:52,304 - trainer - INFO -     val_loss       : 424.83731842041016
2025-01-21 11:11:52,304 - trainer - INFO -     val_sim_loss   : 17.34536361694336
2025-01-21 11:11:52,305 - trainer - INFO -     val_gen_loss   : 407.49195098876953
2025-01-21 11:11:52,305 - trainer - INFO -     val_perplexity : 23.99220085144043
2025-01-21 11:11:52,305 - trainer - INFO -     val_embedding_sim: 0.0920289009809494
2025-01-21 11:11:58,896 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:12:05,470 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:12:05,471 - trainer - INFO - ================================================================================
2025-01-21 11:12:05,471 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:12:05
2025-01-21 11:12:10,108 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:12:10
2025-01-21 11:12:10,108 - trainer - INFO -     epoch          : 11
2025-01-21 11:12:10,108 - trainer - INFO -     elapsed time   : 4.6370322704315186
2025-01-21 11:12:10,108 - trainer - INFO -     loss           : 463.3146041870117
2025-01-21 11:12:10,108 - trainer - INFO -     sim_loss       : 30.59953498840332
2025-01-21 11:12:10,108 - trainer - INFO -     gen_loss       : 648.7639343261719
2025-01-21 11:12:10,108 - trainer - INFO -     val_loss       : 418.480845451355
2025-01-21 11:12:10,108 - trainer - INFO -     val_sim_loss   : 11.31159782409668
2025-01-21 11:12:10,108 - trainer - INFO -     val_gen_loss   : 407.16926097869873
2025-01-21 11:12:10,109 - trainer - INFO -     val_perplexity : 24.4727840423584
2025-01-21 11:12:10,109 - trainer - INFO -     val_embedding_sim: 0.10701514035463333
2025-01-21 11:12:10,109 - trainer - INFO - ================================================================================
2025-01-21 11:12:10,109 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:12:10
2025-01-21 11:12:14,687 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:12:14
2025-01-21 11:12:14,687 - trainer - INFO -     epoch          : 12
2025-01-21 11:12:14,687 - trainer - INFO -     elapsed time   : 4.577651262283325
2025-01-21 11:12:14,687 - trainer - INFO -     loss           : 440.5827133178711
2025-01-21 11:12:14,687 - trainer - INFO -     sim_loss       : 33.56797342300415
2025-01-21 11:12:14,687 - trainer - INFO -     gen_loss       : 615.0176086425781
2025-01-21 11:12:14,687 - trainer - INFO -     val_loss       : 409.22182178497314
2025-01-21 11:12:14,687 - trainer - INFO -     val_sim_loss   : 12.84035873413086
2025-01-21 11:12:14,687 - trainer - INFO -     val_gen_loss   : 396.381459236145
2025-01-21 11:12:14,687 - trainer - INFO -     val_perplexity : 23.77855682373047
2025-01-21 11:12:14,687 - trainer - INFO -     val_embedding_sim: 0.13282810151576996
2025-01-21 11:12:14,687 - trainer - INFO - ================================================================================
2025-01-21 11:12:14,687 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:12:14
2025-01-21 11:12:19,246 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:12:19
2025-01-21 11:12:19,246 - trainer - INFO -     epoch          : 13
2025-01-21 11:12:19,246 - trainer - INFO -     elapsed time   : 4.558616876602173
2025-01-21 11:12:19,246 - trainer - INFO -     loss           : 417.52635650634767
2025-01-21 11:12:19,246 - trainer - INFO -     sim_loss       : 28.900172328948976
2025-01-21 11:12:19,246 - trainer - INFO -     gen_loss       : 584.0804397583008
2025-01-21 11:12:19,246 - trainer - INFO -     val_loss       : 416.8297452926636
2025-01-21 11:12:19,246 - trainer - INFO -     val_sim_loss   : 20.79948616027832
2025-01-21 11:12:19,246 - trainer - INFO -     val_gen_loss   : 396.0302457809448
2025-01-21 11:12:19,246 - trainer - INFO -     val_perplexity : 23.89650535583496
2025-01-21 11:12:19,246 - trainer - INFO -     val_embedding_sim: 0.119126096367836
2025-01-21 11:12:19,246 - trainer - INFO - ================================================================================
2025-01-21 11:12:19,246 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:12:19
2025-01-21 11:12:23,805 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:12:23
2025-01-21 11:12:23,805 - trainer - INFO -     epoch          : 14
2025-01-21 11:12:23,805 - trainer - INFO -     elapsed time   : 4.558057069778442
2025-01-21 11:12:23,805 - trainer - INFO -     loss           : 399.51070404052734
2025-01-21 11:12:23,805 - trainer - INFO -     sim_loss       : 32.1328628540039
2025-01-21 11:12:23,805 - trainer - INFO -     gen_loss       : 556.9583557128906
2025-01-21 11:12:23,805 - trainer - INFO -     val_loss       : 404.58380031585693
2025-01-21 11:12:23,805 - trainer - INFO -     val_sim_loss   : 14.572610855102539
2025-01-21 11:12:23,805 - trainer - INFO -     val_gen_loss   : 390.01119899749756
2025-01-21 11:12:23,805 - trainer - INFO -     val_perplexity : 24.117431640625
2025-01-21 11:12:23,805 - trainer - INFO -     val_embedding_sim: 0.12609568238258362
2025-01-21 11:12:23,805 - trainer - INFO - ================================================================================
2025-01-21 11:12:23,805 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:12:23
2025-01-21 11:12:28,396 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:12:28
2025-01-21 11:12:28,396 - trainer - INFO -     epoch          : 15
2025-01-21 11:12:28,396 - trainer - INFO -     elapsed time   : 4.590826511383057
2025-01-21 11:12:28,397 - trainer - INFO -     loss           : 379.20598754882815
2025-01-21 11:12:28,397 - trainer - INFO -     sim_loss       : 27.439306449890136
2025-01-21 11:12:28,397 - trainer - INFO -     gen_loss       : 529.9631469726562
2025-01-21 11:12:28,397 - trainer - INFO -     val_loss       : 404.70003604888916
2025-01-21 11:12:28,397 - trainer - INFO -     val_sim_loss   : 17.96949005126953
2025-01-21 11:12:28,397 - trainer - INFO -     val_gen_loss   : 386.73055362701416
2025-01-21 11:12:28,397 - trainer - INFO -     val_perplexity : 23.550884246826172
2025-01-21 11:12:28,397 - trainer - INFO -     val_embedding_sim: 0.09444363415241241
2025-01-21 11:12:35,008 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:12:41,596 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:12:41,596 - trainer - INFO - ================================================================================
2025-01-21 11:12:41,596 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:12:41
2025-01-21 11:12:46,219 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:12:46
2025-01-21 11:12:46,219 - trainer - INFO -     epoch          : 16
2025-01-21 11:12:46,219 - trainer - INFO -     elapsed time   : 4.622684001922607
2025-01-21 11:12:46,219 - trainer - INFO -     loss           : 363.85071868896483
2025-01-21 11:12:46,219 - trainer - INFO -     sim_loss       : 29.843349075317384
2025-01-21 11:12:46,219 - trainer - INFO -     gen_loss       : 506.9967346191406
2025-01-21 11:12:46,219 - trainer - INFO -     val_loss       : 402.61656618118286
2025-01-21 11:12:46,219 - trainer - INFO -     val_sim_loss   : 18.385377883911133
2025-01-21 11:12:46,219 - trainer - INFO -     val_gen_loss   : 384.23119020462036
2025-01-21 11:12:46,219 - trainer - INFO -     val_perplexity : 23.620330810546875
2025-01-21 11:12:46,219 - trainer - INFO -     val_embedding_sim: 0.11372670531272888
2025-01-21 11:12:46,219 - trainer - INFO - ================================================================================
2025-01-21 11:12:46,219 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:12:46
2025-01-21 11:12:50,836 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:12:50
2025-01-21 11:12:50,836 - trainer - INFO -     epoch          : 17
2025-01-21 11:12:50,836 - trainer - INFO -     elapsed time   : 4.616598606109619
2025-01-21 11:12:50,836 - trainer - INFO -     loss           : 349.4650512695313
2025-01-21 11:12:50,836 - trainer - INFO -     sim_loss       : 35.022897481918335
2025-01-21 11:12:50,836 - trainer - INFO -     gen_loss       : 484.2259780883789
2025-01-21 11:12:50,837 - trainer - INFO -     val_loss       : 398.7251491546631
2025-01-21 11:12:50,837 - trainer - INFO -     val_sim_loss   : 15.306532859802246
2025-01-21 11:12:50,837 - trainer - INFO -     val_gen_loss   : 383.4186305999756
2025-01-21 11:12:50,837 - trainer - INFO -     val_perplexity : 22.437435150146484
2025-01-21 11:12:50,837 - trainer - INFO -     val_embedding_sim: 0.09559085965156555
2025-01-21 11:12:50,837 - trainer - INFO - ================================================================================
2025-01-21 11:12:50,837 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:12:50
2025-01-21 11:12:55,425 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:12:55
2025-01-21 11:12:55,426 - trainer - INFO -     epoch          : 18
2025-01-21 11:12:55,426 - trainer - INFO -     elapsed time   : 4.588460683822632
2025-01-21 11:12:55,426 - trainer - INFO -     loss           : 333.12967987060546
2025-01-21 11:12:55,426 - trainer - INFO -     sim_loss       : 30.36341276168823
2025-01-21 11:12:55,426 - trainer - INFO -     gen_loss       : 462.88665771484375
2025-01-21 11:12:55,426 - trainer - INFO -     val_loss       : 402.95659041404724
2025-01-21 11:12:55,426 - trainer - INFO -     val_sim_loss   : 19.028987884521484
2025-01-21 11:12:55,426 - trainer - INFO -     val_gen_loss   : 383.9275987148285
2025-01-21 11:12:55,426 - trainer - INFO -     val_perplexity : 23.852079391479492
2025-01-21 11:12:55,426 - trainer - INFO -     val_embedding_sim: 0.1106276884675026
2025-01-21 11:12:55,426 - trainer - INFO - ================================================================================
2025-01-21 11:12:55,426 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:12:55
2025-01-21 11:13:00,000 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:12:59
2025-01-21 11:13:00,000 - trainer - INFO -     epoch          : 19
2025-01-21 11:13:00,000 - trainer - INFO -     elapsed time   : 4.573617219924927
2025-01-21 11:13:00,000 - trainer - INFO -     loss           : 319.1216094970703
2025-01-21 11:13:00,000 - trainer - INFO -     sim_loss       : 26.764625072479248
2025-01-21 11:13:00,000 - trainer - INFO -     gen_loss       : 444.41746673583987
2025-01-21 11:13:00,000 - trainer - INFO -     val_loss       : 399.3265686035156
2025-01-21 11:13:00,000 - trainer - INFO -     val_sim_loss   : 16.95846176147461
2025-01-21 11:13:00,000 - trainer - INFO -     val_gen_loss   : 382.36810302734375
2025-01-21 11:13:00,000 - trainer - INFO -     val_perplexity : 21.784212112426758
2025-01-21 11:13:00,000 - trainer - INFO -     val_embedding_sim: 0.1155744194984436
2025-01-21 11:13:00,000 - trainer - INFO - ================================================================================
2025-01-21 11:13:00,000 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:12:59
2025-01-21 11:13:04,611 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:13:04
2025-01-21 11:13:04,611 - trainer - INFO -     epoch          : 20
2025-01-21 11:13:04,611 - trainer - INFO -     elapsed time   : 4.610732555389404
2025-01-21 11:13:04,611 - trainer - INFO -     loss           : 304.28799591064455
2025-01-21 11:13:04,612 - trainer - INFO -     sim_loss       : 26.882752561569212
2025-01-21 11:13:04,612 - trainer - INFO -     gen_loss       : 423.17596740722655
2025-01-21 11:13:04,612 - trainer - INFO -     val_loss       : 396.1400799751282
2025-01-21 11:13:04,612 - trainer - INFO -     val_sim_loss   : 13.122339248657227
2025-01-21 11:13:04,612 - trainer - INFO -     val_gen_loss   : 383.01773500442505
2025-01-21 11:13:04,612 - trainer - INFO -     val_perplexity : 23.735416412353516
2025-01-21 11:13:04,612 - trainer - INFO -     val_embedding_sim: 0.12525571882724762
2025-01-21 11:13:11,210 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:13:11,210 - trainer - INFO - ================================================================================
2025-01-21 11:13:11,210 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:13:11
2025-01-21 11:13:15,858 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:13:15
2025-01-21 11:13:15,858 - trainer - INFO -     epoch          : 21
2025-01-21 11:13:15,858 - trainer - INFO -     elapsed time   : 4.64765191078186
2025-01-21 11:13:15,858 - trainer - INFO -     loss           : 290.88708267211916
2025-01-21 11:13:15,858 - trainer - INFO -     sim_loss       : 26.345297813415527
2025-01-21 11:13:15,858 - trainer - INFO -     gen_loss       : 404.2621444702148
2025-01-21 11:13:15,858 - trainer - INFO -     val_loss       : 404.9458999633789
2025-01-21 11:13:15,858 - trainer - INFO -     val_sim_loss   : 20.545747756958008
2025-01-21 11:13:15,858 - trainer - INFO -     val_gen_loss   : 384.40015411376953
2025-01-21 11:13:15,858 - trainer - INFO -     val_perplexity : 22.58405876159668
2025-01-21 11:13:15,858 - trainer - INFO -     val_embedding_sim: 0.12570777535438538
2025-01-21 11:13:15,858 - trainer - INFO - ================================================================================
2025-01-21 11:13:15,858 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:13:15
2025-01-21 11:13:20,432 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:13:20
2025-01-21 11:13:20,432 - trainer - INFO -     epoch          : 22
2025-01-21 11:13:20,432 - trainer - INFO -     elapsed time   : 4.573112487792969
2025-01-21 11:13:20,432 - trainer - INFO -     loss           : 282.0966735839844
2025-01-21 11:13:20,432 - trainer - INFO -     sim_loss       : 31.92654094696045
2025-01-21 11:13:20,432 - trainer - INFO -     gen_loss       : 389.3124572753906
2025-01-21 11:13:20,432 - trainer - INFO -     val_loss       : 397.00964546203613
2025-01-21 11:13:20,432 - trainer - INFO -     val_sim_loss   : 19.007495880126953
2025-01-21 11:13:20,432 - trainer - INFO -     val_gen_loss   : 378.0021381378174
2025-01-21 11:13:20,432 - trainer - INFO -     val_perplexity : 22.10340118408203
2025-01-21 11:13:20,432 - trainer - INFO -     val_embedding_sim: 0.12426705658435822
2025-01-21 11:13:20,432 - trainer - INFO - ================================================================================
2025-01-21 11:13:20,432 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:13:20
2025-01-21 11:13:24,993 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:13:24
2025-01-21 11:13:24,993 - trainer - INFO -     epoch          : 23
2025-01-21 11:13:24,994 - trainer - INFO -     elapsed time   : 4.561020135879517
2025-01-21 11:13:24,994 - trainer - INFO -     loss           : 269.63953857421876
2025-01-21 11:13:24,994 - trainer - INFO -     sim_loss       : 26.177098178863524
2025-01-21 11:13:24,994 - trainer - INFO -     gen_loss       : 373.9805908203125
2025-01-21 11:13:24,994 - trainer - INFO -     val_loss       : 393.6212100982666
2025-01-21 11:13:24,994 - trainer - INFO -     val_sim_loss   : 13.56025218963623
2025-01-21 11:13:24,994 - trainer - INFO -     val_gen_loss   : 380.06096839904785
2025-01-21 11:13:24,994 - trainer - INFO -     val_perplexity : 23.169965744018555
2025-01-21 11:13:24,994 - trainer - INFO -     val_embedding_sim: 0.13340717554092407
2025-01-21 11:13:24,994 - trainer - INFO - ================================================================================
2025-01-21 11:13:24,994 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:13:24
2025-01-21 11:13:29,552 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:13:29
2025-01-21 11:13:29,552 - trainer - INFO -     epoch          : 24
2025-01-21 11:13:29,552 - trainer - INFO -     elapsed time   : 4.5580055713653564
2025-01-21 11:13:29,552 - trainer - INFO -     loss           : 260.23777160644534
2025-01-21 11:13:29,552 - trainer - INFO -     sim_loss       : 29.470584630966187
2025-01-21 11:13:29,552 - trainer - INFO -     gen_loss       : 359.138005065918
2025-01-21 11:13:29,552 - trainer - INFO -     val_loss       : 395.44878005981445
2025-01-21 11:13:29,552 - trainer - INFO -     val_sim_loss   : 13.713739395141602
2025-01-21 11:13:29,552 - trainer - INFO -     val_gen_loss   : 381.73503494262695
2025-01-21 11:13:29,552 - trainer - INFO -     val_perplexity : 22.305845260620117
2025-01-21 11:13:29,553 - trainer - INFO -     val_embedding_sim: 0.13657024502754211
2025-01-21 11:13:29,553 - trainer - INFO - ================================================================================
2025-01-21 11:13:29,553 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:13:29
2025-01-21 11:13:34,109 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:13:34
2025-01-21 11:13:34,109 - trainer - INFO -     epoch          : 25
2025-01-21 11:13:34,109 - trainer - INFO -     elapsed time   : 4.555946111679077
2025-01-21 11:13:34,109 - trainer - INFO -     loss           : 250.63036575317383
2025-01-21 11:13:34,109 - trainer - INFO -     sim_loss       : 33.2254695892334
2025-01-21 11:13:34,109 - trainer - INFO -     gen_loss       : 343.8039016723633
2025-01-21 11:13:34,109 - trainer - INFO -     val_loss       : 399.9349250793457
2025-01-21 11:13:34,109 - trainer - INFO -     val_sim_loss   : 20.086755752563477
2025-01-21 11:13:34,109 - trainer - INFO -     val_gen_loss   : 379.8481636047363
2025-01-21 11:13:34,109 - trainer - INFO -     val_perplexity : 22.888904571533203
2025-01-21 11:13:34,109 - trainer - INFO -     val_embedding_sim: 0.1259290874004364
2025-01-21 11:13:40,707 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:13:40,707 - trainer - INFO - ================================================================================
2025-01-21 11:13:40,707 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:13:40
2025-01-21 11:13:45,326 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:13:45
2025-01-21 11:13:45,326 - trainer - INFO -     epoch          : 26
2025-01-21 11:13:45,326 - trainer - INFO -     elapsed time   : 4.618361711502075
2025-01-21 11:13:45,326 - trainer - INFO -     loss           : 241.240877532959
2025-01-21 11:13:45,326 - trainer - INFO -     sim_loss       : 31.417033195495605
2025-01-21 11:13:45,326 - trainer - INFO -     gen_loss       : 331.1653793334961
2025-01-21 11:13:45,326 - trainer - INFO -     val_loss       : 396.8886260986328
2025-01-21 11:13:45,326 - trainer - INFO -     val_sim_loss   : 16.99313735961914
2025-01-21 11:13:45,326 - trainer - INFO -     val_gen_loss   : 379.89549255371094
2025-01-21 11:13:45,326 - trainer - INFO -     val_perplexity : 23.603532791137695
2025-01-21 11:13:45,326 - trainer - INFO -     val_embedding_sim: 0.10897404700517654
2025-01-21 11:13:45,326 - trainer - INFO - ================================================================================
2025-01-21 11:13:45,326 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:13:45
2025-01-21 11:13:49,891 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:13:49
2025-01-21 11:13:49,891 - trainer - INFO -     epoch          : 27
2025-01-21 11:13:49,891 - trainer - INFO -     elapsed time   : 4.564455986022949
2025-01-21 11:13:49,891 - trainer - INFO -     loss           : 230.89159545898437
2025-01-21 11:13:49,891 - trainer - INFO -     sim_loss       : 30.764977788925172
2025-01-21 11:13:49,891 - trainer - INFO -     gen_loss       : 316.66014404296874
2025-01-21 11:13:49,891 - trainer - INFO -     val_loss       : 399.89412665367126
2025-01-21 11:13:49,891 - trainer - INFO -     val_sim_loss   : 18.296344757080078
2025-01-21 11:13:49,891 - trainer - INFO -     val_gen_loss   : 381.5977704524994
2025-01-21 11:13:49,891 - trainer - INFO -     val_perplexity : 23.667680740356445
2025-01-21 11:13:49,892 - trainer - INFO -     val_embedding_sim: 0.12040188163518906
2025-01-21 11:13:49,892 - trainer - INFO - ================================================================================
2025-01-21 11:13:49,892 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:13:49
2025-01-21 11:13:54,454 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:13:54
2025-01-21 11:13:54,454 - trainer - INFO -     epoch          : 28
2025-01-21 11:13:54,454 - trainer - INFO -     elapsed time   : 4.562309503555298
2025-01-21 11:13:54,454 - trainer - INFO -     loss           : 222.8546127319336
2025-01-21 11:13:54,454 - trainer - INFO -     sim_loss       : 33.23492383956909
2025-01-21 11:13:54,454 - trainer - INFO -     gen_loss       : 304.12020416259764
2025-01-21 11:13:54,454 - trainer - INFO -     val_loss       : 391.73510789871216
2025-01-21 11:13:54,454 - trainer - INFO -     val_sim_loss   : 15.501502990722656
2025-01-21 11:13:54,454 - trainer - INFO -     val_gen_loss   : 376.23361253738403
2025-01-21 11:13:54,455 - trainer - INFO -     val_perplexity : 23.231229782104492
2025-01-21 11:13:54,455 - trainer - INFO -     val_embedding_sim: 0.12449227273464203
2025-01-21 11:13:54,455 - trainer - INFO - ================================================================================
2025-01-21 11:13:54,455 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:13:54
2025-01-21 11:13:59,018 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:13:59
2025-01-21 11:13:59,018 - trainer - INFO -     epoch          : 29
2025-01-21 11:13:59,018 - trainer - INFO -     elapsed time   : 4.562906742095947
2025-01-21 11:13:59,018 - trainer - INFO -     loss           : 213.8287139892578
2025-01-21 11:13:59,018 - trainer - INFO -     sim_loss       : 29.46741352081299
2025-01-21 11:13:59,018 - trainer - INFO -     gen_loss       : 292.8407012939453
2025-01-21 11:13:59,018 - trainer - INFO -     val_loss       : 397.1207696199417
2025-01-21 11:13:59,018 - trainer - INFO -     val_sim_loss   : 21.591894149780273
2025-01-21 11:13:59,018 - trainer - INFO -     val_gen_loss   : 375.52888119220734
2025-01-21 11:13:59,018 - trainer - INFO -     val_perplexity : 23.353351593017578
2025-01-21 11:13:59,018 - trainer - INFO -     val_embedding_sim: 0.1492529809474945
2025-01-21 11:13:59,018 - trainer - INFO - ================================================================================
2025-01-21 11:13:59,018 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:13:59
2025-01-21 11:14:03,583 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:14:03
2025-01-21 11:14:03,583 - trainer - INFO -     epoch          : 30
2025-01-21 11:14:03,583 - trainer - INFO -     elapsed time   : 4.564481258392334
2025-01-21 11:14:03,583 - trainer - INFO -     loss           : 206.67319030761718
2025-01-21 11:14:03,583 - trainer - INFO -     sim_loss       : 36.619928169250485
2025-01-21 11:14:03,583 - trainer - INFO -     gen_loss       : 279.55316772460935
2025-01-21 11:14:03,583 - trainer - INFO -     val_loss       : 402.1353015899658
2025-01-21 11:14:03,583 - trainer - INFO -     val_sim_loss   : 25.790145874023438
2025-01-21 11:14:03,583 - trainer - INFO -     val_gen_loss   : 376.34517097473145
2025-01-21 11:14:03,583 - trainer - INFO -     val_perplexity : 22.717466354370117
2025-01-21 11:14:03,583 - trainer - INFO -     val_embedding_sim: 0.13846993446350098
2025-01-21 11:14:10,189 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:14:10,190 - trainer - INFO - ================================================================================
2025-01-21 11:14:10,190 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:14:10
2025-01-21 11:14:14,804 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:14:14
2025-01-21 11:14:14,804 - trainer - INFO -     epoch          : 31
2025-01-21 11:14:14,804 - trainer - INFO -     elapsed time   : 4.613956689834595
2025-01-21 11:14:14,804 - trainer - INFO -     loss           : 194.52911758422852
2025-01-21 11:14:14,804 - trainer - INFO -     sim_loss       : 29.904891538619996
2025-01-21 11:14:14,804 - trainer - INFO -     gen_loss       : 265.0823600769043
2025-01-21 11:14:14,804 - trainer - INFO -     val_loss       : 396.39954662323
2025-01-21 11:14:14,804 - trainer - INFO -     val_sim_loss   : 17.623252868652344
2025-01-21 11:14:14,804 - trainer - INFO -     val_gen_loss   : 378.7762861251831
2025-01-21 11:14:14,805 - trainer - INFO -     val_perplexity : 23.107919692993164
2025-01-21 11:14:14,805 - trainer - INFO -     val_embedding_sim: 0.17073889076709747
2025-01-21 11:14:14,805 - trainer - INFO - ================================================================================
2025-01-21 11:14:14,805 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:14:14
2025-01-21 11:14:19,369 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:14:19
2025-01-21 11:14:19,370 - trainer - INFO -     epoch          : 32
2025-01-21 11:14:19,370 - trainer - INFO -     elapsed time   : 4.56469464302063
2025-01-21 11:14:19,370 - trainer - INFO -     loss           : 189.03326568603515
2025-01-21 11:14:19,370 - trainer - INFO -     sim_loss       : 31.68226718902588
2025-01-21 11:14:19,370 - trainer - INFO -     gen_loss       : 256.469416809082
2025-01-21 11:14:19,370 - trainer - INFO -     val_loss       : 403.6430250406265
2025-01-21 11:14:19,370 - trainer - INFO -     val_sim_loss   : 21.165815353393555
2025-01-21 11:14:19,370 - trainer - INFO -     val_gen_loss   : 382.4772230386734
2025-01-21 11:14:19,370 - trainer - INFO -     val_perplexity : 23.788434982299805
2025-01-21 11:14:19,370 - trainer - INFO -     val_embedding_sim: 0.1371602863073349
2025-01-21 11:14:19,370 - trainer - INFO - ================================================================================
2025-01-21 11:14:19,370 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:14:19
2025-01-21 11:14:23,934 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:14:23
2025-01-21 11:14:23,934 - trainer - INFO -     epoch          : 33
2025-01-21 11:14:23,934 - trainer - INFO -     elapsed time   : 4.5640482902526855
2025-01-21 11:14:23,934 - trainer - INFO -     loss           : 177.63856506347656
2025-01-21 11:14:23,935 - trainer - INFO -     sim_loss       : 27.81475439071655
2025-01-21 11:14:23,935 - trainer - INFO -     gen_loss       : 241.84877166748046
2025-01-21 11:14:23,935 - trainer - INFO -     val_loss       : 391.63689613342285
2025-01-21 11:14:23,935 - trainer - INFO -     val_sim_loss   : 13.929226875305176
2025-01-21 11:14:23,935 - trainer - INFO -     val_gen_loss   : 377.7076663970947
2025-01-21 11:14:23,935 - trainer - INFO -     val_perplexity : 22.54424476623535
2025-01-21 11:14:23,935 - trainer - INFO -     val_embedding_sim: 0.11543358117341995
2025-01-21 11:14:23,935 - trainer - INFO - ================================================================================
2025-01-21 11:14:23,935 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:14:23
2025-01-21 11:14:28,503 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:14:28
2025-01-21 11:14:28,503 - trainer - INFO -     epoch          : 34
2025-01-21 11:14:28,503 - trainer - INFO -     elapsed time   : 4.567615985870361
2025-01-21 11:14:28,503 - trainer - INFO -     loss           : 173.56130828857422
2025-01-21 11:14:28,503 - trainer - INFO -     sim_loss       : 33.98968234062195
2025-01-21 11:14:28,503 - trainer - INFO -     gen_loss       : 233.3777229309082
2025-01-21 11:14:28,503 - trainer - INFO -     val_loss       : 401.06562328338623
2025-01-21 11:14:28,503 - trainer - INFO -     val_sim_loss   : 27.426424026489258
2025-01-21 11:14:28,503 - trainer - INFO -     val_gen_loss   : 373.6392011642456
2025-01-21 11:14:28,503 - trainer - INFO -     val_perplexity : 22.516321182250977
2025-01-21 11:14:28,503 - trainer - INFO -     val_embedding_sim: 0.12199679762125015
2025-01-21 11:14:28,503 - trainer - INFO - ================================================================================
2025-01-21 11:14:28,503 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:14:28
2025-01-21 11:14:33,066 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:14:33
2025-01-21 11:14:33,067 - trainer - INFO -     epoch          : 35
2025-01-21 11:14:33,067 - trainer - INFO -     elapsed time   : 4.562997579574585
2025-01-21 11:14:33,067 - trainer - INFO -     loss           : 163.6370948791504
2025-01-21 11:14:33,067 - trainer - INFO -     sim_loss       : 27.893446063995363
2025-01-21 11:14:33,067 - trainer - INFO -     gen_loss       : 221.8129455566406
2025-01-21 11:14:33,067 - trainer - INFO -     val_loss       : 395.5744094848633
2025-01-21 11:14:33,067 - trainer - INFO -     val_sim_loss   : 21.004871368408203
2025-01-21 11:14:33,067 - trainer - INFO -     val_gen_loss   : 374.5695266723633
2025-01-21 11:14:33,067 - trainer - INFO -     val_perplexity : 22.5820255279541
2025-01-21 11:14:33,067 - trainer - INFO -     val_embedding_sim: 0.1348343938589096
2025-01-21 11:14:39,683 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:14:39,683 - trainer - INFO - ================================================================================
2025-01-21 11:14:39,684 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:14:39
2025-01-21 11:14:44,303 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:14:44
2025-01-21 11:14:44,303 - trainer - INFO -     epoch          : 36
2025-01-21 11:14:44,303 - trainer - INFO -     elapsed time   : 4.618896484375
2025-01-21 11:14:44,303 - trainer - INFO -     loss           : 160.2550277709961
2025-01-21 11:14:44,303 - trainer - INFO -     sim_loss       : 33.60226168632507
2025-01-21 11:14:44,303 - trainer - INFO -     gen_loss       : 214.5347915649414
2025-01-21 11:14:44,303 - trainer - INFO -     val_loss       : 386.07683539390564
2025-01-21 11:14:44,303 - trainer - INFO -     val_sim_loss   : 13.428598403930664
2025-01-21 11:14:44,303 - trainer - INFO -     val_gen_loss   : 372.64824652671814
2025-01-21 11:14:44,303 - trainer - INFO -     val_perplexity : 23.08075714111328
2025-01-21 11:14:44,303 - trainer - INFO -     val_embedding_sim: 0.11242779344320297
2025-01-21 11:14:44,303 - trainer - INFO - ================================================================================
2025-01-21 11:14:44,303 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:14:44
2025-01-21 11:14:48,870 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:14:48
2025-01-21 11:14:48,870 - trainer - INFO -     epoch          : 37
2025-01-21 11:14:48,870 - trainer - INFO -     elapsed time   : 4.566609859466553
2025-01-21 11:14:48,870 - trainer - INFO -     loss           : 148.95243492126465
2025-01-21 11:14:48,870 - trainer - INFO -     sim_loss       : 25.449046206474303
2025-01-21 11:14:48,870 - trainer - INFO -     gen_loss       : 201.88246002197266
2025-01-21 11:14:48,870 - trainer - INFO -     val_loss       : 392.71287536621094
2025-01-21 11:14:48,870 - trainer - INFO -     val_sim_loss   : 20.097923278808594
2025-01-21 11:14:48,870 - trainer - INFO -     val_gen_loss   : 372.6149444580078
2025-01-21 11:14:48,870 - trainer - INFO -     val_perplexity : 23.152469635009766
2025-01-21 11:14:48,870 - trainer - INFO -     val_embedding_sim: 0.1461917757987976
2025-01-21 11:14:48,871 - trainer - INFO - ================================================================================
2025-01-21 11:14:48,871 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:14:48
2025-01-21 11:14:53,430 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:14:53
2025-01-21 11:14:53,430 - trainer - INFO -     epoch          : 38
2025-01-21 11:14:53,430 - trainer - INFO -     elapsed time   : 4.559458017349243
2025-01-21 11:14:53,430 - trainer - INFO -     loss           : 146.4779281616211
2025-01-21 11:14:53,430 - trainer - INFO -     sim_loss       : 31.697963523864747
2025-01-21 11:14:53,430 - trainer - INFO -     gen_loss       : 195.6693473815918
2025-01-21 11:14:53,430 - trainer - INFO -     val_loss       : 389.6636233329773
2025-01-21 11:14:53,431 - trainer - INFO -     val_sim_loss   : 13.5949125289917
2025-01-21 11:14:53,431 - trainer - INFO -     val_gen_loss   : 376.06871366500854
2025-01-21 11:14:53,431 - trainer - INFO -     val_perplexity : 23.394367218017578
2025-01-21 11:14:53,431 - trainer - INFO -     val_embedding_sim: 0.12763938307762146
2025-01-21 11:14:53,431 - trainer - INFO - ================================================================================
2025-01-21 11:14:53,431 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:14:53
2025-01-21 11:14:57,989 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:14:57
2025-01-21 11:14:57,989 - trainer - INFO -     epoch          : 39
2025-01-21 11:14:57,989 - trainer - INFO -     elapsed time   : 4.558018207550049
2025-01-21 11:14:57,989 - trainer - INFO -     loss           : 140.51460914611818
2025-01-21 11:14:57,989 - trainer - INFO -     sim_loss       : 33.50286521911621
2025-01-21 11:14:57,989 - trainer - INFO -     gen_loss       : 186.3767868041992
2025-01-21 11:14:57,989 - trainer - INFO -     val_loss       : 399.5722465515137
2025-01-21 11:14:57,989 - trainer - INFO -     val_sim_loss   : 23.41248893737793
2025-01-21 11:14:57,989 - trainer - INFO -     val_gen_loss   : 376.1597709655762
2025-01-21 11:14:57,989 - trainer - INFO -     val_perplexity : 22.79643440246582
2025-01-21 11:14:57,989 - trainer - INFO -     val_embedding_sim: 0.13913622498512268
2025-01-21 11:14:57,989 - trainer - INFO - ================================================================================
2025-01-21 11:14:57,989 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:14:57
2025-01-21 11:15:02,555 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:15:02
2025-01-21 11:15:02,555 - trainer - INFO -     epoch          : 40
2025-01-21 11:15:02,555 - trainer - INFO -     elapsed time   : 4.565335035324097
2025-01-21 11:15:02,555 - trainer - INFO -     loss           : 136.96771850585938
2025-01-21 11:15:02,555 - trainer - INFO -     sim_loss       : 37.29016489982605
2025-01-21 11:15:02,555 - trainer - INFO -     gen_loss       : 179.6866714477539
2025-01-21 11:15:02,555 - trainer - INFO -     val_loss       : 399.78668785095215
2025-01-21 11:15:02,555 - trainer - INFO -     val_sim_loss   : 24.747440338134766
2025-01-21 11:15:02,555 - trainer - INFO -     val_gen_loss   : 375.03925132751465
2025-01-21 11:15:02,555 - trainer - INFO -     val_perplexity : 21.91678237915039
2025-01-21 11:15:02,555 - trainer - INFO -     val_embedding_sim: 0.13902541995048523
2025-01-21 11:15:09,187 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:15:09,187 - trainer - INFO - ================================================================================
2025-01-21 11:15:09,187 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:15:09
2025-01-21 11:15:13,784 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:15:13
2025-01-21 11:15:13,785 - trainer - INFO -     epoch          : 41
2025-01-21 11:15:13,785 - trainer - INFO -     elapsed time   : 4.597129821777344
2025-01-21 11:15:13,785 - trainer - INFO -     loss           : 128.76530685424805
2025-01-21 11:15:13,785 - trainer - INFO -     sim_loss       : 31.25827827453613
2025-01-21 11:15:13,785 - trainer - INFO -     gen_loss       : 170.5540344238281
2025-01-21 11:15:13,785 - trainer - INFO -     val_loss       : 395.3981956243515
2025-01-21 11:15:13,785 - trainer - INFO -     val_sim_loss   : 18.321426391601562
2025-01-21 11:15:13,785 - trainer - INFO -     val_gen_loss   : 377.076784491539
2025-01-21 11:15:13,785 - trainer - INFO -     val_perplexity : 23.451610565185547
2025-01-21 11:15:13,785 - trainer - INFO -     val_embedding_sim: 0.12217862904071808
2025-01-21 11:15:13,785 - trainer - INFO - ================================================================================
2025-01-21 11:15:13,785 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:15:13
2025-01-21 11:15:18,355 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:15:18
2025-01-21 11:15:18,356 - trainer - INFO -     epoch          : 42
2025-01-21 11:15:18,356 - trainer - INFO -     elapsed time   : 4.570374488830566
2025-01-21 11:15:18,356 - trainer - INFO -     loss           : 123.39893035888672
2025-01-21 11:15:18,356 - trainer - INFO -     sim_loss       : 32.087532711029056
2025-01-21 11:15:18,356 - trainer - INFO -     gen_loss       : 162.5323860168457
2025-01-21 11:15:18,356 - trainer - INFO -     val_loss       : 404.6431770324707
2025-01-21 11:15:18,356 - trainer - INFO -     val_sim_loss   : 25.69782257080078
2025-01-21 11:15:18,356 - trainer - INFO -     val_gen_loss   : 378.94536209106445
2025-01-21 11:15:18,356 - trainer - INFO -     val_perplexity : 22.27101707458496
2025-01-21 11:15:18,356 - trainer - INFO -     val_embedding_sim: 0.1523265838623047
2025-01-21 11:15:18,356 - trainer - INFO - ================================================================================
2025-01-21 11:15:18,356 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:15:18
2025-01-21 11:15:22,932 - trainer - INFO - Epoch 43 completed at 2025-01-21 11:15:22
2025-01-21 11:15:22,932 - trainer - INFO -     epoch          : 43
2025-01-21 11:15:22,932 - trainer - INFO -     elapsed time   : 4.575412273406982
2025-01-21 11:15:22,932 - trainer - INFO -     loss           : 118.55370712280273
2025-01-21 11:15:22,932 - trainer - INFO -     sim_loss       : 30.27674217224121
2025-01-21 11:15:22,932 - trainer - INFO -     gen_loss       : 156.3866958618164
2025-01-21 11:15:22,932 - trainer - INFO -     val_loss       : 391.01464080810547
2025-01-21 11:15:22,932 - trainer - INFO -     val_sim_loss   : 13.437350273132324
2025-01-21 11:15:22,932 - trainer - INFO -     val_gen_loss   : 377.5772933959961
2025-01-21 11:15:22,932 - trainer - INFO -     val_perplexity : 21.341527938842773
2025-01-21 11:15:22,932 - trainer - INFO -     val_embedding_sim: 0.13483595848083496
2025-01-21 11:15:22,932 - trainer - INFO - ================================================================================
2025-01-21 11:15:22,932 - trainer - INFO - Starting epoch 44 at 2025-01-21 11:15:22
2025-01-21 11:15:27,495 - trainer - INFO - Epoch 44 completed at 2025-01-21 11:15:27
2025-01-21 11:15:27,495 - trainer - INFO -     epoch          : 44
2025-01-21 11:15:27,495 - trainer - INFO -     elapsed time   : 4.562167644500732
2025-01-21 11:15:27,495 - trainer - INFO -     loss           : 115.43269653320313
2025-01-21 11:15:27,495 - trainer - INFO -     sim_loss       : 32.80137710571289
2025-01-21 11:15:27,495 - trainer - INFO -     gen_loss       : 150.84612045288085
2025-01-21 11:15:27,495 - trainer - INFO -     val_loss       : 403.5951051712036
2025-01-21 11:15:27,495 - trainer - INFO -     val_sim_loss   : 22.4921817779541
2025-01-21 11:15:27,495 - trainer - INFO -     val_gen_loss   : 381.1029176712036
2025-01-21 11:15:27,495 - trainer - INFO -     val_perplexity : 23.727270126342773
2025-01-21 11:15:27,495 - trainer - INFO -     val_embedding_sim: 0.13543830811977386
2025-01-21 11:15:27,495 - trainer - INFO - ================================================================================
2025-01-21 11:15:27,495 - trainer - INFO - Starting epoch 45 at 2025-01-21 11:15:27
2025-01-21 11:15:32,062 - trainer - INFO - Epoch 45 completed at 2025-01-21 11:15:32
2025-01-21 11:15:32,062 - trainer - INFO -     epoch          : 45
2025-01-21 11:15:32,062 - trainer - INFO -     elapsed time   : 4.567048072814941
2025-01-21 11:15:32,063 - trainer - INFO -     loss           : 110.06602363586425
2025-01-21 11:15:32,063 - trainer - INFO -     sim_loss       : 34.917249584198
2025-01-21 11:15:32,063 - trainer - INFO -     gen_loss       : 142.27264137268065
2025-01-21 11:15:32,063 - trainer - INFO -     val_loss       : 398.8674466609955
2025-01-21 11:15:32,063 - trainer - INFO -     val_sim_loss   : 20.368663787841797
2025-01-21 11:15:32,063 - trainer - INFO -     val_gen_loss   : 378.4987943172455
2025-01-21 11:15:32,063 - trainer - INFO -     val_perplexity : 23.4541072845459
2025-01-21 11:15:32,063 - trainer - INFO -     val_embedding_sim: 0.1700267344713211
2025-01-21 11:15:38,588 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 11:15:38,589 - trainer - INFO - ================================================================================
2025-01-21 11:15:38,589 - trainer - INFO - Starting epoch 46 at 2025-01-21 11:15:38
2025-01-21 11:15:43,204 - trainer - INFO - Epoch 46 completed at 2025-01-21 11:15:43
2025-01-21 11:15:43,204 - trainer - INFO -     epoch          : 46
2025-01-21 11:15:43,204 - trainer - INFO -     elapsed time   : 4.614623546600342
2025-01-21 11:15:43,204 - trainer - INFO -     loss           : 105.03941535949707
2025-01-21 11:15:43,204 - trainer - INFO -     sim_loss       : 35.648542165756226
2025-01-21 11:15:43,204 - trainer - INFO -     gen_loss       : 134.77836494445802
2025-01-21 11:15:43,204 - trainer - INFO -     val_loss       : 395.583779335022
2025-01-21 11:15:43,204 - trainer - INFO -     val_sim_loss   : 16.659791946411133
2025-01-21 11:15:43,204 - trainer - INFO -     val_gen_loss   : 378.9239892959595
2025-01-21 11:15:43,204 - trainer - INFO -     val_perplexity : 23.02998161315918
2025-01-21 11:15:43,204 - trainer - INFO -     val_embedding_sim: 0.14400175213813782
2025-01-21 11:15:43,204 - trainer - INFO - ================================================================================
2025-01-21 11:15:43,204 - trainer - INFO - Starting epoch 47 at 2025-01-21 11:15:43
2025-01-21 11:15:47,772 - trainer - INFO - Epoch 47 completed at 2025-01-21 11:15:47
2025-01-21 11:15:47,772 - trainer - INFO -     epoch          : 47
2025-01-21 11:15:47,772 - trainer - INFO -     elapsed time   : 4.5675928592681885
2025-01-21 11:15:47,772 - trainer - INFO -     loss           : 98.83382110595703
2025-01-21 11:15:47,772 - trainer - INFO -     sim_loss       : 35.197865104675294
2025-01-21 11:15:47,772 - trainer - INFO -     gen_loss       : 126.10637245178222
2025-01-21 11:15:47,772 - trainer - INFO -     val_loss       : 403.45317459106445
2025-01-21 11:15:47,772 - trainer - INFO -     val_sim_loss   : 21.208770751953125
2025-01-21 11:15:47,772 - trainer - INFO -     val_gen_loss   : 382.2444038391113
2025-01-21 11:15:47,772 - trainer - INFO -     val_perplexity : 22.829626083374023
2025-01-21 11:15:47,773 - trainer - INFO -     val_embedding_sim: 0.1363617479801178
2025-01-21 11:15:47,773 - trainer - INFO - ================================================================================
2025-01-21 11:15:47,773 - trainer - INFO - Starting epoch 48 at 2025-01-21 11:15:47
2025-01-21 11:15:52,330 - trainer - INFO - Epoch 48 completed at 2025-01-21 11:15:52
2025-01-21 11:15:52,330 - trainer - INFO -     epoch          : 48
2025-01-21 11:15:52,330 - trainer - INFO -     elapsed time   : 4.5571489334106445
2025-01-21 11:15:52,330 - trainer - INFO -     loss           : 97.1100009918213
2025-01-21 11:15:52,330 - trainer - INFO -     sim_loss       : 36.725960397720335
2025-01-21 11:15:52,330 - trainer - INFO -     gen_loss       : 122.98887672424317
2025-01-21 11:15:52,330 - trainer - INFO -     val_loss       : 395.4956430196762
2025-01-21 11:15:52,330 - trainer - INFO -     val_sim_loss   : 16.857568740844727
2025-01-21 11:15:52,330 - trainer - INFO -     val_gen_loss   : 378.6380685567856
2025-01-21 11:15:52,330 - trainer - INFO -     val_perplexity : 23.586864471435547
2025-01-21 11:15:52,330 - trainer - INFO -     val_embedding_sim: 0.14440932869911194
2025-01-21 11:15:52,330 - trainer - INFO - ================================================================================
2025-01-21 11:15:52,330 - trainer - INFO - Starting epoch 49 at 2025-01-21 11:15:52
2025-01-21 11:15:56,901 - trainer - INFO - Epoch 49 completed at 2025-01-21 11:15:56
2025-01-21 11:15:56,902 - trainer - INFO -     epoch          : 49
2025-01-21 11:15:56,902 - trainer - INFO -     elapsed time   : 4.57081151008606
2025-01-21 11:15:56,902 - trainer - INFO -     loss           : 93.32399291992188
2025-01-21 11:15:56,902 - trainer - INFO -     sim_loss       : 36.04694185256958
2025-01-21 11:15:56,902 - trainer - INFO -     gen_loss       : 117.8713005065918
2025-01-21 11:15:56,902 - trainer - INFO -     val_loss       : 393.8632539510727
2025-01-21 11:15:56,902 - trainer - INFO -     val_sim_loss   : 15.062725067138672
2025-01-21 11:15:56,902 - trainer - INFO -     val_gen_loss   : 378.8005403280258
2025-01-21 11:15:56,902 - trainer - INFO -     val_perplexity : 23.550308227539062
2025-01-21 11:15:56,902 - trainer - INFO -     val_embedding_sim: 0.13131709396839142
2025-01-21 11:15:56,902 - trainer - INFO - ================================================================================
2025-01-21 11:15:56,902 - trainer - INFO - Starting epoch 50 at 2025-01-21 11:15:56
2025-01-21 11:16:01,465 - trainer - INFO - Epoch 50 completed at 2025-01-21 11:16:01
2025-01-21 11:16:01,465 - trainer - INFO -     epoch          : 50
2025-01-21 11:16:01,465 - trainer - INFO -     elapsed time   : 4.562373638153076
2025-01-21 11:16:01,465 - trainer - INFO -     loss           : 88.36971130371094
2025-01-21 11:16:01,465 - trainer - INFO -     sim_loss       : 32.55777258872986
2025-01-21 11:16:01,465 - trainer - INFO -     gen_loss       : 112.28911323547364
2025-01-21 11:16:01,465 - trainer - INFO -     val_loss       : 394.0857892036438
2025-01-21 11:16:01,465 - trainer - INFO -     val_sim_loss   : 11.313129425048828
2025-01-21 11:16:01,465 - trainer - INFO -     val_gen_loss   : 382.7726483345032
2025-01-21 11:16:01,465 - trainer - INFO -     val_perplexity : 23.731475830078125
2025-01-21 11:16:01,465 - trainer - INFO -     val_embedding_sim: 0.1426618993282318
2025-01-21 11:16:07,995 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 11:16:07,995 - trainer - INFO - ================================================================================
2025-01-21 11:16:07,995 - trainer - INFO - Starting epoch 51 at 2025-01-21 11:16:07
2025-01-21 11:16:12,598 - trainer - INFO - Epoch 51 completed at 2025-01-21 11:16:12
2025-01-21 11:16:12,598 - trainer - INFO -     epoch          : 51
2025-01-21 11:16:12,598 - trainer - INFO -     elapsed time   : 4.601958274841309
2025-01-21 11:16:12,598 - trainer - INFO -     loss           : 85.95858802795411
2025-01-21 11:16:12,598 - trainer - INFO -     sim_loss       : 35.77648487091064
2025-01-21 11:16:12,598 - trainer - INFO -     gen_loss       : 107.46520614624023
2025-01-21 11:16:12,598 - trainer - INFO -     val_loss       : 406.21192741394043
2025-01-21 11:16:12,598 - trainer - INFO -     val_sim_loss   : 16.51332664489746
2025-01-21 11:16:12,598 - trainer - INFO -     val_gen_loss   : 389.6985912322998
2025-01-21 11:16:12,598 - trainer - INFO -     val_perplexity : 22.792062759399414
2025-01-21 11:16:12,598 - trainer - INFO -     val_embedding_sim: 0.14329802989959717
2025-01-21 11:16:12,598 - trainer - INFO - ================================================================================
2025-01-21 11:16:12,598 - trainer - INFO - Starting epoch 52 at 2025-01-21 11:16:12
2025-01-21 11:16:17,157 - trainer - INFO - Epoch 52 completed at 2025-01-21 11:16:17
2025-01-21 11:16:17,158 - trainer - INFO -     epoch          : 52
2025-01-21 11:16:17,158 - trainer - INFO -     elapsed time   : 4.559184789657593
2025-01-21 11:16:17,158 - trainer - INFO -     loss           : 82.31015815734864
2025-01-21 11:16:17,158 - trainer - INFO -     sim_loss       : 29.756574440002442
2025-01-21 11:16:17,158 - trainer - INFO -     gen_loss       : 104.83312339782715
2025-01-21 11:16:17,158 - trainer - INFO -     val_loss       : 399.3372573852539
2025-01-21 11:16:17,158 - trainer - INFO -     val_sim_loss   : 16.068708419799805
2025-01-21 11:16:17,158 - trainer - INFO -     val_gen_loss   : 383.26856231689453
2025-01-21 11:16:17,158 - trainer - INFO -     val_perplexity : 21.720365524291992
2025-01-21 11:16:17,158 - trainer - INFO -     val_embedding_sim: 0.13712874054908752
2025-01-21 11:16:17,158 - trainer - INFO - ================================================================================
2025-01-21 11:16:17,158 - trainer - INFO - Starting epoch 53 at 2025-01-21 11:16:17
2025-01-21 11:16:21,729 - trainer - INFO - Epoch 53 completed at 2025-01-21 11:16:21
2025-01-21 11:16:21,730 - trainer - INFO -     epoch          : 53
2025-01-21 11:16:21,730 - trainer - INFO -     elapsed time   : 4.571425914764404
2025-01-21 11:16:21,730 - trainer - INFO -     loss           : 81.50887565612793
2025-01-21 11:16:21,730 - trainer - INFO -     sim_loss       : 32.04063081741333
2025-01-21 11:16:21,730 - trainer - INFO -     gen_loss       : 102.70955200195313
2025-01-21 11:16:21,730 - trainer - INFO -     val_loss       : 409.5026388168335
2025-01-21 11:16:21,730 - trainer - INFO -     val_sim_loss   : 18.835834503173828
2025-01-21 11:16:21,730 - trainer - INFO -     val_gen_loss   : 390.66679286956787
2025-01-21 11:16:21,730 - trainer - INFO -     val_perplexity : 23.63766860961914
2025-01-21 11:16:21,730 - trainer - INFO -     val_embedding_sim: 0.1520335078239441
2025-01-21 11:16:21,730 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
2025-01-21 11:25:51,718 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:25:54,381 - trainer - INFO - ================================================================================
2025-01-21 11:25:54,381 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:25:54
2025-01-21 11:28:40,589 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:28:42,918 - trainer - INFO - ================================================================================
2025-01-21 11:28:42,918 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:28:42
2025-01-21 11:33:15,088 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:33:17,412 - trainer - INFO - ================================================================================
2025-01-21 11:33:17,412 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:33:17
2025-01-21 11:33:22,458 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:33:22
2025-01-21 11:33:22,459 - trainer - INFO -     epoch          : 1
2025-01-21 11:33:22,459 - trainer - INFO -     elapsed time   : 5.0457916259765625
2025-01-21 11:33:22,459 - trainer - INFO -     loss           : -186.0404510498047
2025-01-21 11:33:22,459 - trainer - INFO -     sim_loss       : 103.14251823425293
2025-01-21 11:33:22,459 - trainer - INFO -     gen_loss       : -309.97600536346437
2025-01-21 11:33:22,459 - trainer - INFO -     val_loss       : -271.89404487609863
2025-01-21 11:33:22,459 - trainer - INFO -     val_sim_loss   : 55.4388427734375
2025-01-21 11:33:22,459 - trainer - INFO -     val_gen_loss   : -327.33288764953613
2025-01-21 11:33:22,459 - trainer - INFO -     val_perplexity : -19.720016479492188
2025-01-21 11:33:22,459 - trainer - INFO -     val_embedding_sim: 0.06163272261619568
2025-01-21 11:33:22,459 - trainer - INFO - ================================================================================
2025-01-21 11:33:22,459 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:33:22
2025-01-21 11:33:26,327 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:33:26
2025-01-21 11:33:26,327 - trainer - INFO -     epoch          : 2
2025-01-21 11:33:26,327 - trainer - INFO -     elapsed time   : 3.867727279663086
2025-01-21 11:33:26,327 - trainer - INFO -     loss           : -446.7950927734375
2025-01-21 11:33:26,327 - trainer - INFO -     sim_loss       : 103.08970260620117
2025-01-21 11:33:26,327 - trainer - INFO -     gen_loss       : -682.460009765625
2025-01-21 11:33:26,327 - trainer - INFO -     val_loss       : -360.1834659576416
2025-01-21 11:33:26,327 - trainer - INFO -     val_sim_loss   : 55.436805725097656
2025-01-21 11:33:26,327 - trainer - INFO -     val_gen_loss   : -415.6202640533447
2025-01-21 11:33:26,327 - trainer - INFO -     val_perplexity : -25.247425079345703
2025-01-21 11:33:26,327 - trainer - INFO -     val_embedding_sim: 0.07722928375005722
2025-01-21 11:33:26,327 - trainer - INFO - ================================================================================
2025-01-21 11:33:26,327 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:33:26
2025-01-21 11:33:30,174 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:33:30
2025-01-21 11:33:30,174 - trainer - INFO -     epoch          : 3
2025-01-21 11:33:30,175 - trainer - INFO -     elapsed time   : 3.846780300140381
2025-01-21 11:33:30,175 - trainer - INFO -     loss           : -548.9736419677735
2025-01-21 11:33:30,175 - trainer - INFO -     sim_loss       : 103.09343910217285
2025-01-21 11:33:30,175 - trainer - INFO -     gen_loss       : -828.4309509277343
2025-01-21 11:33:30,175 - trainer - INFO -     val_loss       : -417.46892833709717
2025-01-21 11:33:30,175 - trainer - INFO -     val_sim_loss   : 55.42972183227539
2025-01-21 11:33:30,175 - trainer - INFO -     val_gen_loss   : -472.8986463546753
2025-01-21 11:33:30,175 - trainer - INFO -     val_perplexity : -28.798437118530273
2025-01-21 11:33:30,175 - trainer - INFO -     val_embedding_sim: 0.10232995450496674
2025-01-21 11:33:30,175 - trainer - INFO - ================================================================================
2025-01-21 11:33:30,175 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:33:30
2025-01-21 11:33:34,048 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:33:34
2025-01-21 11:33:34,049 - trainer - INFO -     epoch          : 4
2025-01-21 11:33:34,049 - trainer - INFO -     elapsed time   : 3.8733811378479004
2025-01-21 11:33:34,049 - trainer - INFO -     loss           : -641.108773803711
2025-01-21 11:33:34,049 - trainer - INFO -     sim_loss       : 103.03101615905761
2025-01-21 11:33:34,049 - trainer - INFO -     gen_loss       : -960.0258575439453
2025-01-21 11:33:34,049 - trainer - INFO -     val_loss       : -471.51708984375
2025-01-21 11:33:34,049 - trainer - INFO -     val_sim_loss   : 55.35968017578125
2025-01-21 11:33:34,049 - trainer - INFO -     val_gen_loss   : -526.8767700195312
2025-01-21 11:33:34,049 - trainer - INFO -     val_perplexity : -31.79959487915039
2025-01-21 11:33:34,049 - trainer - INFO -     val_embedding_sim: 0.0743759348988533
2025-01-21 11:33:34,049 - trainer - INFO - ================================================================================
2025-01-21 11:33:34,049 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:33:34
2025-01-21 11:33:37,916 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:33:37
2025-01-21 11:33:37,916 - trainer - INFO -     epoch          : 5
2025-01-21 11:33:37,916 - trainer - INFO -     elapsed time   : 3.866490125656128
2025-01-21 11:33:37,916 - trainer - INFO -     loss           : -725.3343200683594
2025-01-21 11:33:37,916 - trainer - INFO -     sim_loss       : 102.92963676452636
2025-01-21 11:33:37,916 - trainer - INFO -     gen_loss       : -1080.3046020507813
2025-01-21 11:33:37,916 - trainer - INFO -     val_loss       : -517.2770233154297
2025-01-21 11:33:37,916 - trainer - INFO -     val_sim_loss   : 55.31756591796875
2025-01-21 11:33:37,916 - trainer - INFO -     val_gen_loss   : -572.5945892333984
2025-01-21 11:33:37,916 - trainer - INFO -     val_perplexity : -34.9989013671875
2025-01-21 11:33:37,916 - trainer - INFO -     val_embedding_sim: 0.07094588130712509
2025-01-21 11:33:44,469 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:33:51,021 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:33:51,021 - trainer - INFO - ================================================================================
2025-01-21 11:33:51,021 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:33:51
2025-01-21 11:33:54,953 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:33:54
2025-01-21 11:33:54,953 - trainer - INFO -     epoch          : 6
2025-01-21 11:33:54,953 - trainer - INFO -     elapsed time   : 3.931112766265869
2025-01-21 11:33:54,953 - trainer - INFO -     loss           : -803.4116302490235
2025-01-21 11:33:54,953 - trainer - INFO -     sim_loss       : 102.75180358886719
2025-01-21 11:33:54,953 - trainer - INFO -     gen_loss       : -1191.7674072265625
2025-01-21 11:33:54,953 - trainer - INFO -     val_loss       : -558.4826641082764
2025-01-21 11:33:54,953 - trainer - INFO -     val_sim_loss   : 55.269935607910156
2025-01-21 11:33:54,953 - trainer - INFO -     val_gen_loss   : -613.7526226043701
2025-01-21 11:33:54,953 - trainer - INFO -     val_perplexity : -37.490962982177734
2025-01-21 11:33:54,953 - trainer - INFO -     val_embedding_sim: 0.05555592477321625
2025-01-21 11:33:54,953 - trainer - INFO - ================================================================================
2025-01-21 11:33:54,953 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:33:54
2025-01-21 11:33:58,816 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:33:58
2025-01-21 11:33:58,816 - trainer - INFO -     epoch          : 7
2025-01-21 11:33:58,816 - trainer - INFO -     elapsed time   : 3.862797498703003
2025-01-21 11:33:58,816 - trainer - INFO -     loss           : -874.2744110107421
2025-01-21 11:33:58,816 - trainer - INFO -     sim_loss       : 102.52275619506835
2025-01-21 11:33:58,816 - trainer - INFO -     gen_loss       : -1292.9017822265625
2025-01-21 11:33:58,816 - trainer - INFO -     val_loss       : -598.2091226577759
2025-01-21 11:33:58,816 - trainer - INFO -     val_sim_loss   : 55.188926696777344
2025-01-21 11:33:58,816 - trainer - INFO -     val_gen_loss   : -653.3980264663696
2025-01-21 11:33:58,817 - trainer - INFO -     val_perplexity : -39.93813705444336
2025-01-21 11:33:58,817 - trainer - INFO -     val_embedding_sim: 0.07075679302215576
2025-01-21 11:33:58,817 - trainer - INFO - ================================================================================
2025-01-21 11:33:58,817 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:33:58
2025-01-21 11:34:02,689 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:34:02
2025-01-21 11:34:02,689 - trainer - INFO -     epoch          : 8
2025-01-21 11:34:02,689 - trainer - INFO -     elapsed time   : 3.872079372406006
2025-01-21 11:34:02,689 - trainer - INFO -     loss           : -939.8270446777344
2025-01-21 11:34:02,689 - trainer - INFO -     sim_loss       : 102.29838066101074
2025-01-21 11:34:02,689 - trainer - INFO -     gen_loss       : -1386.452294921875
2025-01-21 11:34:02,689 - trainer - INFO -     val_loss       : -635.5187454223633
2025-01-21 11:34:02,689 - trainer - INFO -     val_sim_loss   : 55.10154724121094
2025-01-21 11:34:02,689 - trainer - INFO -     val_gen_loss   : -690.6203079223633
2025-01-21 11:34:02,689 - trainer - INFO -     val_perplexity : -40.83884048461914
2025-01-21 11:34:02,689 - trainer - INFO -     val_embedding_sim: 0.06660252809524536
2025-01-21 11:34:02,689 - trainer - INFO - ================================================================================
2025-01-21 11:34:02,689 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:34:02
2025-01-21 11:34:06,549 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:34:06
2025-01-21 11:34:06,549 - trainer - INFO -     epoch          : 9
2025-01-21 11:34:06,549 - trainer - INFO -     elapsed time   : 3.8592369556427
2025-01-21 11:34:06,549 - trainer - INFO -     loss           : -1001.0354431152343
2025-01-21 11:34:06,549 - trainer - INFO -     sim_loss       : 101.77427291870117
2025-01-21 11:34:06,549 - trainer - INFO -     gen_loss       : -1473.6681701660157
2025-01-21 11:34:06,549 - trainer - INFO -     val_loss       : -668.7088270187378
2025-01-21 11:34:06,549 - trainer - INFO -     val_sim_loss   : 54.96880340576172
2025-01-21 11:34:06,549 - trainer - INFO -     val_gen_loss   : -723.677638053894
2025-01-21 11:34:06,549 - trainer - INFO -     val_perplexity : -44.32826232910156
2025-01-21 11:34:06,549 - trainer - INFO -     val_embedding_sim: 0.08928243815898895
2025-01-21 11:34:06,549 - trainer - INFO - ================================================================================
2025-01-21 11:34:06,549 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:34:06
2025-01-21 11:34:10,408 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:34:10
2025-01-21 11:34:10,408 - trainer - INFO -     epoch          : 10
2025-01-21 11:34:10,408 - trainer - INFO -     elapsed time   : 3.8586230278015137
2025-01-21 11:34:10,408 - trainer - INFO -     loss           : -1058.1934509277344
2025-01-21 11:34:10,409 - trainer - INFO -     sim_loss       : 101.38613014221191
2025-01-21 11:34:10,409 - trainer - INFO -     gen_loss       : -1555.1561706542968
2025-01-21 11:34:10,409 - trainer - INFO -     val_loss       : -700.6395988464355
2025-01-21 11:34:10,409 - trainer - INFO -     val_sim_loss   : 54.681724548339844
2025-01-21 11:34:10,409 - trainer - INFO -     val_gen_loss   : -755.3213005065918
2025-01-21 11:34:10,409 - trainer - INFO -     val_perplexity : -46.28450012207031
2025-01-21 11:34:10,409 - trainer - INFO -     val_embedding_sim: 0.08186450600624084
2025-01-21 11:34:16,946 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:34:23,533 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:34:23,533 - trainer - INFO - ================================================================================
2025-01-21 11:34:23,533 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:34:23
2025-01-21 11:34:27,457 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:34:27
2025-01-21 11:34:27,457 - trainer - INFO -     epoch          : 11
2025-01-21 11:34:27,457 - trainer - INFO -     elapsed time   : 3.923597812652588
2025-01-21 11:34:27,457 - trainer - INFO -     loss           : -1113.4131103515624
2025-01-21 11:34:27,457 - trainer - INFO -     sim_loss       : 100.29055099487304
2025-01-21 11:34:27,457 - trainer - INFO -     gen_loss       : -1633.571826171875
2025-01-21 11:34:27,457 - trainer - INFO -     val_loss       : -731.6909408569336
2025-01-21 11:34:27,457 - trainer - INFO -     val_sim_loss   : 54.351707458496094
2025-01-21 11:34:27,457 - trainer - INFO -     val_gen_loss   : -786.0426254272461
2025-01-21 11:34:27,457 - trainer - INFO -     val_perplexity : -48.05161666870117
2025-01-21 11:34:27,457 - trainer - INFO -     val_embedding_sim: 0.09043010324239731
2025-01-21 11:34:27,457 - trainer - INFO - ================================================================================
2025-01-21 11:34:27,457 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:34:27
2025-01-21 11:34:31,315 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:34:31
2025-01-21 11:34:31,315 - trainer - INFO -     epoch          : 12
2025-01-21 11:34:31,315 - trainer - INFO -     elapsed time   : 3.8574941158294678
2025-01-21 11:34:31,315 - trainer - INFO -     loss           : -1163.8638702392577
2025-01-21 11:34:31,315 - trainer - INFO -     sim_loss       : 99.34797554016113
2025-01-21 11:34:31,315 - trainer - INFO -     gen_loss       : -1705.240411376953
2025-01-21 11:34:31,315 - trainer - INFO -     val_loss       : -760.7771797180176
2025-01-21 11:34:31,315 - trainer - INFO -     val_sim_loss   : 53.50743103027344
2025-01-21 11:34:31,315 - trainer - INFO -     val_gen_loss   : -814.2846260070801
2025-01-21 11:34:31,316 - trainer - INFO -     val_perplexity : -49.79088592529297
2025-01-21 11:34:31,316 - trainer - INFO -     val_embedding_sim: 0.06593193113803864
2025-01-21 11:34:31,316 - trainer - INFO - ================================================================================
2025-01-21 11:34:31,316 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:34:31
2025-01-21 11:34:35,171 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:34:35
2025-01-21 11:34:35,171 - trainer - INFO -     epoch          : 13
2025-01-21 11:34:35,171 - trainer - INFO -     elapsed time   : 3.8551599979400635
2025-01-21 11:34:35,171 - trainer - INFO -     loss           : -1213.942886352539
2025-01-21 11:34:35,171 - trainer - INFO -     sim_loss       : 97.86259651184082
2025-01-21 11:34:35,171 - trainer - INFO -     gen_loss       : -1776.1452392578126
2025-01-21 11:34:35,171 - trainer - INFO -     val_loss       : -790.9666328430176
2025-01-21 11:34:35,171 - trainer - INFO -     val_sim_loss   : 53.09297180175781
2025-01-21 11:34:35,171 - trainer - INFO -     val_gen_loss   : -844.0595893859863
2025-01-21 11:34:35,171 - trainer - INFO -     val_perplexity : -50.53978729248047
2025-01-21 11:34:35,172 - trainer - INFO -     val_embedding_sim: 0.11062753200531006
2025-01-21 11:34:35,172 - trainer - INFO - ================================================================================
2025-01-21 11:34:35,172 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:34:35
2025-01-21 11:34:39,053 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:34:39
2025-01-21 11:34:39,054 - trainer - INFO -     epoch          : 14
2025-01-21 11:34:39,054 - trainer - INFO -     elapsed time   : 3.8817121982574463
2025-01-21 11:34:39,054 - trainer - INFO -     loss           : -1262.364028930664
2025-01-21 11:34:39,054 - trainer - INFO -     sim_loss       : 96.60563850402832
2025-01-21 11:34:39,054 - trainer - INFO -     gen_loss       : -1844.7796203613282
2025-01-21 11:34:39,054 - trainer - INFO -     val_loss       : -820.3282775878906
2025-01-21 11:34:39,054 - trainer - INFO -     val_sim_loss   : 51.41381072998047
2025-01-21 11:34:39,054 - trainer - INFO -     val_gen_loss   : -871.7420959472656
2025-01-21 11:34:39,054 - trainer - INFO -     val_perplexity : -52.82157897949219
2025-01-21 11:34:39,054 - trainer - INFO -     val_embedding_sim: 0.08358731120824814
2025-01-21 11:34:39,054 - trainer - INFO - ================================================================================
2025-01-21 11:34:39,054 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:34:39
2025-01-21 11:34:42,907 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:34:42
2025-01-21 11:34:42,907 - trainer - INFO -     epoch          : 15
2025-01-21 11:34:42,907 - trainer - INFO -     elapsed time   : 3.853060722351074
2025-01-21 11:34:42,907 - trainer - INFO -     loss           : -1309.5500793457031
2025-01-21 11:34:42,907 - trainer - INFO -     sim_loss       : 94.80959854125976
2025-01-21 11:34:42,907 - trainer - INFO -     gen_loss       : -1911.4185485839844
2025-01-21 11:34:42,907 - trainer - INFO -     val_loss       : -848.0251502990723
2025-01-21 11:34:42,907 - trainer - INFO -     val_sim_loss   : 51.61015319824219
2025-01-21 11:34:42,908 - trainer - INFO -     val_gen_loss   : -899.6353187561035
2025-01-21 11:34:42,908 - trainer - INFO -     val_perplexity : -55.12046813964844
2025-01-21 11:34:42,908 - trainer - INFO -     val_embedding_sim: 0.08496900647878647
2025-01-21 11:34:49,466 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:34:56,063 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:34:56,063 - trainer - INFO - ================================================================================
2025-01-21 11:34:56,063 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:34:56
2025-01-21 11:34:59,968 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:34:59
2025-01-21 11:34:59,968 - trainer - INFO -     epoch          : 16
2025-01-21 11:34:59,968 - trainer - INFO -     elapsed time   : 3.9042742252349854
2025-01-21 11:34:59,968 - trainer - INFO -     loss           : -1355.7198364257813
2025-01-21 11:34:59,968 - trainer - INFO -     sim_loss       : 93.69368343353271
2025-01-21 11:34:59,968 - trainer - INFO -     gen_loss       : -1976.8971130371094
2025-01-21 11:34:59,968 - trainer - INFO -     val_loss       : -876.941577911377
2025-01-21 11:34:59,968 - trainer - INFO -     val_sim_loss   : 49.48301696777344
2025-01-21 11:34:59,968 - trainer - INFO -     val_gen_loss   : -926.4246101379395
2025-01-21 11:34:59,968 - trainer - INFO -     val_perplexity : -56.536834716796875
2025-01-21 11:34:59,968 - trainer - INFO -     val_embedding_sim: 0.10025257617235184
2025-01-21 11:34:59,968 - trainer - INFO - ================================================================================
2025-01-21 11:34:59,968 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:34:59
2025-01-21 11:35:03,828 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:35:03
2025-01-21 11:35:03,828 - trainer - INFO -     epoch          : 17
2025-01-21 11:35:03,828 - trainer - INFO -     elapsed time   : 3.8594980239868164
2025-01-21 11:35:03,828 - trainer - INFO -     loss           : -1399.5290405273438
2025-01-21 11:35:03,828 - trainer - INFO -     sim_loss       : 91.9489673614502
2025-01-21 11:35:03,828 - trainer - INFO -     gen_loss       : -2038.7339660644532
2025-01-21 11:35:03,828 - trainer - INFO -     val_loss       : -904.1227703094482
2025-01-21 11:35:03,828 - trainer - INFO -     val_sim_loss   : 48.87616729736328
2025-01-21 11:35:03,828 - trainer - INFO -     val_gen_loss   : -952.998929977417
2025-01-21 11:35:03,828 - trainer - INFO -     val_perplexity : -58.480506896972656
2025-01-21 11:35:03,828 - trainer - INFO -     val_embedding_sim: 0.09093272686004639
2025-01-21 11:35:03,828 - trainer - INFO - ================================================================================
2025-01-21 11:35:03,828 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:35:03
2025-01-21 11:35:07,676 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:35:07
2025-01-21 11:35:07,676 - trainer - INFO -     epoch          : 18
2025-01-21 11:35:07,676 - trainer - INFO -     elapsed time   : 3.8468751907348633
2025-01-21 11:35:07,676 - trainer - INFO -     loss           : -1443.3840881347655
2025-01-21 11:35:07,676 - trainer - INFO -     sim_loss       : 90.67951011657715
2025-01-21 11:35:07,676 - trainer - INFO -     gen_loss       : -2100.83994140625
2025-01-21 11:35:07,676 - trainer - INFO -     val_loss       : -931.7409744262695
2025-01-21 11:35:07,676 - trainer - INFO -     val_sim_loss   : 48.016822814941406
2025-01-21 11:35:07,676 - trainer - INFO -     val_gen_loss   : -979.7578201293945
2025-01-21 11:35:07,676 - trainer - INFO -     val_perplexity : -58.806583404541016
2025-01-21 11:35:07,676 - trainer - INFO -     val_embedding_sim: 0.11219871044158936
2025-01-21 11:35:07,676 - trainer - INFO - ================================================================================
2025-01-21 11:35:07,676 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:35:07
2025-01-21 11:35:11,529 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:35:11
2025-01-21 11:35:11,529 - trainer - INFO -     epoch          : 19
2025-01-21 11:35:11,529 - trainer - INFO -     elapsed time   : 3.8530783653259277
2025-01-21 11:35:11,529 - trainer - INFO -     loss           : -1486.7112182617188
2025-01-21 11:35:11,530 - trainer - INFO -     sim_loss       : 90.07557640075683
2025-01-21 11:35:11,530 - trainer - INFO -     gen_loss       : -2162.4770385742186
2025-01-21 11:35:11,530 - trainer - INFO -     val_loss       : -955.0768737792969
2025-01-21 11:35:11,530 - trainer - INFO -     val_sim_loss   : 49.493064880371094
2025-01-21 11:35:11,530 - trainer - INFO -     val_gen_loss   : -1004.5699157714844
2025-01-21 11:35:11,530 - trainer - INFO -     val_perplexity : -61.09429168701172
2025-01-21 11:35:11,530 - trainer - INFO -     val_embedding_sim: 0.0806393101811409
2025-01-21 11:35:11,530 - trainer - INFO - ================================================================================
2025-01-21 11:35:11,530 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:35:11
2025-01-21 11:35:15,384 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:35:15
2025-01-21 11:35:15,384 - trainer - INFO -     epoch          : 20
2025-01-21 11:35:15,385 - trainer - INFO -     elapsed time   : 3.854320526123047
2025-01-21 11:35:15,385 - trainer - INFO -     loss           : -1528.5861572265626
2025-01-21 11:35:15,385 - trainer - INFO -     sim_loss       : 88.28049430847167
2025-01-21 11:35:15,385 - trainer - INFO -     gen_loss       : -2221.5290710449217
2025-01-21 11:35:15,385 - trainer - INFO -     val_loss       : -981.4649772644043
2025-01-21 11:35:15,385 - trainer - INFO -     val_sim_loss   : 49.12133026123047
2025-01-21 11:35:15,385 - trainer - INFO -     val_gen_loss   : -1030.5863151550293
2025-01-21 11:35:15,385 - trainer - INFO -     val_perplexity : -61.869293212890625
2025-01-21 11:35:15,385 - trainer - INFO -     val_embedding_sim: 0.08316411077976227
2025-01-21 11:35:21,934 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:35:28,525 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:35:28,525 - trainer - INFO - ================================================================================
2025-01-21 11:35:28,525 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:35:28
2025-01-21 11:35:32,432 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:35:32
2025-01-21 11:35:32,432 - trainer - INFO -     epoch          : 21
2025-01-21 11:35:32,432 - trainer - INFO -     elapsed time   : 3.90647029876709
2025-01-21 11:35:32,432 - trainer - INFO -     loss           : -1571.4513916015626
2025-01-21 11:35:32,432 - trainer - INFO -     sim_loss       : 88.00603904724122
2025-01-21 11:35:32,432 - trainer - INFO -     gen_loss       : -2282.6474731445314
2025-01-21 11:35:32,432 - trainer - INFO -     val_loss       : -1010.8232536315918
2025-01-21 11:35:32,432 - trainer - INFO -     val_sim_loss   : 45.342933654785156
2025-01-21 11:35:32,432 - trainer - INFO -     val_gen_loss   : -1056.1662101745605
2025-01-21 11:35:32,432 - trainer - INFO -     val_perplexity : -63.59596633911133
2025-01-21 11:35:32,432 - trainer - INFO -     val_embedding_sim: 0.10119650512933731
2025-01-21 11:35:32,433 - trainer - INFO - ================================================================================
2025-01-21 11:35:32,433 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:35:32
2025-01-21 11:35:36,275 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:35:36
2025-01-21 11:35:36,275 - trainer - INFO -     epoch          : 22
2025-01-21 11:35:36,275 - trainer - INFO -     elapsed time   : 3.842141628265381
2025-01-21 11:35:36,275 - trainer - INFO -     loss           : -1614.409375
2025-01-21 11:35:36,275 - trainer - INFO -     sim_loss       : 86.21554851531982
2025-01-21 11:35:36,275 - trainer - INFO -     gen_loss       : -2343.248669433594
2025-01-21 11:35:36,275 - trainer - INFO -     val_loss       : -1033.7981700897217
2025-01-21 11:35:36,275 - trainer - INFO -     val_sim_loss   : 47.59626770019531
2025-01-21 11:35:36,275 - trainer - INFO -     val_gen_loss   : -1081.394422531128
2025-01-21 11:35:36,275 - trainer - INFO -     val_perplexity : -66.37871551513672
2025-01-21 11:35:36,275 - trainer - INFO -     val_embedding_sim: 0.09707021713256836
2025-01-21 11:35:36,275 - trainer - INFO - ================================================================================
2025-01-21 11:35:36,275 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:35:36
2025-01-21 11:35:40,137 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:35:40
2025-01-21 11:35:40,137 - trainer - INFO -     epoch          : 23
2025-01-21 11:35:40,137 - trainer - INFO -     elapsed time   : 3.8613057136535645
2025-01-21 11:35:40,137 - trainer - INFO -     loss           : -1655.326434326172
2025-01-21 11:35:40,137 - trainer - INFO -     sim_loss       : 86.10839748382568
2025-01-21 11:35:40,137 - trainer - INFO -     gen_loss       : -2401.6556640625
2025-01-21 11:35:40,137 - trainer - INFO -     val_loss       : -1059.4832763671875
2025-01-21 11:35:40,137 - trainer - INFO -     val_sim_loss   : 47.115928649902344
2025-01-21 11:35:40,137 - trainer - INFO -     val_gen_loss   : -1106.5992431640625
2025-01-21 11:35:40,137 - trainer - INFO -     val_perplexity : -67.37611389160156
2025-01-21 11:35:40,137 - trainer - INFO -     val_embedding_sim: 0.09225423634052277
2025-01-21 11:35:40,137 - trainer - INFO - ================================================================================
2025-01-21 11:35:40,137 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:35:40
2025-01-21 11:35:43,991 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:35:43
2025-01-21 11:35:43,991 - trainer - INFO -     epoch          : 24
2025-01-21 11:35:43,991 - trainer - INFO -     elapsed time   : 3.8536946773529053
2025-01-21 11:35:43,991 - trainer - INFO -     loss           : -1695.8412841796876
2025-01-21 11:35:43,991 - trainer - INFO -     sim_loss       : 86.68351459503174
2025-01-21 11:35:43,992 - trainer - INFO -     gen_loss       : -2459.7805358886717
2025-01-21 11:35:43,992 - trainer - INFO -     val_loss       : -1086.747844696045
2025-01-21 11:35:43,992 - trainer - INFO -     val_sim_loss   : 44.997535705566406
2025-01-21 11:35:43,992 - trainer - INFO -     val_gen_loss   : -1131.745403289795
2025-01-21 11:35:43,992 - trainer - INFO -     val_perplexity : -69.48394775390625
2025-01-21 11:35:43,992 - trainer - INFO -     val_embedding_sim: 0.08610042929649353
2025-01-21 11:35:43,992 - trainer - INFO - ================================================================================
2025-01-21 11:35:43,992 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:35:43
2025-01-21 11:35:47,845 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:35:47
2025-01-21 11:35:47,845 - trainer - INFO -     epoch          : 25
2025-01-21 11:35:47,845 - trainer - INFO -     elapsed time   : 3.853248357772827
2025-01-21 11:35:47,845 - trainer - INFO -     loss           : -1737.752392578125
2025-01-21 11:35:47,845 - trainer - INFO -     sim_loss       : 83.66232929229736
2025-01-21 11:35:47,845 - trainer - INFO -     gen_loss       : -2518.358752441406
2025-01-21 11:35:47,845 - trainer - INFO -     val_loss       : -1111.3408279418945
2025-01-21 11:35:47,845 - trainer - INFO -     val_sim_loss   : 45.78282928466797
2025-01-21 11:35:47,846 - trainer - INFO -     val_gen_loss   : -1157.123664855957
2025-01-21 11:35:47,846 - trainer - INFO -     val_perplexity : -68.8338623046875
2025-01-21 11:35:47,846 - trainer - INFO -     val_embedding_sim: 0.09966753423213959
2025-01-21 11:35:54,397 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:36:00,985 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:36:00,986 - trainer - INFO - ================================================================================
2025-01-21 11:36:00,986 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:36:00
2025-01-21 11:36:04,889 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:36:04
2025-01-21 11:36:04,889 - trainer - INFO -     epoch          : 26
2025-01-21 11:36:04,889 - trainer - INFO -     elapsed time   : 3.90309739112854
2025-01-21 11:36:04,889 - trainer - INFO -     loss           : -1778.9022216796875
2025-01-21 11:36:04,889 - trainer - INFO -     sim_loss       : 84.04135665893554
2025-01-21 11:36:04,889 - trainer - INFO -     gen_loss       : -2577.306640625
2025-01-21 11:36:04,889 - trainer - INFO -     val_loss       : -1135.5305442810059
2025-01-21 11:36:04,889 - trainer - INFO -     val_sim_loss   : 45.95737838745117
2025-01-21 11:36:04,889 - trainer - INFO -     val_gen_loss   : -1181.4879417419434
2025-01-21 11:36:04,889 - trainer - INFO -     val_perplexity : -70.94747924804688
2025-01-21 11:36:04,889 - trainer - INFO -     val_embedding_sim: 0.0869031548500061
2025-01-21 11:36:04,890 - trainer - INFO - ================================================================================
2025-01-21 11:36:04,890 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:36:04
2025-01-21 11:36:08,745 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:36:08
2025-01-21 11:36:08,745 - trainer - INFO -     epoch          : 27
2025-01-21 11:36:08,745 - trainer - INFO -     elapsed time   : 3.854985237121582
2025-01-21 11:36:08,745 - trainer - INFO -     loss           : -1819.5608215332031
2025-01-21 11:36:08,745 - trainer - INFO -     sim_loss       : 82.94929428100586
2025-01-21 11:36:08,745 - trainer - INFO -     gen_loss       : -2634.922326660156
2025-01-21 11:36:08,745 - trainer - INFO -     val_loss       : -1163.6177368164062
2025-01-21 11:36:08,745 - trainer - INFO -     val_sim_loss   : 44.41411590576172
2025-01-21 11:36:08,745 - trainer - INFO -     val_gen_loss   : -1208.0317993164062
2025-01-21 11:36:08,745 - trainer - INFO -     val_perplexity : -73.19631958007812
2025-01-21 11:36:08,745 - trainer - INFO -     val_embedding_sim: 0.0931357741355896
2025-01-21 11:36:08,745 - trainer - INFO - ================================================================================
2025-01-21 11:36:08,745 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:36:08
2025-01-21 11:36:12,605 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:36:12
2025-01-21 11:36:12,606 - trainer - INFO -     epoch          : 28
2025-01-21 11:36:12,606 - trainer - INFO -     elapsed time   : 3.8599982261657715
2025-01-21 11:36:12,606 - trainer - INFO -     loss           : -1860.0933471679687
2025-01-21 11:36:12,606 - trainer - INFO -     sim_loss       : 81.69160461425781
2025-01-21 11:36:12,606 - trainer - INFO -     gen_loss       : -2692.286962890625
2025-01-21 11:36:12,606 - trainer - INFO -     val_loss       : -1189.7371215820312
2025-01-21 11:36:12,606 - trainer - INFO -     val_sim_loss   : 44.094749450683594
2025-01-21 11:36:12,606 - trainer - INFO -     val_gen_loss   : -1233.8318481445312
2025-01-21 11:36:12,606 - trainer - INFO -     val_perplexity : -74.95062255859375
2025-01-21 11:36:12,606 - trainer - INFO -     val_embedding_sim: 0.0766286849975586
2025-01-21 11:36:12,606 - trainer - INFO - ================================================================================
2025-01-21 11:36:12,606 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:36:12
2025-01-21 11:36:16,453 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:36:16
2025-01-21 11:36:16,453 - trainer - INFO -     epoch          : 29
2025-01-21 11:36:16,453 - trainer - INFO -     elapsed time   : 3.846794843673706
2025-01-21 11:36:16,453 - trainer - INFO -     loss           : -1900.5028381347656
2025-01-21 11:36:16,453 - trainer - INFO -     sim_loss       : 83.69301853179931
2025-01-21 11:36:16,453 - trainer - INFO -     gen_loss       : -2750.872521972656
2025-01-21 11:36:16,453 - trainer - INFO -     val_loss       : -1213.876781463623
2025-01-21 11:36:16,453 - trainer - INFO -     val_sim_loss   : 44.105072021484375
2025-01-21 11:36:16,453 - trainer - INFO -     val_gen_loss   : -1257.9818840026855
2025-01-21 11:36:16,453 - trainer - INFO -     val_perplexity : -76.26789093017578
2025-01-21 11:36:16,453 - trainer - INFO -     val_embedding_sim: 0.08152681589126587
2025-01-21 11:36:16,454 - trainer - INFO - ================================================================================
2025-01-21 11:36:16,454 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:36:16
2025-01-21 11:36:20,320 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:36:20
2025-01-21 11:36:20,320 - trainer - INFO -     epoch          : 30
2025-01-21 11:36:20,320 - trainer - INFO -     elapsed time   : 3.8657801151275635
2025-01-21 11:36:20,320 - trainer - INFO -     loss           : -1940.8516235351562
2025-01-21 11:36:20,320 - trainer - INFO -     sim_loss       : 81.45773506164551
2025-01-21 11:36:20,320 - trainer - INFO -     gen_loss       : -2807.5555908203123
2025-01-21 11:36:20,320 - trainer - INFO -     val_loss       : -1240.3086853027344
2025-01-21 11:36:20,320 - trainer - INFO -     val_sim_loss   : 43.210693359375
2025-01-21 11:36:20,320 - trainer - INFO -     val_gen_loss   : -1283.5193786621094
2025-01-21 11:36:20,320 - trainer - INFO -     val_perplexity : -78.78577423095703
2025-01-21 11:36:20,320 - trainer - INFO -     val_embedding_sim: 0.09326311945915222
2025-01-21 11:36:26,871 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:36:34,288 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:36:34,288 - trainer - INFO - ================================================================================
2025-01-21 11:36:34,288 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:36:34
2025-01-21 11:36:38,198 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:36:38
2025-01-21 11:36:38,198 - trainer - INFO -     epoch          : 31
2025-01-21 11:36:38,198 - trainer - INFO -     elapsed time   : 3.9094297885894775
2025-01-21 11:36:38,198 - trainer - INFO -     loss           : -1980.8645812988282
2025-01-21 11:36:38,198 - trainer - INFO -     sim_loss       : 82.11081390380859
2025-01-21 11:36:38,198 - trainer - INFO -     gen_loss       : -2864.996936035156
2025-01-21 11:36:38,198 - trainer - INFO -     val_loss       : -1266.655897140503
2025-01-21 11:36:38,198 - trainer - INFO -     val_sim_loss   : 42.852439880371094
2025-01-21 11:36:38,198 - trainer - INFO -     val_gen_loss   : -1309.5083141326904
2025-01-21 11:36:38,198 - trainer - INFO -     val_perplexity : -80.06739807128906
2025-01-21 11:36:38,198 - trainer - INFO -     val_embedding_sim: 0.10465926676988602
2025-01-21 11:36:38,198 - trainer - INFO - ================================================================================
2025-01-21 11:36:38,198 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:36:38
2025-01-21 11:36:42,067 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:36:42
2025-01-21 11:36:42,067 - trainer - INFO -     epoch          : 32
2025-01-21 11:36:42,067 - trainer - INFO -     elapsed time   : 3.868283987045288
2025-01-21 11:36:42,067 - trainer - INFO -     loss           : -2020.8262451171875
2025-01-21 11:36:42,067 - trainer - INFO -     sim_loss       : 80.20629978179932
2025-01-21 11:36:42,067 - trainer - INFO -     gen_loss       : -2921.2688720703127
2025-01-21 11:36:42,067 - trainer - INFO -     val_loss       : -1292.8532180786133
2025-01-21 11:36:42,067 - trainer - INFO -     val_sim_loss   : 41.79969787597656
2025-01-21 11:36:42,067 - trainer - INFO -     val_gen_loss   : -1334.6529006958008
2025-01-21 11:36:42,067 - trainer - INFO -     val_perplexity : -80.92499542236328
2025-01-21 11:36:42,067 - trainer - INFO -     val_embedding_sim: 0.0989282876253128
2025-01-21 11:36:42,067 - trainer - INFO - ================================================================================
2025-01-21 11:36:42,067 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:36:42
2025-01-21 11:36:45,929 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:36:45
2025-01-21 11:36:45,930 - trainer - INFO -     epoch          : 33
2025-01-21 11:36:45,930 - trainer - INFO -     elapsed time   : 3.8620145320892334
2025-01-21 11:36:45,930 - trainer - INFO -     loss           : -2061.950579833984
2025-01-21 11:36:45,930 - trainer - INFO -     sim_loss       : 79.26586170196533
2025-01-21 11:36:45,930 - trainer - INFO -     gen_loss       : -2979.6148315429687
2025-01-21 11:36:45,930 - trainer - INFO -     val_loss       : -1317.4770965576172
2025-01-21 11:36:45,930 - trainer - INFO -     val_sim_loss   : 42.95904541015625
2025-01-21 11:36:45,930 - trainer - INFO -     val_gen_loss   : -1360.4362030029297
2025-01-21 11:36:45,930 - trainer - INFO -     val_perplexity : -82.37413787841797
2025-01-21 11:36:45,930 - trainer - INFO -     val_embedding_sim: 0.08034534007310867
2025-01-21 11:36:45,930 - trainer - INFO - ================================================================================
2025-01-21 11:36:45,930 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:36:45
2025-01-21 11:36:49,781 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:36:49
2025-01-21 11:36:49,781 - trainer - INFO -     epoch          : 34
2025-01-21 11:36:49,781 - trainer - INFO -     elapsed time   : 3.850740432739258
2025-01-21 11:36:49,781 - trainer - INFO -     loss           : -2102.1494384765624
2025-01-21 11:36:49,781 - trainer - INFO -     sim_loss       : 78.07100639343261
2025-01-21 11:36:49,781 - trainer - INFO -     gen_loss       : -3036.529736328125
2025-01-21 11:36:49,781 - trainer - INFO -     val_loss       : -1346.4862594604492
2025-01-21 11:36:49,781 - trainer - INFO -     val_sim_loss   : 40.05866622924805
2025-01-21 11:36:49,781 - trainer - INFO -     val_gen_loss   : -1386.5449752807617
2025-01-21 11:36:49,781 - trainer - INFO -     val_perplexity : -83.05432891845703
2025-01-21 11:36:49,781 - trainer - INFO -     val_embedding_sim: 0.06155431643128395
2025-01-21 11:36:49,782 - trainer - INFO - ================================================================================
2025-01-21 11:36:49,782 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:36:49
2025-01-21 11:36:53,694 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:36:53
2025-01-21 11:36:53,695 - trainer - INFO -     epoch          : 35
2025-01-21 11:36:53,695 - trainer - INFO -     elapsed time   : 3.912766456604004
2025-01-21 11:36:53,695 - trainer - INFO -     loss           : -2142.778778076172
2025-01-21 11:36:53,695 - trainer - INFO -     sim_loss       : 77.80232162475586
2025-01-21 11:36:53,695 - trainer - INFO -     gen_loss       : -3094.456433105469
2025-01-21 11:36:53,695 - trainer - INFO -     val_loss       : -1369.281644821167
2025-01-21 11:36:53,695 - trainer - INFO -     val_sim_loss   : 43.07615661621094
2025-01-21 11:36:53,695 - trainer - INFO -     val_gen_loss   : -1412.357816696167
2025-01-21 11:36:53,695 - trainer - INFO -     val_perplexity : -86.69133758544922
2025-01-21 11:36:53,695 - trainer - INFO -     val_embedding_sim: 0.10259759426116943
2025-01-21 11:37:00,258 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:37:06,873 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:37:06,874 - trainer - INFO - ================================================================================
2025-01-21 11:37:06,874 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:37:06
2025-01-21 11:37:10,783 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:37:10
2025-01-21 11:37:10,784 - trainer - INFO -     epoch          : 36
2025-01-21 11:37:10,784 - trainer - INFO -     elapsed time   : 3.9095311164855957
2025-01-21 11:37:10,784 - trainer - INFO -     loss           : -2184.286730957031
2025-01-21 11:37:10,784 - trainer - INFO -     sim_loss       : 77.34680061340332
2025-01-21 11:37:10,784 - trainer - INFO -     gen_loss       : -3153.558239746094
2025-01-21 11:37:10,784 - trainer - INFO -     val_loss       : -1396.4896430969238
2025-01-21 11:37:10,784 - trainer - INFO -     val_sim_loss   : 41.32496643066406
2025-01-21 11:37:10,784 - trainer - INFO -     val_gen_loss   : -1437.8145942687988
2025-01-21 11:37:10,784 - trainer - INFO -     val_perplexity : -87.33863830566406
2025-01-21 11:37:10,784 - trainer - INFO -     val_embedding_sim: 0.10073013603687286
2025-01-21 11:37:10,784 - trainer - INFO - ================================================================================
2025-01-21 11:37:10,784 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:37:10
2025-01-21 11:37:14,628 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:37:14
2025-01-21 11:37:14,628 - trainer - INFO -     epoch          : 37
2025-01-21 11:37:14,628 - trainer - INFO -     elapsed time   : 3.843770742416382
2025-01-21 11:37:14,628 - trainer - INFO -     loss           : -2223.3567626953127
2025-01-21 11:37:14,628 - trainer - INFO -     sim_loss       : 77.26308059692383
2025-01-21 11:37:14,628 - trainer - INFO -     gen_loss       : -3209.3368286132813
2025-01-21 11:37:14,628 - trainer - INFO -     val_loss       : -1419.7557945251465
2025-01-21 11:37:14,628 - trainer - INFO -     val_sim_loss   : 43.289920806884766
2025-01-21 11:37:14,628 - trainer - INFO -     val_gen_loss   : -1463.045711517334
2025-01-21 11:37:14,628 - trainer - INFO -     val_perplexity : -87.90691375732422
2025-01-21 11:37:14,629 - trainer - INFO -     val_embedding_sim: 0.07766325026750565
2025-01-21 11:37:14,629 - trainer - INFO - ================================================================================
2025-01-21 11:37:14,629 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:37:14
2025-01-21 11:37:18,490 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:37:18
2025-01-21 11:37:18,490 - trainer - INFO -     epoch          : 38
2025-01-21 11:37:18,490 - trainer - INFO -     elapsed time   : 3.8615331649780273
2025-01-21 11:37:18,491 - trainer - INFO -     loss           : -2264.5408264160155
2025-01-21 11:37:18,491 - trainer - INFO -     sim_loss       : 76.34947700500489
2025-01-21 11:37:18,491 - trainer - INFO -     gen_loss       : -3267.779541015625
2025-01-21 11:37:18,491 - trainer - INFO -     val_loss       : -1450.1892471313477
2025-01-21 11:37:18,491 - trainer - INFO -     val_sim_loss   : 38.99394226074219
2025-01-21 11:37:18,491 - trainer - INFO -     val_gen_loss   : -1489.1831436157227
2025-01-21 11:37:18,491 - trainer - INFO -     val_perplexity : -89.48136138916016
2025-01-21 11:37:18,491 - trainer - INFO -     val_embedding_sim: 0.08502323925495148
2025-01-21 11:37:18,491 - trainer - INFO - ================================================================================
2025-01-21 11:37:18,491 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:37:18
2025-01-21 11:37:22,340 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:37:22
2025-01-21 11:37:22,340 - trainer - INFO -     epoch          : 39
2025-01-21 11:37:22,340 - trainer - INFO -     elapsed time   : 3.8492188453674316
2025-01-21 11:37:22,340 - trainer - INFO -     loss           : -2304.8083374023436
2025-01-21 11:37:22,341 - trainer - INFO -     sim_loss       : 76.81127166748047
2025-01-21 11:37:22,341 - trainer - INFO -     gen_loss       : -3325.5025390625
2025-01-21 11:37:22,341 - trainer - INFO -     val_loss       : -1474.651107788086
2025-01-21 11:37:22,341 - trainer - INFO -     val_sim_loss   : 40.969871520996094
2025-01-21 11:37:22,341 - trainer - INFO -     val_gen_loss   : -1515.6209564208984
2025-01-21 11:37:22,341 - trainer - INFO -     val_perplexity : -92.06000518798828
2025-01-21 11:37:22,341 - trainer - INFO -     val_embedding_sim: 0.11550602316856384
2025-01-21 11:37:22,341 - trainer - INFO - ================================================================================
2025-01-21 11:37:22,341 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:37:22
2025-01-21 11:37:26,190 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:37:26
2025-01-21 11:37:26,190 - trainer - INFO -     epoch          : 40
2025-01-21 11:37:26,190 - trainer - INFO -     elapsed time   : 3.8485870361328125
2025-01-21 11:37:26,190 - trainer - INFO -     loss           : -2345.038818359375
2025-01-21 11:37:26,190 - trainer - INFO -     sim_loss       : 77.0888011932373
2025-01-21 11:37:26,190 - trainer - INFO -     gen_loss       : -3383.0935791015627
2025-01-21 11:37:26,190 - trainer - INFO -     val_loss       : -1498.8420295715332
2025-01-21 11:37:26,190 - trainer - INFO -     val_sim_loss   : 42.892303466796875
2025-01-21 11:37:26,190 - trainer - INFO -     val_gen_loss   : -1541.7343635559082
2025-01-21 11:37:26,190 - trainer - INFO -     val_perplexity : -94.67070770263672
2025-01-21 11:37:26,190 - trainer - INFO -     val_embedding_sim: 0.1063811331987381
2025-01-21 11:37:32,748 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:37:39,347 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:37:39,348 - trainer - INFO - ================================================================================
2025-01-21 11:37:39,348 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:37:39
2025-01-21 11:37:43,244 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:37:43
2025-01-21 11:37:43,244 - trainer - INFO -     epoch          : 41
2025-01-21 11:37:43,244 - trainer - INFO -     elapsed time   : 3.8959996700286865
2025-01-21 11:37:43,244 - trainer - INFO -     loss           : -2385.9146728515625
2025-01-21 11:37:43,244 - trainer - INFO -     sim_loss       : 75.7332260131836
2025-01-21 11:37:43,244 - trainer - INFO -     gen_loss       : -3440.9067138671876
2025-01-21 11:37:43,244 - trainer - INFO -     val_loss       : -1524.7807083129883
2025-01-21 11:37:43,244 - trainer - INFO -     val_sim_loss   : 42.39923095703125
2025-01-21 11:37:43,244 - trainer - INFO -     val_gen_loss   : -1567.1800003051758
2025-01-21 11:37:43,244 - trainer - INFO -     val_perplexity : -94.17537689208984
2025-01-21 11:37:43,244 - trainer - INFO -     val_embedding_sim: 0.0976472869515419
2025-01-21 11:37:43,244 - trainer - INFO - ================================================================================
2025-01-21 11:37:43,244 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:37:43
2025-01-21 11:37:47,096 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:37:47
2025-01-21 11:37:47,096 - trainer - INFO -     epoch          : 42
2025-01-21 11:37:47,096 - trainer - INFO -     elapsed time   : 3.8515963554382324
2025-01-21 11:37:47,096 - trainer - INFO -     loss           : -2427.26064453125
2025-01-21 11:37:47,096 - trainer - INFO -     sim_loss       : 76.18685646057129
2025-01-21 11:37:47,096 - trainer - INFO -     gen_loss       : -3500.1667602539064
2025-01-21 11:37:47,096 - trainer - INFO -     val_loss       : -1549.9650421142578
2025-01-21 11:37:47,096 - trainer - INFO -     val_sim_loss   : 43.83110427856445
2025-01-21 11:37:47,097 - trainer - INFO -     val_gen_loss   : -1593.7960968017578
2025-01-21 11:37:47,097 - trainer - INFO -     val_perplexity : -95.95436096191406
2025-01-21 11:37:47,097 - trainer - INFO -     val_embedding_sim: 0.0856391042470932
2025-01-21 11:37:47,097 - trainer - INFO - ================================================================================
2025-01-21 11:37:47,097 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:37:47
2025-01-21 11:37:50,947 - trainer - INFO - Epoch 43 completed at 2025-01-21 11:37:50
2025-01-21 11:37:50,947 - trainer - INFO -     epoch          : 43
2025-01-21 11:37:50,947 - trainer - INFO -     elapsed time   : 3.850001811981201
2025-01-21 11:37:50,947 - trainer - INFO -     loss           : -2468.268347167969
2025-01-21 11:37:50,947 - trainer - INFO -     sim_loss       : 75.33574333190919
2025-01-21 11:37:50,947 - trainer - INFO -     gen_loss       : -3558.384387207031
2025-01-21 11:37:50,947 - trainer - INFO -     val_loss       : -1579.6711311340332
2025-01-21 11:37:50,947 - trainer - INFO -     val_sim_loss   : 40.06618118286133
2025-01-21 11:37:50,947 - trainer - INFO -     val_gen_loss   : -1619.7372932434082
2025-01-21 11:37:50,947 - trainer - INFO -     val_perplexity : -98.45176696777344
2025-01-21 11:37:50,947 - trainer - INFO -     val_embedding_sim: 0.10070370137691498
2025-01-21 11:37:50,947 - trainer - INFO - ================================================================================
2025-01-21 11:37:50,947 - trainer - INFO - Starting epoch 44 at 2025-01-21 11:37:50
2025-01-21 11:37:54,792 - trainer - INFO - Epoch 44 completed at 2025-01-21 11:37:54
2025-01-21 11:37:54,792 - trainer - INFO -     epoch          : 44
2025-01-21 11:37:54,793 - trainer - INFO -     elapsed time   : 3.844726085662842
2025-01-21 11:37:54,793 - trainer - INFO -     loss           : -2509.1872680664064
2025-01-21 11:37:54,793 - trainer - INFO -     sim_loss       : 74.28163471221924
2025-01-21 11:37:54,793 - trainer - INFO -     gen_loss       : -3616.3883422851563
2025-01-21 11:37:54,793 - trainer - INFO -     val_loss       : -1606.2369995117188
2025-01-21 11:37:54,793 - trainer - INFO -     val_sim_loss   : 39.384620666503906
2025-01-21 11:37:54,793 - trainer - INFO -     val_gen_loss   : -1645.6216430664062
2025-01-21 11:37:54,793 - trainer - INFO -     val_perplexity : -98.90141296386719
2025-01-21 11:37:54,793 - trainer - INFO -     val_embedding_sim: 0.09731203317642212
2025-01-21 11:37:54,793 - trainer - INFO - ================================================================================
2025-01-21 11:37:54,793 - trainer - INFO - Starting epoch 45 at 2025-01-21 11:37:54
2025-01-21 11:37:58,653 - trainer - INFO - Epoch 45 completed at 2025-01-21 11:37:58
2025-01-21 11:37:58,653 - trainer - INFO -     epoch          : 45
2025-01-21 11:37:58,653 - trainer - INFO -     elapsed time   : 3.8594396114349365
2025-01-21 11:37:58,653 - trainer - INFO -     loss           : -2550.0631591796873
2025-01-21 11:37:58,653 - trainer - INFO -     sim_loss       : 73.99302959442139
2025-01-21 11:37:58,653 - trainer - INFO -     gen_loss       : -3674.658728027344
2025-01-21 11:37:58,653 - trainer - INFO -     val_loss       : -1633.1077117919922
2025-01-21 11:37:58,653 - trainer - INFO -     val_sim_loss   : 37.862892150878906
2025-01-21 11:37:58,653 - trainer - INFO -     val_gen_loss   : -1670.9706268310547
2025-01-21 11:37:58,653 - trainer - INFO -     val_perplexity : -101.30294799804688
2025-01-21 11:37:58,653 - trainer - INFO -     val_embedding_sim: 0.09755571186542511
2025-01-21 11:38:05,195 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 11:38:11,798 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:38:11,798 - trainer - INFO - ================================================================================
2025-01-21 11:38:11,798 - trainer - INFO - Starting epoch 46 at 2025-01-21 11:38:11
2025-01-21 11:38:15,711 - trainer - INFO - Epoch 46 completed at 2025-01-21 11:38:15
2025-01-21 11:38:15,711 - trainer - INFO -     epoch          : 46
2025-01-21 11:38:15,711 - trainer - INFO -     elapsed time   : 3.912022590637207
2025-01-21 11:38:15,711 - trainer - INFO -     loss           : -2591.267712402344
2025-01-21 11:38:15,711 - trainer - INFO -     sim_loss       : 73.96552886962891
2025-01-21 11:38:15,711 - trainer - INFO -     gen_loss       : -3733.510632324219
2025-01-21 11:38:15,711 - trainer - INFO -     val_loss       : -1657.9219131469727
2025-01-21 11:38:15,711 - trainer - INFO -     val_sim_loss   : 40.40351867675781
2025-01-21 11:38:15,711 - trainer - INFO -     val_gen_loss   : -1698.3254776000977
2025-01-21 11:38:15,711 - trainer - INFO -     val_perplexity : -103.3705062866211
2025-01-21 11:38:15,711 - trainer - INFO -     val_embedding_sim: 0.09245061129331589
2025-01-21 11:38:15,711 - trainer - INFO - ================================================================================
2025-01-21 11:38:15,711 - trainer - INFO - Starting epoch 47 at 2025-01-21 11:38:15
2025-01-21 11:38:19,563 - trainer - INFO - Epoch 47 completed at 2025-01-21 11:38:19
2025-01-21 11:38:19,563 - trainer - INFO -     epoch          : 47
2025-01-21 11:38:19,563 - trainer - INFO -     elapsed time   : 3.851414918899536
2025-01-21 11:38:19,563 - trainer - INFO -     loss           : -2631.3988525390623
2025-01-21 11:38:19,563 - trainer - INFO -     sim_loss       : 76.4115644454956
2025-01-21 11:38:19,563 - trainer - INFO -     gen_loss       : -3791.8890869140623
2025-01-21 11:38:19,563 - trainer - INFO -     val_loss       : -1687.8711853027344
2025-01-21 11:38:19,563 - trainer - INFO -     val_sim_loss   : 36.902191162109375
2025-01-21 11:38:19,563 - trainer - INFO -     val_gen_loss   : -1724.7734069824219
2025-01-21 11:38:19,563 - trainer - INFO -     val_perplexity : -105.42739868164062
2025-01-21 11:38:19,563 - trainer - INFO -     val_embedding_sim: 0.10027376562356949
2025-01-21 11:38:19,563 - trainer - INFO - ================================================================================
2025-01-21 11:38:19,563 - trainer - INFO - Starting epoch 48 at 2025-01-21 11:38:19
2025-01-21 11:38:23,423 - trainer - INFO - Epoch 48 completed at 2025-01-21 11:38:23
2025-01-21 11:38:23,423 - trainer - INFO -     epoch          : 48
2025-01-21 11:38:23,423 - trainer - INFO -     elapsed time   : 3.8597142696380615
2025-01-21 11:38:23,423 - trainer - INFO -     loss           : -2673.606640625
2025-01-21 11:38:23,423 - trainer - INFO -     sim_loss       : 70.75715770721436
2025-01-21 11:38:23,423 - trainer - INFO -     gen_loss       : -3849.7626098632813
2025-01-21 11:38:23,424 - trainer - INFO -     val_loss       : -1714.1301803588867
2025-01-21 11:38:23,424 - trainer - INFO -     val_sim_loss   : 37.34070587158203
2025-01-21 11:38:23,424 - trainer - INFO -     val_gen_loss   : -1751.4708786010742
2025-01-21 11:38:23,424 - trainer - INFO -     val_perplexity : -104.18269348144531
2025-01-21 11:38:23,424 - trainer - INFO -     val_embedding_sim: 0.10375803709030151
2025-01-21 11:38:23,424 - trainer - INFO - ================================================================================
2025-01-21 11:38:23,424 - trainer - INFO - Starting epoch 49 at 2025-01-21 11:38:23
2025-01-21 11:38:27,283 - trainer - INFO - Epoch 49 completed at 2025-01-21 11:38:27
2025-01-21 11:38:27,283 - trainer - INFO -     epoch          : 49
2025-01-21 11:38:27,283 - trainer - INFO -     elapsed time   : 3.858851432800293
2025-01-21 11:38:27,283 - trainer - INFO -     loss           : -2711.926867675781
2025-01-21 11:38:27,283 - trainer - INFO -     sim_loss       : 75.55915088653565
2025-01-21 11:38:27,283 - trainer - INFO -     gen_loss       : -3906.563854980469
2025-01-21 11:38:27,283 - trainer - INFO -     val_loss       : -1737.6555252075195
2025-01-21 11:38:27,283 - trainer - INFO -     val_sim_loss   : 39.453426361083984
2025-01-21 11:38:27,283 - trainer - INFO -     val_gen_loss   : -1777.1088943481445
2025-01-21 11:38:27,283 - trainer - INFO -     val_perplexity : -105.70716857910156
2025-01-21 11:38:27,283 - trainer - INFO -     val_embedding_sim: 0.1044783964753151
2025-01-21 11:38:27,283 - trainer - INFO - ================================================================================
2025-01-21 11:38:27,283 - trainer - INFO - Starting epoch 50 at 2025-01-21 11:38:27
2025-01-21 11:38:31,142 - trainer - INFO - Epoch 50 completed at 2025-01-21 11:38:31
2025-01-21 11:38:31,142 - trainer - INFO -     epoch          : 50
2025-01-21 11:38:31,142 - trainer - INFO -     elapsed time   : 3.858666181564331
2025-01-21 11:38:31,142 - trainer - INFO -     loss           : -2753.8928833007812
2025-01-21 11:38:31,142 - trainer - INFO -     sim_loss       : 73.24702224731445
2025-01-21 11:38:31,142 - trainer - INFO -     gen_loss       : -3965.5243286132813
2025-01-21 11:38:31,143 - trainer - INFO -     val_loss       : -1765.5945892333984
2025-01-21 11:38:31,143 - trainer - INFO -     val_sim_loss   : 38.9703369140625
2025-01-21 11:38:31,143 - trainer - INFO -     val_gen_loss   : -1804.564926147461
2025-01-21 11:38:31,143 - trainer - INFO -     val_perplexity : -109.9386978149414
2025-01-21 11:38:31,143 - trainer - INFO -     val_embedding_sim: 0.09104909002780914
2025-01-21 11:38:37,697 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 11:38:44,297 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:38:44,297 - trainer - INFO - ================================================================================
2025-01-21 11:38:44,298 - trainer - INFO - Starting epoch 51 at 2025-01-21 11:38:44
2025-01-21 11:38:48,194 - trainer - INFO - Epoch 51 completed at 2025-01-21 11:38:48
2025-01-21 11:38:48,195 - trainer - INFO -     epoch          : 51
2025-01-21 11:38:48,195 - trainer - INFO -     elapsed time   : 3.8967435359954834
2025-01-21 11:38:48,195 - trainer - INFO -     loss           : -2795.883203125
2025-01-21 11:38:48,195 - trainer - INFO -     sim_loss       : 73.45217323303223
2025-01-21 11:38:48,195 - trainer - INFO -     gen_loss       : -4025.5984375
2025-01-21 11:38:48,195 - trainer - INFO -     val_loss       : -1793.0777893066406
2025-01-21 11:38:48,195 - trainer - INFO -     val_sim_loss   : 37.98595428466797
2025-01-21 11:38:48,195 - trainer - INFO -     val_gen_loss   : -1831.0637512207031
2025-01-21 11:38:48,195 - trainer - INFO -     val_perplexity : -110.23809051513672
2025-01-21 11:38:48,195 - trainer - INFO -     val_embedding_sim: 0.08676950633525848
2025-01-21 11:38:48,195 - trainer - INFO - ================================================================================
2025-01-21 11:38:48,195 - trainer - INFO - Starting epoch 52 at 2025-01-21 11:38:48
2025-01-21 11:38:52,048 - trainer - INFO - Epoch 52 completed at 2025-01-21 11:38:52
2025-01-21 11:38:52,049 - trainer - INFO -     epoch          : 52
2025-01-21 11:38:52,049 - trainer - INFO -     elapsed time   : 3.8532040119171143
2025-01-21 11:38:52,049 - trainer - INFO -     loss           : -2837.225927734375
2025-01-21 11:38:52,049 - trainer - INFO -     sim_loss       : 71.69684066772462
2025-01-21 11:38:52,049 - trainer - INFO -     gen_loss       : -4083.907189941406
2025-01-21 11:38:52,049 - trainer - INFO -     val_loss       : -1815.1030464172363
2025-01-21 11:38:52,049 - trainer - INFO -     val_sim_loss   : 41.84125900268555
2025-01-21 11:38:52,049 - trainer - INFO -     val_gen_loss   : -1856.9443550109863
2025-01-21 11:38:52,049 - trainer - INFO -     val_perplexity : -112.87704467773438
2025-01-21 11:38:52,049 - trainer - INFO -     val_embedding_sim: 0.11805813759565353
2025-01-21 11:38:52,049 - trainer - INFO - ================================================================================
2025-01-21 11:38:52,049 - trainer - INFO - Starting epoch 53 at 2025-01-21 11:38:52
2025-01-21 11:38:55,904 - trainer - INFO - Epoch 53 completed at 2025-01-21 11:38:55
2025-01-21 11:38:55,904 - trainer - INFO -     epoch          : 53
2025-01-21 11:38:55,904 - trainer - INFO -     elapsed time   : 3.8547964096069336
2025-01-21 11:38:55,904 - trainer - INFO -     loss           : -2878.731787109375
2025-01-21 11:38:55,904 - trainer - INFO -     sim_loss       : 70.25033912658691
2025-01-21 11:38:55,904 - trainer - INFO -     gen_loss       : -4142.581262207032
2025-01-21 11:38:55,904 - trainer - INFO -     val_loss       : -1845.7966384887695
2025-01-21 11:38:55,904 - trainer - INFO -     val_sim_loss   : 38.65176773071289
2025-01-21 11:38:55,904 - trainer - INFO -     val_gen_loss   : -1884.448371887207
2025-01-21 11:38:55,904 - trainer - INFO -     val_perplexity : -115.58982849121094
2025-01-21 11:38:55,904 - trainer - INFO -     val_embedding_sim: 0.09517958015203476
2025-01-21 11:38:55,904 - trainer - INFO - ================================================================================
2025-01-21 11:38:55,904 - trainer - INFO - Starting epoch 54 at 2025-01-21 11:38:55
2025-01-21 11:38:59,758 - trainer - INFO - Epoch 54 completed at 2025-01-21 11:38:59
2025-01-21 11:38:59,759 - trainer - INFO -     epoch          : 54
2025-01-21 11:38:59,759 - trainer - INFO -     elapsed time   : 3.853804349899292
2025-01-21 11:38:59,759 - trainer - INFO -     loss           : -2920.5029174804686
2025-01-21 11:38:59,759 - trainer - INFO -     sim_loss       : 69.8355058670044
2025-01-21 11:38:59,759 - trainer - INFO -     gen_loss       : -4202.076586914062
2025-01-21 11:38:59,759 - trainer - INFO -     val_loss       : -1873.1986389160156
2025-01-21 11:38:59,759 - trainer - INFO -     val_sim_loss   : 37.97411346435547
2025-01-21 11:38:59,759 - trainer - INFO -     val_gen_loss   : -1911.1727600097656
2025-01-21 11:38:59,759 - trainer - INFO -     val_perplexity : -115.0547866821289
2025-01-21 11:38:59,759 - trainer - INFO -     val_embedding_sim: 0.09239823371171951
2025-01-21 11:38:59,759 - trainer - INFO - ================================================================================
2025-01-21 11:38:59,759 - trainer - INFO - Starting epoch 55 at 2025-01-21 11:38:59
2025-01-21 11:39:03,613 - trainer - INFO - Epoch 55 completed at 2025-01-21 11:39:03
2025-01-21 11:39:03,614 - trainer - INFO -     epoch          : 55
2025-01-21 11:39:03,614 - trainer - INFO -     elapsed time   : 3.854220390319824
2025-01-21 11:39:03,614 - trainer - INFO -     loss           : -2961.2542724609375
2025-01-21 11:39:03,614 - trainer - INFO -     sim_loss       : 70.43880004882813
2025-01-21 11:39:03,614 - trainer - INFO -     gen_loss       : -4260.551342773438
2025-01-21 11:39:03,614 - trainer - INFO -     val_loss       : -1902.3735046386719
2025-01-21 11:39:03,614 - trainer - INFO -     val_sim_loss   : 35.92854690551758
2025-01-21 11:39:03,614 - trainer - INFO -     val_gen_loss   : -1938.3020935058594
2025-01-21 11:39:03,614 - trainer - INFO -     val_perplexity : -117.36457824707031
2025-01-21 11:39:03,614 - trainer - INFO -     val_embedding_sim: 0.11226416379213333
2025-01-21 11:39:10,174 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch55.pth ...
2025-01-21 11:39:16,798 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:39:16,799 - trainer - INFO - ================================================================================
2025-01-21 11:39:16,799 - trainer - INFO - Starting epoch 56 at 2025-01-21 11:39:16
2025-01-21 11:39:20,700 - trainer - INFO - Epoch 56 completed at 2025-01-21 11:39:20
2025-01-21 11:39:20,701 - trainer - INFO -     epoch          : 56
2025-01-21 11:39:20,701 - trainer - INFO -     elapsed time   : 3.901456117630005
2025-01-21 11:39:20,701 - trainer - INFO -     loss           : -3003.9733764648436
2025-01-21 11:39:20,701 - trainer - INFO -     sim_loss       : 69.51186714172363
2025-01-21 11:39:20,701 - trainer - INFO -     gen_loss       : -4321.181420898438
2025-01-21 11:39:20,701 - trainer - INFO -     val_loss       : -1926.7077865600586
2025-01-21 11:39:20,701 - trainer - INFO -     val_sim_loss   : 39.23253631591797
2025-01-21 11:39:20,701 - trainer - INFO -     val_gen_loss   : -1965.940330505371
2025-01-21 11:39:20,701 - trainer - INFO -     val_perplexity : -119.08241271972656
2025-01-21 11:39:20,701 - trainer - INFO -     val_embedding_sim: 0.09082214534282684
2025-01-21 11:39:20,701 - trainer - INFO - ================================================================================
2025-01-21 11:39:20,701 - trainer - INFO - Starting epoch 57 at 2025-01-21 11:39:20
2025-01-21 11:39:24,555 - trainer - INFO - Epoch 57 completed at 2025-01-21 11:39:24
2025-01-21 11:39:24,555 - trainer - INFO -     epoch          : 57
2025-01-21 11:39:24,555 - trainer - INFO -     elapsed time   : 3.8541078567504883
2025-01-21 11:39:24,555 - trainer - INFO -     loss           : -3047.860144042969
2025-01-21 11:39:24,555 - trainer - INFO -     sim_loss       : 67.12817039489747
2025-01-21 11:39:24,556 - trainer - INFO -     gen_loss       : -4382.855151367187
2025-01-21 11:39:24,556 - trainer - INFO -     val_loss       : -1956.1656494140625
2025-01-21 11:39:24,556 - trainer - INFO -     val_sim_loss   : 36.867820739746094
2025-01-21 11:39:24,556 - trainer - INFO -     val_gen_loss   : -1993.033447265625
2025-01-21 11:39:24,556 - trainer - INFO -     val_perplexity : -119.80303955078125
2025-01-21 11:39:24,556 - trainer - INFO -     val_embedding_sim: 0.08787734806537628
2025-01-21 11:39:24,556 - trainer - INFO - ================================================================================
2025-01-21 11:39:24,556 - trainer - INFO - Starting epoch 58 at 2025-01-21 11:39:24
2025-01-21 11:39:28,416 - trainer - INFO - Epoch 58 completed at 2025-01-21 11:39:28
2025-01-21 11:39:28,417 - trainer - INFO -     epoch          : 58
2025-01-21 11:39:28,417 - trainer - INFO -     elapsed time   : 3.860516309738159
2025-01-21 11:39:28,417 - trainer - INFO -     loss           : -3087.99580078125
2025-01-21 11:39:28,417 - trainer - INFO -     sim_loss       : 67.39743080139161
2025-01-21 11:39:28,417 - trainer - INFO -     gen_loss       : -4440.307202148438
2025-01-21 11:39:28,417 - trainer - INFO -     val_loss       : -1984.9580612182617
2025-01-21 11:39:28,417 - trainer - INFO -     val_sim_loss   : 35.626670837402344
2025-01-21 11:39:28,417 - trainer - INFO -     val_gen_loss   : -2020.5847702026367
2025-01-21 11:39:28,417 - trainer - INFO -     val_perplexity : -120.18952941894531
2025-01-21 11:39:28,417 - trainer - INFO -     val_embedding_sim: 0.1063355877995491
2025-01-21 11:39:28,417 - trainer - INFO - ================================================================================
2025-01-21 11:39:28,417 - trainer - INFO - Starting epoch 59 at 2025-01-21 11:39:28
2025-01-21 11:39:32,269 - trainer - INFO - Epoch 59 completed at 2025-01-21 11:39:32
2025-01-21 11:39:32,269 - trainer - INFO -     epoch          : 59
2025-01-21 11:39:32,269 - trainer - INFO -     elapsed time   : 3.8519866466522217
2025-01-21 11:39:32,269 - trainer - INFO -     loss           : -3129.365576171875
2025-01-21 11:39:32,269 - trainer - INFO -     sim_loss       : 70.77721519470215
2025-01-21 11:39:32,270 - trainer - INFO -     gen_loss       : -4500.855358886719
2025-01-21 11:39:32,270 - trainer - INFO -     val_loss       : -2013.987205505371
2025-01-21 11:39:32,270 - trainer - INFO -     val_sim_loss   : 33.510074615478516
2025-01-21 11:39:32,270 - trainer - INFO -     val_gen_loss   : -2047.4973373413086
2025-01-21 11:39:32,270 - trainer - INFO -     val_perplexity : -124.7423095703125
2025-01-21 11:39:32,270 - trainer - INFO -     val_embedding_sim: 0.07616426050662994
2025-01-21 11:39:32,270 - trainer - INFO - ================================================================================
2025-01-21 11:39:32,270 - trainer - INFO - Starting epoch 60 at 2025-01-21 11:39:32
2025-01-21 11:39:36,115 - trainer - INFO - Epoch 60 completed at 2025-01-21 11:39:36
2025-01-21 11:39:36,115 - trainer - INFO -     epoch          : 60
2025-01-21 11:39:36,115 - trainer - INFO -     elapsed time   : 3.845266819000244
2025-01-21 11:39:36,115 - trainer - INFO -     loss           : -3172.0904052734377
2025-01-21 11:39:36,116 - trainer - INFO -     sim_loss       : 69.09343318939209
2025-01-21 11:39:36,116 - trainer - INFO -     gen_loss       : -4561.169360351562
2025-01-21 11:39:36,116 - trainer - INFO -     val_loss       : -2039.872703552246
2025-01-21 11:39:36,116 - trainer - INFO -     val_sim_loss   : 34.60113525390625
2025-01-21 11:39:36,116 - trainer - INFO -     val_gen_loss   : -2074.4738998413086
2025-01-21 11:39:36,116 - trainer - INFO -     val_perplexity : -126.38379669189453
2025-01-21 11:39:36,116 - trainer - INFO -     val_embedding_sim: 0.10495314747095108
2025-01-21 11:39:42,667 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch60.pth ...
2025-01-21 11:39:49,255 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:39:49,255 - trainer - INFO - ================================================================================
2025-01-21 11:39:49,255 - trainer - INFO - Starting epoch 61 at 2025-01-21 11:39:49
2025-01-21 11:39:53,183 - trainer - INFO - Epoch 61 completed at 2025-01-21 11:39:53
2025-01-21 11:39:53,183 - trainer - INFO -     epoch          : 61
2025-01-21 11:39:53,183 - trainer - INFO -     elapsed time   : 3.9274678230285645
2025-01-21 11:39:53,183 - trainer - INFO -     loss           : -3214.6062744140627
2025-01-21 11:39:53,183 - trainer - INFO -     sim_loss       : 67.89113941192628
2025-01-21 11:39:53,183 - trainer - INFO -     gen_loss       : -4621.39091796875
2025-01-21 11:39:53,183 - trainer - INFO -     val_loss       : -2062.5592041015625
2025-01-21 11:39:53,183 - trainer - INFO -     val_sim_loss   : 38.85088348388672
2025-01-21 11:39:53,183 - trainer - INFO -     val_gen_loss   : -2101.4100341796875
2025-01-21 11:39:53,183 - trainer - INFO -     val_perplexity : -124.9877700805664
2025-01-21 11:39:53,183 - trainer - INFO -     val_embedding_sim: 0.08296334743499756
2025-01-21 11:39:53,183 - trainer - INFO - ================================================================================
2025-01-21 11:39:53,183 - trainer - INFO - Starting epoch 62 at 2025-01-21 11:39:53
2025-01-21 11:39:57,029 - trainer - INFO - Epoch 62 completed at 2025-01-21 11:39:57
2025-01-21 11:39:57,029 - trainer - INFO -     epoch          : 62
2025-01-21 11:39:57,029 - trainer - INFO -     elapsed time   : 3.845672130584717
2025-01-21 11:39:57,029 - trainer - INFO -     loss           : -3256.899938964844
2025-01-21 11:39:57,029 - trainer - INFO -     sim_loss       : 67.32930412292481
2025-01-21 11:39:57,029 - trainer - INFO -     gen_loss       : -4681.569738769531
2025-01-21 11:39:57,029 - trainer - INFO -     val_loss       : -2094.203800201416
2025-01-21 11:39:57,029 - trainer - INFO -     val_sim_loss   : 34.36250305175781
2025-01-21 11:39:57,029 - trainer - INFO -     val_gen_loss   : -2128.566349029541
2025-01-21 11:39:57,029 - trainer - INFO -     val_perplexity : -130.56100463867188
2025-01-21 11:39:57,029 - trainer - INFO -     val_embedding_sim: 0.09941250085830688
2025-01-21 11:39:57,029 - trainer - INFO - ================================================================================
2025-01-21 11:39:57,030 - trainer - INFO - Starting epoch 63 at 2025-01-21 11:39:57
2025-01-21 11:40:00,900 - trainer - INFO - Epoch 63 completed at 2025-01-21 11:40:00
2025-01-21 11:40:00,900 - trainer - INFO -     epoch          : 63
2025-01-21 11:40:00,900 - trainer - INFO -     elapsed time   : 3.8705294132232666
2025-01-21 11:40:00,900 - trainer - INFO -     loss           : -3298.88134765625
2025-01-21 11:40:00,901 - trainer - INFO -     sim_loss       : 66.12339134216309
2025-01-21 11:40:00,901 - trainer - INFO -     gen_loss       : -4741.026318359375
2025-01-21 11:40:00,901 - trainer - INFO -     val_loss       : -2117.917495727539
2025-01-21 11:40:00,901 - trainer - INFO -     val_sim_loss   : 38.50506591796875
2025-01-21 11:40:00,901 - trainer - INFO -     val_gen_loss   : -2156.422622680664
2025-01-21 11:40:00,901 - trainer - INFO -     val_perplexity : -128.25857543945312
2025-01-21 11:40:00,901 - trainer - INFO -     val_embedding_sim: 0.0908043161034584
2025-01-21 11:40:00,901 - trainer - INFO - ================================================================================
2025-01-21 11:40:00,901 - trainer - INFO - Starting epoch 64 at 2025-01-21 11:40:00
2025-01-21 11:40:04,766 - trainer - INFO - Epoch 64 completed at 2025-01-21 11:40:04
2025-01-21 11:40:04,766 - trainer - INFO -     epoch          : 64
2025-01-21 11:40:04,766 - trainer - INFO -     elapsed time   : 3.8648557662963867
2025-01-21 11:40:04,766 - trainer - INFO -     loss           : -3340.477746582031
2025-01-21 11:40:04,766 - trainer - INFO -     sim_loss       : 68.29282913208007
2025-01-21 11:40:04,766 - trainer - INFO -     gen_loss       : -4801.379443359375
2025-01-21 11:40:04,766 - trainer - INFO -     val_loss       : -2150.5014114379883
2025-01-21 11:40:04,766 - trainer - INFO -     val_sim_loss   : 33.39997863769531
2025-01-21 11:40:04,766 - trainer - INFO -     val_gen_loss   : -2183.9013137817383
2025-01-21 11:40:04,766 - trainer - INFO -     val_perplexity : -130.61631774902344
2025-01-21 11:40:04,766 - trainer - INFO -     val_embedding_sim: 0.10759813338518143
2025-01-21 11:40:04,766 - trainer - INFO - ================================================================================
2025-01-21 11:40:04,766 - trainer - INFO - Starting epoch 65 at 2025-01-21 11:40:04
2025-01-21 11:40:08,621 - trainer - INFO - Epoch 65 completed at 2025-01-21 11:40:08
2025-01-21 11:40:08,621 - trainer - INFO -     epoch          : 65
2025-01-21 11:40:08,621 - trainer - INFO -     elapsed time   : 3.8545684814453125
2025-01-21 11:40:08,621 - trainer - INFO -     loss           : -3385.2120727539063
2025-01-21 11:40:08,621 - trainer - INFO -     sim_loss       : 65.1438491821289
2025-01-21 11:40:08,621 - trainer - INFO -     gen_loss       : -4863.936010742187
2025-01-21 11:40:08,621 - trainer - INFO -     val_loss       : -2176.315528869629
2025-01-21 11:40:08,622 - trainer - INFO -     val_sim_loss   : 35.625282287597656
2025-01-21 11:40:08,622 - trainer - INFO -     val_gen_loss   : -2211.940773010254
2025-01-21 11:40:08,622 - trainer - INFO -     val_perplexity : -135.69491577148438
2025-01-21 11:40:08,622 - trainer - INFO -     val_embedding_sim: 0.07681941986083984
2025-01-21 11:40:15,281 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch65.pth ...
2025-01-21 11:40:21,873 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:40:21,874 - trainer - INFO - ================================================================================
2025-01-21 11:40:21,874 - trainer - INFO - Starting epoch 66 at 2025-01-21 11:40:21
2025-01-21 11:40:25,789 - trainer - INFO - Epoch 66 completed at 2025-01-21 11:40:25
2025-01-21 11:40:25,789 - trainer - INFO -     epoch          : 66
2025-01-21 11:40:25,789 - trainer - INFO -     elapsed time   : 3.9148364067077637
2025-01-21 11:40:25,789 - trainer - INFO -     loss           : -3425.6460815429687
2025-01-21 11:40:25,789 - trainer - INFO -     sim_loss       : 67.53076610565185
2025-01-21 11:40:25,789 - trainer - INFO -     gen_loss       : -4922.721984863281
2025-01-21 11:40:25,789 - trainer - INFO -     val_loss       : -2204.9837188720703
2025-01-21 11:40:25,789 - trainer - INFO -     val_sim_loss   : 33.96293640136719
2025-01-21 11:40:25,789 - trainer - INFO -     val_gen_loss   : -2238.9466094970703
2025-01-21 11:40:25,789 - trainer - INFO -     val_perplexity : -134.07745361328125
2025-01-21 11:40:25,789 - trainer - INFO -     val_embedding_sim: 0.10451582074165344
2025-01-21 11:40:25,789 - trainer - INFO - ================================================================================
2025-01-21 11:40:25,789 - trainer - INFO - Starting epoch 67 at 2025-01-21 11:40:25
2025-01-21 11:40:29,647 - trainer - INFO - Epoch 67 completed at 2025-01-21 11:40:29
2025-01-21 11:40:29,647 - trainer - INFO -     epoch          : 67
2025-01-21 11:40:29,647 - trainer - INFO -     elapsed time   : 3.8577089309692383
2025-01-21 11:40:29,647 - trainer - INFO -     loss           : -3469.8456298828123
2025-01-21 11:40:29,647 - trainer - INFO -     sim_loss       : 65.20297765731812
2025-01-21 11:40:29,647 - trainer - INFO -     gen_loss       : -4984.8665771484375
2025-01-21 11:40:29,647 - trainer - INFO -     val_loss       : -2234.6198654174805
2025-01-21 11:40:29,647 - trainer - INFO -     val_sim_loss   : 31.873641967773438
2025-01-21 11:40:29,647 - trainer - INFO -     val_gen_loss   : -2266.4934005737305
2025-01-21 11:40:29,648 - trainer - INFO -     val_perplexity : -137.24610900878906
2025-01-21 11:40:29,648 - trainer - INFO -     val_embedding_sim: 0.10185625404119492
2025-01-21 11:40:29,648 - trainer - INFO - ================================================================================
2025-01-21 11:40:29,648 - trainer - INFO - Starting epoch 68 at 2025-01-21 11:40:29
2025-01-21 11:40:33,499 - trainer - INFO - Epoch 68 completed at 2025-01-21 11:40:33
2025-01-21 11:40:33,499 - trainer - INFO -     epoch          : 68
2025-01-21 11:40:33,499 - trainer - INFO -     elapsed time   : 3.850823402404785
2025-01-21 11:40:33,499 - trainer - INFO -     loss           : -3511.760217285156
2025-01-21 11:40:33,499 - trainer - INFO -     sim_loss       : 62.902677631378175
2025-01-21 11:40:33,499 - trainer - INFO -     gen_loss       : -5043.75869140625
2025-01-21 11:40:33,499 - trainer - INFO -     val_loss       : -2261.3970336914062
2025-01-21 11:40:33,499 - trainer - INFO -     val_sim_loss   : 32.59728240966797
2025-01-21 11:40:33,499 - trainer - INFO -     val_gen_loss   : -2293.9942016601562
2025-01-21 11:40:33,499 - trainer - INFO -     val_perplexity : -139.34759521484375
2025-01-21 11:40:33,499 - trainer - INFO -     val_embedding_sim: 0.10231219232082367
2025-01-21 11:40:33,499 - trainer - INFO - ================================================================================
2025-01-21 11:40:33,499 - trainer - INFO - Starting epoch 69 at 2025-01-21 11:40:33
2025-01-21 11:40:37,350 - trainer - INFO - Epoch 69 completed at 2025-01-21 11:40:37
2025-01-21 11:40:37,350 - trainer - INFO -     epoch          : 69
2025-01-21 11:40:37,350 - trainer - INFO -     elapsed time   : 3.850903272628784
2025-01-21 11:40:37,351 - trainer - INFO -     loss           : -3554.969519042969
2025-01-21 11:40:37,351 - trainer - INFO -     sim_loss       : 63.04167652130127
2025-01-21 11:40:37,351 - trainer - INFO -     gen_loss       : -5105.545837402344
2025-01-21 11:40:37,351 - trainer - INFO -     val_loss       : -2290.2427673339844
2025-01-21 11:40:37,351 - trainer - INFO -     val_sim_loss   : 32.42544174194336
2025-01-21 11:40:37,351 - trainer - INFO -     val_gen_loss   : -2322.6683044433594
2025-01-21 11:40:37,351 - trainer - INFO -     val_perplexity : -140.94505310058594
2025-01-21 11:40:37,351 - trainer - INFO -     val_embedding_sim: 0.10396154969930649
2025-01-21 11:40:37,351 - trainer - INFO - ================================================================================
2025-01-21 11:40:37,351 - trainer - INFO - Starting epoch 70 at 2025-01-21 11:40:37
2025-01-21 11:40:41,204 - trainer - INFO - Epoch 70 completed at 2025-01-21 11:40:41
2025-01-21 11:40:41,204 - trainer - INFO -     epoch          : 70
2025-01-21 11:40:41,204 - trainer - INFO -     elapsed time   : 3.852869749069214
2025-01-21 11:40:41,204 - trainer - INFO -     loss           : -3597.9919311523436
2025-01-21 11:40:41,204 - trainer - INFO -     sim_loss       : 64.13758068084717
2025-01-21 11:40:41,204 - trainer - INFO -     gen_loss       : -5167.476098632813
2025-01-21 11:40:41,204 - trainer - INFO -     val_loss       : -2314.008499145508
2025-01-21 11:40:41,204 - trainer - INFO -     val_sim_loss   : 37.4765625
2025-01-21 11:40:41,204 - trainer - INFO -     val_gen_loss   : -2351.485061645508
2025-01-21 11:40:41,204 - trainer - INFO -     val_perplexity : -142.64352416992188
2025-01-21 11:40:41,204 - trainer - INFO -     val_embedding_sim: 0.07707889378070831
