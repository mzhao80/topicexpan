2025-01-21 11:01:04,762 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:01:07,093 - trainer - INFO - ================================================================================
2025-01-21 11:01:07,093 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:01:07
2025-01-21 11:03:40,474 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:03:42,799 - trainer - INFO - ================================================================================
2025-01-21 11:03:42,799 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:03:42
2025-01-21 11:03:48,569 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:03:48
2025-01-21 11:03:48,570 - trainer - INFO -     epoch          : 1
2025-01-21 11:03:48,570 - trainer - INFO -     elapsed time   : 5.769897222518921
2025-01-21 11:03:48,570 - trainer - INFO -     loss           : 926.0519439697266
2025-01-21 11:03:48,570 - trainer - INFO -     sim_loss       : 80.15059967041016
2025-01-21 11:03:48,570 - trainer - INFO -     gen_loss       : 1288.581137084961
2025-01-21 11:03:48,570 - trainer - INFO -     val_loss       : 597.9047985076904
2025-01-21 11:03:48,570 - trainer - INFO -     val_sim_loss   : 30.897884368896484
2025-01-21 11:03:48,570 - trainer - INFO -     val_gen_loss   : 567.0069103240967
2025-01-21 11:03:48,570 - trainer - INFO -     val_perplexity : 34.28977584838867
2025-01-21 11:03:48,570 - trainer - INFO -     val_embedding_sim: 0.13666823506355286
2025-01-21 11:03:48,570 - trainer - INFO - ================================================================================
2025-01-21 11:03:48,570 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:03:48
2025-01-21 11:03:53,132 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:03:53
2025-01-21 11:03:53,132 - trainer - INFO -     epoch          : 2
2025-01-21 11:03:53,132 - trainer - INFO -     elapsed time   : 4.561354637145996
2025-01-21 11:03:53,132 - trainer - INFO -     loss           : 818.1401336669921
2025-01-21 11:03:53,132 - trainer - INFO -     sim_loss       : 44.15964412689209
2025-01-21 11:03:53,132 - trainer - INFO -     gen_loss       : 1149.8460571289063
2025-01-21 11:03:53,132 - trainer - INFO -     val_loss       : 568.61376953125
2025-01-21 11:03:53,132 - trainer - INFO -     val_sim_loss   : 25.156253814697266
2025-01-21 11:03:53,132 - trainer - INFO -     val_gen_loss   : 543.45751953125
2025-01-21 11:03:53,132 - trainer - INFO -     val_perplexity : 32.679656982421875
2025-01-21 11:03:53,132 - trainer - INFO -     val_embedding_sim: 0.12289004027843475
2025-01-21 11:03:53,132 - trainer - INFO - ================================================================================
2025-01-21 11:03:53,132 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:03:53
2025-01-21 11:03:57,703 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:03:57
2025-01-21 11:03:57,703 - trainer - INFO -     epoch          : 3
2025-01-21 11:03:57,703 - trainer - INFO -     elapsed time   : 4.5706470012664795
2025-01-21 11:03:57,703 - trainer - INFO -     loss           : 769.9964965820312
2025-01-21 11:03:57,703 - trainer - INFO -     sim_loss       : 31.62858376502991
2025-01-21 11:03:57,703 - trainer - INFO -     gen_loss       : 1086.4399047851562
2025-01-21 11:03:57,703 - trainer - INFO -     val_loss       : 539.9116134643555
2025-01-21 11:03:57,703 - trainer - INFO -     val_sim_loss   : 18.201324462890625
2025-01-21 11:03:57,703 - trainer - INFO -     val_gen_loss   : 521.7102890014648
2025-01-21 11:03:57,703 - trainer - INFO -     val_perplexity : 30.639623641967773
2025-01-21 11:03:57,703 - trainer - INFO -     val_embedding_sim: 0.12869185209274292
2025-01-21 11:03:57,703 - trainer - INFO - ================================================================================
2025-01-21 11:03:57,703 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:03:57
2025-01-21 11:04:02,280 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:04:02
2025-01-21 11:04:02,280 - trainer - INFO -     epoch          : 4
2025-01-21 11:04:02,280 - trainer - INFO -     elapsed time   : 4.576574325561523
2025-01-21 11:04:02,280 - trainer - INFO -     loss           : 725.3969787597656
2025-01-21 11:04:02,280 - trainer - INFO -     sim_loss       : 32.78736534118652
2025-01-21 11:04:02,280 - trainer - INFO -     gen_loss       : 1022.2296752929688
2025-01-21 11:04:02,280 - trainer - INFO -     val_loss       : 523.198091506958
2025-01-21 11:04:02,280 - trainer - INFO -     val_sim_loss   : 23.64540672302246
2025-01-21 11:04:02,280 - trainer - INFO -     val_gen_loss   : 499.5526752471924
2025-01-21 11:04:02,281 - trainer - INFO -     val_perplexity : 29.813417434692383
2025-01-21 11:04:02,281 - trainer - INFO -     val_embedding_sim: 0.12147559225559235
2025-01-21 11:04:02,281 - trainer - INFO - ================================================================================
2025-01-21 11:04:02,281 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:04:02
2025-01-21 11:04:06,842 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:04:06
2025-01-21 11:04:06,843 - trainer - INFO -     epoch          : 5
2025-01-21 11:04:06,843 - trainer - INFO -     elapsed time   : 4.561597585678101
2025-01-21 11:04:06,843 - trainer - INFO -     loss           : 679.582080078125
2025-01-21 11:04:06,843 - trainer - INFO -     sim_loss       : 34.431762504577634
2025-01-21 11:04:06,843 - trainer - INFO -     gen_loss       : 956.0750854492187
2025-01-21 11:04:06,843 - trainer - INFO -     val_loss       : 490.88640880584717
2025-01-21 11:04:06,843 - trainer - INFO -     val_sim_loss   : 16.582721710205078
2025-01-21 11:04:06,843 - trainer - INFO -     val_gen_loss   : 474.3036756515503
2025-01-21 11:04:06,843 - trainer - INFO -     val_perplexity : 28.8875675201416
2025-01-21 11:04:06,843 - trainer - INFO -     val_embedding_sim: 0.12403754889965057
2025-01-21 11:04:13,400 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:04:19,930 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:04:19,930 - trainer - INFO - ================================================================================
2025-01-21 11:04:19,930 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:04:19
2025-01-21 11:04:24,561 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:04:24
2025-01-21 11:04:24,562 - trainer - INFO -     epoch          : 6
2025-01-21 11:04:24,562 - trainer - INFO -     elapsed time   : 4.631126165390015
2025-01-21 11:04:24,562 - trainer - INFO -     loss           : 631.5764312744141
2025-01-21 11:04:24,562 - trainer - INFO -     sim_loss       : 34.07801918983459
2025-01-21 11:04:24,562 - trainer - INFO -     gen_loss       : 887.6471923828125
2025-01-21 11:04:24,562 - trainer - INFO -     val_loss       : 465.33051204681396
2025-01-21 11:04:24,562 - trainer - INFO -     val_sim_loss   : 12.27341079711914
2025-01-21 11:04:24,562 - trainer - INFO -     val_gen_loss   : 453.0571050643921
2025-01-21 11:04:24,562 - trainer - INFO -     val_perplexity : 27.352720260620117
2025-01-21 11:04:24,562 - trainer - INFO -     val_embedding_sim: 0.14163225889205933
2025-01-21 11:04:24,562 - trainer - INFO - ================================================================================
2025-01-21 11:04:24,562 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:04:24
2025-01-21 11:04:29,139 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:04:29
2025-01-21 11:04:29,139 - trainer - INFO -     epoch          : 7
2025-01-21 11:04:29,139 - trainer - INFO -     elapsed time   : 4.5769476890563965
2025-01-21 11:04:29,139 - trainer - INFO -     loss           : 589.1849075317383
2025-01-21 11:04:29,139 - trainer - INFO -     sim_loss       : 31.078872680664062
2025-01-21 11:04:29,139 - trainer - INFO -     gen_loss       : 828.3732299804688
2025-01-21 11:04:29,139 - trainer - INFO -     val_loss       : 450.8620386123657
2025-01-21 11:04:29,140 - trainer - INFO -     val_sim_loss   : 14.327374458312988
2025-01-21 11:04:29,140 - trainer - INFO -     val_gen_loss   : 436.53467655181885
2025-01-21 11:04:29,140 - trainer - INFO -     val_perplexity : 26.328960418701172
2025-01-21 11:04:29,140 - trainer - INFO -     val_embedding_sim: 0.12669633328914642
2025-01-21 11:04:29,140 - trainer - INFO - ================================================================================
2025-01-21 11:04:29,140 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:04:29
2025-01-21 11:04:33,707 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:04:33
2025-01-21 11:04:33,707 - trainer - INFO -     epoch          : 8
2025-01-21 11:04:33,708 - trainer - INFO -     elapsed time   : 4.567424297332764
2025-01-21 11:04:33,708 - trainer - INFO -     loss           : 554.25791015625
2025-01-21 11:04:33,708 - trainer - INFO -     sim_loss       : 29.116330003738405
2025-01-21 11:04:33,708 - trainer - INFO -     gen_loss       : 779.3186126708985
2025-01-21 11:04:33,708 - trainer - INFO -     val_loss       : 442.81386137008667
2025-01-21 11:04:33,708 - trainer - INFO -     val_sim_loss   : 16.141357421875
2025-01-21 11:04:33,708 - trainer - INFO -     val_gen_loss   : 426.67250394821167
2025-01-21 11:04:33,708 - trainer - INFO -     val_perplexity : 26.25133514404297
2025-01-21 11:04:33,708 - trainer - INFO -     val_embedding_sim: 0.1423085629940033
2025-01-21 11:04:33,708 - trainer - INFO - ================================================================================
2025-01-21 11:04:33,708 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:04:33
2025-01-21 11:04:38,278 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:04:38
2025-01-21 11:04:38,278 - trainer - INFO -     epoch          : 9
2025-01-21 11:04:38,278 - trainer - INFO -     elapsed time   : 4.5699896812438965
2025-01-21 11:04:38,278 - trainer - INFO -     loss           : 523.0952331542969
2025-01-21 11:04:38,278 - trainer - INFO -     sim_loss       : 33.39409275054932
2025-01-21 11:04:38,278 - trainer - INFO -     gen_loss       : 732.9671691894531
2025-01-21 11:04:38,278 - trainer - INFO -     val_loss       : 431.00056171417236
2025-01-21 11:04:38,278 - trainer - INFO -     val_sim_loss   : 13.267549514770508
2025-01-21 11:04:38,278 - trainer - INFO -     val_gen_loss   : 417.7330141067505
2025-01-21 11:04:38,279 - trainer - INFO -     val_perplexity : 25.40492820739746
2025-01-21 11:04:38,279 - trainer - INFO -     val_embedding_sim: 0.10869182646274567
2025-01-21 11:04:38,279 - trainer - INFO - ================================================================================
2025-01-21 11:04:38,279 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:04:38
2025-01-21 11:04:42,881 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:04:42
2025-01-21 11:04:42,881 - trainer - INFO -     epoch          : 10
2025-01-21 11:04:42,881 - trainer - INFO -     elapsed time   : 4.6018993854522705
2025-01-21 11:04:42,881 - trainer - INFO -     loss           : 491.5878143310547
2025-01-21 11:04:42,881 - trainer - INFO -     sim_loss       : 27.67424144744873
2025-01-21 11:04:42,881 - trainer - INFO -     gen_loss       : 690.407925415039
2025-01-21 11:04:42,881 - trainer - INFO -     val_loss       : 425.7060203552246
2025-01-21 11:04:42,881 - trainer - INFO -     val_sim_loss   : 17.344375610351562
2025-01-21 11:04:42,881 - trainer - INFO -     val_gen_loss   : 408.361629486084
2025-01-21 11:04:42,881 - trainer - INFO -     val_perplexity : 24.039384841918945
2025-01-21 11:04:42,881 - trainer - INFO -     val_embedding_sim: 0.09287156909704208
2025-01-21 11:04:49,408 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:04:55,988 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:04:55,989 - trainer - INFO - ================================================================================
2025-01-21 11:04:55,989 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:04:55
2025-01-21 11:05:00,669 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:05:00
2025-01-21 11:05:00,669 - trainer - INFO -     epoch          : 11
2025-01-21 11:05:00,669 - trainer - INFO -     elapsed time   : 4.67994236946106
2025-01-21 11:05:00,669 - trainer - INFO -     loss           : 464.9297836303711
2025-01-21 11:05:00,669 - trainer - INFO -     sim_loss       : 30.61037149429321
2025-01-21 11:05:00,669 - trainer - INFO -     gen_loss       : 651.0666900634766
2025-01-21 11:05:00,669 - trainer - INFO -     val_loss       : 418.3226079940796
2025-01-21 11:05:00,669 - trainer - INFO -     val_sim_loss   : 11.309075355529785
2025-01-21 11:05:00,669 - trainer - INFO -     val_gen_loss   : 407.0135259628296
2025-01-21 11:05:00,669 - trainer - INFO -     val_perplexity : 24.466413497924805
2025-01-21 11:05:00,669 - trainer - INFO -     val_embedding_sim: 0.09262049198150635
2025-01-21 11:05:00,669 - trainer - INFO - ================================================================================
2025-01-21 11:05:00,669 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:05:00
2025-01-21 11:05:05,255 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:05:05
2025-01-21 11:05:05,255 - trainer - INFO -     epoch          : 12
2025-01-21 11:05:05,255 - trainer - INFO -     elapsed time   : 4.5855443477630615
2025-01-21 11:05:05,255 - trainer - INFO -     loss           : 438.79956970214846
2025-01-21 11:05:05,255 - trainer - INFO -     sim_loss       : 29.593007850646973
2025-01-21 11:05:05,256 - trainer - INFO -     gen_loss       : 614.1738159179688
2025-01-21 11:05:05,256 - trainer - INFO -     val_loss       : 419.10369205474854
2025-01-21 11:05:05,256 - trainer - INFO -     val_sim_loss   : 22.183757781982422
2025-01-21 11:05:05,256 - trainer - INFO -     val_gen_loss   : 396.9199457168579
2025-01-21 11:05:05,256 - trainer - INFO -     val_perplexity : 23.82119369506836
2025-01-21 11:05:05,256 - trainer - INFO -     val_embedding_sim: 0.09391862154006958
2025-01-21 11:05:05,256 - trainer - INFO - ================================================================================
2025-01-21 11:05:05,256 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:05:05
2025-01-21 11:05:09,814 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:05:09
2025-01-21 11:05:09,814 - trainer - INFO -     epoch          : 13
2025-01-21 11:05:09,815 - trainer - INFO -     elapsed time   : 4.5583672523498535
2025-01-21 11:05:09,815 - trainer - INFO -     loss           : 418.70814056396483
2025-01-21 11:05:09,815 - trainer - INFO -     sim_loss       : 27.70587158203125
2025-01-21 11:05:09,815 - trainer - INFO -     gen_loss       : 586.2805480957031
2025-01-21 11:05:09,815 - trainer - INFO -     val_loss       : 410.1313934326172
2025-01-21 11:05:09,815 - trainer - INFO -     val_sim_loss   : 13.565485000610352
2025-01-21 11:05:09,815 - trainer - INFO -     val_gen_loss   : 396.56590270996094
2025-01-21 11:05:09,815 - trainer - INFO -     val_perplexity : 23.933002471923828
2025-01-21 11:05:09,815 - trainer - INFO -     val_embedding_sim: 0.11216865479946136
2025-01-21 11:05:09,815 - trainer - INFO - ================================================================================
2025-01-21 11:05:09,815 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:05:09
2025-01-21 11:05:14,429 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:05:14
2025-01-21 11:05:14,430 - trainer - INFO -     epoch          : 14
2025-01-21 11:05:14,430 - trainer - INFO -     elapsed time   : 4.614391088485718
2025-01-21 11:05:14,430 - trainer - INFO -     loss           : 398.6117248535156
2025-01-21 11:05:14,430 - trainer - INFO -     sim_loss       : 26.843203639984132
2025-01-21 11:05:14,430 - trainer - INFO -     gen_loss       : 557.9410949707031
2025-01-21 11:05:14,430 - trainer - INFO -     val_loss       : 403.31173038482666
2025-01-21 11:05:14,430 - trainer - INFO -     val_sim_loss   : 13.994431495666504
2025-01-21 11:05:14,430 - trainer - INFO -     val_gen_loss   : 389.3172845840454
2025-01-21 11:05:14,430 - trainer - INFO -     val_perplexity : 24.07252311706543
2025-01-21 11:05:14,430 - trainer - INFO -     val_embedding_sim: 0.10106629133224487
2025-01-21 11:05:14,430 - trainer - INFO - ================================================================================
2025-01-21 11:05:14,430 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:05:14
2025-01-21 11:05:19,004 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:05:19
2025-01-21 11:05:19,004 - trainer - INFO -     epoch          : 15
2025-01-21 11:05:19,004 - trainer - INFO -     elapsed time   : 4.573880910873413
2025-01-21 11:05:19,004 - trainer - INFO -     loss           : 379.553173828125
2025-01-21 11:05:19,004 - trainer - INFO -     sim_loss       : 29.399465084075928
2025-01-21 11:05:19,004 - trainer - INFO -     gen_loss       : 529.6190628051758
2025-01-21 11:05:19,004 - trainer - INFO -     val_loss       : 400.81122493743896
2025-01-21 11:05:19,004 - trainer - INFO -     val_sim_loss   : 11.285567283630371
2025-01-21 11:05:19,004 - trainer - INFO -     val_gen_loss   : 389.52567195892334
2025-01-21 11:05:19,004 - trainer - INFO -     val_perplexity : 23.721189498901367
2025-01-21 11:05:19,004 - trainer - INFO -     val_embedding_sim: 0.14927928149700165
2025-01-21 11:05:25,562 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:05:25,562 - trainer - INFO - ================================================================================
2025-01-21 11:05:25,563 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:05:25
2025-01-21 11:05:30,154 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:05:30
2025-01-21 11:05:30,154 - trainer - INFO -     epoch          : 16
2025-01-21 11:05:30,154 - trainer - INFO -     elapsed time   : 4.591327667236328
2025-01-21 11:05:30,154 - trainer - INFO -     loss           : 362.56701507568357
2025-01-21 11:05:30,154 - trainer - INFO -     sim_loss       : 28.248128271102907
2025-01-21 11:05:30,154 - trainer - INFO -     gen_loss       : 505.8465515136719
2025-01-21 11:05:30,154 - trainer - INFO -     val_loss       : 410.37131357192993
2025-01-21 11:05:30,154 - trainer - INFO -     val_sim_loss   : 22.40926170349121
2025-01-21 11:05:30,154 - trainer - INFO -     val_gen_loss   : 387.96204233169556
2025-01-21 11:05:30,155 - trainer - INFO -     val_perplexity : 23.8521728515625
2025-01-21 11:05:30,155 - trainer - INFO -     val_embedding_sim: 0.11508586257696152
2025-01-21 11:05:30,155 - trainer - INFO - ================================================================================
2025-01-21 11:05:30,155 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:05:30
2025-01-21 11:05:34,716 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:05:34
2025-01-21 11:05:34,716 - trainer - INFO -     epoch          : 17
2025-01-21 11:05:34,716 - trainer - INFO -     elapsed time   : 4.561405181884766
2025-01-21 11:05:34,716 - trainer - INFO -     loss           : 348.59795532226565
2025-01-21 11:05:34,716 - trainer - INFO -     sim_loss       : 31.981904792785645
2025-01-21 11:05:34,716 - trainer - INFO -     gen_loss       : 484.2905471801758
2025-01-21 11:05:34,716 - trainer - INFO -     val_loss       : 392.96069717407227
2025-01-21 11:05:34,716 - trainer - INFO -     val_sim_loss   : 11.984954833984375
2025-01-21 11:05:34,716 - trainer - INFO -     val_gen_loss   : 380.9757423400879
2025-01-21 11:05:34,717 - trainer - INFO -     val_perplexity : 22.341129302978516
2025-01-21 11:05:34,717 - trainer - INFO -     val_embedding_sim: 0.13425487279891968
2025-01-21 11:05:34,717 - trainer - INFO - ================================================================================
2025-01-21 11:05:34,717 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:05:34
2025-01-21 11:05:39,288 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:05:39
2025-01-21 11:05:39,288 - trainer - INFO -     epoch          : 18
2025-01-21 11:05:39,288 - trainer - INFO -     elapsed time   : 4.571536064147949
2025-01-21 11:05:39,289 - trainer - INFO -     loss           : 332.93125
2025-01-21 11:05:39,289 - trainer - INFO -     sim_loss       : 30.995863723754884
2025-01-21 11:05:39,289 - trainer - INFO -     gen_loss       : 462.33212890625
2025-01-21 11:05:39,289 - trainer - INFO -     val_loss       : 395.7828621864319
2025-01-21 11:05:39,289 - trainer - INFO -     val_sim_loss   : 14.72945785522461
2025-01-21 11:05:39,289 - trainer - INFO -     val_gen_loss   : 381.05340051651
2025-01-21 11:05:39,289 - trainer - INFO -     val_perplexity : 23.6783390045166
2025-01-21 11:05:39,289 - trainer - INFO -     val_embedding_sim: 0.12871184945106506
2025-01-21 11:05:39,289 - trainer - INFO - ================================================================================
2025-01-21 11:05:39,289 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:05:39
2025-01-21 11:05:43,858 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:05:43
2025-01-21 11:05:43,858 - trainer - INFO -     epoch          : 19
2025-01-21 11:05:43,858 - trainer - INFO -     elapsed time   : 4.568909168243408
2025-01-21 11:05:43,858 - trainer - INFO -     loss           : 317.53098449707034
2025-01-21 11:05:43,858 - trainer - INFO -     sim_loss       : 26.617593193054198
2025-01-21 11:05:43,858 - trainer - INFO -     gen_loss       : 442.20815124511716
2025-01-21 11:05:43,858 - trainer - INFO -     val_loss       : 400.50645446777344
2025-01-21 11:05:43,858 - trainer - INFO -     val_sim_loss   : 16.905010223388672
2025-01-21 11:05:43,858 - trainer - INFO -     val_gen_loss   : 383.60145568847656
2025-01-21 11:05:43,858 - trainer - INFO -     val_perplexity : 21.875045776367188
2025-01-21 11:05:43,858 - trainer - INFO -     val_embedding_sim: 0.12683440744876862
2025-01-21 11:05:43,858 - trainer - INFO - ================================================================================
2025-01-21 11:05:43,859 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:05:43
2025-01-21 11:05:48,475 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:05:48
2025-01-21 11:05:48,475 - trainer - INFO -     epoch          : 20
2025-01-21 11:05:48,475 - trainer - INFO -     elapsed time   : 4.616438627243042
2025-01-21 11:05:48,475 - trainer - INFO -     loss           : 304.07374267578126
2025-01-21 11:05:48,475 - trainer - INFO -     sim_loss       : 26.845297050476074
2025-01-21 11:05:48,475 - trainer - INFO -     gen_loss       : 422.88594512939454
2025-01-21 11:05:48,475 - trainer - INFO -     val_loss       : 396.75442457199097
2025-01-21 11:05:48,475 - trainer - INFO -     val_sim_loss   : 13.29230785369873
2025-01-21 11:05:48,476 - trainer - INFO -     val_gen_loss   : 383.4621272087097
2025-01-21 11:05:48,476 - trainer - INFO -     val_perplexity : 23.7319393157959
2025-01-21 11:05:48,476 - trainer - INFO -     val_embedding_sim: 0.12024622410535812
2025-01-21 11:05:55,016 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:05:55,016 - trainer - INFO - ================================================================================
2025-01-21 11:05:55,016 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:05:55
2025-01-21 11:05:59,628 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:05:59
2025-01-21 11:05:59,628 - trainer - INFO -     epoch          : 21
2025-01-21 11:05:59,628 - trainer - INFO -     elapsed time   : 4.611464262008667
2025-01-21 11:05:59,628 - trainer - INFO -     loss           : 289.8626235961914
2025-01-21 11:05:59,628 - trainer - INFO -     sim_loss       : 26.495360946655275
2025-01-21 11:05:59,628 - trainer - INFO -     gen_loss       : 402.73431701660155
2025-01-21 11:05:59,628 - trainer - INFO -     val_loss       : 404.3116569519043
2025-01-21 11:05:59,628 - trainer - INFO -     val_sim_loss   : 20.561983108520508
2025-01-21 11:05:59,628 - trainer - INFO -     val_gen_loss   : 383.7496757507324
2025-01-21 11:05:59,628 - trainer - INFO -     val_perplexity : 22.541950225830078
2025-01-21 11:05:59,628 - trainer - INFO -     val_embedding_sim: 0.13378143310546875
2025-01-21 11:05:59,628 - trainer - INFO - ================================================================================
2025-01-21 11:05:59,628 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:05:59
2025-01-21 11:06:04,212 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:06:04
2025-01-21 11:06:04,212 - trainer - INFO -     epoch          : 22
2025-01-21 11:06:04,212 - trainer - INFO -     elapsed time   : 4.583429574966431
2025-01-21 11:06:04,212 - trainer - INFO -     loss           : 278.73849029541014
2025-01-21 11:06:04,212 - trainer - INFO -     sim_loss       : 28.3484069455415
2025-01-21 11:06:04,212 - trainer - INFO -     gen_loss       : 386.04854278564454
2025-01-21 11:06:04,212 - trainer - INFO -     val_loss       : 401.3933849334717
2025-01-21 11:06:04,212 - trainer - INFO -     val_sim_loss   : 21.331533432006836
2025-01-21 11:06:04,212 - trainer - INFO -     val_gen_loss   : 380.0618419647217
2025-01-21 11:06:04,212 - trainer - INFO -     val_perplexity : 22.21444320678711
2025-01-21 11:06:04,212 - trainer - INFO -     val_embedding_sim: 0.0923214852809906
2025-01-21 11:06:04,212 - trainer - INFO - ================================================================================
2025-01-21 11:06:04,212 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:06:04
2025-01-21 11:06:08,796 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:06:08
2025-01-21 11:06:08,796 - trainer - INFO -     epoch          : 23
2025-01-21 11:06:08,796 - trainer - INFO -     elapsed time   : 4.583087205886841
2025-01-21 11:06:08,796 - trainer - INFO -     loss           : 267.6239471435547
2025-01-21 11:06:08,796 - trainer - INFO -     sim_loss       : 26.38816108703613
2025-01-21 11:06:08,796 - trainer - INFO -     gen_loss       : 371.0107162475586
2025-01-21 11:06:08,796 - trainer - INFO -     val_loss       : 394.9864454269409
2025-01-21 11:06:08,796 - trainer - INFO -     val_sim_loss   : 13.367634773254395
2025-01-21 11:06:08,796 - trainer - INFO -     val_gen_loss   : 381.61880016326904
2025-01-21 11:06:08,796 - trainer - INFO -     val_perplexity : 23.28582763671875
2025-01-21 11:06:08,796 - trainer - INFO -     val_embedding_sim: 0.13532155752182007
2025-01-21 11:06:08,796 - trainer - INFO - ================================================================================
2025-01-21 11:06:08,796 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:06:08
2025-01-21 11:06:13,378 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:06:13
2025-01-21 11:06:13,378 - trainer - INFO -     epoch          : 24
2025-01-21 11:06:13,378 - trainer - INFO -     elapsed time   : 4.5814478397369385
2025-01-21 11:06:13,378 - trainer - INFO -     loss           : 256.7323974609375
2025-01-21 11:06:13,378 - trainer - INFO -     sim_loss       : 29.187371730804443
2025-01-21 11:06:13,378 - trainer - INFO -     gen_loss       : 354.25169982910154
2025-01-21 11:06:13,378 - trainer - INFO -     val_loss       : 394.3366184234619
2025-01-21 11:06:13,378 - trainer - INFO -     val_sim_loss   : 12.41535472869873
2025-01-21 11:06:13,378 - trainer - INFO -     val_gen_loss   : 381.92127418518066
2025-01-21 11:06:13,378 - trainer - INFO -     val_perplexity : 22.326684951782227
2025-01-21 11:06:13,378 - trainer - INFO -     val_embedding_sim: 0.13327088952064514
2025-01-21 11:06:13,378 - trainer - INFO - ================================================================================
2025-01-21 11:06:13,378 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:06:13
2025-01-21 11:06:17,939 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:06:17
2025-01-21 11:06:17,939 - trainer - INFO -     epoch          : 25
2025-01-21 11:06:17,939 - trainer - INFO -     elapsed time   : 4.560091018676758
2025-01-21 11:06:17,939 - trainer - INFO -     loss           : 247.40595245361328
2025-01-21 11:06:17,939 - trainer - INFO -     sim_loss       : 32.51254043579102
2025-01-21 11:06:17,939 - trainer - INFO -     gen_loss       : 339.5031280517578
2025-01-21 11:06:17,939 - trainer - INFO -     val_loss       : 402.5485563278198
2025-01-21 11:06:17,939 - trainer - INFO -     val_sim_loss   : 19.839874267578125
2025-01-21 11:06:17,939 - trainer - INFO -     val_gen_loss   : 382.7086820602417
2025-01-21 11:06:17,939 - trainer - INFO -     val_perplexity : 23.071298599243164
2025-01-21 11:06:17,939 - trainer - INFO -     val_embedding_sim: 0.12485183030366898
2025-01-21 11:06:24,481 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:06:24,481 - trainer - INFO - ================================================================================
2025-01-21 11:06:24,481 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:06:24
2025-01-21 11:06:29,118 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:06:29
2025-01-21 11:06:29,118 - trainer - INFO -     epoch          : 26
2025-01-21 11:06:29,118 - trainer - INFO -     elapsed time   : 4.63640022277832
2025-01-21 11:06:29,118 - trainer - INFO -     loss           : 237.32769165039062
2025-01-21 11:06:29,118 - trainer - INFO -     sim_loss       : 30.976594734191895
2025-01-21 11:06:29,118 - trainer - INFO -     gen_loss       : 325.7638824462891
2025-01-21 11:06:29,118 - trainer - INFO -     val_loss       : 398.11186027526855
2025-01-21 11:06:29,118 - trainer - INFO -     val_sim_loss   : 16.67139434814453
2025-01-21 11:06:29,118 - trainer - INFO -     val_gen_loss   : 381.44047355651855
2025-01-21 11:06:29,118 - trainer - INFO -     val_perplexity : 23.701885223388672
2025-01-21 11:06:29,118 - trainer - INFO -     val_embedding_sim: 0.13946932554244995
2025-01-21 11:06:29,118 - trainer - INFO - ================================================================================
2025-01-21 11:06:29,118 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:06:29
2025-01-21 11:06:33,698 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:06:33
2025-01-21 11:06:33,698 - trainer - INFO -     epoch          : 27
2025-01-21 11:06:33,698 - trainer - INFO -     elapsed time   : 4.579484701156616
2025-01-21 11:06:33,698 - trainer - INFO -     loss           : 225.3188934326172
2025-01-21 11:06:33,698 - trainer - INFO -     sim_loss       : 28.23128433227539
2025-01-21 11:06:33,698 - trainer - INFO -     gen_loss       : 309.7850227355957
2025-01-21 11:06:33,698 - trainer - INFO -     val_loss       : 394.7086944580078
2025-01-21 11:06:33,698 - trainer - INFO -     val_sim_loss   : 12.547508239746094
2025-01-21 11:06:33,698 - trainer - INFO -     val_gen_loss   : 382.1611785888672
2025-01-21 11:06:33,698 - trainer - INFO -     val_perplexity : 23.72279930114746
2025-01-21 11:06:33,698 - trainer - INFO -     val_embedding_sim: 0.11035062372684479
2025-01-21 11:06:33,698 - trainer - INFO - ================================================================================
2025-01-21 11:06:33,698 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:06:33
2025-01-21 11:06:38,261 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:06:38
2025-01-21 11:06:38,261 - trainer - INFO -     epoch          : 28
2025-01-21 11:06:38,262 - trainer - INFO -     elapsed time   : 4.562955141067505
2025-01-21 11:06:38,262 - trainer - INFO -     loss           : 219.90910949707032
2025-01-21 11:06:38,262 - trainer - INFO -     sim_loss       : 35.44960741996765
2025-01-21 11:06:38,262 - trainer - INFO -     gen_loss       : 298.9631881713867
2025-01-21 11:06:38,262 - trainer - INFO -     val_loss       : 395.7241415977478
2025-01-21 11:06:38,262 - trainer - INFO -     val_sim_loss   : 16.152671813964844
2025-01-21 11:06:38,262 - trainer - INFO -     val_gen_loss   : 379.5714621543884
2025-01-21 11:06:38,262 - trainer - INFO -     val_perplexity : 23.45545768737793
2025-01-21 11:06:38,262 - trainer - INFO -     val_embedding_sim: 0.12125259637832642
2025-01-21 11:06:38,262 - trainer - INFO - ================================================================================
2025-01-21 11:06:38,262 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:06:38
2025-01-21 11:06:42,834 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:06:42
2025-01-21 11:06:42,834 - trainer - INFO -     epoch          : 29
2025-01-21 11:06:42,834 - trainer - INFO -     elapsed time   : 4.57200026512146
2025-01-21 11:06:42,834 - trainer - INFO -     loss           : 209.67716369628906
2025-01-21 11:06:42,834 - trainer - INFO -     sim_loss       : 32.89674882888794
2025-01-21 11:06:42,834 - trainer - INFO -     gen_loss       : 285.4402053833008
2025-01-21 11:06:42,834 - trainer - INFO -     val_loss       : 389.5766201019287
2025-01-21 11:06:42,834 - trainer - INFO -     val_sim_loss   : 9.445537567138672
2025-01-21 11:06:42,834 - trainer - INFO -     val_gen_loss   : 380.13109397888184
2025-01-21 11:06:42,835 - trainer - INFO -     val_perplexity : 23.628822326660156
2025-01-21 11:06:42,835 - trainer - INFO -     val_embedding_sim: 0.15667513012886047
2025-01-21 11:06:42,835 - trainer - INFO - ================================================================================
2025-01-21 11:06:42,835 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:06:42
2025-01-21 11:06:47,409 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:06:47
2025-01-21 11:06:47,409 - trainer - INFO -     epoch          : 30
2025-01-21 11:06:47,409 - trainer - INFO -     elapsed time   : 4.57393217086792
2025-01-21 11:06:47,409 - trainer - INFO -     loss           : 198.5173599243164
2025-01-21 11:06:47,409 - trainer - INFO -     sim_loss       : 30.605120277404787
2025-01-21 11:06:47,409 - trainer - INFO -     gen_loss       : 270.4797523498535
2025-01-21 11:06:47,409 - trainer - INFO -     val_loss       : 399.3052816390991
2025-01-21 11:06:47,409 - trainer - INFO -     val_sim_loss   : 19.226608276367188
2025-01-21 11:06:47,409 - trainer - INFO -     val_gen_loss   : 380.078688621521
2025-01-21 11:06:47,409 - trainer - INFO -     val_perplexity : 22.93596076965332
2025-01-21 11:06:47,409 - trainer - INFO -     val_embedding_sim: 0.1265895962715149
2025-01-21 11:06:53,954 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:06:53,955 - trainer - INFO - ================================================================================
2025-01-21 11:06:53,955 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:06:53
2025-01-21 11:06:58,559 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:06:58
2025-01-21 11:06:58,559 - trainer - INFO -     epoch          : 31
2025-01-21 11:06:58,559 - trainer - INFO -     elapsed time   : 4.603986740112305
2025-01-21 11:06:58,559 - trainer - INFO -     loss           : 192.83720855712892
2025-01-21 11:06:58,559 - trainer - INFO -     sim_loss       : 32.622314453125
2025-01-21 11:06:58,559 - trainer - INFO -     gen_loss       : 261.50073394775393
2025-01-21 11:06:58,559 - trainer - INFO -     val_loss       : 395.8862247467041
2025-01-21 11:06:58,559 - trainer - INFO -     val_sim_loss   : 18.706209182739258
2025-01-21 11:06:58,559 - trainer - INFO -     val_gen_loss   : 377.1800174713135
2025-01-21 11:06:58,559 - trainer - INFO -     val_perplexity : 23.001020431518555
2025-01-21 11:06:58,560 - trainer - INFO -     val_embedding_sim: 0.14227081835269928
2025-01-21 11:06:58,560 - trainer - INFO - ================================================================================
2025-01-21 11:06:58,560 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:06:58
2025-01-21 11:07:03,136 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:07:03
2025-01-21 11:07:03,136 - trainer - INFO -     epoch          : 32
2025-01-21 11:07:03,136 - trainer - INFO -     elapsed time   : 4.575792074203491
2025-01-21 11:07:03,136 - trainer - INFO -     loss           : 185.6061584472656
2025-01-21 11:07:03,136 - trainer - INFO -     sim_loss       : 32.09314727783203
2025-01-21 11:07:03,136 - trainer - INFO -     gen_loss       : 251.3974494934082
2025-01-21 11:07:03,136 - trainer - INFO -     val_loss       : 396.84227871894836
2025-01-21 11:07:03,136 - trainer - INFO -     val_sim_loss   : 17.165834426879883
2025-01-21 11:07:03,136 - trainer - INFO -     val_gen_loss   : 379.6764461994171
2025-01-21 11:07:03,136 - trainer - INFO -     val_perplexity : 23.615575790405273
2025-01-21 11:07:03,136 - trainer - INFO -     val_embedding_sim: 0.1305200159549713
2025-01-21 11:07:03,136 - trainer - INFO - ================================================================================
2025-01-21 11:07:03,136 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:07:03
2025-01-21 11:07:07,700 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:07:07
2025-01-21 11:07:07,701 - trainer - INFO -     epoch          : 33
2025-01-21 11:07:07,701 - trainer - INFO -     elapsed time   : 4.564084529876709
2025-01-21 11:07:07,701 - trainer - INFO -     loss           : 177.87935256958008
2025-01-21 11:07:07,701 - trainer - INFO -     sim_loss       : 31.279668617248536
2025-01-21 11:07:07,701 - trainer - INFO -     gen_loss       : 240.70779037475586
2025-01-21 11:07:07,701 - trainer - INFO -     val_loss       : 397.1735324859619
2025-01-21 11:07:07,701 - trainer - INFO -     val_sim_loss   : 19.88849639892578
2025-01-21 11:07:07,701 - trainer - INFO -     val_gen_loss   : 377.28504371643066
2025-01-21 11:07:07,701 - trainer - INFO -     val_perplexity : 22.446870803833008
2025-01-21 11:07:07,701 - trainer - INFO -     val_embedding_sim: 0.14647454023361206
2025-01-21 11:07:07,701 - trainer - INFO - ================================================================================
2025-01-21 11:07:07,701 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:07:07
2025-01-21 11:07:12,269 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:07:12
2025-01-21 11:07:12,270 - trainer - INFO -     epoch          : 34
2025-01-21 11:07:12,270 - trainer - INFO -     elapsed time   : 4.568286895751953
2025-01-21 11:07:12,270 - trainer - INFO -     loss           : 172.16134872436524
2025-01-21 11:07:12,270 - trainer - INFO -     sim_loss       : 35.688871192932126
2025-01-21 11:07:12,270 - trainer - INFO -     gen_loss       : 230.6495590209961
2025-01-21 11:07:12,270 - trainer - INFO -     val_loss       : 398.82242584228516
2025-01-21 11:07:12,270 - trainer - INFO -     val_sim_loss   : 22.559608459472656
2025-01-21 11:07:12,270 - trainer - INFO -     val_gen_loss   : 376.26282501220703
2025-01-21 11:07:12,270 - trainer - INFO -     val_perplexity : 22.672943115234375
2025-01-21 11:07:12,270 - trainer - INFO -     val_embedding_sim: 0.10685752332210541
2025-01-21 11:07:12,270 - trainer - INFO - ================================================================================
2025-01-21 11:07:12,270 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:07:12
2025-01-21 11:07:16,841 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:07:16
2025-01-21 11:07:16,841 - trainer - INFO -     epoch          : 35
2025-01-21 11:07:16,841 - trainer - INFO -     elapsed time   : 4.570559740066528
2025-01-21 11:07:16,841 - trainer - INFO -     loss           : 164.98186340332032
2025-01-21 11:07:16,841 - trainer - INFO -     sim_loss       : 35.72227935791015
2025-01-21 11:07:16,841 - trainer - INFO -     gen_loss       : 220.3788284301758
2025-01-21 11:07:16,841 - trainer - INFO -     val_loss       : 392.46038150787354
2025-01-21 11:07:16,841 - trainer - INFO -     val_sim_loss   : 15.513741493225098
2025-01-21 11:07:16,841 - trainer - INFO -     val_gen_loss   : 376.9466485977173
2025-01-21 11:07:16,841 - trainer - INFO -     val_perplexity : 22.735275268554688
2025-01-21 11:07:16,841 - trainer - INFO -     val_embedding_sim: 0.11791209876537323
2025-01-21 11:07:23,385 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:07:23,385 - trainer - INFO - ================================================================================
2025-01-21 11:07:23,386 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:07:23
2025-01-21 11:07:28,010 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:07:28
2025-01-21 11:07:28,010 - trainer - INFO -     epoch          : 36
2025-01-21 11:07:28,010 - trainer - INFO -     elapsed time   : 4.624375581741333
2025-01-21 11:07:28,010 - trainer - INFO -     loss           : 160.03375091552735
2025-01-21 11:07:28,010 - trainer - INFO -     sim_loss       : 36.06581039428711
2025-01-21 11:07:28,010 - trainer - INFO -     gen_loss       : 213.1628730773926
2025-01-21 11:07:28,010 - trainer - INFO -     val_loss       : 399.7429094314575
2025-01-21 11:07:28,010 - trainer - INFO -     val_sim_loss   : 23.07292938232422
2025-01-21 11:07:28,010 - trainer - INFO -     val_gen_loss   : 376.66997241973877
2025-01-21 11:07:28,011 - trainer - INFO -     val_perplexity : 23.340465545654297
2025-01-21 11:07:28,011 - trainer - INFO -     val_embedding_sim: 0.11261183023452759
2025-01-21 11:07:28,011 - trainer - INFO - ================================================================================
2025-01-21 11:07:28,011 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:07:28
2025-01-21 11:07:32,674 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:07:32
2025-01-21 11:07:32,675 - trainer - INFO -     epoch          : 37
2025-01-21 11:07:32,675 - trainer - INFO -     elapsed time   : 4.663675308227539
2025-01-21 11:07:32,675 - trainer - INFO -     loss           : 152.88824577331542
2025-01-21 11:07:32,675 - trainer - INFO -     sim_loss       : 34.17824096679688
2025-01-21 11:07:32,675 - trainer - INFO -     gen_loss       : 203.76396636962892
2025-01-21 11:07:32,675 - trainer - INFO -     val_loss       : 399.6528694629669
2025-01-21 11:07:32,675 - trainer - INFO -     val_sim_loss   : 22.959774017333984
2025-01-21 11:07:32,675 - trainer - INFO -     val_gen_loss   : 376.69309163093567
2025-01-21 11:07:32,675 - trainer - INFO -     val_perplexity : 23.43353271484375
2025-01-21 11:07:32,675 - trainer - INFO -     val_embedding_sim: 0.12836489081382751
2025-01-21 11:07:32,675 - trainer - INFO - ================================================================================
2025-01-21 11:07:32,675 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:07:32
2025-01-21 11:07:37,240 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:07:37
2025-01-21 11:07:37,240 - trainer - INFO -     epoch          : 38
2025-01-21 11:07:37,240 - trainer - INFO -     elapsed time   : 4.564334392547607
2025-01-21 11:07:37,240 - trainer - INFO -     loss           : 142.66408462524413
2025-01-21 11:07:37,240 - trainer - INFO -     sim_loss       : 29.484304869174956
2025-01-21 11:07:37,240 - trainer - INFO -     gen_loss       : 191.16970291137696
2025-01-21 11:07:37,240 - trainer - INFO -     val_loss       : 392.1994709968567
2025-01-21 11:07:37,240 - trainer - INFO -     val_sim_loss   : 14.515802383422852
2025-01-21 11:07:37,240 - trainer - INFO -     val_gen_loss   : 377.68366289138794
2025-01-21 11:07:37,240 - trainer - INFO -     val_perplexity : 23.521451950073242
2025-01-21 11:07:37,240 - trainer - INFO -     val_embedding_sim: 0.12678614258766174
2025-01-21 11:07:37,240 - trainer - INFO - ================================================================================
2025-01-21 11:07:37,240 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:07:37
2025-01-21 11:07:41,805 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:07:41
2025-01-21 11:07:41,805 - trainer - INFO -     epoch          : 39
2025-01-21 11:07:41,806 - trainer - INFO -     elapsed time   : 4.565058708190918
2025-01-21 11:07:41,806 - trainer - INFO -     loss           : 137.12266731262207
2025-01-21 11:07:41,806 - trainer - INFO -     sim_loss       : 33.069167137145996
2025-01-21 11:07:41,806 - trainer - INFO -     gen_loss       : 181.71702880859374
2025-01-21 11:07:41,806 - trainer - INFO -     val_loss       : 401.5969982147217
2025-01-21 11:07:41,806 - trainer - INFO -     val_sim_loss   : 19.5091552734375
2025-01-21 11:07:41,806 - trainer - INFO -     val_gen_loss   : 382.0878429412842
2025-01-21 11:07:41,806 - trainer - INFO -     val_perplexity : 23.13101577758789
2025-01-21 11:07:41,806 - trainer - INFO -     val_embedding_sim: 0.1344166249036789
2025-01-21 11:07:41,806 - trainer - INFO - ================================================================================
2025-01-21 11:07:41,806 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:07:41
2025-01-21 11:07:46,387 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:07:46
2025-01-21 11:07:46,387 - trainer - INFO -     epoch          : 40
2025-01-21 11:07:46,387 - trainer - INFO -     elapsed time   : 4.58116888999939
2025-01-21 11:07:46,387 - trainer - INFO -     loss           : 132.0966640472412
2025-01-21 11:07:46,387 - trainer - INFO -     sim_loss       : 33.135322380065915
2025-01-21 11:07:46,388 - trainer - INFO -     gen_loss       : 174.5086685180664
2025-01-21 11:07:46,388 - trainer - INFO -     val_loss       : 391.88061714172363
2025-01-21 11:07:46,388 - trainer - INFO -     val_sim_loss   : 16.57118034362793
2025-01-21 11:07:46,388 - trainer - INFO -     val_gen_loss   : 375.30945014953613
2025-01-21 11:07:46,388 - trainer - INFO -     val_perplexity : 21.921201705932617
2025-01-21 11:07:46,388 - trainer - INFO -     val_embedding_sim: 0.1477673202753067
2025-01-21 11:07:52,932 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:07:59,599 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:07:59,599 - trainer - INFO - ================================================================================
2025-01-21 11:07:59,599 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:07:59
2025-01-21 11:08:04,222 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:08:04
2025-01-21 11:08:04,222 - trainer - INFO -     epoch          : 41
2025-01-21 11:08:04,222 - trainer - INFO -     elapsed time   : 4.622908115386963
2025-01-21 11:08:04,222 - trainer - INFO -     loss           : 125.65115585327149
2025-01-21 11:08:04,222 - trainer - INFO -     sim_loss       : 28.30113353729248
2025-01-21 11:08:04,222 - trainer - INFO -     gen_loss       : 167.37259979248046
2025-01-21 11:08:04,222 - trainer - INFO -     val_loss       : 396.57395219802856
2025-01-21 11:08:04,222 - trainer - INFO -     val_sim_loss   : 13.655406951904297
2025-01-21 11:08:04,222 - trainer - INFO -     val_gen_loss   : 382.91855669021606
2025-01-21 11:08:04,223 - trainer - INFO -     val_perplexity : 23.848617553710938
2025-01-21 11:08:04,223 - trainer - INFO -     val_embedding_sim: 0.14294463396072388
2025-01-21 11:08:04,223 - trainer - INFO - ================================================================================
2025-01-21 11:08:04,223 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:08:04
2025-01-21 11:08:08,793 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:08:08
2025-01-21 11:08:08,793 - trainer - INFO -     epoch          : 42
2025-01-21 11:08:08,793 - trainer - INFO -     elapsed time   : 4.56999397277832
2025-01-21 11:08:08,793 - trainer - INFO -     loss           : 121.72511367797851
2025-01-21 11:08:08,793 - trainer - INFO -     sim_loss       : 31.011959409713747
2025-01-21 11:08:08,793 - trainer - INFO -     gen_loss       : 160.6021842956543
2025-01-21 11:08:08,793 - trainer - INFO -     val_loss       : 406.6568946838379
2025-01-21 11:08:08,793 - trainer - INFO -     val_sim_loss   : 25.481201171875
2025-01-21 11:08:08,793 - trainer - INFO -     val_gen_loss   : 381.1756935119629
2025-01-21 11:08:08,793 - trainer - INFO -     val_perplexity : 22.3211727142334
2025-01-21 11:08:08,793 - trainer - INFO -     val_embedding_sim: 0.1632392406463623
2025-01-21 11:08:08,793 - trainer - INFO - ================================================================================
2025-01-21 11:08:08,793 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:08:08
2025-01-21 11:10:49,041 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:10:51,357 - trainer - INFO - ================================================================================
2025-01-21 11:10:51,357 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:10:51
2025-01-21 11:10:57,127 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:10:57
2025-01-21 11:10:57,127 - trainer - INFO -     epoch          : 1
2025-01-21 11:10:57,127 - trainer - INFO -     elapsed time   : 5.769922733306885
2025-01-21 11:10:57,127 - trainer - INFO -     loss           : 926.0518676757813
2025-01-21 11:10:57,127 - trainer - INFO -     sim_loss       : 80.15060462951661
2025-01-21 11:10:57,127 - trainer - INFO -     gen_loss       : 1288.581021118164
2025-01-21 11:10:57,127 - trainer - INFO -     val_loss       : 597.9046440124512
2025-01-21 11:10:57,127 - trainer - INFO -     val_sim_loss   : 30.897905349731445
2025-01-21 11:10:57,127 - trainer - INFO -     val_gen_loss   : 567.0067558288574
2025-01-21 11:10:57,127 - trainer - INFO -     val_perplexity : 34.28976821899414
2025-01-21 11:10:57,128 - trainer - INFO -     val_embedding_sim: 0.13666823506355286
2025-01-21 11:10:57,128 - trainer - INFO - ================================================================================
2025-01-21 11:10:57,128 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:10:57
2025-01-21 11:11:01,685 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:11:01
2025-01-21 11:11:01,685 - trainer - INFO -     epoch          : 2
2025-01-21 11:11:01,685 - trainer - INFO -     elapsed time   : 4.556779861450195
2025-01-21 11:11:01,685 - trainer - INFO -     loss           : 818.138818359375
2025-01-21 11:11:01,685 - trainer - INFO -     sim_loss       : 44.15967655181885
2025-01-21 11:11:01,685 - trainer - INFO -     gen_loss       : 1149.8442016601562
2025-01-21 11:11:01,685 - trainer - INFO -     val_loss       : 568.6213397979736
2025-01-21 11:11:01,685 - trainer - INFO -     val_sim_loss   : 25.156375885009766
2025-01-21 11:11:01,685 - trainer - INFO -     val_gen_loss   : 543.4649677276611
2025-01-21 11:11:01,685 - trainer - INFO -     val_perplexity : 32.68014144897461
2025-01-21 11:11:01,685 - trainer - INFO -     val_embedding_sim: 0.12105973064899445
2025-01-21 11:11:01,685 - trainer - INFO - ================================================================================
2025-01-21 11:11:01,685 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:11:01
2025-01-21 11:11:06,248 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:11:06
2025-01-21 11:11:06,248 - trainer - INFO -     epoch          : 3
2025-01-21 11:11:06,249 - trainer - INFO -     elapsed time   : 4.563124179840088
2025-01-21 11:11:06,249 - trainer - INFO -     loss           : 769.9986541748046
2025-01-21 11:11:06,249 - trainer - INFO -     sim_loss       : 31.62845907211304
2025-01-21 11:11:06,249 - trainer - INFO -     gen_loss       : 1086.443032836914
2025-01-21 11:11:06,249 - trainer - INFO -     val_loss       : 539.9182319641113
2025-01-21 11:11:06,249 - trainer - INFO -     val_sim_loss   : 18.201953887939453
2025-01-21 11:11:06,249 - trainer - INFO -     val_gen_loss   : 521.7162666320801
2025-01-21 11:11:06,249 - trainer - INFO -     val_perplexity : 30.639976501464844
2025-01-21 11:11:06,249 - trainer - INFO -     val_embedding_sim: 0.12869185209274292
2025-01-21 11:11:06,249 - trainer - INFO - ================================================================================
2025-01-21 11:11:06,249 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:11:06
2025-01-21 11:11:10,808 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:11:10
2025-01-21 11:11:10,808 - trainer - INFO -     epoch          : 4
2025-01-21 11:11:10,808 - trainer - INFO -     elapsed time   : 4.559024810791016
2025-01-21 11:11:10,808 - trainer - INFO -     loss           : 725.4052124023438
2025-01-21 11:11:10,808 - trainer - INFO -     sim_loss       : 32.788217544555664
2025-01-21 11:11:10,808 - trainer - INFO -     gen_loss       : 1022.2411071777344
2025-01-21 11:11:10,808 - trainer - INFO -     val_loss       : 523.2192535400391
2025-01-21 11:11:10,808 - trainer - INFO -     val_sim_loss   : 23.645509719848633
2025-01-21 11:11:10,808 - trainer - INFO -     val_gen_loss   : 499.57374572753906
2025-01-21 11:11:10,809 - trainer - INFO -     val_perplexity : 29.814695358276367
2025-01-21 11:11:10,809 - trainer - INFO -     val_embedding_sim: 0.12242409586906433
2025-01-21 11:11:10,809 - trainer - INFO - ================================================================================
2025-01-21 11:11:10,809 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:11:10
2025-01-21 11:11:15,368 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:11:15
2025-01-21 11:11:15,368 - trainer - INFO -     epoch          : 5
2025-01-21 11:11:15,368 - trainer - INFO -     elapsed time   : 4.558699607849121
2025-01-21 11:11:15,368 - trainer - INFO -     loss           : 679.5910797119141
2025-01-21 11:11:15,368 - trainer - INFO -     sim_loss       : 34.43480815887451
2025-01-21 11:11:15,368 - trainer - INFO -     gen_loss       : 956.0866394042969
2025-01-21 11:11:15,368 - trainer - INFO -     val_loss       : 490.8685760498047
2025-01-21 11:11:15,368 - trainer - INFO -     val_sim_loss   : 16.582136154174805
2025-01-21 11:11:15,368 - trainer - INFO -     val_gen_loss   : 474.2864532470703
2025-01-21 11:11:15,368 - trainer - INFO -     val_perplexity : 28.886428833007812
2025-01-21 11:11:15,368 - trainer - INFO -     val_embedding_sim: 0.12403754889965057
2025-01-21 11:11:22,839 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:11:29,413 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:11:29,414 - trainer - INFO - ================================================================================
2025-01-21 11:11:29,414 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:11:29
2025-01-21 11:11:34,012 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:11:34
2025-01-21 11:11:34,012 - trainer - INFO -     epoch          : 6
2025-01-21 11:11:34,012 - trainer - INFO -     elapsed time   : 4.598479270935059
2025-01-21 11:11:34,012 - trainer - INFO -     loss           : 631.5791168212891
2025-01-21 11:11:34,012 - trainer - INFO -     sim_loss       : 34.07434663772583
2025-01-21 11:11:34,013 - trainer - INFO -     gen_loss       : 887.6526000976562
2025-01-21 11:11:34,013 - trainer - INFO -     val_loss       : 465.3702869415283
2025-01-21 11:11:34,013 - trainer - INFO -     val_sim_loss   : 12.26746940612793
2025-01-21 11:11:34,013 - trainer - INFO -     val_gen_loss   : 453.1028308868408
2025-01-21 11:11:34,013 - trainer - INFO -     val_perplexity : 27.35556983947754
2025-01-21 11:11:34,013 - trainer - INFO -     val_embedding_sim: 0.14163225889205933
2025-01-21 11:11:34,013 - trainer - INFO - ================================================================================
2025-01-21 11:11:34,013 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:11:34
2025-01-21 11:11:38,583 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:11:38
2025-01-21 11:11:38,584 - trainer - INFO -     epoch          : 7
2025-01-21 11:11:38,584 - trainer - INFO -     elapsed time   : 4.570445537567139
2025-01-21 11:11:38,584 - trainer - INFO -     loss           : 589.1755661010742
2025-01-21 11:11:38,584 - trainer - INFO -     sim_loss       : 31.072006034851075
2025-01-21 11:11:38,584 - trainer - INFO -     gen_loss       : 828.3628082275391
2025-01-21 11:11:38,584 - trainer - INFO -     val_loss       : 450.8003463745117
2025-01-21 11:11:38,584 - trainer - INFO -     val_sim_loss   : 14.321913719177246
2025-01-21 11:11:38,584 - trainer - INFO -     val_gen_loss   : 436.4784469604492
2025-01-21 11:11:38,584 - trainer - INFO -     val_perplexity : 26.324954986572266
2025-01-21 11:11:38,584 - trainer - INFO -     val_embedding_sim: 0.125660240650177
2025-01-21 11:11:38,584 - trainer - INFO - ================================================================================
2025-01-21 11:11:38,584 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:11:38
2025-01-21 11:11:43,143 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:11:43
2025-01-21 11:11:43,143 - trainer - INFO -     epoch          : 8
2025-01-21 11:11:43,143 - trainer - INFO -     elapsed time   : 4.558593511581421
2025-01-21 11:11:43,143 - trainer - INFO -     loss           : 554.0099960327149
2025-01-21 11:11:43,143 - trainer - INFO -     sim_loss       : 29.116068983078
2025-01-21 11:11:43,143 - trainer - INFO -     gen_loss       : 778.9645477294922
2025-01-21 11:11:43,143 - trainer - INFO -     val_loss       : 442.2682161331177
2025-01-21 11:11:43,143 - trainer - INFO -     val_sim_loss   : 16.102643966674805
2025-01-21 11:11:43,143 - trainer - INFO -     val_gen_loss   : 426.1655855178833
2025-01-21 11:11:43,143 - trainer - INFO -     val_perplexity : 26.222999572753906
2025-01-21 11:11:43,143 - trainer - INFO -     val_embedding_sim: 0.14288844168186188
2025-01-21 11:11:43,143 - trainer - INFO - ================================================================================
2025-01-21 11:11:43,143 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:11:43
2025-01-21 11:11:47,716 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:11:47
2025-01-21 11:11:47,716 - trainer - INFO -     epoch          : 9
2025-01-21 11:11:47,717 - trainer - INFO -     elapsed time   : 4.572819948196411
2025-01-21 11:11:47,717 - trainer - INFO -     loss           : 522.4518264770508
2025-01-21 11:11:47,717 - trainer - INFO -     sim_loss       : 33.35802459716797
2025-01-21 11:11:47,717 - trainer - INFO -     gen_loss       : 732.0634735107421
2025-01-21 11:11:47,717 - trainer - INFO -     val_loss       : 430.36391735076904
2025-01-21 11:11:47,717 - trainer - INFO -     val_sim_loss   : 13.264713287353516
2025-01-21 11:11:47,717 - trainer - INFO -     val_gen_loss   : 417.0992078781128
2025-01-21 11:11:47,717 - trainer - INFO -     val_perplexity : 25.366470336914062
2025-01-21 11:11:47,717 - trainer - INFO -     val_embedding_sim: 0.10869182646274567
2025-01-21 11:11:47,717 - trainer - INFO - ================================================================================
2025-01-21 11:11:47,717 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:11:47
2025-01-21 11:11:52,304 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:11:52
2025-01-21 11:11:52,304 - trainer - INFO -     epoch          : 10
2025-01-21 11:11:52,304 - trainer - INFO -     elapsed time   : 4.587069988250732
2025-01-21 11:11:52,304 - trainer - INFO -     loss           : 490.16400756835935
2025-01-21 11:11:52,304 - trainer - INFO -     sim_loss       : 27.644661140441894
2025-01-21 11:11:52,304 - trainer - INFO -     gen_loss       : 688.3865966796875
2025-01-21 11:11:52,304 - trainer - INFO -     val_loss       : 424.83731842041016
2025-01-21 11:11:52,304 - trainer - INFO -     val_sim_loss   : 17.34536361694336
2025-01-21 11:11:52,305 - trainer - INFO -     val_gen_loss   : 407.49195098876953
2025-01-21 11:11:52,305 - trainer - INFO -     val_perplexity : 23.99220085144043
2025-01-21 11:11:52,305 - trainer - INFO -     val_embedding_sim: 0.0920289009809494
2025-01-21 11:11:58,896 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:12:05,470 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:12:05,471 - trainer - INFO - ================================================================================
2025-01-21 11:12:05,471 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:12:05
2025-01-21 11:12:10,108 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:12:10
2025-01-21 11:12:10,108 - trainer - INFO -     epoch          : 11
2025-01-21 11:12:10,108 - trainer - INFO -     elapsed time   : 4.6370322704315186
2025-01-21 11:12:10,108 - trainer - INFO -     loss           : 463.3146041870117
2025-01-21 11:12:10,108 - trainer - INFO -     sim_loss       : 30.59953498840332
2025-01-21 11:12:10,108 - trainer - INFO -     gen_loss       : 648.7639343261719
2025-01-21 11:12:10,108 - trainer - INFO -     val_loss       : 418.480845451355
2025-01-21 11:12:10,108 - trainer - INFO -     val_sim_loss   : 11.31159782409668
2025-01-21 11:12:10,108 - trainer - INFO -     val_gen_loss   : 407.16926097869873
2025-01-21 11:12:10,109 - trainer - INFO -     val_perplexity : 24.4727840423584
2025-01-21 11:12:10,109 - trainer - INFO -     val_embedding_sim: 0.10701514035463333
2025-01-21 11:12:10,109 - trainer - INFO - ================================================================================
2025-01-21 11:12:10,109 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:12:10
2025-01-21 11:12:14,687 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:12:14
2025-01-21 11:12:14,687 - trainer - INFO -     epoch          : 12
2025-01-21 11:12:14,687 - trainer - INFO -     elapsed time   : 4.577651262283325
2025-01-21 11:12:14,687 - trainer - INFO -     loss           : 440.5827133178711
2025-01-21 11:12:14,687 - trainer - INFO -     sim_loss       : 33.56797342300415
2025-01-21 11:12:14,687 - trainer - INFO -     gen_loss       : 615.0176086425781
2025-01-21 11:12:14,687 - trainer - INFO -     val_loss       : 409.22182178497314
2025-01-21 11:12:14,687 - trainer - INFO -     val_sim_loss   : 12.84035873413086
2025-01-21 11:12:14,687 - trainer - INFO -     val_gen_loss   : 396.381459236145
2025-01-21 11:12:14,687 - trainer - INFO -     val_perplexity : 23.77855682373047
2025-01-21 11:12:14,687 - trainer - INFO -     val_embedding_sim: 0.13282810151576996
2025-01-21 11:12:14,687 - trainer - INFO - ================================================================================
2025-01-21 11:12:14,687 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:12:14
2025-01-21 11:12:19,246 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:12:19
2025-01-21 11:12:19,246 - trainer - INFO -     epoch          : 13
2025-01-21 11:12:19,246 - trainer - INFO -     elapsed time   : 4.558616876602173
2025-01-21 11:12:19,246 - trainer - INFO -     loss           : 417.52635650634767
2025-01-21 11:12:19,246 - trainer - INFO -     sim_loss       : 28.900172328948976
2025-01-21 11:12:19,246 - trainer - INFO -     gen_loss       : 584.0804397583008
2025-01-21 11:12:19,246 - trainer - INFO -     val_loss       : 416.8297452926636
2025-01-21 11:12:19,246 - trainer - INFO -     val_sim_loss   : 20.79948616027832
2025-01-21 11:12:19,246 - trainer - INFO -     val_gen_loss   : 396.0302457809448
2025-01-21 11:12:19,246 - trainer - INFO -     val_perplexity : 23.89650535583496
2025-01-21 11:12:19,246 - trainer - INFO -     val_embedding_sim: 0.119126096367836
2025-01-21 11:12:19,246 - trainer - INFO - ================================================================================
2025-01-21 11:12:19,246 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:12:19
2025-01-21 11:12:23,805 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:12:23
2025-01-21 11:12:23,805 - trainer - INFO -     epoch          : 14
2025-01-21 11:12:23,805 - trainer - INFO -     elapsed time   : 4.558057069778442
2025-01-21 11:12:23,805 - trainer - INFO -     loss           : 399.51070404052734
2025-01-21 11:12:23,805 - trainer - INFO -     sim_loss       : 32.1328628540039
2025-01-21 11:12:23,805 - trainer - INFO -     gen_loss       : 556.9583557128906
2025-01-21 11:12:23,805 - trainer - INFO -     val_loss       : 404.58380031585693
2025-01-21 11:12:23,805 - trainer - INFO -     val_sim_loss   : 14.572610855102539
2025-01-21 11:12:23,805 - trainer - INFO -     val_gen_loss   : 390.01119899749756
2025-01-21 11:12:23,805 - trainer - INFO -     val_perplexity : 24.117431640625
2025-01-21 11:12:23,805 - trainer - INFO -     val_embedding_sim: 0.12609568238258362
2025-01-21 11:12:23,805 - trainer - INFO - ================================================================================
2025-01-21 11:12:23,805 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:12:23
2025-01-21 11:12:28,396 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:12:28
2025-01-21 11:12:28,396 - trainer - INFO -     epoch          : 15
2025-01-21 11:12:28,396 - trainer - INFO -     elapsed time   : 4.590826511383057
2025-01-21 11:12:28,397 - trainer - INFO -     loss           : 379.20598754882815
2025-01-21 11:12:28,397 - trainer - INFO -     sim_loss       : 27.439306449890136
2025-01-21 11:12:28,397 - trainer - INFO -     gen_loss       : 529.9631469726562
2025-01-21 11:12:28,397 - trainer - INFO -     val_loss       : 404.70003604888916
2025-01-21 11:12:28,397 - trainer - INFO -     val_sim_loss   : 17.96949005126953
2025-01-21 11:12:28,397 - trainer - INFO -     val_gen_loss   : 386.73055362701416
2025-01-21 11:12:28,397 - trainer - INFO -     val_perplexity : 23.550884246826172
2025-01-21 11:12:28,397 - trainer - INFO -     val_embedding_sim: 0.09444363415241241
2025-01-21 11:12:35,008 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:12:41,596 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:12:41,596 - trainer - INFO - ================================================================================
2025-01-21 11:12:41,596 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:12:41
2025-01-21 11:12:46,219 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:12:46
2025-01-21 11:12:46,219 - trainer - INFO -     epoch          : 16
2025-01-21 11:12:46,219 - trainer - INFO -     elapsed time   : 4.622684001922607
2025-01-21 11:12:46,219 - trainer - INFO -     loss           : 363.85071868896483
2025-01-21 11:12:46,219 - trainer - INFO -     sim_loss       : 29.843349075317384
2025-01-21 11:12:46,219 - trainer - INFO -     gen_loss       : 506.9967346191406
2025-01-21 11:12:46,219 - trainer - INFO -     val_loss       : 402.61656618118286
2025-01-21 11:12:46,219 - trainer - INFO -     val_sim_loss   : 18.385377883911133
2025-01-21 11:12:46,219 - trainer - INFO -     val_gen_loss   : 384.23119020462036
2025-01-21 11:12:46,219 - trainer - INFO -     val_perplexity : 23.620330810546875
2025-01-21 11:12:46,219 - trainer - INFO -     val_embedding_sim: 0.11372670531272888
2025-01-21 11:12:46,219 - trainer - INFO - ================================================================================
2025-01-21 11:12:46,219 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:12:46
2025-01-21 11:12:50,836 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:12:50
2025-01-21 11:12:50,836 - trainer - INFO -     epoch          : 17
2025-01-21 11:12:50,836 - trainer - INFO -     elapsed time   : 4.616598606109619
2025-01-21 11:12:50,836 - trainer - INFO -     loss           : 349.4650512695313
2025-01-21 11:12:50,836 - trainer - INFO -     sim_loss       : 35.022897481918335
2025-01-21 11:12:50,836 - trainer - INFO -     gen_loss       : 484.2259780883789
2025-01-21 11:12:50,837 - trainer - INFO -     val_loss       : 398.7251491546631
2025-01-21 11:12:50,837 - trainer - INFO -     val_sim_loss   : 15.306532859802246
2025-01-21 11:12:50,837 - trainer - INFO -     val_gen_loss   : 383.4186305999756
2025-01-21 11:12:50,837 - trainer - INFO -     val_perplexity : 22.437435150146484
2025-01-21 11:12:50,837 - trainer - INFO -     val_embedding_sim: 0.09559085965156555
2025-01-21 11:12:50,837 - trainer - INFO - ================================================================================
2025-01-21 11:12:50,837 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:12:50
2025-01-21 11:12:55,425 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:12:55
2025-01-21 11:12:55,426 - trainer - INFO -     epoch          : 18
2025-01-21 11:12:55,426 - trainer - INFO -     elapsed time   : 4.588460683822632
2025-01-21 11:12:55,426 - trainer - INFO -     loss           : 333.12967987060546
2025-01-21 11:12:55,426 - trainer - INFO -     sim_loss       : 30.36341276168823
2025-01-21 11:12:55,426 - trainer - INFO -     gen_loss       : 462.88665771484375
2025-01-21 11:12:55,426 - trainer - INFO -     val_loss       : 402.95659041404724
2025-01-21 11:12:55,426 - trainer - INFO -     val_sim_loss   : 19.028987884521484
2025-01-21 11:12:55,426 - trainer - INFO -     val_gen_loss   : 383.9275987148285
2025-01-21 11:12:55,426 - trainer - INFO -     val_perplexity : 23.852079391479492
2025-01-21 11:12:55,426 - trainer - INFO -     val_embedding_sim: 0.1106276884675026
2025-01-21 11:12:55,426 - trainer - INFO - ================================================================================
2025-01-21 11:12:55,426 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:12:55
2025-01-21 11:13:00,000 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:12:59
2025-01-21 11:13:00,000 - trainer - INFO -     epoch          : 19
2025-01-21 11:13:00,000 - trainer - INFO -     elapsed time   : 4.573617219924927
2025-01-21 11:13:00,000 - trainer - INFO -     loss           : 319.1216094970703
2025-01-21 11:13:00,000 - trainer - INFO -     sim_loss       : 26.764625072479248
2025-01-21 11:13:00,000 - trainer - INFO -     gen_loss       : 444.41746673583987
2025-01-21 11:13:00,000 - trainer - INFO -     val_loss       : 399.3265686035156
2025-01-21 11:13:00,000 - trainer - INFO -     val_sim_loss   : 16.95846176147461
2025-01-21 11:13:00,000 - trainer - INFO -     val_gen_loss   : 382.36810302734375
2025-01-21 11:13:00,000 - trainer - INFO -     val_perplexity : 21.784212112426758
2025-01-21 11:13:00,000 - trainer - INFO -     val_embedding_sim: 0.1155744194984436
2025-01-21 11:13:00,000 - trainer - INFO - ================================================================================
2025-01-21 11:13:00,000 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:12:59
2025-01-21 11:13:04,611 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:13:04
2025-01-21 11:13:04,611 - trainer - INFO -     epoch          : 20
2025-01-21 11:13:04,611 - trainer - INFO -     elapsed time   : 4.610732555389404
2025-01-21 11:13:04,611 - trainer - INFO -     loss           : 304.28799591064455
2025-01-21 11:13:04,612 - trainer - INFO -     sim_loss       : 26.882752561569212
2025-01-21 11:13:04,612 - trainer - INFO -     gen_loss       : 423.17596740722655
2025-01-21 11:13:04,612 - trainer - INFO -     val_loss       : 396.1400799751282
2025-01-21 11:13:04,612 - trainer - INFO -     val_sim_loss   : 13.122339248657227
2025-01-21 11:13:04,612 - trainer - INFO -     val_gen_loss   : 383.01773500442505
2025-01-21 11:13:04,612 - trainer - INFO -     val_perplexity : 23.735416412353516
2025-01-21 11:13:04,612 - trainer - INFO -     val_embedding_sim: 0.12525571882724762
2025-01-21 11:13:11,210 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:13:11,210 - trainer - INFO - ================================================================================
2025-01-21 11:13:11,210 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:13:11
2025-01-21 11:13:15,858 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:13:15
2025-01-21 11:13:15,858 - trainer - INFO -     epoch          : 21
2025-01-21 11:13:15,858 - trainer - INFO -     elapsed time   : 4.64765191078186
2025-01-21 11:13:15,858 - trainer - INFO -     loss           : 290.88708267211916
2025-01-21 11:13:15,858 - trainer - INFO -     sim_loss       : 26.345297813415527
2025-01-21 11:13:15,858 - trainer - INFO -     gen_loss       : 404.2621444702148
2025-01-21 11:13:15,858 - trainer - INFO -     val_loss       : 404.9458999633789
2025-01-21 11:13:15,858 - trainer - INFO -     val_sim_loss   : 20.545747756958008
2025-01-21 11:13:15,858 - trainer - INFO -     val_gen_loss   : 384.40015411376953
2025-01-21 11:13:15,858 - trainer - INFO -     val_perplexity : 22.58405876159668
2025-01-21 11:13:15,858 - trainer - INFO -     val_embedding_sim: 0.12570777535438538
2025-01-21 11:13:15,858 - trainer - INFO - ================================================================================
2025-01-21 11:13:15,858 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:13:15
2025-01-21 11:13:20,432 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:13:20
2025-01-21 11:13:20,432 - trainer - INFO -     epoch          : 22
2025-01-21 11:13:20,432 - trainer - INFO -     elapsed time   : 4.573112487792969
2025-01-21 11:13:20,432 - trainer - INFO -     loss           : 282.0966735839844
2025-01-21 11:13:20,432 - trainer - INFO -     sim_loss       : 31.92654094696045
2025-01-21 11:13:20,432 - trainer - INFO -     gen_loss       : 389.3124572753906
2025-01-21 11:13:20,432 - trainer - INFO -     val_loss       : 397.00964546203613
2025-01-21 11:13:20,432 - trainer - INFO -     val_sim_loss   : 19.007495880126953
2025-01-21 11:13:20,432 - trainer - INFO -     val_gen_loss   : 378.0021381378174
2025-01-21 11:13:20,432 - trainer - INFO -     val_perplexity : 22.10340118408203
2025-01-21 11:13:20,432 - trainer - INFO -     val_embedding_sim: 0.12426705658435822
2025-01-21 11:13:20,432 - trainer - INFO - ================================================================================
2025-01-21 11:13:20,432 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:13:20
2025-01-21 11:13:24,993 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:13:24
2025-01-21 11:13:24,993 - trainer - INFO -     epoch          : 23
2025-01-21 11:13:24,994 - trainer - INFO -     elapsed time   : 4.561020135879517
2025-01-21 11:13:24,994 - trainer - INFO -     loss           : 269.63953857421876
2025-01-21 11:13:24,994 - trainer - INFO -     sim_loss       : 26.177098178863524
2025-01-21 11:13:24,994 - trainer - INFO -     gen_loss       : 373.9805908203125
2025-01-21 11:13:24,994 - trainer - INFO -     val_loss       : 393.6212100982666
2025-01-21 11:13:24,994 - trainer - INFO -     val_sim_loss   : 13.56025218963623
2025-01-21 11:13:24,994 - trainer - INFO -     val_gen_loss   : 380.06096839904785
2025-01-21 11:13:24,994 - trainer - INFO -     val_perplexity : 23.169965744018555
2025-01-21 11:13:24,994 - trainer - INFO -     val_embedding_sim: 0.13340717554092407
2025-01-21 11:13:24,994 - trainer - INFO - ================================================================================
2025-01-21 11:13:24,994 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:13:24
2025-01-21 11:13:29,552 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:13:29
2025-01-21 11:13:29,552 - trainer - INFO -     epoch          : 24
2025-01-21 11:13:29,552 - trainer - INFO -     elapsed time   : 4.5580055713653564
2025-01-21 11:13:29,552 - trainer - INFO -     loss           : 260.23777160644534
2025-01-21 11:13:29,552 - trainer - INFO -     sim_loss       : 29.470584630966187
2025-01-21 11:13:29,552 - trainer - INFO -     gen_loss       : 359.138005065918
2025-01-21 11:13:29,552 - trainer - INFO -     val_loss       : 395.44878005981445
2025-01-21 11:13:29,552 - trainer - INFO -     val_sim_loss   : 13.713739395141602
2025-01-21 11:13:29,552 - trainer - INFO -     val_gen_loss   : 381.73503494262695
2025-01-21 11:13:29,552 - trainer - INFO -     val_perplexity : 22.305845260620117
2025-01-21 11:13:29,553 - trainer - INFO -     val_embedding_sim: 0.13657024502754211
2025-01-21 11:13:29,553 - trainer - INFO - ================================================================================
2025-01-21 11:13:29,553 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:13:29
2025-01-21 11:13:34,109 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:13:34
2025-01-21 11:13:34,109 - trainer - INFO -     epoch          : 25
2025-01-21 11:13:34,109 - trainer - INFO -     elapsed time   : 4.555946111679077
2025-01-21 11:13:34,109 - trainer - INFO -     loss           : 250.63036575317383
2025-01-21 11:13:34,109 - trainer - INFO -     sim_loss       : 33.2254695892334
2025-01-21 11:13:34,109 - trainer - INFO -     gen_loss       : 343.8039016723633
2025-01-21 11:13:34,109 - trainer - INFO -     val_loss       : 399.9349250793457
2025-01-21 11:13:34,109 - trainer - INFO -     val_sim_loss   : 20.086755752563477
2025-01-21 11:13:34,109 - trainer - INFO -     val_gen_loss   : 379.8481636047363
2025-01-21 11:13:34,109 - trainer - INFO -     val_perplexity : 22.888904571533203
2025-01-21 11:13:34,109 - trainer - INFO -     val_embedding_sim: 0.1259290874004364
2025-01-21 11:13:40,707 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:13:40,707 - trainer - INFO - ================================================================================
2025-01-21 11:13:40,707 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:13:40
2025-01-21 11:13:45,326 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:13:45
2025-01-21 11:13:45,326 - trainer - INFO -     epoch          : 26
2025-01-21 11:13:45,326 - trainer - INFO -     elapsed time   : 4.618361711502075
2025-01-21 11:13:45,326 - trainer - INFO -     loss           : 241.240877532959
2025-01-21 11:13:45,326 - trainer - INFO -     sim_loss       : 31.417033195495605
2025-01-21 11:13:45,326 - trainer - INFO -     gen_loss       : 331.1653793334961
2025-01-21 11:13:45,326 - trainer - INFO -     val_loss       : 396.8886260986328
2025-01-21 11:13:45,326 - trainer - INFO -     val_sim_loss   : 16.99313735961914
2025-01-21 11:13:45,326 - trainer - INFO -     val_gen_loss   : 379.89549255371094
2025-01-21 11:13:45,326 - trainer - INFO -     val_perplexity : 23.603532791137695
2025-01-21 11:13:45,326 - trainer - INFO -     val_embedding_sim: 0.10897404700517654
2025-01-21 11:13:45,326 - trainer - INFO - ================================================================================
2025-01-21 11:13:45,326 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:13:45
2025-01-21 11:13:49,891 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:13:49
2025-01-21 11:13:49,891 - trainer - INFO -     epoch          : 27
2025-01-21 11:13:49,891 - trainer - INFO -     elapsed time   : 4.564455986022949
2025-01-21 11:13:49,891 - trainer - INFO -     loss           : 230.89159545898437
2025-01-21 11:13:49,891 - trainer - INFO -     sim_loss       : 30.764977788925172
2025-01-21 11:13:49,891 - trainer - INFO -     gen_loss       : 316.66014404296874
2025-01-21 11:13:49,891 - trainer - INFO -     val_loss       : 399.89412665367126
2025-01-21 11:13:49,891 - trainer - INFO -     val_sim_loss   : 18.296344757080078
2025-01-21 11:13:49,891 - trainer - INFO -     val_gen_loss   : 381.5977704524994
2025-01-21 11:13:49,891 - trainer - INFO -     val_perplexity : 23.667680740356445
2025-01-21 11:13:49,892 - trainer - INFO -     val_embedding_sim: 0.12040188163518906
2025-01-21 11:13:49,892 - trainer - INFO - ================================================================================
2025-01-21 11:13:49,892 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:13:49
2025-01-21 11:13:54,454 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:13:54
2025-01-21 11:13:54,454 - trainer - INFO -     epoch          : 28
2025-01-21 11:13:54,454 - trainer - INFO -     elapsed time   : 4.562309503555298
2025-01-21 11:13:54,454 - trainer - INFO -     loss           : 222.8546127319336
2025-01-21 11:13:54,454 - trainer - INFO -     sim_loss       : 33.23492383956909
2025-01-21 11:13:54,454 - trainer - INFO -     gen_loss       : 304.12020416259764
2025-01-21 11:13:54,454 - trainer - INFO -     val_loss       : 391.73510789871216
2025-01-21 11:13:54,454 - trainer - INFO -     val_sim_loss   : 15.501502990722656
2025-01-21 11:13:54,454 - trainer - INFO -     val_gen_loss   : 376.23361253738403
2025-01-21 11:13:54,455 - trainer - INFO -     val_perplexity : 23.231229782104492
2025-01-21 11:13:54,455 - trainer - INFO -     val_embedding_sim: 0.12449227273464203
2025-01-21 11:13:54,455 - trainer - INFO - ================================================================================
2025-01-21 11:13:54,455 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:13:54
2025-01-21 11:13:59,018 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:13:59
2025-01-21 11:13:59,018 - trainer - INFO -     epoch          : 29
2025-01-21 11:13:59,018 - trainer - INFO -     elapsed time   : 4.562906742095947
2025-01-21 11:13:59,018 - trainer - INFO -     loss           : 213.8287139892578
2025-01-21 11:13:59,018 - trainer - INFO -     sim_loss       : 29.46741352081299
2025-01-21 11:13:59,018 - trainer - INFO -     gen_loss       : 292.8407012939453
2025-01-21 11:13:59,018 - trainer - INFO -     val_loss       : 397.1207696199417
2025-01-21 11:13:59,018 - trainer - INFO -     val_sim_loss   : 21.591894149780273
2025-01-21 11:13:59,018 - trainer - INFO -     val_gen_loss   : 375.52888119220734
2025-01-21 11:13:59,018 - trainer - INFO -     val_perplexity : 23.353351593017578
2025-01-21 11:13:59,018 - trainer - INFO -     val_embedding_sim: 0.1492529809474945
2025-01-21 11:13:59,018 - trainer - INFO - ================================================================================
2025-01-21 11:13:59,018 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:13:59
2025-01-21 11:14:03,583 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:14:03
2025-01-21 11:14:03,583 - trainer - INFO -     epoch          : 30
2025-01-21 11:14:03,583 - trainer - INFO -     elapsed time   : 4.564481258392334
2025-01-21 11:14:03,583 - trainer - INFO -     loss           : 206.67319030761718
2025-01-21 11:14:03,583 - trainer - INFO -     sim_loss       : 36.619928169250485
2025-01-21 11:14:03,583 - trainer - INFO -     gen_loss       : 279.55316772460935
2025-01-21 11:14:03,583 - trainer - INFO -     val_loss       : 402.1353015899658
2025-01-21 11:14:03,583 - trainer - INFO -     val_sim_loss   : 25.790145874023438
2025-01-21 11:14:03,583 - trainer - INFO -     val_gen_loss   : 376.34517097473145
2025-01-21 11:14:03,583 - trainer - INFO -     val_perplexity : 22.717466354370117
2025-01-21 11:14:03,583 - trainer - INFO -     val_embedding_sim: 0.13846993446350098
2025-01-21 11:14:10,189 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:14:10,190 - trainer - INFO - ================================================================================
2025-01-21 11:14:10,190 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:14:10
2025-01-21 11:14:14,804 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:14:14
2025-01-21 11:14:14,804 - trainer - INFO -     epoch          : 31
2025-01-21 11:14:14,804 - trainer - INFO -     elapsed time   : 4.613956689834595
2025-01-21 11:14:14,804 - trainer - INFO -     loss           : 194.52911758422852
2025-01-21 11:14:14,804 - trainer - INFO -     sim_loss       : 29.904891538619996
2025-01-21 11:14:14,804 - trainer - INFO -     gen_loss       : 265.0823600769043
2025-01-21 11:14:14,804 - trainer - INFO -     val_loss       : 396.39954662323
2025-01-21 11:14:14,804 - trainer - INFO -     val_sim_loss   : 17.623252868652344
2025-01-21 11:14:14,804 - trainer - INFO -     val_gen_loss   : 378.7762861251831
2025-01-21 11:14:14,805 - trainer - INFO -     val_perplexity : 23.107919692993164
2025-01-21 11:14:14,805 - trainer - INFO -     val_embedding_sim: 0.17073889076709747
2025-01-21 11:14:14,805 - trainer - INFO - ================================================================================
2025-01-21 11:14:14,805 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:14:14
2025-01-21 11:14:19,369 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:14:19
2025-01-21 11:14:19,370 - trainer - INFO -     epoch          : 32
2025-01-21 11:14:19,370 - trainer - INFO -     elapsed time   : 4.56469464302063
2025-01-21 11:14:19,370 - trainer - INFO -     loss           : 189.03326568603515
2025-01-21 11:14:19,370 - trainer - INFO -     sim_loss       : 31.68226718902588
2025-01-21 11:14:19,370 - trainer - INFO -     gen_loss       : 256.469416809082
2025-01-21 11:14:19,370 - trainer - INFO -     val_loss       : 403.6430250406265
2025-01-21 11:14:19,370 - trainer - INFO -     val_sim_loss   : 21.165815353393555
2025-01-21 11:14:19,370 - trainer - INFO -     val_gen_loss   : 382.4772230386734
2025-01-21 11:14:19,370 - trainer - INFO -     val_perplexity : 23.788434982299805
2025-01-21 11:14:19,370 - trainer - INFO -     val_embedding_sim: 0.1371602863073349
2025-01-21 11:14:19,370 - trainer - INFO - ================================================================================
2025-01-21 11:14:19,370 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:14:19
2025-01-21 11:14:23,934 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:14:23
2025-01-21 11:14:23,934 - trainer - INFO -     epoch          : 33
2025-01-21 11:14:23,934 - trainer - INFO -     elapsed time   : 4.5640482902526855
2025-01-21 11:14:23,934 - trainer - INFO -     loss           : 177.63856506347656
2025-01-21 11:14:23,935 - trainer - INFO -     sim_loss       : 27.81475439071655
2025-01-21 11:14:23,935 - trainer - INFO -     gen_loss       : 241.84877166748046
2025-01-21 11:14:23,935 - trainer - INFO -     val_loss       : 391.63689613342285
2025-01-21 11:14:23,935 - trainer - INFO -     val_sim_loss   : 13.929226875305176
2025-01-21 11:14:23,935 - trainer - INFO -     val_gen_loss   : 377.7076663970947
2025-01-21 11:14:23,935 - trainer - INFO -     val_perplexity : 22.54424476623535
2025-01-21 11:14:23,935 - trainer - INFO -     val_embedding_sim: 0.11543358117341995
2025-01-21 11:14:23,935 - trainer - INFO - ================================================================================
2025-01-21 11:14:23,935 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:14:23
2025-01-21 11:14:28,503 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:14:28
2025-01-21 11:14:28,503 - trainer - INFO -     epoch          : 34
2025-01-21 11:14:28,503 - trainer - INFO -     elapsed time   : 4.567615985870361
2025-01-21 11:14:28,503 - trainer - INFO -     loss           : 173.56130828857422
2025-01-21 11:14:28,503 - trainer - INFO -     sim_loss       : 33.98968234062195
2025-01-21 11:14:28,503 - trainer - INFO -     gen_loss       : 233.3777229309082
2025-01-21 11:14:28,503 - trainer - INFO -     val_loss       : 401.06562328338623
2025-01-21 11:14:28,503 - trainer - INFO -     val_sim_loss   : 27.426424026489258
2025-01-21 11:14:28,503 - trainer - INFO -     val_gen_loss   : 373.6392011642456
2025-01-21 11:14:28,503 - trainer - INFO -     val_perplexity : 22.516321182250977
2025-01-21 11:14:28,503 - trainer - INFO -     val_embedding_sim: 0.12199679762125015
2025-01-21 11:14:28,503 - trainer - INFO - ================================================================================
2025-01-21 11:14:28,503 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:14:28
2025-01-21 11:14:33,066 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:14:33
2025-01-21 11:14:33,067 - trainer - INFO -     epoch          : 35
2025-01-21 11:14:33,067 - trainer - INFO -     elapsed time   : 4.562997579574585
2025-01-21 11:14:33,067 - trainer - INFO -     loss           : 163.6370948791504
2025-01-21 11:14:33,067 - trainer - INFO -     sim_loss       : 27.893446063995363
2025-01-21 11:14:33,067 - trainer - INFO -     gen_loss       : 221.8129455566406
2025-01-21 11:14:33,067 - trainer - INFO -     val_loss       : 395.5744094848633
2025-01-21 11:14:33,067 - trainer - INFO -     val_sim_loss   : 21.004871368408203
2025-01-21 11:14:33,067 - trainer - INFO -     val_gen_loss   : 374.5695266723633
2025-01-21 11:14:33,067 - trainer - INFO -     val_perplexity : 22.5820255279541
2025-01-21 11:14:33,067 - trainer - INFO -     val_embedding_sim: 0.1348343938589096
2025-01-21 11:14:39,683 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:14:39,683 - trainer - INFO - ================================================================================
2025-01-21 11:14:39,684 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:14:39
2025-01-21 11:14:44,303 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:14:44
2025-01-21 11:14:44,303 - trainer - INFO -     epoch          : 36
2025-01-21 11:14:44,303 - trainer - INFO -     elapsed time   : 4.618896484375
2025-01-21 11:14:44,303 - trainer - INFO -     loss           : 160.2550277709961
2025-01-21 11:14:44,303 - trainer - INFO -     sim_loss       : 33.60226168632507
2025-01-21 11:14:44,303 - trainer - INFO -     gen_loss       : 214.5347915649414
2025-01-21 11:14:44,303 - trainer - INFO -     val_loss       : 386.07683539390564
2025-01-21 11:14:44,303 - trainer - INFO -     val_sim_loss   : 13.428598403930664
2025-01-21 11:14:44,303 - trainer - INFO -     val_gen_loss   : 372.64824652671814
2025-01-21 11:14:44,303 - trainer - INFO -     val_perplexity : 23.08075714111328
2025-01-21 11:14:44,303 - trainer - INFO -     val_embedding_sim: 0.11242779344320297
2025-01-21 11:14:44,303 - trainer - INFO - ================================================================================
2025-01-21 11:14:44,303 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:14:44
2025-01-21 11:14:48,870 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:14:48
2025-01-21 11:14:48,870 - trainer - INFO -     epoch          : 37
2025-01-21 11:14:48,870 - trainer - INFO -     elapsed time   : 4.566609859466553
2025-01-21 11:14:48,870 - trainer - INFO -     loss           : 148.95243492126465
2025-01-21 11:14:48,870 - trainer - INFO -     sim_loss       : 25.449046206474303
2025-01-21 11:14:48,870 - trainer - INFO -     gen_loss       : 201.88246002197266
2025-01-21 11:14:48,870 - trainer - INFO -     val_loss       : 392.71287536621094
2025-01-21 11:14:48,870 - trainer - INFO -     val_sim_loss   : 20.097923278808594
2025-01-21 11:14:48,870 - trainer - INFO -     val_gen_loss   : 372.6149444580078
2025-01-21 11:14:48,870 - trainer - INFO -     val_perplexity : 23.152469635009766
2025-01-21 11:14:48,870 - trainer - INFO -     val_embedding_sim: 0.1461917757987976
2025-01-21 11:14:48,871 - trainer - INFO - ================================================================================
2025-01-21 11:14:48,871 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:14:48
2025-01-21 11:14:53,430 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:14:53
2025-01-21 11:14:53,430 - trainer - INFO -     epoch          : 38
2025-01-21 11:14:53,430 - trainer - INFO -     elapsed time   : 4.559458017349243
2025-01-21 11:14:53,430 - trainer - INFO -     loss           : 146.4779281616211
2025-01-21 11:14:53,430 - trainer - INFO -     sim_loss       : 31.697963523864747
2025-01-21 11:14:53,430 - trainer - INFO -     gen_loss       : 195.6693473815918
2025-01-21 11:14:53,430 - trainer - INFO -     val_loss       : 389.6636233329773
2025-01-21 11:14:53,431 - trainer - INFO -     val_sim_loss   : 13.5949125289917
2025-01-21 11:14:53,431 - trainer - INFO -     val_gen_loss   : 376.06871366500854
2025-01-21 11:14:53,431 - trainer - INFO -     val_perplexity : 23.394367218017578
2025-01-21 11:14:53,431 - trainer - INFO -     val_embedding_sim: 0.12763938307762146
2025-01-21 11:14:53,431 - trainer - INFO - ================================================================================
2025-01-21 11:14:53,431 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:14:53
2025-01-21 11:14:57,989 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:14:57
2025-01-21 11:14:57,989 - trainer - INFO -     epoch          : 39
2025-01-21 11:14:57,989 - trainer - INFO -     elapsed time   : 4.558018207550049
2025-01-21 11:14:57,989 - trainer - INFO -     loss           : 140.51460914611818
2025-01-21 11:14:57,989 - trainer - INFO -     sim_loss       : 33.50286521911621
2025-01-21 11:14:57,989 - trainer - INFO -     gen_loss       : 186.3767868041992
2025-01-21 11:14:57,989 - trainer - INFO -     val_loss       : 399.5722465515137
2025-01-21 11:14:57,989 - trainer - INFO -     val_sim_loss   : 23.41248893737793
2025-01-21 11:14:57,989 - trainer - INFO -     val_gen_loss   : 376.1597709655762
2025-01-21 11:14:57,989 - trainer - INFO -     val_perplexity : 22.79643440246582
2025-01-21 11:14:57,989 - trainer - INFO -     val_embedding_sim: 0.13913622498512268
2025-01-21 11:14:57,989 - trainer - INFO - ================================================================================
2025-01-21 11:14:57,989 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:14:57
2025-01-21 11:15:02,555 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:15:02
2025-01-21 11:15:02,555 - trainer - INFO -     epoch          : 40
2025-01-21 11:15:02,555 - trainer - INFO -     elapsed time   : 4.565335035324097
2025-01-21 11:15:02,555 - trainer - INFO -     loss           : 136.96771850585938
2025-01-21 11:15:02,555 - trainer - INFO -     sim_loss       : 37.29016489982605
2025-01-21 11:15:02,555 - trainer - INFO -     gen_loss       : 179.6866714477539
2025-01-21 11:15:02,555 - trainer - INFO -     val_loss       : 399.78668785095215
2025-01-21 11:15:02,555 - trainer - INFO -     val_sim_loss   : 24.747440338134766
2025-01-21 11:15:02,555 - trainer - INFO -     val_gen_loss   : 375.03925132751465
2025-01-21 11:15:02,555 - trainer - INFO -     val_perplexity : 21.91678237915039
2025-01-21 11:15:02,555 - trainer - INFO -     val_embedding_sim: 0.13902541995048523
2025-01-21 11:15:09,187 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:15:09,187 - trainer - INFO - ================================================================================
2025-01-21 11:15:09,187 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:15:09
2025-01-21 11:15:13,784 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:15:13
2025-01-21 11:15:13,785 - trainer - INFO -     epoch          : 41
2025-01-21 11:15:13,785 - trainer - INFO -     elapsed time   : 4.597129821777344
2025-01-21 11:15:13,785 - trainer - INFO -     loss           : 128.76530685424805
2025-01-21 11:15:13,785 - trainer - INFO -     sim_loss       : 31.25827827453613
2025-01-21 11:15:13,785 - trainer - INFO -     gen_loss       : 170.5540344238281
2025-01-21 11:15:13,785 - trainer - INFO -     val_loss       : 395.3981956243515
2025-01-21 11:15:13,785 - trainer - INFO -     val_sim_loss   : 18.321426391601562
2025-01-21 11:15:13,785 - trainer - INFO -     val_gen_loss   : 377.076784491539
2025-01-21 11:15:13,785 - trainer - INFO -     val_perplexity : 23.451610565185547
2025-01-21 11:15:13,785 - trainer - INFO -     val_embedding_sim: 0.12217862904071808
2025-01-21 11:15:13,785 - trainer - INFO - ================================================================================
2025-01-21 11:15:13,785 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:15:13
2025-01-21 11:15:18,355 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:15:18
2025-01-21 11:15:18,356 - trainer - INFO -     epoch          : 42
2025-01-21 11:15:18,356 - trainer - INFO -     elapsed time   : 4.570374488830566
2025-01-21 11:15:18,356 - trainer - INFO -     loss           : 123.39893035888672
2025-01-21 11:15:18,356 - trainer - INFO -     sim_loss       : 32.087532711029056
2025-01-21 11:15:18,356 - trainer - INFO -     gen_loss       : 162.5323860168457
2025-01-21 11:15:18,356 - trainer - INFO -     val_loss       : 404.6431770324707
2025-01-21 11:15:18,356 - trainer - INFO -     val_sim_loss   : 25.69782257080078
2025-01-21 11:15:18,356 - trainer - INFO -     val_gen_loss   : 378.94536209106445
2025-01-21 11:15:18,356 - trainer - INFO -     val_perplexity : 22.27101707458496
2025-01-21 11:15:18,356 - trainer - INFO -     val_embedding_sim: 0.1523265838623047
2025-01-21 11:15:18,356 - trainer - INFO - ================================================================================
2025-01-21 11:15:18,356 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:15:18
2025-01-21 11:15:22,932 - trainer - INFO - Epoch 43 completed at 2025-01-21 11:15:22
2025-01-21 11:15:22,932 - trainer - INFO -     epoch          : 43
2025-01-21 11:15:22,932 - trainer - INFO -     elapsed time   : 4.575412273406982
2025-01-21 11:15:22,932 - trainer - INFO -     loss           : 118.55370712280273
2025-01-21 11:15:22,932 - trainer - INFO -     sim_loss       : 30.27674217224121
2025-01-21 11:15:22,932 - trainer - INFO -     gen_loss       : 156.3866958618164
2025-01-21 11:15:22,932 - trainer - INFO -     val_loss       : 391.01464080810547
2025-01-21 11:15:22,932 - trainer - INFO -     val_sim_loss   : 13.437350273132324
2025-01-21 11:15:22,932 - trainer - INFO -     val_gen_loss   : 377.5772933959961
2025-01-21 11:15:22,932 - trainer - INFO -     val_perplexity : 21.341527938842773
2025-01-21 11:15:22,932 - trainer - INFO -     val_embedding_sim: 0.13483595848083496
2025-01-21 11:15:22,932 - trainer - INFO - ================================================================================
2025-01-21 11:15:22,932 - trainer - INFO - Starting epoch 44 at 2025-01-21 11:15:22
2025-01-21 11:15:27,495 - trainer - INFO - Epoch 44 completed at 2025-01-21 11:15:27
2025-01-21 11:15:27,495 - trainer - INFO -     epoch          : 44
2025-01-21 11:15:27,495 - trainer - INFO -     elapsed time   : 4.562167644500732
2025-01-21 11:15:27,495 - trainer - INFO -     loss           : 115.43269653320313
2025-01-21 11:15:27,495 - trainer - INFO -     sim_loss       : 32.80137710571289
2025-01-21 11:15:27,495 - trainer - INFO -     gen_loss       : 150.84612045288085
2025-01-21 11:15:27,495 - trainer - INFO -     val_loss       : 403.5951051712036
2025-01-21 11:15:27,495 - trainer - INFO -     val_sim_loss   : 22.4921817779541
2025-01-21 11:15:27,495 - trainer - INFO -     val_gen_loss   : 381.1029176712036
2025-01-21 11:15:27,495 - trainer - INFO -     val_perplexity : 23.727270126342773
2025-01-21 11:15:27,495 - trainer - INFO -     val_embedding_sim: 0.13543830811977386
2025-01-21 11:15:27,495 - trainer - INFO - ================================================================================
2025-01-21 11:15:27,495 - trainer - INFO - Starting epoch 45 at 2025-01-21 11:15:27
2025-01-21 11:15:32,062 - trainer - INFO - Epoch 45 completed at 2025-01-21 11:15:32
2025-01-21 11:15:32,062 - trainer - INFO -     epoch          : 45
2025-01-21 11:15:32,062 - trainer - INFO -     elapsed time   : 4.567048072814941
2025-01-21 11:15:32,063 - trainer - INFO -     loss           : 110.06602363586425
2025-01-21 11:15:32,063 - trainer - INFO -     sim_loss       : 34.917249584198
2025-01-21 11:15:32,063 - trainer - INFO -     gen_loss       : 142.27264137268065
2025-01-21 11:15:32,063 - trainer - INFO -     val_loss       : 398.8674466609955
2025-01-21 11:15:32,063 - trainer - INFO -     val_sim_loss   : 20.368663787841797
2025-01-21 11:15:32,063 - trainer - INFO -     val_gen_loss   : 378.4987943172455
2025-01-21 11:15:32,063 - trainer - INFO -     val_perplexity : 23.4541072845459
2025-01-21 11:15:32,063 - trainer - INFO -     val_embedding_sim: 0.1700267344713211
2025-01-21 11:15:38,588 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 11:15:38,589 - trainer - INFO - ================================================================================
2025-01-21 11:15:38,589 - trainer - INFO - Starting epoch 46 at 2025-01-21 11:15:38
2025-01-21 11:15:43,204 - trainer - INFO - Epoch 46 completed at 2025-01-21 11:15:43
2025-01-21 11:15:43,204 - trainer - INFO -     epoch          : 46
2025-01-21 11:15:43,204 - trainer - INFO -     elapsed time   : 4.614623546600342
2025-01-21 11:15:43,204 - trainer - INFO -     loss           : 105.03941535949707
2025-01-21 11:15:43,204 - trainer - INFO -     sim_loss       : 35.648542165756226
2025-01-21 11:15:43,204 - trainer - INFO -     gen_loss       : 134.77836494445802
2025-01-21 11:15:43,204 - trainer - INFO -     val_loss       : 395.583779335022
2025-01-21 11:15:43,204 - trainer - INFO -     val_sim_loss   : 16.659791946411133
2025-01-21 11:15:43,204 - trainer - INFO -     val_gen_loss   : 378.9239892959595
2025-01-21 11:15:43,204 - trainer - INFO -     val_perplexity : 23.02998161315918
2025-01-21 11:15:43,204 - trainer - INFO -     val_embedding_sim: 0.14400175213813782
2025-01-21 11:15:43,204 - trainer - INFO - ================================================================================
2025-01-21 11:15:43,204 - trainer - INFO - Starting epoch 47 at 2025-01-21 11:15:43
2025-01-21 11:15:47,772 - trainer - INFO - Epoch 47 completed at 2025-01-21 11:15:47
2025-01-21 11:15:47,772 - trainer - INFO -     epoch          : 47
2025-01-21 11:15:47,772 - trainer - INFO -     elapsed time   : 4.5675928592681885
2025-01-21 11:15:47,772 - trainer - INFO -     loss           : 98.83382110595703
2025-01-21 11:15:47,772 - trainer - INFO -     sim_loss       : 35.197865104675294
2025-01-21 11:15:47,772 - trainer - INFO -     gen_loss       : 126.10637245178222
2025-01-21 11:15:47,772 - trainer - INFO -     val_loss       : 403.45317459106445
2025-01-21 11:15:47,772 - trainer - INFO -     val_sim_loss   : 21.208770751953125
2025-01-21 11:15:47,772 - trainer - INFO -     val_gen_loss   : 382.2444038391113
2025-01-21 11:15:47,772 - trainer - INFO -     val_perplexity : 22.829626083374023
2025-01-21 11:15:47,773 - trainer - INFO -     val_embedding_sim: 0.1363617479801178
2025-01-21 11:15:47,773 - trainer - INFO - ================================================================================
2025-01-21 11:15:47,773 - trainer - INFO - Starting epoch 48 at 2025-01-21 11:15:47
2025-01-21 11:15:52,330 - trainer - INFO - Epoch 48 completed at 2025-01-21 11:15:52
2025-01-21 11:15:52,330 - trainer - INFO -     epoch          : 48
2025-01-21 11:15:52,330 - trainer - INFO -     elapsed time   : 4.5571489334106445
2025-01-21 11:15:52,330 - trainer - INFO -     loss           : 97.1100009918213
2025-01-21 11:15:52,330 - trainer - INFO -     sim_loss       : 36.725960397720335
2025-01-21 11:15:52,330 - trainer - INFO -     gen_loss       : 122.98887672424317
2025-01-21 11:15:52,330 - trainer - INFO -     val_loss       : 395.4956430196762
2025-01-21 11:15:52,330 - trainer - INFO -     val_sim_loss   : 16.857568740844727
2025-01-21 11:15:52,330 - trainer - INFO -     val_gen_loss   : 378.6380685567856
2025-01-21 11:15:52,330 - trainer - INFO -     val_perplexity : 23.586864471435547
2025-01-21 11:15:52,330 - trainer - INFO -     val_embedding_sim: 0.14440932869911194
2025-01-21 11:15:52,330 - trainer - INFO - ================================================================================
2025-01-21 11:15:52,330 - trainer - INFO - Starting epoch 49 at 2025-01-21 11:15:52
2025-01-21 11:15:56,901 - trainer - INFO - Epoch 49 completed at 2025-01-21 11:15:56
2025-01-21 11:15:56,902 - trainer - INFO -     epoch          : 49
2025-01-21 11:15:56,902 - trainer - INFO -     elapsed time   : 4.57081151008606
2025-01-21 11:15:56,902 - trainer - INFO -     loss           : 93.32399291992188
2025-01-21 11:15:56,902 - trainer - INFO -     sim_loss       : 36.04694185256958
2025-01-21 11:15:56,902 - trainer - INFO -     gen_loss       : 117.8713005065918
2025-01-21 11:15:56,902 - trainer - INFO -     val_loss       : 393.8632539510727
2025-01-21 11:15:56,902 - trainer - INFO -     val_sim_loss   : 15.062725067138672
2025-01-21 11:15:56,902 - trainer - INFO -     val_gen_loss   : 378.8005403280258
2025-01-21 11:15:56,902 - trainer - INFO -     val_perplexity : 23.550308227539062
2025-01-21 11:15:56,902 - trainer - INFO -     val_embedding_sim: 0.13131709396839142
2025-01-21 11:15:56,902 - trainer - INFO - ================================================================================
2025-01-21 11:15:56,902 - trainer - INFO - Starting epoch 50 at 2025-01-21 11:15:56
2025-01-21 11:16:01,465 - trainer - INFO - Epoch 50 completed at 2025-01-21 11:16:01
2025-01-21 11:16:01,465 - trainer - INFO -     epoch          : 50
2025-01-21 11:16:01,465 - trainer - INFO -     elapsed time   : 4.562373638153076
2025-01-21 11:16:01,465 - trainer - INFO -     loss           : 88.36971130371094
2025-01-21 11:16:01,465 - trainer - INFO -     sim_loss       : 32.55777258872986
2025-01-21 11:16:01,465 - trainer - INFO -     gen_loss       : 112.28911323547364
2025-01-21 11:16:01,465 - trainer - INFO -     val_loss       : 394.0857892036438
2025-01-21 11:16:01,465 - trainer - INFO -     val_sim_loss   : 11.313129425048828
2025-01-21 11:16:01,465 - trainer - INFO -     val_gen_loss   : 382.7726483345032
2025-01-21 11:16:01,465 - trainer - INFO -     val_perplexity : 23.731475830078125
2025-01-21 11:16:01,465 - trainer - INFO -     val_embedding_sim: 0.1426618993282318
2025-01-21 11:16:07,995 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 11:16:07,995 - trainer - INFO - ================================================================================
2025-01-21 11:16:07,995 - trainer - INFO - Starting epoch 51 at 2025-01-21 11:16:07
2025-01-21 11:16:12,598 - trainer - INFO - Epoch 51 completed at 2025-01-21 11:16:12
2025-01-21 11:16:12,598 - trainer - INFO -     epoch          : 51
2025-01-21 11:16:12,598 - trainer - INFO -     elapsed time   : 4.601958274841309
2025-01-21 11:16:12,598 - trainer - INFO -     loss           : 85.95858802795411
2025-01-21 11:16:12,598 - trainer - INFO -     sim_loss       : 35.77648487091064
2025-01-21 11:16:12,598 - trainer - INFO -     gen_loss       : 107.46520614624023
2025-01-21 11:16:12,598 - trainer - INFO -     val_loss       : 406.21192741394043
2025-01-21 11:16:12,598 - trainer - INFO -     val_sim_loss   : 16.51332664489746
2025-01-21 11:16:12,598 - trainer - INFO -     val_gen_loss   : 389.6985912322998
2025-01-21 11:16:12,598 - trainer - INFO -     val_perplexity : 22.792062759399414
2025-01-21 11:16:12,598 - trainer - INFO -     val_embedding_sim: 0.14329802989959717
2025-01-21 11:16:12,598 - trainer - INFO - ================================================================================
2025-01-21 11:16:12,598 - trainer - INFO - Starting epoch 52 at 2025-01-21 11:16:12
2025-01-21 11:16:17,157 - trainer - INFO - Epoch 52 completed at 2025-01-21 11:16:17
2025-01-21 11:16:17,158 - trainer - INFO -     epoch          : 52
2025-01-21 11:16:17,158 - trainer - INFO -     elapsed time   : 4.559184789657593
2025-01-21 11:16:17,158 - trainer - INFO -     loss           : 82.31015815734864
2025-01-21 11:16:17,158 - trainer - INFO -     sim_loss       : 29.756574440002442
2025-01-21 11:16:17,158 - trainer - INFO -     gen_loss       : 104.83312339782715
2025-01-21 11:16:17,158 - trainer - INFO -     val_loss       : 399.3372573852539
2025-01-21 11:16:17,158 - trainer - INFO -     val_sim_loss   : 16.068708419799805
2025-01-21 11:16:17,158 - trainer - INFO -     val_gen_loss   : 383.26856231689453
2025-01-21 11:16:17,158 - trainer - INFO -     val_perplexity : 21.720365524291992
2025-01-21 11:16:17,158 - trainer - INFO -     val_embedding_sim: 0.13712874054908752
2025-01-21 11:16:17,158 - trainer - INFO - ================================================================================
2025-01-21 11:16:17,158 - trainer - INFO - Starting epoch 53 at 2025-01-21 11:16:17
2025-01-21 11:16:21,729 - trainer - INFO - Epoch 53 completed at 2025-01-21 11:16:21
2025-01-21 11:16:21,730 - trainer - INFO -     epoch          : 53
2025-01-21 11:16:21,730 - trainer - INFO -     elapsed time   : 4.571425914764404
2025-01-21 11:16:21,730 - trainer - INFO -     loss           : 81.50887565612793
2025-01-21 11:16:21,730 - trainer - INFO -     sim_loss       : 32.04063081741333
2025-01-21 11:16:21,730 - trainer - INFO -     gen_loss       : 102.70955200195313
2025-01-21 11:16:21,730 - trainer - INFO -     val_loss       : 409.5026388168335
2025-01-21 11:16:21,730 - trainer - INFO -     val_sim_loss   : 18.835834503173828
2025-01-21 11:16:21,730 - trainer - INFO -     val_gen_loss   : 390.66679286956787
2025-01-21 11:16:21,730 - trainer - INFO -     val_perplexity : 23.63766860961914
2025-01-21 11:16:21,730 - trainer - INFO -     val_embedding_sim: 0.1520335078239441
2025-01-21 11:16:21,730 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
2025-01-21 11:25:51,718 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:25:54,381 - trainer - INFO - ================================================================================
2025-01-21 11:25:54,381 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:25:54
2025-01-21 11:28:40,589 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:28:42,918 - trainer - INFO - ================================================================================
2025-01-21 11:28:42,918 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:28:42
2025-01-21 11:33:15,088 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 11:33:17,412 - trainer - INFO - ================================================================================
2025-01-21 11:33:17,412 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:33:17
2025-01-21 11:33:22,458 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:33:22
2025-01-21 11:33:22,459 - trainer - INFO -     epoch          : 1
2025-01-21 11:33:22,459 - trainer - INFO -     elapsed time   : 5.0457916259765625
2025-01-21 11:33:22,459 - trainer - INFO -     loss           : -186.0404510498047
2025-01-21 11:33:22,459 - trainer - INFO -     sim_loss       : 103.14251823425293
2025-01-21 11:33:22,459 - trainer - INFO -     gen_loss       : -309.97600536346437
2025-01-21 11:33:22,459 - trainer - INFO -     val_loss       : -271.89404487609863
2025-01-21 11:33:22,459 - trainer - INFO -     val_sim_loss   : 55.4388427734375
2025-01-21 11:33:22,459 - trainer - INFO -     val_gen_loss   : -327.33288764953613
2025-01-21 11:33:22,459 - trainer - INFO -     val_perplexity : -19.720016479492188
2025-01-21 11:33:22,459 - trainer - INFO -     val_embedding_sim: 0.06163272261619568
2025-01-21 11:33:22,459 - trainer - INFO - ================================================================================
2025-01-21 11:33:22,459 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:33:22
2025-01-21 11:33:26,327 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:33:26
2025-01-21 11:33:26,327 - trainer - INFO -     epoch          : 2
2025-01-21 11:33:26,327 - trainer - INFO -     elapsed time   : 3.867727279663086
2025-01-21 11:33:26,327 - trainer - INFO -     loss           : -446.7950927734375
2025-01-21 11:33:26,327 - trainer - INFO -     sim_loss       : 103.08970260620117
2025-01-21 11:33:26,327 - trainer - INFO -     gen_loss       : -682.460009765625
2025-01-21 11:33:26,327 - trainer - INFO -     val_loss       : -360.1834659576416
2025-01-21 11:33:26,327 - trainer - INFO -     val_sim_loss   : 55.436805725097656
2025-01-21 11:33:26,327 - trainer - INFO -     val_gen_loss   : -415.6202640533447
2025-01-21 11:33:26,327 - trainer - INFO -     val_perplexity : -25.247425079345703
2025-01-21 11:33:26,327 - trainer - INFO -     val_embedding_sim: 0.07722928375005722
2025-01-21 11:33:26,327 - trainer - INFO - ================================================================================
2025-01-21 11:33:26,327 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:33:26
2025-01-21 11:33:30,174 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:33:30
2025-01-21 11:33:30,174 - trainer - INFO -     epoch          : 3
2025-01-21 11:33:30,175 - trainer - INFO -     elapsed time   : 3.846780300140381
2025-01-21 11:33:30,175 - trainer - INFO -     loss           : -548.9736419677735
2025-01-21 11:33:30,175 - trainer - INFO -     sim_loss       : 103.09343910217285
2025-01-21 11:33:30,175 - trainer - INFO -     gen_loss       : -828.4309509277343
2025-01-21 11:33:30,175 - trainer - INFO -     val_loss       : -417.46892833709717
2025-01-21 11:33:30,175 - trainer - INFO -     val_sim_loss   : 55.42972183227539
2025-01-21 11:33:30,175 - trainer - INFO -     val_gen_loss   : -472.8986463546753
2025-01-21 11:33:30,175 - trainer - INFO -     val_perplexity : -28.798437118530273
2025-01-21 11:33:30,175 - trainer - INFO -     val_embedding_sim: 0.10232995450496674
2025-01-21 11:33:30,175 - trainer - INFO - ================================================================================
2025-01-21 11:33:30,175 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:33:30
2025-01-21 11:33:34,048 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:33:34
2025-01-21 11:33:34,049 - trainer - INFO -     epoch          : 4
2025-01-21 11:33:34,049 - trainer - INFO -     elapsed time   : 3.8733811378479004
2025-01-21 11:33:34,049 - trainer - INFO -     loss           : -641.108773803711
2025-01-21 11:33:34,049 - trainer - INFO -     sim_loss       : 103.03101615905761
2025-01-21 11:33:34,049 - trainer - INFO -     gen_loss       : -960.0258575439453
2025-01-21 11:33:34,049 - trainer - INFO -     val_loss       : -471.51708984375
2025-01-21 11:33:34,049 - trainer - INFO -     val_sim_loss   : 55.35968017578125
2025-01-21 11:33:34,049 - trainer - INFO -     val_gen_loss   : -526.8767700195312
2025-01-21 11:33:34,049 - trainer - INFO -     val_perplexity : -31.79959487915039
2025-01-21 11:33:34,049 - trainer - INFO -     val_embedding_sim: 0.0743759348988533
2025-01-21 11:33:34,049 - trainer - INFO - ================================================================================
2025-01-21 11:33:34,049 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:33:34
2025-01-21 11:33:37,916 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:33:37
2025-01-21 11:33:37,916 - trainer - INFO -     epoch          : 5
2025-01-21 11:33:37,916 - trainer - INFO -     elapsed time   : 3.866490125656128
2025-01-21 11:33:37,916 - trainer - INFO -     loss           : -725.3343200683594
2025-01-21 11:33:37,916 - trainer - INFO -     sim_loss       : 102.92963676452636
2025-01-21 11:33:37,916 - trainer - INFO -     gen_loss       : -1080.3046020507813
2025-01-21 11:33:37,916 - trainer - INFO -     val_loss       : -517.2770233154297
2025-01-21 11:33:37,916 - trainer - INFO -     val_sim_loss   : 55.31756591796875
2025-01-21 11:33:37,916 - trainer - INFO -     val_gen_loss   : -572.5945892333984
2025-01-21 11:33:37,916 - trainer - INFO -     val_perplexity : -34.9989013671875
2025-01-21 11:33:37,916 - trainer - INFO -     val_embedding_sim: 0.07094588130712509
2025-01-21 11:33:44,469 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:33:51,021 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:33:51,021 - trainer - INFO - ================================================================================
2025-01-21 11:33:51,021 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:33:51
2025-01-21 11:33:54,953 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:33:54
2025-01-21 11:33:54,953 - trainer - INFO -     epoch          : 6
2025-01-21 11:33:54,953 - trainer - INFO -     elapsed time   : 3.931112766265869
2025-01-21 11:33:54,953 - trainer - INFO -     loss           : -803.4116302490235
2025-01-21 11:33:54,953 - trainer - INFO -     sim_loss       : 102.75180358886719
2025-01-21 11:33:54,953 - trainer - INFO -     gen_loss       : -1191.7674072265625
2025-01-21 11:33:54,953 - trainer - INFO -     val_loss       : -558.4826641082764
2025-01-21 11:33:54,953 - trainer - INFO -     val_sim_loss   : 55.269935607910156
2025-01-21 11:33:54,953 - trainer - INFO -     val_gen_loss   : -613.7526226043701
2025-01-21 11:33:54,953 - trainer - INFO -     val_perplexity : -37.490962982177734
2025-01-21 11:33:54,953 - trainer - INFO -     val_embedding_sim: 0.05555592477321625
2025-01-21 11:33:54,953 - trainer - INFO - ================================================================================
2025-01-21 11:33:54,953 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:33:54
2025-01-21 11:33:58,816 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:33:58
2025-01-21 11:33:58,816 - trainer - INFO -     epoch          : 7
2025-01-21 11:33:58,816 - trainer - INFO -     elapsed time   : 3.862797498703003
2025-01-21 11:33:58,816 - trainer - INFO -     loss           : -874.2744110107421
2025-01-21 11:33:58,816 - trainer - INFO -     sim_loss       : 102.52275619506835
2025-01-21 11:33:58,816 - trainer - INFO -     gen_loss       : -1292.9017822265625
2025-01-21 11:33:58,816 - trainer - INFO -     val_loss       : -598.2091226577759
2025-01-21 11:33:58,816 - trainer - INFO -     val_sim_loss   : 55.188926696777344
2025-01-21 11:33:58,816 - trainer - INFO -     val_gen_loss   : -653.3980264663696
2025-01-21 11:33:58,817 - trainer - INFO -     val_perplexity : -39.93813705444336
2025-01-21 11:33:58,817 - trainer - INFO -     val_embedding_sim: 0.07075679302215576
2025-01-21 11:33:58,817 - trainer - INFO - ================================================================================
2025-01-21 11:33:58,817 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:33:58
2025-01-21 11:34:02,689 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:34:02
2025-01-21 11:34:02,689 - trainer - INFO -     epoch          : 8
2025-01-21 11:34:02,689 - trainer - INFO -     elapsed time   : 3.872079372406006
2025-01-21 11:34:02,689 - trainer - INFO -     loss           : -939.8270446777344
2025-01-21 11:34:02,689 - trainer - INFO -     sim_loss       : 102.29838066101074
2025-01-21 11:34:02,689 - trainer - INFO -     gen_loss       : -1386.452294921875
2025-01-21 11:34:02,689 - trainer - INFO -     val_loss       : -635.5187454223633
2025-01-21 11:34:02,689 - trainer - INFO -     val_sim_loss   : 55.10154724121094
2025-01-21 11:34:02,689 - trainer - INFO -     val_gen_loss   : -690.6203079223633
2025-01-21 11:34:02,689 - trainer - INFO -     val_perplexity : -40.83884048461914
2025-01-21 11:34:02,689 - trainer - INFO -     val_embedding_sim: 0.06660252809524536
2025-01-21 11:34:02,689 - trainer - INFO - ================================================================================
2025-01-21 11:34:02,689 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:34:02
2025-01-21 11:34:06,549 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:34:06
2025-01-21 11:34:06,549 - trainer - INFO -     epoch          : 9
2025-01-21 11:34:06,549 - trainer - INFO -     elapsed time   : 3.8592369556427
2025-01-21 11:34:06,549 - trainer - INFO -     loss           : -1001.0354431152343
2025-01-21 11:34:06,549 - trainer - INFO -     sim_loss       : 101.77427291870117
2025-01-21 11:34:06,549 - trainer - INFO -     gen_loss       : -1473.6681701660157
2025-01-21 11:34:06,549 - trainer - INFO -     val_loss       : -668.7088270187378
2025-01-21 11:34:06,549 - trainer - INFO -     val_sim_loss   : 54.96880340576172
2025-01-21 11:34:06,549 - trainer - INFO -     val_gen_loss   : -723.677638053894
2025-01-21 11:34:06,549 - trainer - INFO -     val_perplexity : -44.32826232910156
2025-01-21 11:34:06,549 - trainer - INFO -     val_embedding_sim: 0.08928243815898895
2025-01-21 11:34:06,549 - trainer - INFO - ================================================================================
2025-01-21 11:34:06,549 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:34:06
2025-01-21 11:34:10,408 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:34:10
2025-01-21 11:34:10,408 - trainer - INFO -     epoch          : 10
2025-01-21 11:34:10,408 - trainer - INFO -     elapsed time   : 3.8586230278015137
2025-01-21 11:34:10,408 - trainer - INFO -     loss           : -1058.1934509277344
2025-01-21 11:34:10,409 - trainer - INFO -     sim_loss       : 101.38613014221191
2025-01-21 11:34:10,409 - trainer - INFO -     gen_loss       : -1555.1561706542968
2025-01-21 11:34:10,409 - trainer - INFO -     val_loss       : -700.6395988464355
2025-01-21 11:34:10,409 - trainer - INFO -     val_sim_loss   : 54.681724548339844
2025-01-21 11:34:10,409 - trainer - INFO -     val_gen_loss   : -755.3213005065918
2025-01-21 11:34:10,409 - trainer - INFO -     val_perplexity : -46.28450012207031
2025-01-21 11:34:10,409 - trainer - INFO -     val_embedding_sim: 0.08186450600624084
2025-01-21 11:34:16,946 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:34:23,533 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:34:23,533 - trainer - INFO - ================================================================================
2025-01-21 11:34:23,533 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:34:23
2025-01-21 11:34:27,457 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:34:27
2025-01-21 11:34:27,457 - trainer - INFO -     epoch          : 11
2025-01-21 11:34:27,457 - trainer - INFO -     elapsed time   : 3.923597812652588
2025-01-21 11:34:27,457 - trainer - INFO -     loss           : -1113.4131103515624
2025-01-21 11:34:27,457 - trainer - INFO -     sim_loss       : 100.29055099487304
2025-01-21 11:34:27,457 - trainer - INFO -     gen_loss       : -1633.571826171875
2025-01-21 11:34:27,457 - trainer - INFO -     val_loss       : -731.6909408569336
2025-01-21 11:34:27,457 - trainer - INFO -     val_sim_loss   : 54.351707458496094
2025-01-21 11:34:27,457 - trainer - INFO -     val_gen_loss   : -786.0426254272461
2025-01-21 11:34:27,457 - trainer - INFO -     val_perplexity : -48.05161666870117
2025-01-21 11:34:27,457 - trainer - INFO -     val_embedding_sim: 0.09043010324239731
2025-01-21 11:34:27,457 - trainer - INFO - ================================================================================
2025-01-21 11:34:27,457 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:34:27
2025-01-21 11:34:31,315 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:34:31
2025-01-21 11:34:31,315 - trainer - INFO -     epoch          : 12
2025-01-21 11:34:31,315 - trainer - INFO -     elapsed time   : 3.8574941158294678
2025-01-21 11:34:31,315 - trainer - INFO -     loss           : -1163.8638702392577
2025-01-21 11:34:31,315 - trainer - INFO -     sim_loss       : 99.34797554016113
2025-01-21 11:34:31,315 - trainer - INFO -     gen_loss       : -1705.240411376953
2025-01-21 11:34:31,315 - trainer - INFO -     val_loss       : -760.7771797180176
2025-01-21 11:34:31,315 - trainer - INFO -     val_sim_loss   : 53.50743103027344
2025-01-21 11:34:31,315 - trainer - INFO -     val_gen_loss   : -814.2846260070801
2025-01-21 11:34:31,316 - trainer - INFO -     val_perplexity : -49.79088592529297
2025-01-21 11:34:31,316 - trainer - INFO -     val_embedding_sim: 0.06593193113803864
2025-01-21 11:34:31,316 - trainer - INFO - ================================================================================
2025-01-21 11:34:31,316 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:34:31
2025-01-21 11:34:35,171 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:34:35
2025-01-21 11:34:35,171 - trainer - INFO -     epoch          : 13
2025-01-21 11:34:35,171 - trainer - INFO -     elapsed time   : 3.8551599979400635
2025-01-21 11:34:35,171 - trainer - INFO -     loss           : -1213.942886352539
2025-01-21 11:34:35,171 - trainer - INFO -     sim_loss       : 97.86259651184082
2025-01-21 11:34:35,171 - trainer - INFO -     gen_loss       : -1776.1452392578126
2025-01-21 11:34:35,171 - trainer - INFO -     val_loss       : -790.9666328430176
2025-01-21 11:34:35,171 - trainer - INFO -     val_sim_loss   : 53.09297180175781
2025-01-21 11:34:35,171 - trainer - INFO -     val_gen_loss   : -844.0595893859863
2025-01-21 11:34:35,171 - trainer - INFO -     val_perplexity : -50.53978729248047
2025-01-21 11:34:35,172 - trainer - INFO -     val_embedding_sim: 0.11062753200531006
2025-01-21 11:34:35,172 - trainer - INFO - ================================================================================
2025-01-21 11:34:35,172 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:34:35
2025-01-21 11:34:39,053 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:34:39
2025-01-21 11:34:39,054 - trainer - INFO -     epoch          : 14
2025-01-21 11:34:39,054 - trainer - INFO -     elapsed time   : 3.8817121982574463
2025-01-21 11:34:39,054 - trainer - INFO -     loss           : -1262.364028930664
2025-01-21 11:34:39,054 - trainer - INFO -     sim_loss       : 96.60563850402832
2025-01-21 11:34:39,054 - trainer - INFO -     gen_loss       : -1844.7796203613282
2025-01-21 11:34:39,054 - trainer - INFO -     val_loss       : -820.3282775878906
2025-01-21 11:34:39,054 - trainer - INFO -     val_sim_loss   : 51.41381072998047
2025-01-21 11:34:39,054 - trainer - INFO -     val_gen_loss   : -871.7420959472656
2025-01-21 11:34:39,054 - trainer - INFO -     val_perplexity : -52.82157897949219
2025-01-21 11:34:39,054 - trainer - INFO -     val_embedding_sim: 0.08358731120824814
2025-01-21 11:34:39,054 - trainer - INFO - ================================================================================
2025-01-21 11:34:39,054 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:34:39
2025-01-21 11:34:42,907 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:34:42
2025-01-21 11:34:42,907 - trainer - INFO -     epoch          : 15
2025-01-21 11:34:42,907 - trainer - INFO -     elapsed time   : 3.853060722351074
2025-01-21 11:34:42,907 - trainer - INFO -     loss           : -1309.5500793457031
2025-01-21 11:34:42,907 - trainer - INFO -     sim_loss       : 94.80959854125976
2025-01-21 11:34:42,907 - trainer - INFO -     gen_loss       : -1911.4185485839844
2025-01-21 11:34:42,907 - trainer - INFO -     val_loss       : -848.0251502990723
2025-01-21 11:34:42,907 - trainer - INFO -     val_sim_loss   : 51.61015319824219
2025-01-21 11:34:42,908 - trainer - INFO -     val_gen_loss   : -899.6353187561035
2025-01-21 11:34:42,908 - trainer - INFO -     val_perplexity : -55.12046813964844
2025-01-21 11:34:42,908 - trainer - INFO -     val_embedding_sim: 0.08496900647878647
2025-01-21 11:34:49,466 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:34:56,063 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:34:56,063 - trainer - INFO - ================================================================================
2025-01-21 11:34:56,063 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:34:56
2025-01-21 11:34:59,968 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:34:59
2025-01-21 11:34:59,968 - trainer - INFO -     epoch          : 16
2025-01-21 11:34:59,968 - trainer - INFO -     elapsed time   : 3.9042742252349854
2025-01-21 11:34:59,968 - trainer - INFO -     loss           : -1355.7198364257813
2025-01-21 11:34:59,968 - trainer - INFO -     sim_loss       : 93.69368343353271
2025-01-21 11:34:59,968 - trainer - INFO -     gen_loss       : -1976.8971130371094
2025-01-21 11:34:59,968 - trainer - INFO -     val_loss       : -876.941577911377
2025-01-21 11:34:59,968 - trainer - INFO -     val_sim_loss   : 49.48301696777344
2025-01-21 11:34:59,968 - trainer - INFO -     val_gen_loss   : -926.4246101379395
2025-01-21 11:34:59,968 - trainer - INFO -     val_perplexity : -56.536834716796875
2025-01-21 11:34:59,968 - trainer - INFO -     val_embedding_sim: 0.10025257617235184
2025-01-21 11:34:59,968 - trainer - INFO - ================================================================================
2025-01-21 11:34:59,968 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:34:59
2025-01-21 11:35:03,828 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:35:03
2025-01-21 11:35:03,828 - trainer - INFO -     epoch          : 17
2025-01-21 11:35:03,828 - trainer - INFO -     elapsed time   : 3.8594980239868164
2025-01-21 11:35:03,828 - trainer - INFO -     loss           : -1399.5290405273438
2025-01-21 11:35:03,828 - trainer - INFO -     sim_loss       : 91.9489673614502
2025-01-21 11:35:03,828 - trainer - INFO -     gen_loss       : -2038.7339660644532
2025-01-21 11:35:03,828 - trainer - INFO -     val_loss       : -904.1227703094482
2025-01-21 11:35:03,828 - trainer - INFO -     val_sim_loss   : 48.87616729736328
2025-01-21 11:35:03,828 - trainer - INFO -     val_gen_loss   : -952.998929977417
2025-01-21 11:35:03,828 - trainer - INFO -     val_perplexity : -58.480506896972656
2025-01-21 11:35:03,828 - trainer - INFO -     val_embedding_sim: 0.09093272686004639
2025-01-21 11:35:03,828 - trainer - INFO - ================================================================================
2025-01-21 11:35:03,828 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:35:03
2025-01-21 11:35:07,676 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:35:07
2025-01-21 11:35:07,676 - trainer - INFO -     epoch          : 18
2025-01-21 11:35:07,676 - trainer - INFO -     elapsed time   : 3.8468751907348633
2025-01-21 11:35:07,676 - trainer - INFO -     loss           : -1443.3840881347655
2025-01-21 11:35:07,676 - trainer - INFO -     sim_loss       : 90.67951011657715
2025-01-21 11:35:07,676 - trainer - INFO -     gen_loss       : -2100.83994140625
2025-01-21 11:35:07,676 - trainer - INFO -     val_loss       : -931.7409744262695
2025-01-21 11:35:07,676 - trainer - INFO -     val_sim_loss   : 48.016822814941406
2025-01-21 11:35:07,676 - trainer - INFO -     val_gen_loss   : -979.7578201293945
2025-01-21 11:35:07,676 - trainer - INFO -     val_perplexity : -58.806583404541016
2025-01-21 11:35:07,676 - trainer - INFO -     val_embedding_sim: 0.11219871044158936
2025-01-21 11:35:07,676 - trainer - INFO - ================================================================================
2025-01-21 11:35:07,676 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:35:07
2025-01-21 11:35:11,529 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:35:11
2025-01-21 11:35:11,529 - trainer - INFO -     epoch          : 19
2025-01-21 11:35:11,529 - trainer - INFO -     elapsed time   : 3.8530783653259277
2025-01-21 11:35:11,529 - trainer - INFO -     loss           : -1486.7112182617188
2025-01-21 11:35:11,530 - trainer - INFO -     sim_loss       : 90.07557640075683
2025-01-21 11:35:11,530 - trainer - INFO -     gen_loss       : -2162.4770385742186
2025-01-21 11:35:11,530 - trainer - INFO -     val_loss       : -955.0768737792969
2025-01-21 11:35:11,530 - trainer - INFO -     val_sim_loss   : 49.493064880371094
2025-01-21 11:35:11,530 - trainer - INFO -     val_gen_loss   : -1004.5699157714844
2025-01-21 11:35:11,530 - trainer - INFO -     val_perplexity : -61.09429168701172
2025-01-21 11:35:11,530 - trainer - INFO -     val_embedding_sim: 0.0806393101811409
2025-01-21 11:35:11,530 - trainer - INFO - ================================================================================
2025-01-21 11:35:11,530 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:35:11
2025-01-21 11:35:15,384 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:35:15
2025-01-21 11:35:15,384 - trainer - INFO -     epoch          : 20
2025-01-21 11:35:15,385 - trainer - INFO -     elapsed time   : 3.854320526123047
2025-01-21 11:35:15,385 - trainer - INFO -     loss           : -1528.5861572265626
2025-01-21 11:35:15,385 - trainer - INFO -     sim_loss       : 88.28049430847167
2025-01-21 11:35:15,385 - trainer - INFO -     gen_loss       : -2221.5290710449217
2025-01-21 11:35:15,385 - trainer - INFO -     val_loss       : -981.4649772644043
2025-01-21 11:35:15,385 - trainer - INFO -     val_sim_loss   : 49.12133026123047
2025-01-21 11:35:15,385 - trainer - INFO -     val_gen_loss   : -1030.5863151550293
2025-01-21 11:35:15,385 - trainer - INFO -     val_perplexity : -61.869293212890625
2025-01-21 11:35:15,385 - trainer - INFO -     val_embedding_sim: 0.08316411077976227
2025-01-21 11:35:21,934 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:35:28,525 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:35:28,525 - trainer - INFO - ================================================================================
2025-01-21 11:35:28,525 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:35:28
2025-01-21 11:35:32,432 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:35:32
2025-01-21 11:35:32,432 - trainer - INFO -     epoch          : 21
2025-01-21 11:35:32,432 - trainer - INFO -     elapsed time   : 3.90647029876709
2025-01-21 11:35:32,432 - trainer - INFO -     loss           : -1571.4513916015626
2025-01-21 11:35:32,432 - trainer - INFO -     sim_loss       : 88.00603904724122
2025-01-21 11:35:32,432 - trainer - INFO -     gen_loss       : -2282.6474731445314
2025-01-21 11:35:32,432 - trainer - INFO -     val_loss       : -1010.8232536315918
2025-01-21 11:35:32,432 - trainer - INFO -     val_sim_loss   : 45.342933654785156
2025-01-21 11:35:32,432 - trainer - INFO -     val_gen_loss   : -1056.1662101745605
2025-01-21 11:35:32,432 - trainer - INFO -     val_perplexity : -63.59596633911133
2025-01-21 11:35:32,432 - trainer - INFO -     val_embedding_sim: 0.10119650512933731
2025-01-21 11:35:32,433 - trainer - INFO - ================================================================================
2025-01-21 11:35:32,433 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:35:32
2025-01-21 11:35:36,275 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:35:36
2025-01-21 11:35:36,275 - trainer - INFO -     epoch          : 22
2025-01-21 11:35:36,275 - trainer - INFO -     elapsed time   : 3.842141628265381
2025-01-21 11:35:36,275 - trainer - INFO -     loss           : -1614.409375
2025-01-21 11:35:36,275 - trainer - INFO -     sim_loss       : 86.21554851531982
2025-01-21 11:35:36,275 - trainer - INFO -     gen_loss       : -2343.248669433594
2025-01-21 11:35:36,275 - trainer - INFO -     val_loss       : -1033.7981700897217
2025-01-21 11:35:36,275 - trainer - INFO -     val_sim_loss   : 47.59626770019531
2025-01-21 11:35:36,275 - trainer - INFO -     val_gen_loss   : -1081.394422531128
2025-01-21 11:35:36,275 - trainer - INFO -     val_perplexity : -66.37871551513672
2025-01-21 11:35:36,275 - trainer - INFO -     val_embedding_sim: 0.09707021713256836
2025-01-21 11:35:36,275 - trainer - INFO - ================================================================================
2025-01-21 11:35:36,275 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:35:36
2025-01-21 11:35:40,137 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:35:40
2025-01-21 11:35:40,137 - trainer - INFO -     epoch          : 23
2025-01-21 11:35:40,137 - trainer - INFO -     elapsed time   : 3.8613057136535645
2025-01-21 11:35:40,137 - trainer - INFO -     loss           : -1655.326434326172
2025-01-21 11:35:40,137 - trainer - INFO -     sim_loss       : 86.10839748382568
2025-01-21 11:35:40,137 - trainer - INFO -     gen_loss       : -2401.6556640625
2025-01-21 11:35:40,137 - trainer - INFO -     val_loss       : -1059.4832763671875
2025-01-21 11:35:40,137 - trainer - INFO -     val_sim_loss   : 47.115928649902344
2025-01-21 11:35:40,137 - trainer - INFO -     val_gen_loss   : -1106.5992431640625
2025-01-21 11:35:40,137 - trainer - INFO -     val_perplexity : -67.37611389160156
2025-01-21 11:35:40,137 - trainer - INFO -     val_embedding_sim: 0.09225423634052277
2025-01-21 11:35:40,137 - trainer - INFO - ================================================================================
2025-01-21 11:35:40,137 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:35:40
2025-01-21 11:35:43,991 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:35:43
2025-01-21 11:35:43,991 - trainer - INFO -     epoch          : 24
2025-01-21 11:35:43,991 - trainer - INFO -     elapsed time   : 3.8536946773529053
2025-01-21 11:35:43,991 - trainer - INFO -     loss           : -1695.8412841796876
2025-01-21 11:35:43,991 - trainer - INFO -     sim_loss       : 86.68351459503174
2025-01-21 11:35:43,992 - trainer - INFO -     gen_loss       : -2459.7805358886717
2025-01-21 11:35:43,992 - trainer - INFO -     val_loss       : -1086.747844696045
2025-01-21 11:35:43,992 - trainer - INFO -     val_sim_loss   : 44.997535705566406
2025-01-21 11:35:43,992 - trainer - INFO -     val_gen_loss   : -1131.745403289795
2025-01-21 11:35:43,992 - trainer - INFO -     val_perplexity : -69.48394775390625
2025-01-21 11:35:43,992 - trainer - INFO -     val_embedding_sim: 0.08610042929649353
2025-01-21 11:35:43,992 - trainer - INFO - ================================================================================
2025-01-21 11:35:43,992 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:35:43
2025-01-21 11:35:47,845 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:35:47
2025-01-21 11:35:47,845 - trainer - INFO -     epoch          : 25
2025-01-21 11:35:47,845 - trainer - INFO -     elapsed time   : 3.853248357772827
2025-01-21 11:35:47,845 - trainer - INFO -     loss           : -1737.752392578125
2025-01-21 11:35:47,845 - trainer - INFO -     sim_loss       : 83.66232929229736
2025-01-21 11:35:47,845 - trainer - INFO -     gen_loss       : -2518.358752441406
2025-01-21 11:35:47,845 - trainer - INFO -     val_loss       : -1111.3408279418945
2025-01-21 11:35:47,845 - trainer - INFO -     val_sim_loss   : 45.78282928466797
2025-01-21 11:35:47,846 - trainer - INFO -     val_gen_loss   : -1157.123664855957
2025-01-21 11:35:47,846 - trainer - INFO -     val_perplexity : -68.8338623046875
2025-01-21 11:35:47,846 - trainer - INFO -     val_embedding_sim: 0.09966753423213959
2025-01-21 11:35:54,397 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:36:00,985 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:36:00,986 - trainer - INFO - ================================================================================
2025-01-21 11:36:00,986 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:36:00
2025-01-21 11:36:04,889 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:36:04
2025-01-21 11:36:04,889 - trainer - INFO -     epoch          : 26
2025-01-21 11:36:04,889 - trainer - INFO -     elapsed time   : 3.90309739112854
2025-01-21 11:36:04,889 - trainer - INFO -     loss           : -1778.9022216796875
2025-01-21 11:36:04,889 - trainer - INFO -     sim_loss       : 84.04135665893554
2025-01-21 11:36:04,889 - trainer - INFO -     gen_loss       : -2577.306640625
2025-01-21 11:36:04,889 - trainer - INFO -     val_loss       : -1135.5305442810059
2025-01-21 11:36:04,889 - trainer - INFO -     val_sim_loss   : 45.95737838745117
2025-01-21 11:36:04,889 - trainer - INFO -     val_gen_loss   : -1181.4879417419434
2025-01-21 11:36:04,889 - trainer - INFO -     val_perplexity : -70.94747924804688
2025-01-21 11:36:04,889 - trainer - INFO -     val_embedding_sim: 0.0869031548500061
2025-01-21 11:36:04,890 - trainer - INFO - ================================================================================
2025-01-21 11:36:04,890 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:36:04
2025-01-21 11:36:08,745 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:36:08
2025-01-21 11:36:08,745 - trainer - INFO -     epoch          : 27
2025-01-21 11:36:08,745 - trainer - INFO -     elapsed time   : 3.854985237121582
2025-01-21 11:36:08,745 - trainer - INFO -     loss           : -1819.5608215332031
2025-01-21 11:36:08,745 - trainer - INFO -     sim_loss       : 82.94929428100586
2025-01-21 11:36:08,745 - trainer - INFO -     gen_loss       : -2634.922326660156
2025-01-21 11:36:08,745 - trainer - INFO -     val_loss       : -1163.6177368164062
2025-01-21 11:36:08,745 - trainer - INFO -     val_sim_loss   : 44.41411590576172
2025-01-21 11:36:08,745 - trainer - INFO -     val_gen_loss   : -1208.0317993164062
2025-01-21 11:36:08,745 - trainer - INFO -     val_perplexity : -73.19631958007812
2025-01-21 11:36:08,745 - trainer - INFO -     val_embedding_sim: 0.0931357741355896
2025-01-21 11:36:08,745 - trainer - INFO - ================================================================================
2025-01-21 11:36:08,745 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:36:08
2025-01-21 11:36:12,605 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:36:12
2025-01-21 11:36:12,606 - trainer - INFO -     epoch          : 28
2025-01-21 11:36:12,606 - trainer - INFO -     elapsed time   : 3.8599982261657715
2025-01-21 11:36:12,606 - trainer - INFO -     loss           : -1860.0933471679687
2025-01-21 11:36:12,606 - trainer - INFO -     sim_loss       : 81.69160461425781
2025-01-21 11:36:12,606 - trainer - INFO -     gen_loss       : -2692.286962890625
2025-01-21 11:36:12,606 - trainer - INFO -     val_loss       : -1189.7371215820312
2025-01-21 11:36:12,606 - trainer - INFO -     val_sim_loss   : 44.094749450683594
2025-01-21 11:36:12,606 - trainer - INFO -     val_gen_loss   : -1233.8318481445312
2025-01-21 11:36:12,606 - trainer - INFO -     val_perplexity : -74.95062255859375
2025-01-21 11:36:12,606 - trainer - INFO -     val_embedding_sim: 0.0766286849975586
2025-01-21 11:36:12,606 - trainer - INFO - ================================================================================
2025-01-21 11:36:12,606 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:36:12
2025-01-21 11:36:16,453 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:36:16
2025-01-21 11:36:16,453 - trainer - INFO -     epoch          : 29
2025-01-21 11:36:16,453 - trainer - INFO -     elapsed time   : 3.846794843673706
2025-01-21 11:36:16,453 - trainer - INFO -     loss           : -1900.5028381347656
2025-01-21 11:36:16,453 - trainer - INFO -     sim_loss       : 83.69301853179931
2025-01-21 11:36:16,453 - trainer - INFO -     gen_loss       : -2750.872521972656
2025-01-21 11:36:16,453 - trainer - INFO -     val_loss       : -1213.876781463623
2025-01-21 11:36:16,453 - trainer - INFO -     val_sim_loss   : 44.105072021484375
2025-01-21 11:36:16,453 - trainer - INFO -     val_gen_loss   : -1257.9818840026855
2025-01-21 11:36:16,453 - trainer - INFO -     val_perplexity : -76.26789093017578
2025-01-21 11:36:16,453 - trainer - INFO -     val_embedding_sim: 0.08152681589126587
2025-01-21 11:36:16,454 - trainer - INFO - ================================================================================
2025-01-21 11:36:16,454 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:36:16
2025-01-21 11:36:20,320 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:36:20
2025-01-21 11:36:20,320 - trainer - INFO -     epoch          : 30
2025-01-21 11:36:20,320 - trainer - INFO -     elapsed time   : 3.8657801151275635
2025-01-21 11:36:20,320 - trainer - INFO -     loss           : -1940.8516235351562
2025-01-21 11:36:20,320 - trainer - INFO -     sim_loss       : 81.45773506164551
2025-01-21 11:36:20,320 - trainer - INFO -     gen_loss       : -2807.5555908203123
2025-01-21 11:36:20,320 - trainer - INFO -     val_loss       : -1240.3086853027344
2025-01-21 11:36:20,320 - trainer - INFO -     val_sim_loss   : 43.210693359375
2025-01-21 11:36:20,320 - trainer - INFO -     val_gen_loss   : -1283.5193786621094
2025-01-21 11:36:20,320 - trainer - INFO -     val_perplexity : -78.78577423095703
2025-01-21 11:36:20,320 - trainer - INFO -     val_embedding_sim: 0.09326311945915222
2025-01-21 11:36:26,871 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:36:34,288 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:36:34,288 - trainer - INFO - ================================================================================
2025-01-21 11:36:34,288 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:36:34
2025-01-21 11:36:38,198 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:36:38
2025-01-21 11:36:38,198 - trainer - INFO -     epoch          : 31
2025-01-21 11:36:38,198 - trainer - INFO -     elapsed time   : 3.9094297885894775
2025-01-21 11:36:38,198 - trainer - INFO -     loss           : -1980.8645812988282
2025-01-21 11:36:38,198 - trainer - INFO -     sim_loss       : 82.11081390380859
2025-01-21 11:36:38,198 - trainer - INFO -     gen_loss       : -2864.996936035156
2025-01-21 11:36:38,198 - trainer - INFO -     val_loss       : -1266.655897140503
2025-01-21 11:36:38,198 - trainer - INFO -     val_sim_loss   : 42.852439880371094
2025-01-21 11:36:38,198 - trainer - INFO -     val_gen_loss   : -1309.5083141326904
2025-01-21 11:36:38,198 - trainer - INFO -     val_perplexity : -80.06739807128906
2025-01-21 11:36:38,198 - trainer - INFO -     val_embedding_sim: 0.10465926676988602
2025-01-21 11:36:38,198 - trainer - INFO - ================================================================================
2025-01-21 11:36:38,198 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:36:38
2025-01-21 11:36:42,067 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:36:42
2025-01-21 11:36:42,067 - trainer - INFO -     epoch          : 32
2025-01-21 11:36:42,067 - trainer - INFO -     elapsed time   : 3.868283987045288
2025-01-21 11:36:42,067 - trainer - INFO -     loss           : -2020.8262451171875
2025-01-21 11:36:42,067 - trainer - INFO -     sim_loss       : 80.20629978179932
2025-01-21 11:36:42,067 - trainer - INFO -     gen_loss       : -2921.2688720703127
2025-01-21 11:36:42,067 - trainer - INFO -     val_loss       : -1292.8532180786133
2025-01-21 11:36:42,067 - trainer - INFO -     val_sim_loss   : 41.79969787597656
2025-01-21 11:36:42,067 - trainer - INFO -     val_gen_loss   : -1334.6529006958008
2025-01-21 11:36:42,067 - trainer - INFO -     val_perplexity : -80.92499542236328
2025-01-21 11:36:42,067 - trainer - INFO -     val_embedding_sim: 0.0989282876253128
2025-01-21 11:36:42,067 - trainer - INFO - ================================================================================
2025-01-21 11:36:42,067 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:36:42
2025-01-21 11:36:45,929 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:36:45
2025-01-21 11:36:45,930 - trainer - INFO -     epoch          : 33
2025-01-21 11:36:45,930 - trainer - INFO -     elapsed time   : 3.8620145320892334
2025-01-21 11:36:45,930 - trainer - INFO -     loss           : -2061.950579833984
2025-01-21 11:36:45,930 - trainer - INFO -     sim_loss       : 79.26586170196533
2025-01-21 11:36:45,930 - trainer - INFO -     gen_loss       : -2979.6148315429687
2025-01-21 11:36:45,930 - trainer - INFO -     val_loss       : -1317.4770965576172
2025-01-21 11:36:45,930 - trainer - INFO -     val_sim_loss   : 42.95904541015625
2025-01-21 11:36:45,930 - trainer - INFO -     val_gen_loss   : -1360.4362030029297
2025-01-21 11:36:45,930 - trainer - INFO -     val_perplexity : -82.37413787841797
2025-01-21 11:36:45,930 - trainer - INFO -     val_embedding_sim: 0.08034534007310867
2025-01-21 11:36:45,930 - trainer - INFO - ================================================================================
2025-01-21 11:36:45,930 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:36:45
2025-01-21 11:36:49,781 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:36:49
2025-01-21 11:36:49,781 - trainer - INFO -     epoch          : 34
2025-01-21 11:36:49,781 - trainer - INFO -     elapsed time   : 3.850740432739258
2025-01-21 11:36:49,781 - trainer - INFO -     loss           : -2102.1494384765624
2025-01-21 11:36:49,781 - trainer - INFO -     sim_loss       : 78.07100639343261
2025-01-21 11:36:49,781 - trainer - INFO -     gen_loss       : -3036.529736328125
2025-01-21 11:36:49,781 - trainer - INFO -     val_loss       : -1346.4862594604492
2025-01-21 11:36:49,781 - trainer - INFO -     val_sim_loss   : 40.05866622924805
2025-01-21 11:36:49,781 - trainer - INFO -     val_gen_loss   : -1386.5449752807617
2025-01-21 11:36:49,781 - trainer - INFO -     val_perplexity : -83.05432891845703
2025-01-21 11:36:49,781 - trainer - INFO -     val_embedding_sim: 0.06155431643128395
2025-01-21 11:36:49,782 - trainer - INFO - ================================================================================
2025-01-21 11:36:49,782 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:36:49
2025-01-21 11:36:53,694 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:36:53
2025-01-21 11:36:53,695 - trainer - INFO -     epoch          : 35
2025-01-21 11:36:53,695 - trainer - INFO -     elapsed time   : 3.912766456604004
2025-01-21 11:36:53,695 - trainer - INFO -     loss           : -2142.778778076172
2025-01-21 11:36:53,695 - trainer - INFO -     sim_loss       : 77.80232162475586
2025-01-21 11:36:53,695 - trainer - INFO -     gen_loss       : -3094.456433105469
2025-01-21 11:36:53,695 - trainer - INFO -     val_loss       : -1369.281644821167
2025-01-21 11:36:53,695 - trainer - INFO -     val_sim_loss   : 43.07615661621094
2025-01-21 11:36:53,695 - trainer - INFO -     val_gen_loss   : -1412.357816696167
2025-01-21 11:36:53,695 - trainer - INFO -     val_perplexity : -86.69133758544922
2025-01-21 11:36:53,695 - trainer - INFO -     val_embedding_sim: 0.10259759426116943
2025-01-21 11:37:00,258 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:37:06,873 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:37:06,874 - trainer - INFO - ================================================================================
2025-01-21 11:37:06,874 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:37:06
2025-01-21 11:37:10,783 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:37:10
2025-01-21 11:37:10,784 - trainer - INFO -     epoch          : 36
2025-01-21 11:37:10,784 - trainer - INFO -     elapsed time   : 3.9095311164855957
2025-01-21 11:37:10,784 - trainer - INFO -     loss           : -2184.286730957031
2025-01-21 11:37:10,784 - trainer - INFO -     sim_loss       : 77.34680061340332
2025-01-21 11:37:10,784 - trainer - INFO -     gen_loss       : -3153.558239746094
2025-01-21 11:37:10,784 - trainer - INFO -     val_loss       : -1396.4896430969238
2025-01-21 11:37:10,784 - trainer - INFO -     val_sim_loss   : 41.32496643066406
2025-01-21 11:37:10,784 - trainer - INFO -     val_gen_loss   : -1437.8145942687988
2025-01-21 11:37:10,784 - trainer - INFO -     val_perplexity : -87.33863830566406
2025-01-21 11:37:10,784 - trainer - INFO -     val_embedding_sim: 0.10073013603687286
2025-01-21 11:37:10,784 - trainer - INFO - ================================================================================
2025-01-21 11:37:10,784 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:37:10
2025-01-21 11:37:14,628 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:37:14
2025-01-21 11:37:14,628 - trainer - INFO -     epoch          : 37
2025-01-21 11:37:14,628 - trainer - INFO -     elapsed time   : 3.843770742416382
2025-01-21 11:37:14,628 - trainer - INFO -     loss           : -2223.3567626953127
2025-01-21 11:37:14,628 - trainer - INFO -     sim_loss       : 77.26308059692383
2025-01-21 11:37:14,628 - trainer - INFO -     gen_loss       : -3209.3368286132813
2025-01-21 11:37:14,628 - trainer - INFO -     val_loss       : -1419.7557945251465
2025-01-21 11:37:14,628 - trainer - INFO -     val_sim_loss   : 43.289920806884766
2025-01-21 11:37:14,628 - trainer - INFO -     val_gen_loss   : -1463.045711517334
2025-01-21 11:37:14,628 - trainer - INFO -     val_perplexity : -87.90691375732422
2025-01-21 11:37:14,629 - trainer - INFO -     val_embedding_sim: 0.07766325026750565
2025-01-21 11:37:14,629 - trainer - INFO - ================================================================================
2025-01-21 11:37:14,629 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:37:14
2025-01-21 11:37:18,490 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:37:18
2025-01-21 11:37:18,490 - trainer - INFO -     epoch          : 38
2025-01-21 11:37:18,490 - trainer - INFO -     elapsed time   : 3.8615331649780273
2025-01-21 11:37:18,491 - trainer - INFO -     loss           : -2264.5408264160155
2025-01-21 11:37:18,491 - trainer - INFO -     sim_loss       : 76.34947700500489
2025-01-21 11:37:18,491 - trainer - INFO -     gen_loss       : -3267.779541015625
2025-01-21 11:37:18,491 - trainer - INFO -     val_loss       : -1450.1892471313477
2025-01-21 11:37:18,491 - trainer - INFO -     val_sim_loss   : 38.99394226074219
2025-01-21 11:37:18,491 - trainer - INFO -     val_gen_loss   : -1489.1831436157227
2025-01-21 11:37:18,491 - trainer - INFO -     val_perplexity : -89.48136138916016
2025-01-21 11:37:18,491 - trainer - INFO -     val_embedding_sim: 0.08502323925495148
2025-01-21 11:37:18,491 - trainer - INFO - ================================================================================
2025-01-21 11:37:18,491 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:37:18
2025-01-21 11:37:22,340 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:37:22
2025-01-21 11:37:22,340 - trainer - INFO -     epoch          : 39
2025-01-21 11:37:22,340 - trainer - INFO -     elapsed time   : 3.8492188453674316
2025-01-21 11:37:22,340 - trainer - INFO -     loss           : -2304.8083374023436
2025-01-21 11:37:22,341 - trainer - INFO -     sim_loss       : 76.81127166748047
2025-01-21 11:37:22,341 - trainer - INFO -     gen_loss       : -3325.5025390625
2025-01-21 11:37:22,341 - trainer - INFO -     val_loss       : -1474.651107788086
2025-01-21 11:37:22,341 - trainer - INFO -     val_sim_loss   : 40.969871520996094
2025-01-21 11:37:22,341 - trainer - INFO -     val_gen_loss   : -1515.6209564208984
2025-01-21 11:37:22,341 - trainer - INFO -     val_perplexity : -92.06000518798828
2025-01-21 11:37:22,341 - trainer - INFO -     val_embedding_sim: 0.11550602316856384
2025-01-21 11:37:22,341 - trainer - INFO - ================================================================================
2025-01-21 11:37:22,341 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:37:22
2025-01-21 11:37:26,190 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:37:26
2025-01-21 11:37:26,190 - trainer - INFO -     epoch          : 40
2025-01-21 11:37:26,190 - trainer - INFO -     elapsed time   : 3.8485870361328125
2025-01-21 11:37:26,190 - trainer - INFO -     loss           : -2345.038818359375
2025-01-21 11:37:26,190 - trainer - INFO -     sim_loss       : 77.0888011932373
2025-01-21 11:37:26,190 - trainer - INFO -     gen_loss       : -3383.0935791015627
2025-01-21 11:37:26,190 - trainer - INFO -     val_loss       : -1498.8420295715332
2025-01-21 11:37:26,190 - trainer - INFO -     val_sim_loss   : 42.892303466796875
2025-01-21 11:37:26,190 - trainer - INFO -     val_gen_loss   : -1541.7343635559082
2025-01-21 11:37:26,190 - trainer - INFO -     val_perplexity : -94.67070770263672
2025-01-21 11:37:26,190 - trainer - INFO -     val_embedding_sim: 0.1063811331987381
2025-01-21 11:37:32,748 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:37:39,347 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:37:39,348 - trainer - INFO - ================================================================================
2025-01-21 11:37:39,348 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:37:39
2025-01-21 11:37:43,244 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:37:43
2025-01-21 11:37:43,244 - trainer - INFO -     epoch          : 41
2025-01-21 11:37:43,244 - trainer - INFO -     elapsed time   : 3.8959996700286865
2025-01-21 11:37:43,244 - trainer - INFO -     loss           : -2385.9146728515625
2025-01-21 11:37:43,244 - trainer - INFO -     sim_loss       : 75.7332260131836
2025-01-21 11:37:43,244 - trainer - INFO -     gen_loss       : -3440.9067138671876
2025-01-21 11:37:43,244 - trainer - INFO -     val_loss       : -1524.7807083129883
2025-01-21 11:37:43,244 - trainer - INFO -     val_sim_loss   : 42.39923095703125
2025-01-21 11:37:43,244 - trainer - INFO -     val_gen_loss   : -1567.1800003051758
2025-01-21 11:37:43,244 - trainer - INFO -     val_perplexity : -94.17537689208984
2025-01-21 11:37:43,244 - trainer - INFO -     val_embedding_sim: 0.0976472869515419
2025-01-21 11:37:43,244 - trainer - INFO - ================================================================================
2025-01-21 11:37:43,244 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:37:43
2025-01-21 11:37:47,096 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:37:47
2025-01-21 11:37:47,096 - trainer - INFO -     epoch          : 42
2025-01-21 11:37:47,096 - trainer - INFO -     elapsed time   : 3.8515963554382324
2025-01-21 11:37:47,096 - trainer - INFO -     loss           : -2427.26064453125
2025-01-21 11:37:47,096 - trainer - INFO -     sim_loss       : 76.18685646057129
2025-01-21 11:37:47,096 - trainer - INFO -     gen_loss       : -3500.1667602539064
2025-01-21 11:37:47,096 - trainer - INFO -     val_loss       : -1549.9650421142578
2025-01-21 11:37:47,096 - trainer - INFO -     val_sim_loss   : 43.83110427856445
2025-01-21 11:37:47,097 - trainer - INFO -     val_gen_loss   : -1593.7960968017578
2025-01-21 11:37:47,097 - trainer - INFO -     val_perplexity : -95.95436096191406
2025-01-21 11:37:47,097 - trainer - INFO -     val_embedding_sim: 0.0856391042470932
2025-01-21 11:37:47,097 - trainer - INFO - ================================================================================
2025-01-21 11:37:47,097 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:37:47
2025-01-21 11:37:50,947 - trainer - INFO - Epoch 43 completed at 2025-01-21 11:37:50
2025-01-21 11:37:50,947 - trainer - INFO -     epoch          : 43
2025-01-21 11:37:50,947 - trainer - INFO -     elapsed time   : 3.850001811981201
2025-01-21 11:37:50,947 - trainer - INFO -     loss           : -2468.268347167969
2025-01-21 11:37:50,947 - trainer - INFO -     sim_loss       : 75.33574333190919
2025-01-21 11:37:50,947 - trainer - INFO -     gen_loss       : -3558.384387207031
2025-01-21 11:37:50,947 - trainer - INFO -     val_loss       : -1579.6711311340332
2025-01-21 11:37:50,947 - trainer - INFO -     val_sim_loss   : 40.06618118286133
2025-01-21 11:37:50,947 - trainer - INFO -     val_gen_loss   : -1619.7372932434082
2025-01-21 11:37:50,947 - trainer - INFO -     val_perplexity : -98.45176696777344
2025-01-21 11:37:50,947 - trainer - INFO -     val_embedding_sim: 0.10070370137691498
2025-01-21 11:37:50,947 - trainer - INFO - ================================================================================
2025-01-21 11:37:50,947 - trainer - INFO - Starting epoch 44 at 2025-01-21 11:37:50
2025-01-21 11:37:54,792 - trainer - INFO - Epoch 44 completed at 2025-01-21 11:37:54
2025-01-21 11:37:54,792 - trainer - INFO -     epoch          : 44
2025-01-21 11:37:54,793 - trainer - INFO -     elapsed time   : 3.844726085662842
2025-01-21 11:37:54,793 - trainer - INFO -     loss           : -2509.1872680664064
2025-01-21 11:37:54,793 - trainer - INFO -     sim_loss       : 74.28163471221924
2025-01-21 11:37:54,793 - trainer - INFO -     gen_loss       : -3616.3883422851563
2025-01-21 11:37:54,793 - trainer - INFO -     val_loss       : -1606.2369995117188
2025-01-21 11:37:54,793 - trainer - INFO -     val_sim_loss   : 39.384620666503906
2025-01-21 11:37:54,793 - trainer - INFO -     val_gen_loss   : -1645.6216430664062
2025-01-21 11:37:54,793 - trainer - INFO -     val_perplexity : -98.90141296386719
2025-01-21 11:37:54,793 - trainer - INFO -     val_embedding_sim: 0.09731203317642212
2025-01-21 11:37:54,793 - trainer - INFO - ================================================================================
2025-01-21 11:37:54,793 - trainer - INFO - Starting epoch 45 at 2025-01-21 11:37:54
2025-01-21 11:37:58,653 - trainer - INFO - Epoch 45 completed at 2025-01-21 11:37:58
2025-01-21 11:37:58,653 - trainer - INFO -     epoch          : 45
2025-01-21 11:37:58,653 - trainer - INFO -     elapsed time   : 3.8594396114349365
2025-01-21 11:37:58,653 - trainer - INFO -     loss           : -2550.0631591796873
2025-01-21 11:37:58,653 - trainer - INFO -     sim_loss       : 73.99302959442139
2025-01-21 11:37:58,653 - trainer - INFO -     gen_loss       : -3674.658728027344
2025-01-21 11:37:58,653 - trainer - INFO -     val_loss       : -1633.1077117919922
2025-01-21 11:37:58,653 - trainer - INFO -     val_sim_loss   : 37.862892150878906
2025-01-21 11:37:58,653 - trainer - INFO -     val_gen_loss   : -1670.9706268310547
2025-01-21 11:37:58,653 - trainer - INFO -     val_perplexity : -101.30294799804688
2025-01-21 11:37:58,653 - trainer - INFO -     val_embedding_sim: 0.09755571186542511
2025-01-21 11:38:05,195 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 11:38:11,798 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:38:11,798 - trainer - INFO - ================================================================================
2025-01-21 11:38:11,798 - trainer - INFO - Starting epoch 46 at 2025-01-21 11:38:11
2025-01-21 11:38:15,711 - trainer - INFO - Epoch 46 completed at 2025-01-21 11:38:15
2025-01-21 11:38:15,711 - trainer - INFO -     epoch          : 46
2025-01-21 11:38:15,711 - trainer - INFO -     elapsed time   : 3.912022590637207
2025-01-21 11:38:15,711 - trainer - INFO -     loss           : -2591.267712402344
2025-01-21 11:38:15,711 - trainer - INFO -     sim_loss       : 73.96552886962891
2025-01-21 11:38:15,711 - trainer - INFO -     gen_loss       : -3733.510632324219
2025-01-21 11:38:15,711 - trainer - INFO -     val_loss       : -1657.9219131469727
2025-01-21 11:38:15,711 - trainer - INFO -     val_sim_loss   : 40.40351867675781
2025-01-21 11:38:15,711 - trainer - INFO -     val_gen_loss   : -1698.3254776000977
2025-01-21 11:38:15,711 - trainer - INFO -     val_perplexity : -103.3705062866211
2025-01-21 11:38:15,711 - trainer - INFO -     val_embedding_sim: 0.09245061129331589
2025-01-21 11:38:15,711 - trainer - INFO - ================================================================================
2025-01-21 11:38:15,711 - trainer - INFO - Starting epoch 47 at 2025-01-21 11:38:15
2025-01-21 11:38:19,563 - trainer - INFO - Epoch 47 completed at 2025-01-21 11:38:19
2025-01-21 11:38:19,563 - trainer - INFO -     epoch          : 47
2025-01-21 11:38:19,563 - trainer - INFO -     elapsed time   : 3.851414918899536
2025-01-21 11:38:19,563 - trainer - INFO -     loss           : -2631.3988525390623
2025-01-21 11:38:19,563 - trainer - INFO -     sim_loss       : 76.4115644454956
2025-01-21 11:38:19,563 - trainer - INFO -     gen_loss       : -3791.8890869140623
2025-01-21 11:38:19,563 - trainer - INFO -     val_loss       : -1687.8711853027344
2025-01-21 11:38:19,563 - trainer - INFO -     val_sim_loss   : 36.902191162109375
2025-01-21 11:38:19,563 - trainer - INFO -     val_gen_loss   : -1724.7734069824219
2025-01-21 11:38:19,563 - trainer - INFO -     val_perplexity : -105.42739868164062
2025-01-21 11:38:19,563 - trainer - INFO -     val_embedding_sim: 0.10027376562356949
2025-01-21 11:38:19,563 - trainer - INFO - ================================================================================
2025-01-21 11:38:19,563 - trainer - INFO - Starting epoch 48 at 2025-01-21 11:38:19
2025-01-21 11:38:23,423 - trainer - INFO - Epoch 48 completed at 2025-01-21 11:38:23
2025-01-21 11:38:23,423 - trainer - INFO -     epoch          : 48
2025-01-21 11:38:23,423 - trainer - INFO -     elapsed time   : 3.8597142696380615
2025-01-21 11:38:23,423 - trainer - INFO -     loss           : -2673.606640625
2025-01-21 11:38:23,423 - trainer - INFO -     sim_loss       : 70.75715770721436
2025-01-21 11:38:23,423 - trainer - INFO -     gen_loss       : -3849.7626098632813
2025-01-21 11:38:23,424 - trainer - INFO -     val_loss       : -1714.1301803588867
2025-01-21 11:38:23,424 - trainer - INFO -     val_sim_loss   : 37.34070587158203
2025-01-21 11:38:23,424 - trainer - INFO -     val_gen_loss   : -1751.4708786010742
2025-01-21 11:38:23,424 - trainer - INFO -     val_perplexity : -104.18269348144531
2025-01-21 11:38:23,424 - trainer - INFO -     val_embedding_sim: 0.10375803709030151
2025-01-21 11:38:23,424 - trainer - INFO - ================================================================================
2025-01-21 11:38:23,424 - trainer - INFO - Starting epoch 49 at 2025-01-21 11:38:23
2025-01-21 11:38:27,283 - trainer - INFO - Epoch 49 completed at 2025-01-21 11:38:27
2025-01-21 11:38:27,283 - trainer - INFO -     epoch          : 49
2025-01-21 11:38:27,283 - trainer - INFO -     elapsed time   : 3.858851432800293
2025-01-21 11:38:27,283 - trainer - INFO -     loss           : -2711.926867675781
2025-01-21 11:38:27,283 - trainer - INFO -     sim_loss       : 75.55915088653565
2025-01-21 11:38:27,283 - trainer - INFO -     gen_loss       : -3906.563854980469
2025-01-21 11:38:27,283 - trainer - INFO -     val_loss       : -1737.6555252075195
2025-01-21 11:38:27,283 - trainer - INFO -     val_sim_loss   : 39.453426361083984
2025-01-21 11:38:27,283 - trainer - INFO -     val_gen_loss   : -1777.1088943481445
2025-01-21 11:38:27,283 - trainer - INFO -     val_perplexity : -105.70716857910156
2025-01-21 11:38:27,283 - trainer - INFO -     val_embedding_sim: 0.1044783964753151
2025-01-21 11:38:27,283 - trainer - INFO - ================================================================================
2025-01-21 11:38:27,283 - trainer - INFO - Starting epoch 50 at 2025-01-21 11:38:27
2025-01-21 11:38:31,142 - trainer - INFO - Epoch 50 completed at 2025-01-21 11:38:31
2025-01-21 11:38:31,142 - trainer - INFO -     epoch          : 50
2025-01-21 11:38:31,142 - trainer - INFO -     elapsed time   : 3.858666181564331
2025-01-21 11:38:31,142 - trainer - INFO -     loss           : -2753.8928833007812
2025-01-21 11:38:31,142 - trainer - INFO -     sim_loss       : 73.24702224731445
2025-01-21 11:38:31,142 - trainer - INFO -     gen_loss       : -3965.5243286132813
2025-01-21 11:38:31,143 - trainer - INFO -     val_loss       : -1765.5945892333984
2025-01-21 11:38:31,143 - trainer - INFO -     val_sim_loss   : 38.9703369140625
2025-01-21 11:38:31,143 - trainer - INFO -     val_gen_loss   : -1804.564926147461
2025-01-21 11:38:31,143 - trainer - INFO -     val_perplexity : -109.9386978149414
2025-01-21 11:38:31,143 - trainer - INFO -     val_embedding_sim: 0.09104909002780914
2025-01-21 11:38:37,697 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 11:38:44,297 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:38:44,297 - trainer - INFO - ================================================================================
2025-01-21 11:38:44,298 - trainer - INFO - Starting epoch 51 at 2025-01-21 11:38:44
2025-01-21 11:38:48,194 - trainer - INFO - Epoch 51 completed at 2025-01-21 11:38:48
2025-01-21 11:38:48,195 - trainer - INFO -     epoch          : 51
2025-01-21 11:38:48,195 - trainer - INFO -     elapsed time   : 3.8967435359954834
2025-01-21 11:38:48,195 - trainer - INFO -     loss           : -2795.883203125
2025-01-21 11:38:48,195 - trainer - INFO -     sim_loss       : 73.45217323303223
2025-01-21 11:38:48,195 - trainer - INFO -     gen_loss       : -4025.5984375
2025-01-21 11:38:48,195 - trainer - INFO -     val_loss       : -1793.0777893066406
2025-01-21 11:38:48,195 - trainer - INFO -     val_sim_loss   : 37.98595428466797
2025-01-21 11:38:48,195 - trainer - INFO -     val_gen_loss   : -1831.0637512207031
2025-01-21 11:38:48,195 - trainer - INFO -     val_perplexity : -110.23809051513672
2025-01-21 11:38:48,195 - trainer - INFO -     val_embedding_sim: 0.08676950633525848
2025-01-21 11:38:48,195 - trainer - INFO - ================================================================================
2025-01-21 11:38:48,195 - trainer - INFO - Starting epoch 52 at 2025-01-21 11:38:48
2025-01-21 11:38:52,048 - trainer - INFO - Epoch 52 completed at 2025-01-21 11:38:52
2025-01-21 11:38:52,049 - trainer - INFO -     epoch          : 52
2025-01-21 11:38:52,049 - trainer - INFO -     elapsed time   : 3.8532040119171143
2025-01-21 11:38:52,049 - trainer - INFO -     loss           : -2837.225927734375
2025-01-21 11:38:52,049 - trainer - INFO -     sim_loss       : 71.69684066772462
2025-01-21 11:38:52,049 - trainer - INFO -     gen_loss       : -4083.907189941406
2025-01-21 11:38:52,049 - trainer - INFO -     val_loss       : -1815.1030464172363
2025-01-21 11:38:52,049 - trainer - INFO -     val_sim_loss   : 41.84125900268555
2025-01-21 11:38:52,049 - trainer - INFO -     val_gen_loss   : -1856.9443550109863
2025-01-21 11:38:52,049 - trainer - INFO -     val_perplexity : -112.87704467773438
2025-01-21 11:38:52,049 - trainer - INFO -     val_embedding_sim: 0.11805813759565353
2025-01-21 11:38:52,049 - trainer - INFO - ================================================================================
2025-01-21 11:38:52,049 - trainer - INFO - Starting epoch 53 at 2025-01-21 11:38:52
2025-01-21 11:38:55,904 - trainer - INFO - Epoch 53 completed at 2025-01-21 11:38:55
2025-01-21 11:38:55,904 - trainer - INFO -     epoch          : 53
2025-01-21 11:38:55,904 - trainer - INFO -     elapsed time   : 3.8547964096069336
2025-01-21 11:38:55,904 - trainer - INFO -     loss           : -2878.731787109375
2025-01-21 11:38:55,904 - trainer - INFO -     sim_loss       : 70.25033912658691
2025-01-21 11:38:55,904 - trainer - INFO -     gen_loss       : -4142.581262207032
2025-01-21 11:38:55,904 - trainer - INFO -     val_loss       : -1845.7966384887695
2025-01-21 11:38:55,904 - trainer - INFO -     val_sim_loss   : 38.65176773071289
2025-01-21 11:38:55,904 - trainer - INFO -     val_gen_loss   : -1884.448371887207
2025-01-21 11:38:55,904 - trainer - INFO -     val_perplexity : -115.58982849121094
2025-01-21 11:38:55,904 - trainer - INFO -     val_embedding_sim: 0.09517958015203476
2025-01-21 11:38:55,904 - trainer - INFO - ================================================================================
2025-01-21 11:38:55,904 - trainer - INFO - Starting epoch 54 at 2025-01-21 11:38:55
2025-01-21 11:38:59,758 - trainer - INFO - Epoch 54 completed at 2025-01-21 11:38:59
2025-01-21 11:38:59,759 - trainer - INFO -     epoch          : 54
2025-01-21 11:38:59,759 - trainer - INFO -     elapsed time   : 3.853804349899292
2025-01-21 11:38:59,759 - trainer - INFO -     loss           : -2920.5029174804686
2025-01-21 11:38:59,759 - trainer - INFO -     sim_loss       : 69.8355058670044
2025-01-21 11:38:59,759 - trainer - INFO -     gen_loss       : -4202.076586914062
2025-01-21 11:38:59,759 - trainer - INFO -     val_loss       : -1873.1986389160156
2025-01-21 11:38:59,759 - trainer - INFO -     val_sim_loss   : 37.97411346435547
2025-01-21 11:38:59,759 - trainer - INFO -     val_gen_loss   : -1911.1727600097656
2025-01-21 11:38:59,759 - trainer - INFO -     val_perplexity : -115.0547866821289
2025-01-21 11:38:59,759 - trainer - INFO -     val_embedding_sim: 0.09239823371171951
2025-01-21 11:38:59,759 - trainer - INFO - ================================================================================
2025-01-21 11:38:59,759 - trainer - INFO - Starting epoch 55 at 2025-01-21 11:38:59
2025-01-21 11:39:03,613 - trainer - INFO - Epoch 55 completed at 2025-01-21 11:39:03
2025-01-21 11:39:03,614 - trainer - INFO -     epoch          : 55
2025-01-21 11:39:03,614 - trainer - INFO -     elapsed time   : 3.854220390319824
2025-01-21 11:39:03,614 - trainer - INFO -     loss           : -2961.2542724609375
2025-01-21 11:39:03,614 - trainer - INFO -     sim_loss       : 70.43880004882813
2025-01-21 11:39:03,614 - trainer - INFO -     gen_loss       : -4260.551342773438
2025-01-21 11:39:03,614 - trainer - INFO -     val_loss       : -1902.3735046386719
2025-01-21 11:39:03,614 - trainer - INFO -     val_sim_loss   : 35.92854690551758
2025-01-21 11:39:03,614 - trainer - INFO -     val_gen_loss   : -1938.3020935058594
2025-01-21 11:39:03,614 - trainer - INFO -     val_perplexity : -117.36457824707031
2025-01-21 11:39:03,614 - trainer - INFO -     val_embedding_sim: 0.11226416379213333
2025-01-21 11:39:10,174 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch55.pth ...
2025-01-21 11:39:16,798 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:39:16,799 - trainer - INFO - ================================================================================
2025-01-21 11:39:16,799 - trainer - INFO - Starting epoch 56 at 2025-01-21 11:39:16
2025-01-21 11:39:20,700 - trainer - INFO - Epoch 56 completed at 2025-01-21 11:39:20
2025-01-21 11:39:20,701 - trainer - INFO -     epoch          : 56
2025-01-21 11:39:20,701 - trainer - INFO -     elapsed time   : 3.901456117630005
2025-01-21 11:39:20,701 - trainer - INFO -     loss           : -3003.9733764648436
2025-01-21 11:39:20,701 - trainer - INFO -     sim_loss       : 69.51186714172363
2025-01-21 11:39:20,701 - trainer - INFO -     gen_loss       : -4321.181420898438
2025-01-21 11:39:20,701 - trainer - INFO -     val_loss       : -1926.7077865600586
2025-01-21 11:39:20,701 - trainer - INFO -     val_sim_loss   : 39.23253631591797
2025-01-21 11:39:20,701 - trainer - INFO -     val_gen_loss   : -1965.940330505371
2025-01-21 11:39:20,701 - trainer - INFO -     val_perplexity : -119.08241271972656
2025-01-21 11:39:20,701 - trainer - INFO -     val_embedding_sim: 0.09082214534282684
2025-01-21 11:39:20,701 - trainer - INFO - ================================================================================
2025-01-21 11:39:20,701 - trainer - INFO - Starting epoch 57 at 2025-01-21 11:39:20
2025-01-21 11:39:24,555 - trainer - INFO - Epoch 57 completed at 2025-01-21 11:39:24
2025-01-21 11:39:24,555 - trainer - INFO -     epoch          : 57
2025-01-21 11:39:24,555 - trainer - INFO -     elapsed time   : 3.8541078567504883
2025-01-21 11:39:24,555 - trainer - INFO -     loss           : -3047.860144042969
2025-01-21 11:39:24,555 - trainer - INFO -     sim_loss       : 67.12817039489747
2025-01-21 11:39:24,556 - trainer - INFO -     gen_loss       : -4382.855151367187
2025-01-21 11:39:24,556 - trainer - INFO -     val_loss       : -1956.1656494140625
2025-01-21 11:39:24,556 - trainer - INFO -     val_sim_loss   : 36.867820739746094
2025-01-21 11:39:24,556 - trainer - INFO -     val_gen_loss   : -1993.033447265625
2025-01-21 11:39:24,556 - trainer - INFO -     val_perplexity : -119.80303955078125
2025-01-21 11:39:24,556 - trainer - INFO -     val_embedding_sim: 0.08787734806537628
2025-01-21 11:39:24,556 - trainer - INFO - ================================================================================
2025-01-21 11:39:24,556 - trainer - INFO - Starting epoch 58 at 2025-01-21 11:39:24
2025-01-21 11:39:28,416 - trainer - INFO - Epoch 58 completed at 2025-01-21 11:39:28
2025-01-21 11:39:28,417 - trainer - INFO -     epoch          : 58
2025-01-21 11:39:28,417 - trainer - INFO -     elapsed time   : 3.860516309738159
2025-01-21 11:39:28,417 - trainer - INFO -     loss           : -3087.99580078125
2025-01-21 11:39:28,417 - trainer - INFO -     sim_loss       : 67.39743080139161
2025-01-21 11:39:28,417 - trainer - INFO -     gen_loss       : -4440.307202148438
2025-01-21 11:39:28,417 - trainer - INFO -     val_loss       : -1984.9580612182617
2025-01-21 11:39:28,417 - trainer - INFO -     val_sim_loss   : 35.626670837402344
2025-01-21 11:39:28,417 - trainer - INFO -     val_gen_loss   : -2020.5847702026367
2025-01-21 11:39:28,417 - trainer - INFO -     val_perplexity : -120.18952941894531
2025-01-21 11:39:28,417 - trainer - INFO -     val_embedding_sim: 0.1063355877995491
2025-01-21 11:39:28,417 - trainer - INFO - ================================================================================
2025-01-21 11:39:28,417 - trainer - INFO - Starting epoch 59 at 2025-01-21 11:39:28
2025-01-21 11:39:32,269 - trainer - INFO - Epoch 59 completed at 2025-01-21 11:39:32
2025-01-21 11:39:32,269 - trainer - INFO -     epoch          : 59
2025-01-21 11:39:32,269 - trainer - INFO -     elapsed time   : 3.8519866466522217
2025-01-21 11:39:32,269 - trainer - INFO -     loss           : -3129.365576171875
2025-01-21 11:39:32,269 - trainer - INFO -     sim_loss       : 70.77721519470215
2025-01-21 11:39:32,270 - trainer - INFO -     gen_loss       : -4500.855358886719
2025-01-21 11:39:32,270 - trainer - INFO -     val_loss       : -2013.987205505371
2025-01-21 11:39:32,270 - trainer - INFO -     val_sim_loss   : 33.510074615478516
2025-01-21 11:39:32,270 - trainer - INFO -     val_gen_loss   : -2047.4973373413086
2025-01-21 11:39:32,270 - trainer - INFO -     val_perplexity : -124.7423095703125
2025-01-21 11:39:32,270 - trainer - INFO -     val_embedding_sim: 0.07616426050662994
2025-01-21 11:39:32,270 - trainer - INFO - ================================================================================
2025-01-21 11:39:32,270 - trainer - INFO - Starting epoch 60 at 2025-01-21 11:39:32
2025-01-21 11:39:36,115 - trainer - INFO - Epoch 60 completed at 2025-01-21 11:39:36
2025-01-21 11:39:36,115 - trainer - INFO -     epoch          : 60
2025-01-21 11:39:36,115 - trainer - INFO -     elapsed time   : 3.845266819000244
2025-01-21 11:39:36,115 - trainer - INFO -     loss           : -3172.0904052734377
2025-01-21 11:39:36,116 - trainer - INFO -     sim_loss       : 69.09343318939209
2025-01-21 11:39:36,116 - trainer - INFO -     gen_loss       : -4561.169360351562
2025-01-21 11:39:36,116 - trainer - INFO -     val_loss       : -2039.872703552246
2025-01-21 11:39:36,116 - trainer - INFO -     val_sim_loss   : 34.60113525390625
2025-01-21 11:39:36,116 - trainer - INFO -     val_gen_loss   : -2074.4738998413086
2025-01-21 11:39:36,116 - trainer - INFO -     val_perplexity : -126.38379669189453
2025-01-21 11:39:36,116 - trainer - INFO -     val_embedding_sim: 0.10495314747095108
2025-01-21 11:39:42,667 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch60.pth ...
2025-01-21 11:39:49,255 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:39:49,255 - trainer - INFO - ================================================================================
2025-01-21 11:39:49,255 - trainer - INFO - Starting epoch 61 at 2025-01-21 11:39:49
2025-01-21 11:39:53,183 - trainer - INFO - Epoch 61 completed at 2025-01-21 11:39:53
2025-01-21 11:39:53,183 - trainer - INFO -     epoch          : 61
2025-01-21 11:39:53,183 - trainer - INFO -     elapsed time   : 3.9274678230285645
2025-01-21 11:39:53,183 - trainer - INFO -     loss           : -3214.6062744140627
2025-01-21 11:39:53,183 - trainer - INFO -     sim_loss       : 67.89113941192628
2025-01-21 11:39:53,183 - trainer - INFO -     gen_loss       : -4621.39091796875
2025-01-21 11:39:53,183 - trainer - INFO -     val_loss       : -2062.5592041015625
2025-01-21 11:39:53,183 - trainer - INFO -     val_sim_loss   : 38.85088348388672
2025-01-21 11:39:53,183 - trainer - INFO -     val_gen_loss   : -2101.4100341796875
2025-01-21 11:39:53,183 - trainer - INFO -     val_perplexity : -124.9877700805664
2025-01-21 11:39:53,183 - trainer - INFO -     val_embedding_sim: 0.08296334743499756
2025-01-21 11:39:53,183 - trainer - INFO - ================================================================================
2025-01-21 11:39:53,183 - trainer - INFO - Starting epoch 62 at 2025-01-21 11:39:53
2025-01-21 11:39:57,029 - trainer - INFO - Epoch 62 completed at 2025-01-21 11:39:57
2025-01-21 11:39:57,029 - trainer - INFO -     epoch          : 62
2025-01-21 11:39:57,029 - trainer - INFO -     elapsed time   : 3.845672130584717
2025-01-21 11:39:57,029 - trainer - INFO -     loss           : -3256.899938964844
2025-01-21 11:39:57,029 - trainer - INFO -     sim_loss       : 67.32930412292481
2025-01-21 11:39:57,029 - trainer - INFO -     gen_loss       : -4681.569738769531
2025-01-21 11:39:57,029 - trainer - INFO -     val_loss       : -2094.203800201416
2025-01-21 11:39:57,029 - trainer - INFO -     val_sim_loss   : 34.36250305175781
2025-01-21 11:39:57,029 - trainer - INFO -     val_gen_loss   : -2128.566349029541
2025-01-21 11:39:57,029 - trainer - INFO -     val_perplexity : -130.56100463867188
2025-01-21 11:39:57,029 - trainer - INFO -     val_embedding_sim: 0.09941250085830688
2025-01-21 11:39:57,029 - trainer - INFO - ================================================================================
2025-01-21 11:39:57,030 - trainer - INFO - Starting epoch 63 at 2025-01-21 11:39:57
2025-01-21 11:40:00,900 - trainer - INFO - Epoch 63 completed at 2025-01-21 11:40:00
2025-01-21 11:40:00,900 - trainer - INFO -     epoch          : 63
2025-01-21 11:40:00,900 - trainer - INFO -     elapsed time   : 3.8705294132232666
2025-01-21 11:40:00,900 - trainer - INFO -     loss           : -3298.88134765625
2025-01-21 11:40:00,901 - trainer - INFO -     sim_loss       : 66.12339134216309
2025-01-21 11:40:00,901 - trainer - INFO -     gen_loss       : -4741.026318359375
2025-01-21 11:40:00,901 - trainer - INFO -     val_loss       : -2117.917495727539
2025-01-21 11:40:00,901 - trainer - INFO -     val_sim_loss   : 38.50506591796875
2025-01-21 11:40:00,901 - trainer - INFO -     val_gen_loss   : -2156.422622680664
2025-01-21 11:40:00,901 - trainer - INFO -     val_perplexity : -128.25857543945312
2025-01-21 11:40:00,901 - trainer - INFO -     val_embedding_sim: 0.0908043161034584
2025-01-21 11:40:00,901 - trainer - INFO - ================================================================================
2025-01-21 11:40:00,901 - trainer - INFO - Starting epoch 64 at 2025-01-21 11:40:00
2025-01-21 11:40:04,766 - trainer - INFO - Epoch 64 completed at 2025-01-21 11:40:04
2025-01-21 11:40:04,766 - trainer - INFO -     epoch          : 64
2025-01-21 11:40:04,766 - trainer - INFO -     elapsed time   : 3.8648557662963867
2025-01-21 11:40:04,766 - trainer - INFO -     loss           : -3340.477746582031
2025-01-21 11:40:04,766 - trainer - INFO -     sim_loss       : 68.29282913208007
2025-01-21 11:40:04,766 - trainer - INFO -     gen_loss       : -4801.379443359375
2025-01-21 11:40:04,766 - trainer - INFO -     val_loss       : -2150.5014114379883
2025-01-21 11:40:04,766 - trainer - INFO -     val_sim_loss   : 33.39997863769531
2025-01-21 11:40:04,766 - trainer - INFO -     val_gen_loss   : -2183.9013137817383
2025-01-21 11:40:04,766 - trainer - INFO -     val_perplexity : -130.61631774902344
2025-01-21 11:40:04,766 - trainer - INFO -     val_embedding_sim: 0.10759813338518143
2025-01-21 11:40:04,766 - trainer - INFO - ================================================================================
2025-01-21 11:40:04,766 - trainer - INFO - Starting epoch 65 at 2025-01-21 11:40:04
2025-01-21 11:40:08,621 - trainer - INFO - Epoch 65 completed at 2025-01-21 11:40:08
2025-01-21 11:40:08,621 - trainer - INFO -     epoch          : 65
2025-01-21 11:40:08,621 - trainer - INFO -     elapsed time   : 3.8545684814453125
2025-01-21 11:40:08,621 - trainer - INFO -     loss           : -3385.2120727539063
2025-01-21 11:40:08,621 - trainer - INFO -     sim_loss       : 65.1438491821289
2025-01-21 11:40:08,621 - trainer - INFO -     gen_loss       : -4863.936010742187
2025-01-21 11:40:08,621 - trainer - INFO -     val_loss       : -2176.315528869629
2025-01-21 11:40:08,622 - trainer - INFO -     val_sim_loss   : 35.625282287597656
2025-01-21 11:40:08,622 - trainer - INFO -     val_gen_loss   : -2211.940773010254
2025-01-21 11:40:08,622 - trainer - INFO -     val_perplexity : -135.69491577148438
2025-01-21 11:40:08,622 - trainer - INFO -     val_embedding_sim: 0.07681941986083984
2025-01-21 11:40:15,281 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch65.pth ...
2025-01-21 11:40:21,873 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:40:21,874 - trainer - INFO - ================================================================================
2025-01-21 11:40:21,874 - trainer - INFO - Starting epoch 66 at 2025-01-21 11:40:21
2025-01-21 11:40:25,789 - trainer - INFO - Epoch 66 completed at 2025-01-21 11:40:25
2025-01-21 11:40:25,789 - trainer - INFO -     epoch          : 66
2025-01-21 11:40:25,789 - trainer - INFO -     elapsed time   : 3.9148364067077637
2025-01-21 11:40:25,789 - trainer - INFO -     loss           : -3425.6460815429687
2025-01-21 11:40:25,789 - trainer - INFO -     sim_loss       : 67.53076610565185
2025-01-21 11:40:25,789 - trainer - INFO -     gen_loss       : -4922.721984863281
2025-01-21 11:40:25,789 - trainer - INFO -     val_loss       : -2204.9837188720703
2025-01-21 11:40:25,789 - trainer - INFO -     val_sim_loss   : 33.96293640136719
2025-01-21 11:40:25,789 - trainer - INFO -     val_gen_loss   : -2238.9466094970703
2025-01-21 11:40:25,789 - trainer - INFO -     val_perplexity : -134.07745361328125
2025-01-21 11:40:25,789 - trainer - INFO -     val_embedding_sim: 0.10451582074165344
2025-01-21 11:40:25,789 - trainer - INFO - ================================================================================
2025-01-21 11:40:25,789 - trainer - INFO - Starting epoch 67 at 2025-01-21 11:40:25
2025-01-21 11:40:29,647 - trainer - INFO - Epoch 67 completed at 2025-01-21 11:40:29
2025-01-21 11:40:29,647 - trainer - INFO -     epoch          : 67
2025-01-21 11:40:29,647 - trainer - INFO -     elapsed time   : 3.8577089309692383
2025-01-21 11:40:29,647 - trainer - INFO -     loss           : -3469.8456298828123
2025-01-21 11:40:29,647 - trainer - INFO -     sim_loss       : 65.20297765731812
2025-01-21 11:40:29,647 - trainer - INFO -     gen_loss       : -4984.8665771484375
2025-01-21 11:40:29,647 - trainer - INFO -     val_loss       : -2234.6198654174805
2025-01-21 11:40:29,647 - trainer - INFO -     val_sim_loss   : 31.873641967773438
2025-01-21 11:40:29,647 - trainer - INFO -     val_gen_loss   : -2266.4934005737305
2025-01-21 11:40:29,648 - trainer - INFO -     val_perplexity : -137.24610900878906
2025-01-21 11:40:29,648 - trainer - INFO -     val_embedding_sim: 0.10185625404119492
2025-01-21 11:40:29,648 - trainer - INFO - ================================================================================
2025-01-21 11:40:29,648 - trainer - INFO - Starting epoch 68 at 2025-01-21 11:40:29
2025-01-21 11:40:33,499 - trainer - INFO - Epoch 68 completed at 2025-01-21 11:40:33
2025-01-21 11:40:33,499 - trainer - INFO -     epoch          : 68
2025-01-21 11:40:33,499 - trainer - INFO -     elapsed time   : 3.850823402404785
2025-01-21 11:40:33,499 - trainer - INFO -     loss           : -3511.760217285156
2025-01-21 11:40:33,499 - trainer - INFO -     sim_loss       : 62.902677631378175
2025-01-21 11:40:33,499 - trainer - INFO -     gen_loss       : -5043.75869140625
2025-01-21 11:40:33,499 - trainer - INFO -     val_loss       : -2261.3970336914062
2025-01-21 11:40:33,499 - trainer - INFO -     val_sim_loss   : 32.59728240966797
2025-01-21 11:40:33,499 - trainer - INFO -     val_gen_loss   : -2293.9942016601562
2025-01-21 11:40:33,499 - trainer - INFO -     val_perplexity : -139.34759521484375
2025-01-21 11:40:33,499 - trainer - INFO -     val_embedding_sim: 0.10231219232082367
2025-01-21 11:40:33,499 - trainer - INFO - ================================================================================
2025-01-21 11:40:33,499 - trainer - INFO - Starting epoch 69 at 2025-01-21 11:40:33
2025-01-21 11:40:37,350 - trainer - INFO - Epoch 69 completed at 2025-01-21 11:40:37
2025-01-21 11:40:37,350 - trainer - INFO -     epoch          : 69
2025-01-21 11:40:37,350 - trainer - INFO -     elapsed time   : 3.850903272628784
2025-01-21 11:40:37,351 - trainer - INFO -     loss           : -3554.969519042969
2025-01-21 11:40:37,351 - trainer - INFO -     sim_loss       : 63.04167652130127
2025-01-21 11:40:37,351 - trainer - INFO -     gen_loss       : -5105.545837402344
2025-01-21 11:40:37,351 - trainer - INFO -     val_loss       : -2290.2427673339844
2025-01-21 11:40:37,351 - trainer - INFO -     val_sim_loss   : 32.42544174194336
2025-01-21 11:40:37,351 - trainer - INFO -     val_gen_loss   : -2322.6683044433594
2025-01-21 11:40:37,351 - trainer - INFO -     val_perplexity : -140.94505310058594
2025-01-21 11:40:37,351 - trainer - INFO -     val_embedding_sim: 0.10396154969930649
2025-01-21 11:40:37,351 - trainer - INFO - ================================================================================
2025-01-21 11:40:37,351 - trainer - INFO - Starting epoch 70 at 2025-01-21 11:40:37
2025-01-21 11:40:41,204 - trainer - INFO - Epoch 70 completed at 2025-01-21 11:40:41
2025-01-21 11:40:41,204 - trainer - INFO -     epoch          : 70
2025-01-21 11:40:41,204 - trainer - INFO -     elapsed time   : 3.852869749069214
2025-01-21 11:40:41,204 - trainer - INFO -     loss           : -3597.9919311523436
2025-01-21 11:40:41,204 - trainer - INFO -     sim_loss       : 64.13758068084717
2025-01-21 11:40:41,204 - trainer - INFO -     gen_loss       : -5167.476098632813
2025-01-21 11:40:41,204 - trainer - INFO -     val_loss       : -2314.008499145508
2025-01-21 11:40:41,204 - trainer - INFO -     val_sim_loss   : 37.4765625
2025-01-21 11:40:41,204 - trainer - INFO -     val_gen_loss   : -2351.485061645508
2025-01-21 11:40:41,204 - trainer - INFO -     val_perplexity : -142.64352416992188
2025-01-21 11:40:41,204 - trainer - INFO -     val_embedding_sim: 0.07707889378070831
2025-01-21 11:44:42,158 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 11:44:44,576 - trainer - INFO - ================================================================================
2025-01-21 11:44:44,576 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:44:44
2025-01-21 11:49:15,482 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 11:49:17,801 - trainer - INFO - ================================================================================
2025-01-21 11:49:17,801 - trainer - INFO - Starting epoch 1 at 2025-01-21 11:49:17
2025-01-21 11:49:22,957 - trainer - INFO - Epoch 1 completed at 2025-01-21 11:49:22
2025-01-21 11:49:22,957 - trainer - INFO -     epoch          : 1
2025-01-21 11:49:22,957 - trainer - INFO -     elapsed time   : 5.156244516372681
2025-01-21 11:49:22,957 - trainer - INFO -     loss           : 102.95152854919434
2025-01-21 11:49:22,957 - trainer - INFO -     sim_loss       : 97.88229026794434
2025-01-21 11:49:22,957 - trainer - INFO -     gen_loss       : 5.069239282608033
2025-01-21 11:49:22,957 - trainer - INFO -     val_loss       : 49.49008911848068
2025-01-21 11:49:22,957 - trainer - INFO -     val_sim_loss   : 47.70063400268555
2025-01-21 11:49:22,957 - trainer - INFO -     val_gen_loss   : 1.78945392370224
2025-01-21 11:49:22,958 - trainer - INFO -     val_perplexity : -53.79003143310547
2025-01-21 11:49:22,958 - trainer - INFO -     val_embedding_sim: 0.09426932036876678
2025-01-21 11:49:22,958 - trainer - INFO - ================================================================================
2025-01-21 11:49:22,958 - trainer - INFO - Starting epoch 2 at 2025-01-21 11:49:22
2025-01-21 11:49:26,854 - trainer - INFO - Epoch 2 completed at 2025-01-21 11:49:26
2025-01-21 11:49:26,854 - trainer - INFO -     epoch          : 2
2025-01-21 11:49:26,854 - trainer - INFO -     elapsed time   : 3.896470069885254
2025-01-21 11:49:26,855 - trainer - INFO -     loss           : 79.02820892333985
2025-01-21 11:49:26,855 - trainer - INFO -     sim_loss       : 76.63975391387939
2025-01-21 11:49:26,855 - trainer - INFO -     gen_loss       : 2.3884539127349855
2025-01-21 11:49:26,855 - trainer - INFO -     val_loss       : 35.05019634962082
2025-01-21 11:49:26,855 - trainer - INFO -     val_sim_loss   : 33.583839416503906
2025-01-21 11:49:26,855 - trainer - INFO -     val_gen_loss   : 1.4663558602333069
2025-01-21 11:49:26,855 - trainer - INFO -     val_perplexity : -62.66594696044922
2025-01-21 11:49:26,855 - trainer - INFO -     val_embedding_sim: 0.08795792609453201
2025-01-21 11:49:26,855 - trainer - INFO - ================================================================================
2025-01-21 11:49:26,855 - trainer - INFO - Starting epoch 3 at 2025-01-21 11:49:26
2025-01-21 11:49:30,753 - trainer - INFO - Epoch 3 completed at 2025-01-21 11:49:30
2025-01-21 11:49:30,754 - trainer - INFO -     epoch          : 3
2025-01-21 11:49:30,754 - trainer - INFO -     elapsed time   : 3.8984200954437256
2025-01-21 11:49:30,754 - trainer - INFO -     loss           : 52.80432949066162
2025-01-21 11:49:30,754 - trainer - INFO -     sim_loss       : 51.37944540977478
2025-01-21 11:49:30,754 - trainer - INFO -     gen_loss       : 1.4248840451240539
2025-01-21 11:49:30,754 - trainer - INFO -     val_loss       : 20.591113924980164
2025-01-21 11:49:30,754 - trainer - INFO -     val_sim_loss   : 19.330907821655273
2025-01-21 11:49:30,754 - trainer - INFO -     val_gen_loss   : 1.26020547747612
2025-01-21 11:49:30,754 - trainer - INFO -     val_perplexity : -69.84300994873047
2025-01-21 11:49:30,754 - trainer - INFO -     val_embedding_sim: 0.0451747290790081
2025-01-21 11:49:30,754 - trainer - INFO - ================================================================================
2025-01-21 11:49:30,754 - trainer - INFO - Starting epoch 4 at 2025-01-21 11:49:30
2025-01-21 11:49:34,649 - trainer - INFO - Epoch 4 completed at 2025-01-21 11:49:34
2025-01-21 11:49:34,649 - trainer - INFO -     epoch          : 4
2025-01-21 11:49:34,649 - trainer - INFO -     elapsed time   : 3.894462823867798
2025-01-21 11:49:34,649 - trainer - INFO -     loss           : 44.827364444732666
2025-01-21 11:49:34,649 - trainer - INFO -     sim_loss       : 43.77515201568603
2025-01-21 11:49:34,649 - trainer - INFO -     gen_loss       : 1.0522122621536254
2025-01-21 11:49:34,649 - trainer - INFO -     val_loss       : 18.397818833589554
2025-01-21 11:49:34,649 - trainer - INFO -     val_sim_loss   : 17.689342498779297
2025-01-21 11:49:34,649 - trainer - INFO -     val_gen_loss   : 0.7084760665893555
2025-01-21 11:49:34,649 - trainer - INFO -     val_perplexity : -69.78539276123047
2025-01-21 11:49:34,649 - trainer - INFO -     val_embedding_sim: 0.07924466580152512
2025-01-21 11:49:34,649 - trainer - INFO - ================================================================================
2025-01-21 11:49:34,649 - trainer - INFO - Starting epoch 5 at 2025-01-21 11:49:34
2025-01-21 11:49:38,556 - trainer - INFO - Epoch 5 completed at 2025-01-21 11:49:38
2025-01-21 11:49:38,556 - trainer - INFO -     epoch          : 5
2025-01-21 11:49:38,556 - trainer - INFO -     elapsed time   : 3.90693736076355
2025-01-21 11:49:38,556 - trainer - INFO -     loss           : 43.04612007141113
2025-01-21 11:49:38,557 - trainer - INFO -     sim_loss       : 42.39628791809082
2025-01-21 11:49:38,557 - trainer - INFO -     gen_loss       : 0.6498324751853943
2025-01-21 11:49:38,557 - trainer - INFO -     val_loss       : 19.59760496020317
2025-01-21 11:49:38,557 - trainer - INFO -     val_sim_loss   : 19.063613891601562
2025-01-21 11:49:38,557 - trainer - INFO -     val_gen_loss   : 0.5339904874563217
2025-01-21 11:49:38,557 - trainer - INFO -     val_perplexity : -76.46090698242188
2025-01-21 11:49:38,557 - trainer - INFO -     val_embedding_sim: 0.09653247892856598
2025-01-21 11:49:43,897 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 11:49:49,200 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:49:49,200 - trainer - INFO - ================================================================================
2025-01-21 11:49:49,200 - trainer - INFO - Starting epoch 6 at 2025-01-21 11:49:49
2025-01-21 11:49:53,131 - trainer - INFO - Epoch 6 completed at 2025-01-21 11:49:53
2025-01-21 11:49:53,131 - trainer - INFO -     epoch          : 6
2025-01-21 11:49:53,131 - trainer - INFO -     elapsed time   : 3.9303927421569824
2025-01-21 11:49:53,131 - trainer - INFO -     loss           : 42.154565048217776
2025-01-21 11:49:53,131 - trainer - INFO -     sim_loss       : 41.31720972061157
2025-01-21 11:49:53,131 - trainer - INFO -     gen_loss       : 0.8373551368713379
2025-01-21 11:49:53,131 - trainer - INFO -     val_loss       : 19.490671932697296
2025-01-21 11:49:53,131 - trainer - INFO -     val_sim_loss   : 19.156238555908203
2025-01-21 11:49:53,131 - trainer - INFO -     val_gen_loss   : 0.33443303406238556
2025-01-21 11:49:53,132 - trainer - INFO -     val_perplexity : -76.4686050415039
2025-01-21 11:49:53,132 - trainer - INFO -     val_embedding_sim: 0.07515169680118561
2025-01-21 11:49:53,132 - trainer - INFO - ================================================================================
2025-01-21 11:49:53,132 - trainer - INFO - Starting epoch 7 at 2025-01-21 11:49:53
2025-01-21 11:49:57,029 - trainer - INFO - Epoch 7 completed at 2025-01-21 11:49:57
2025-01-21 11:49:57,029 - trainer - INFO -     epoch          : 7
2025-01-21 11:49:57,029 - trainer - INFO -     elapsed time   : 3.8971831798553467
2025-01-21 11:49:57,029 - trainer - INFO -     loss           : 43.85702924728393
2025-01-21 11:49:57,029 - trainer - INFO -     sim_loss       : 43.07454595565796
2025-01-21 11:49:57,029 - trainer - INFO -     gen_loss       : 0.7824832320213317
2025-01-21 11:49:57,029 - trainer - INFO -     val_loss       : 26.585116744041443
2025-01-21 11:49:57,029 - trainer - INFO -     val_sim_loss   : 26.10791778564453
2025-01-21 11:49:57,029 - trainer - INFO -     val_gen_loss   : 0.47719910740852356
2025-01-21 11:49:57,029 - trainer - INFO -     val_perplexity : -73.32011413574219
2025-01-21 11:49:57,029 - trainer - INFO -     val_embedding_sim: 0.05079925060272217
2025-01-21 11:49:57,029 - trainer - INFO - ================================================================================
2025-01-21 11:49:57,030 - trainer - INFO - Starting epoch 8 at 2025-01-21 11:49:57
2025-01-21 11:50:00,939 - trainer - INFO - Epoch 8 completed at 2025-01-21 11:50:00
2025-01-21 11:50:00,939 - trainer - INFO -     epoch          : 8
2025-01-21 11:50:00,939 - trainer - INFO -     elapsed time   : 3.9089581966400146
2025-01-21 11:50:00,939 - trainer - INFO -     loss           : 36.16460342407227
2025-01-21 11:50:00,939 - trainer - INFO -     sim_loss       : 35.72179536819458
2025-01-21 11:50:00,939 - trainer - INFO -     gen_loss       : 0.44280811250209806
2025-01-21 11:50:00,939 - trainer - INFO -     val_loss       : 13.237189578823745
2025-01-21 11:50:00,939 - trainer - INFO -     val_sim_loss   : 13.057483673095703
2025-01-21 11:50:00,939 - trainer - INFO -     val_gen_loss   : 0.17970559280365705
2025-01-21 11:50:00,939 - trainer - INFO -     val_perplexity : -78.95053100585938
2025-01-21 11:50:00,939 - trainer - INFO -     val_embedding_sim: 0.07003651559352875
2025-01-21 11:50:00,939 - trainer - INFO - ================================================================================
2025-01-21 11:50:00,939 - trainer - INFO - Starting epoch 9 at 2025-01-21 11:50:00
2025-01-21 11:50:04,838 - trainer - INFO - Epoch 9 completed at 2025-01-21 11:50:04
2025-01-21 11:50:04,838 - trainer - INFO -     epoch          : 9
2025-01-21 11:50:04,838 - trainer - INFO -     elapsed time   : 3.898214101791382
2025-01-21 11:50:04,838 - trainer - INFO -     loss           : 33.09935445785523
2025-01-21 11:50:04,838 - trainer - INFO -     sim_loss       : 32.81751708984375
2025-01-21 11:50:04,838 - trainer - INFO -     gen_loss       : 0.2818374827504158
2025-01-21 11:50:04,838 - trainer - INFO -     val_loss       : 21.326683424413204
2025-01-21 11:50:04,838 - trainer - INFO -     val_sim_loss   : 21.112171173095703
2025-01-21 11:50:04,838 - trainer - INFO -     val_gen_loss   : 0.2145116627216339
2025-01-21 11:50:04,838 - trainer - INFO -     val_perplexity : -83.11112976074219
2025-01-21 11:50:04,838 - trainer - INFO -     val_embedding_sim: 0.0622745044529438
2025-01-21 11:50:04,838 - trainer - INFO - ================================================================================
2025-01-21 11:50:04,838 - trainer - INFO - Starting epoch 10 at 2025-01-21 11:50:04
2025-01-21 11:50:08,733 - trainer - INFO - Epoch 10 completed at 2025-01-21 11:50:08
2025-01-21 11:50:08,733 - trainer - INFO -     epoch          : 10
2025-01-21 11:50:08,733 - trainer - INFO -     elapsed time   : 3.894296169281006
2025-01-21 11:50:08,733 - trainer - INFO -     loss           : 35.6852240562439
2025-01-21 11:50:08,733 - trainer - INFO -     sim_loss       : 35.49512004852295
2025-01-21 11:50:08,733 - trainer - INFO -     gen_loss       : 0.1901041276752949
2025-01-21 11:50:08,733 - trainer - INFO -     val_loss       : 17.875832319259644
2025-01-21 11:50:08,733 - trainer - INFO -     val_sim_loss   : 17.398006439208984
2025-01-21 11:50:08,733 - trainer - INFO -     val_gen_loss   : 0.47782571613788605
2025-01-21 11:50:08,733 - trainer - INFO -     val_perplexity : -83.8989028930664
2025-01-21 11:50:08,733 - trainer - INFO -     val_embedding_sim: 0.06385539472103119
2025-01-21 11:50:14,066 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 11:50:14,067 - trainer - INFO - ================================================================================
2025-01-21 11:50:14,067 - trainer - INFO - Starting epoch 11 at 2025-01-21 11:50:14
2025-01-21 11:50:18,034 - trainer - INFO - Epoch 11 completed at 2025-01-21 11:50:18
2025-01-21 11:50:18,034 - trainer - INFO -     epoch          : 11
2025-01-21 11:50:18,034 - trainer - INFO -     elapsed time   : 3.9666194915771484
2025-01-21 11:50:18,034 - trainer - INFO -     loss           : 36.86928205490112
2025-01-21 11:50:18,034 - trainer - INFO -     sim_loss       : 36.7141074180603
2025-01-21 11:50:18,034 - trainer - INFO -     gen_loss       : 0.1551746666431427
2025-01-21 11:50:18,034 - trainer - INFO -     val_loss       : 12.299183808267117
2025-01-21 11:50:18,034 - trainer - INFO -     val_sim_loss   : 12.191130638122559
2025-01-21 11:50:18,034 - trainer - INFO -     val_gen_loss   : 0.10805343091487885
2025-01-21 11:50:18,034 - trainer - INFO -     val_perplexity : -84.7973403930664
2025-01-21 11:50:18,034 - trainer - INFO -     val_embedding_sim: 0.07155749201774597
2025-01-21 11:50:18,034 - trainer - INFO - ================================================================================
2025-01-21 11:50:18,034 - trainer - INFO - Starting epoch 12 at 2025-01-21 11:50:18
2025-01-21 11:50:21,940 - trainer - INFO - Epoch 12 completed at 2025-01-21 11:50:21
2025-01-21 11:50:21,941 - trainer - INFO -     epoch          : 12
2025-01-21 11:50:21,941 - trainer - INFO -     elapsed time   : 3.9061851501464844
2025-01-21 11:50:21,941 - trainer - INFO -     loss           : 27.74122552871704
2025-01-21 11:50:21,941 - trainer - INFO -     sim_loss       : 27.60865526199341
2025-01-21 11:50:21,941 - trainer - INFO -     gen_loss       : 0.1325703077018261
2025-01-21 11:50:21,941 - trainer - INFO -     val_loss       : 23.666495135053992
2025-01-21 11:50:21,941 - trainer - INFO -     val_sim_loss   : 23.568262100219727
2025-01-21 11:50:21,941 - trainer - INFO -     val_gen_loss   : 0.09823366813361645
2025-01-21 11:50:21,941 - trainer - INFO -     val_perplexity : -84.42609405517578
2025-01-21 11:50:21,941 - trainer - INFO -     val_embedding_sim: 0.06951591372489929
2025-01-21 11:50:21,941 - trainer - INFO - ================================================================================
2025-01-21 11:50:21,941 - trainer - INFO - Starting epoch 13 at 2025-01-21 11:50:21
2025-01-21 11:50:25,837 - trainer - INFO - Epoch 13 completed at 2025-01-21 11:50:25
2025-01-21 11:50:25,837 - trainer - INFO -     epoch          : 13
2025-01-21 11:50:25,838 - trainer - INFO -     elapsed time   : 3.896059036254883
2025-01-21 11:50:25,838 - trainer - INFO -     loss           : 32.817892169952394
2025-01-21 11:50:25,838 - trainer - INFO -     sim_loss       : 32.700362586975096
2025-01-21 11:50:25,838 - trainer - INFO -     gen_loss       : 0.11752968057990074
2025-01-21 11:50:25,838 - trainer - INFO -     val_loss       : 20.861506515182555
2025-01-21 11:50:25,838 - trainer - INFO -     val_sim_loss   : 20.795907974243164
2025-01-21 11:50:25,838 - trainer - INFO -     val_gen_loss   : 0.06559930462390184
2025-01-21 11:50:25,838 - trainer - INFO -     val_perplexity : -84.90316772460938
2025-01-21 11:50:25,838 - trainer - INFO -     val_embedding_sim: 0.06308415532112122
2025-01-21 11:50:25,838 - trainer - INFO - ================================================================================
2025-01-21 11:50:25,838 - trainer - INFO - Starting epoch 14 at 2025-01-21 11:50:25
2025-01-21 11:50:29,736 - trainer - INFO - Epoch 14 completed at 2025-01-21 11:50:29
2025-01-21 11:50:29,736 - trainer - INFO -     epoch          : 14
2025-01-21 11:50:29,736 - trainer - INFO -     elapsed time   : 3.8976168632507324
2025-01-21 11:50:29,736 - trainer - INFO -     loss           : 35.91234951019287
2025-01-21 11:50:29,736 - trainer - INFO -     sim_loss       : 35.81747651100159
2025-01-21 11:50:29,736 - trainer - INFO -     gen_loss       : 0.09487279951572418
2025-01-21 11:50:29,736 - trainer - INFO -     val_loss       : 17.1511818068102
2025-01-21 11:50:29,736 - trainer - INFO -     val_sim_loss   : 17.087909698486328
2025-01-21 11:50:29,736 - trainer - INFO -     val_gen_loss   : 0.06327152717858553
2025-01-21 11:50:29,736 - trainer - INFO -     val_perplexity : -85.77523803710938
2025-01-21 11:50:29,736 - trainer - INFO -     val_embedding_sim: 0.09493432193994522
2025-01-21 11:50:29,736 - trainer - INFO - ================================================================================
2025-01-21 11:50:29,736 - trainer - INFO - Starting epoch 15 at 2025-01-21 11:50:29
2025-01-21 11:50:33,631 - trainer - INFO - Epoch 15 completed at 2025-01-21 11:50:33
2025-01-21 11:50:33,631 - trainer - INFO -     epoch          : 15
2025-01-21 11:50:33,631 - trainer - INFO -     elapsed time   : 3.894291400909424
2025-01-21 11:50:33,631 - trainer - INFO -     loss           : 29.238430976867676
2025-01-21 11:50:33,631 - trainer - INFO -     sim_loss       : 28.96125888824463
2025-01-21 11:50:33,631 - trainer - INFO -     gen_loss       : 0.2771724611520767
2025-01-21 11:50:33,631 - trainer - INFO -     val_loss       : 14.563717514276505
2025-01-21 11:50:33,631 - trainer - INFO -     val_sim_loss   : 14.378755569458008
2025-01-21 11:50:33,631 - trainer - INFO -     val_gen_loss   : 0.18496181815862656
2025-01-21 11:50:33,631 - trainer - INFO -     val_perplexity : -81.88407897949219
2025-01-21 11:50:33,631 - trainer - INFO -     val_embedding_sim: 0.07848864048719406
2025-01-21 11:50:38,991 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 11:50:38,991 - trainer - INFO - ================================================================================
2025-01-21 11:50:38,991 - trainer - INFO - Starting epoch 16 at 2025-01-21 11:50:38
2025-01-21 11:50:42,943 - trainer - INFO - Epoch 16 completed at 2025-01-21 11:50:42
2025-01-21 11:50:42,943 - trainer - INFO -     epoch          : 16
2025-01-21 11:50:42,944 - trainer - INFO -     elapsed time   : 3.951948642730713
2025-01-21 11:50:42,944 - trainer - INFO -     loss           : 32.760385966300966
2025-01-21 11:50:42,944 - trainer - INFO -     sim_loss       : 32.623337745666504
2025-01-21 11:50:42,944 - trainer - INFO -     gen_loss       : 0.137047827988863
2025-01-21 11:50:42,944 - trainer - INFO -     val_loss       : 12.076284892857075
2025-01-21 11:50:42,944 - trainer - INFO -     val_sim_loss   : 11.996061325073242
2025-01-21 11:50:42,944 - trainer - INFO -     val_gen_loss   : 0.08022347837686539
2025-01-21 11:50:42,944 - trainer - INFO -     val_perplexity : -86.29341888427734
2025-01-21 11:50:42,944 - trainer - INFO -     val_embedding_sim: 0.08958129584789276
2025-01-21 11:50:42,944 - trainer - INFO - ================================================================================
2025-01-21 11:50:42,944 - trainer - INFO - Starting epoch 17 at 2025-01-21 11:50:42
2025-01-21 11:50:46,853 - trainer - INFO - Epoch 17 completed at 2025-01-21 11:50:46
2025-01-21 11:50:46,853 - trainer - INFO -     epoch          : 17
2025-01-21 11:50:46,854 - trainer - INFO -     elapsed time   : 3.909254550933838
2025-01-21 11:50:46,854 - trainer - INFO -     loss           : 32.27160491943359
2025-01-21 11:50:46,854 - trainer - INFO -     sim_loss       : 32.10098457336426
2025-01-21 11:50:46,854 - trainer - INFO -     gen_loss       : 0.17062052339315414
2025-01-21 11:50:46,854 - trainer - INFO -     val_loss       : 17.940883487462997
2025-01-21 11:50:46,854 - trainer - INFO -     val_sim_loss   : 17.481365203857422
2025-01-21 11:50:46,854 - trainer - INFO -     val_gen_loss   : 0.4595181420445442
2025-01-21 11:50:46,854 - trainer - INFO -     val_perplexity : -83.98291015625
2025-01-21 11:50:46,854 - trainer - INFO -     val_embedding_sim: 0.06882192194461823
2025-01-21 11:50:46,854 - trainer - INFO - ================================================================================
2025-01-21 11:50:46,854 - trainer - INFO - Starting epoch 18 at 2025-01-21 11:50:46
2025-01-21 11:50:50,741 - trainer - INFO - Epoch 18 completed at 2025-01-21 11:50:50
2025-01-21 11:50:50,741 - trainer - INFO -     epoch          : 18
2025-01-21 11:50:50,741 - trainer - INFO -     elapsed time   : 3.886695384979248
2025-01-21 11:50:50,741 - trainer - INFO -     loss           : 31.729412746429443
2025-01-21 11:50:50,741 - trainer - INFO -     sim_loss       : 31.64859733581543
2025-01-21 11:50:50,741 - trainer - INFO -     gen_loss       : 0.08081533871591091
2025-01-21 11:50:50,741 - trainer - INFO -     val_loss       : 21.421797486487776
2025-01-21 11:50:50,741 - trainer - INFO -     val_sim_loss   : 21.35936164855957
2025-01-21 11:50:50,741 - trainer - INFO -     val_gen_loss   : 0.06243556598201394
2025-01-21 11:50:50,741 - trainer - INFO -     val_perplexity : -87.58531951904297
2025-01-21 11:50:50,741 - trainer - INFO -     val_embedding_sim: 0.07120607048273087
2025-01-21 11:50:50,741 - trainer - INFO - ================================================================================
2025-01-21 11:50:50,741 - trainer - INFO - Starting epoch 19 at 2025-01-21 11:50:50
2025-01-21 11:50:54,642 - trainer - INFO - Epoch 19 completed at 2025-01-21 11:50:54
2025-01-21 11:50:54,642 - trainer - INFO -     epoch          : 19
2025-01-21 11:50:54,642 - trainer - INFO -     elapsed time   : 3.90048885345459
2025-01-21 11:50:54,642 - trainer - INFO -     loss           : 31.895515298843385
2025-01-21 11:50:54,642 - trainer - INFO -     sim_loss       : 31.835129070281983
2025-01-21 11:50:54,642 - trainer - INFO -     gen_loss       : 0.06038621291518211
2025-01-21 11:50:54,642 - trainer - INFO -     val_loss       : 13.882936306297779
2025-01-21 11:50:54,642 - trainer - INFO -     val_sim_loss   : 13.759049415588379
2025-01-21 11:50:54,642 - trainer - INFO -     val_gen_loss   : 0.1238868311047554
2025-01-21 11:50:54,642 - trainer - INFO -     val_perplexity : -88.04969787597656
2025-01-21 11:50:54,642 - trainer - INFO -     val_embedding_sim: 0.08056817203760147
2025-01-21 11:50:54,642 - trainer - INFO - ================================================================================
2025-01-21 11:50:54,643 - trainer - INFO - Starting epoch 20 at 2025-01-21 11:50:54
2025-01-21 11:50:58,550 - trainer - INFO - Epoch 20 completed at 2025-01-21 11:50:58
2025-01-21 11:50:58,550 - trainer - INFO -     epoch          : 20
2025-01-21 11:50:58,550 - trainer - INFO -     elapsed time   : 3.907536268234253
2025-01-21 11:50:58,550 - trainer - INFO -     loss           : 28.90456509590149
2025-01-21 11:50:58,550 - trainer - INFO -     sim_loss       : 28.755478942394255
2025-01-21 11:50:58,551 - trainer - INFO -     gen_loss       : 0.1490861728787422
2025-01-21 11:50:58,551 - trainer - INFO -     val_loss       : 17.987740215379745
2025-01-21 11:50:58,551 - trainer - INFO -     val_sim_loss   : 17.92511749267578
2025-01-21 11:50:58,551 - trainer - INFO -     val_gen_loss   : 0.06262264447286725
2025-01-21 11:50:58,551 - trainer - INFO -     val_perplexity : -86.11958312988281
2025-01-21 11:50:58,551 - trainer - INFO -     val_embedding_sim: 0.059175729751586914
2025-01-21 11:51:03,858 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 11:51:03,858 - trainer - INFO - ================================================================================
2025-01-21 11:51:03,858 - trainer - INFO - Starting epoch 21 at 2025-01-21 11:51:03
2025-01-21 11:51:07,831 - trainer - INFO - Epoch 21 completed at 2025-01-21 11:51:07
2025-01-21 11:51:07,831 - trainer - INFO -     epoch          : 21
2025-01-21 11:51:07,831 - trainer - INFO -     elapsed time   : 3.972583532333374
2025-01-21 11:51:07,831 - trainer - INFO -     loss           : 29.206982803344726
2025-01-21 11:51:07,831 - trainer - INFO -     sim_loss       : 28.967704677581786
2025-01-21 11:51:07,831 - trainer - INFO -     gen_loss       : 0.239278244972229
2025-01-21 11:51:07,831 - trainer - INFO -     val_loss       : 18.036723345518112
2025-01-21 11:51:07,831 - trainer - INFO -     val_sim_loss   : 17.712080001831055
2025-01-21 11:51:07,831 - trainer - INFO -     val_gen_loss   : 0.3246435225009918
2025-01-21 11:51:07,831 - trainer - INFO -     val_perplexity : -80.51309967041016
2025-01-21 11:51:07,832 - trainer - INFO -     val_embedding_sim: 0.06677299737930298
2025-01-21 11:51:07,832 - trainer - INFO - ================================================================================
2025-01-21 11:51:07,832 - trainer - INFO - Starting epoch 22 at 2025-01-21 11:51:07
2025-01-21 11:51:11,723 - trainer - INFO - Epoch 22 completed at 2025-01-21 11:51:11
2025-01-21 11:51:11,723 - trainer - INFO -     epoch          : 22
2025-01-21 11:51:11,723 - trainer - INFO -     elapsed time   : 3.8914859294891357
2025-01-21 11:51:11,723 - trainer - INFO -     loss           : 34.34671275615692
2025-01-21 11:51:11,723 - trainer - INFO -     sim_loss       : 34.169129881262776
2025-01-21 11:51:11,724 - trainer - INFO -     gen_loss       : 0.1775826595723629
2025-01-21 11:51:11,724 - trainer - INFO -     val_loss       : 20.69346123933792
2025-01-21 11:51:11,724 - trainer - INFO -     val_sim_loss   : 19.947586059570312
2025-01-21 11:51:11,724 - trainer - INFO -     val_gen_loss   : 0.7458756268024445
2025-01-21 11:51:11,724 - trainer - INFO -     val_perplexity : -82.5449447631836
2025-01-21 11:51:11,724 - trainer - INFO -     val_embedding_sim: 0.08209624886512756
2025-01-21 11:51:11,724 - trainer - INFO - ================================================================================
2025-01-21 11:51:11,724 - trainer - INFO - Starting epoch 23 at 2025-01-21 11:51:11
2025-01-21 11:51:15,621 - trainer - INFO - Epoch 23 completed at 2025-01-21 11:51:15
2025-01-21 11:51:15,621 - trainer - INFO -     epoch          : 23
2025-01-21 11:51:15,622 - trainer - INFO -     elapsed time   : 3.8974294662475586
2025-01-21 11:51:15,622 - trainer - INFO -     loss           : 26.892923951148987
2025-01-21 11:51:15,622 - trainer - INFO -     sim_loss       : 26.794725847244262
2025-01-21 11:51:15,622 - trainer - INFO -     gen_loss       : 0.0981984294950962
2025-01-21 11:51:15,622 - trainer - INFO -     val_loss       : 13.034090591594577
2025-01-21 11:51:15,622 - trainer - INFO -     val_sim_loss   : 12.94668197631836
2025-01-21 11:51:15,622 - trainer - INFO -     val_gen_loss   : 0.08740864507853985
2025-01-21 11:51:15,622 - trainer - INFO -     val_perplexity : -87.49156188964844
2025-01-21 11:51:15,622 - trainer - INFO -     val_embedding_sim: 0.08975640684366226
2025-01-21 11:51:15,622 - trainer - INFO - ================================================================================
2025-01-21 11:51:15,622 - trainer - INFO - Starting epoch 24 at 2025-01-21 11:51:15
2025-01-21 11:51:19,532 - trainer - INFO - Epoch 24 completed at 2025-01-21 11:51:19
2025-01-21 11:51:19,532 - trainer - INFO -     epoch          : 24
2025-01-21 11:51:19,532 - trainer - INFO -     elapsed time   : 3.909888505935669
2025-01-21 11:51:19,532 - trainer - INFO -     loss           : 34.57878437042236
2025-01-21 11:51:19,532 - trainer - INFO -     sim_loss       : 34.410037422180174
2025-01-21 11:51:19,532 - trainer - INFO -     gen_loss       : 0.16874698661267756
2025-01-21 11:51:19,532 - trainer - INFO -     val_loss       : 15.070483803749084
2025-01-21 11:51:19,532 - trainer - INFO -     val_sim_loss   : 14.340513229370117
2025-01-21 11:51:19,532 - trainer - INFO -     val_gen_loss   : 0.7299705371260643
2025-01-21 11:51:19,532 - trainer - INFO -     val_perplexity : -80.7220230102539
2025-01-21 11:51:19,532 - trainer - INFO -     val_embedding_sim: 0.10059677809476852
2025-01-21 11:51:19,532 - trainer - INFO - ================================================================================
2025-01-21 11:51:19,532 - trainer - INFO - Starting epoch 25 at 2025-01-21 11:51:19
2025-01-21 11:51:23,395 - trainer - INFO - Epoch 25 completed at 2025-01-21 11:51:23
2025-01-21 11:51:23,396 - trainer - INFO -     epoch          : 25
2025-01-21 11:51:23,396 - trainer - INFO -     elapsed time   : 3.862780809402466
2025-01-21 11:51:23,396 - trainer - INFO -     loss           : 30.13241367340088
2025-01-21 11:51:23,396 - trainer - INFO -     sim_loss       : 30.01881675720215
2025-01-21 11:51:23,396 - trainer - INFO -     gen_loss       : 0.11359690986573696
2025-01-21 11:51:23,396 - trainer - INFO -     val_loss       : 13.473788725212216
2025-01-21 11:51:23,396 - trainer - INFO -     val_sim_loss   : 13.38083267211914
2025-01-21 11:51:23,396 - trainer - INFO -     val_gen_loss   : 0.0929559338837862
2025-01-21 11:51:23,396 - trainer - INFO -     val_perplexity : -85.31546020507812
2025-01-21 11:51:23,396 - trainer - INFO -     val_embedding_sim: 0.09753642976284027
2025-01-21 11:51:28,703 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 11:51:28,703 - trainer - INFO - ================================================================================
2025-01-21 11:51:28,703 - trainer - INFO - Starting epoch 26 at 2025-01-21 11:51:28
2025-01-21 11:51:32,612 - trainer - INFO - Epoch 26 completed at 2025-01-21 11:51:32
2025-01-21 11:51:32,612 - trainer - INFO -     epoch          : 26
2025-01-21 11:51:32,612 - trainer - INFO -     elapsed time   : 3.909207344055176
2025-01-21 11:51:32,613 - trainer - INFO -     loss           : 29.975876140594483
2025-01-21 11:51:32,613 - trainer - INFO -     sim_loss       : 29.926427268981932
2025-01-21 11:51:32,613 - trainer - INFO -     gen_loss       : 0.049448934569954875
2025-01-21 11:51:32,613 - trainer - INFO -     val_loss       : 19.286802959279157
2025-01-21 11:51:32,613 - trainer - INFO -     val_sim_loss   : 19.24026107788086
2025-01-21 11:51:32,613 - trainer - INFO -     val_gen_loss   : 0.04654256685171276
2025-01-21 11:51:32,613 - trainer - INFO -     val_perplexity : -89.79769897460938
2025-01-21 11:51:32,613 - trainer - INFO -     val_embedding_sim: 0.0962705984711647
2025-01-21 11:51:32,613 - trainer - INFO - ================================================================================
2025-01-21 11:51:32,613 - trainer - INFO - Starting epoch 27 at 2025-01-21 11:51:32
2025-01-21 11:51:36,482 - trainer - INFO - Epoch 27 completed at 2025-01-21 11:51:36
2025-01-21 11:51:36,482 - trainer - INFO -     epoch          : 27
2025-01-21 11:51:36,482 - trainer - INFO -     elapsed time   : 3.8693156242370605
2025-01-21 11:51:36,482 - trainer - INFO -     loss           : 25.75558958053589
2025-01-21 11:51:36,483 - trainer - INFO -     sim_loss       : 25.705552577972412
2025-01-21 11:51:36,483 - trainer - INFO -     gen_loss       : 0.050036878883838655
2025-01-21 11:51:36,483 - trainer - INFO -     val_loss       : 13.005407206481323
2025-01-21 11:51:36,483 - trainer - INFO -     val_sim_loss   : 12.95765495300293
2025-01-21 11:51:36,483 - trainer - INFO -     val_gen_loss   : 0.04775255895219743
2025-01-21 11:51:36,483 - trainer - INFO -     val_perplexity : -88.34058380126953
2025-01-21 11:51:36,483 - trainer - INFO -     val_embedding_sim: 0.10590662062168121
2025-01-21 11:51:36,483 - trainer - INFO - ================================================================================
2025-01-21 11:51:36,483 - trainer - INFO - Starting epoch 28 at 2025-01-21 11:51:36
2025-01-21 11:51:40,347 - trainer - INFO - Epoch 28 completed at 2025-01-21 11:51:40
2025-01-21 11:51:40,347 - trainer - INFO -     epoch          : 28
2025-01-21 11:51:40,347 - trainer - INFO -     elapsed time   : 3.863931894302368
2025-01-21 11:51:40,347 - trainer - INFO -     loss           : 34.1936794757843
2025-01-21 11:51:40,347 - trainer - INFO -     sim_loss       : 34.15441632270813
2025-01-21 11:51:40,347 - trainer - INFO -     gen_loss       : 0.03926295563578606
2025-01-21 11:51:40,347 - trainer - INFO -     val_loss       : 20.2707963057328
2025-01-21 11:51:40,347 - trainer - INFO -     val_sim_loss   : 20.23833465576172
2025-01-21 11:51:40,347 - trainer - INFO -     val_gen_loss   : 0.032462260918691754
2025-01-21 11:51:40,347 - trainer - INFO -     val_perplexity : -91.47073364257812
2025-01-21 11:51:40,347 - trainer - INFO -     val_embedding_sim: 0.10997350513935089
2025-01-21 11:51:40,347 - trainer - INFO - ================================================================================
2025-01-21 11:51:40,347 - trainer - INFO - Starting epoch 29 at 2025-01-21 11:51:40
2025-01-21 11:51:44,249 - trainer - INFO - Epoch 29 completed at 2025-01-21 11:51:44
2025-01-21 11:51:44,249 - trainer - INFO -     epoch          : 29
2025-01-21 11:51:44,249 - trainer - INFO -     elapsed time   : 3.9011125564575195
2025-01-21 11:51:44,249 - trainer - INFO -     loss           : 29.344252109527588
2025-01-21 11:51:44,249 - trainer - INFO -     sim_loss       : 29.318860912322997
2025-01-21 11:51:44,249 - trainer - INFO -     gen_loss       : 0.025390875712037086
2025-01-21 11:51:44,249 - trainer - INFO -     val_loss       : 11.099590518279001
2025-01-21 11:51:44,249 - trainer - INFO -     val_sim_loss   : 11.071952819824219
2025-01-21 11:51:44,249 - trainer - INFO -     val_gen_loss   : 0.02763730543665588
2025-01-21 11:51:44,249 - trainer - INFO -     val_perplexity : -93.45362091064453
2025-01-21 11:51:44,249 - trainer - INFO -     val_embedding_sim: 0.05427968502044678
2025-01-21 11:51:44,249 - trainer - INFO - ================================================================================
2025-01-21 11:51:44,249 - trainer - INFO - Starting epoch 30 at 2025-01-21 11:51:44
2025-01-21 11:51:48,115 - trainer - INFO - Epoch 30 completed at 2025-01-21 11:51:48
2025-01-21 11:51:48,115 - trainer - INFO -     epoch          : 30
2025-01-21 11:51:48,115 - trainer - INFO -     elapsed time   : 3.865752696990967
2025-01-21 11:51:48,115 - trainer - INFO -     loss           : 32.611788272857666
2025-01-21 11:51:48,115 - trainer - INFO -     sim_loss       : 32.58996229171753
2025-01-21 11:51:48,115 - trainer - INFO -     gen_loss       : 0.02182641513645649
2025-01-21 11:51:48,115 - trainer - INFO -     val_loss       : 20.782798554748297
2025-01-21 11:51:48,115 - trainer - INFO -     val_sim_loss   : 20.716283798217773
2025-01-21 11:51:48,116 - trainer - INFO -     val_gen_loss   : 0.06651470623910427
2025-01-21 11:51:48,116 - trainer - INFO -     val_perplexity : -94.41609954833984
2025-01-21 11:51:48,116 - trainer - INFO -     val_embedding_sim: 0.08025842905044556
2025-01-21 11:51:53,401 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 11:51:53,401 - trainer - INFO - ================================================================================
2025-01-21 11:51:53,401 - trainer - INFO - Starting epoch 31 at 2025-01-21 11:51:53
2025-01-21 11:51:57,347 - trainer - INFO - Epoch 31 completed at 2025-01-21 11:51:57
2025-01-21 11:51:57,347 - trainer - INFO -     epoch          : 31
2025-01-21 11:51:57,347 - trainer - INFO -     elapsed time   : 3.9454288482666016
2025-01-21 11:51:57,347 - trainer - INFO -     loss           : 31.292864894866945
2025-01-21 11:51:57,347 - trainer - INFO -     sim_loss       : 31.27500400543213
2025-01-21 11:51:57,347 - trainer - INFO -     gen_loss       : 0.017860841099172832
2025-01-21 11:51:57,347 - trainer - INFO -     val_loss       : 17.578264124691486
2025-01-21 11:51:57,347 - trainer - INFO -     val_sim_loss   : 17.549468994140625
2025-01-21 11:51:57,347 - trainer - INFO -     val_gen_loss   : 0.02879492938518524
2025-01-21 11:51:57,347 - trainer - INFO -     val_perplexity : -94.90470886230469
2025-01-21 11:51:57,347 - trainer - INFO -     val_embedding_sim: 0.07000546902418137
2025-01-21 11:51:57,347 - trainer - INFO - ================================================================================
2025-01-21 11:51:57,347 - trainer - INFO - Starting epoch 32 at 2025-01-21 11:51:57
2025-01-21 11:52:01,260 - trainer - INFO - Epoch 32 completed at 2025-01-21 11:52:01
2025-01-21 11:52:01,260 - trainer - INFO -     epoch          : 32
2025-01-21 11:52:01,260 - trainer - INFO -     elapsed time   : 3.912168264389038
2025-01-21 11:52:01,260 - trainer - INFO -     loss           : 30.90624780654907
2025-01-21 11:52:01,260 - trainer - INFO -     sim_loss       : 30.888568592071532
2025-01-21 11:52:01,260 - trainer - INFO -     gen_loss       : 0.01767909452319145
2025-01-21 11:52:01,260 - trainer - INFO -     val_loss       : 17.2210193015635
2025-01-21 11:52:01,260 - trainer - INFO -     val_sim_loss   : 17.197219848632812
2025-01-21 11:52:01,260 - trainer - INFO -     val_gen_loss   : 0.023798562586307526
2025-01-21 11:52:01,260 - trainer - INFO -     val_perplexity : -95.09236907958984
2025-01-21 11:52:01,260 - trainer - INFO -     val_embedding_sim: 0.0666707381606102
2025-01-21 11:52:01,260 - trainer - INFO - ================================================================================
2025-01-21 11:52:01,260 - trainer - INFO - Starting epoch 33 at 2025-01-21 11:52:01
2025-01-21 11:52:05,170 - trainer - INFO - Epoch 33 completed at 2025-01-21 11:52:05
2025-01-21 11:52:05,171 - trainer - INFO -     epoch          : 33
2025-01-21 11:52:05,171 - trainer - INFO -     elapsed time   : 3.9100053310394287
2025-01-21 11:52:05,171 - trainer - INFO -     loss           : 32.43614916801452
2025-01-21 11:52:05,171 - trainer - INFO -     sim_loss       : 32.41979823112488
2025-01-21 11:52:05,171 - trainer - INFO -     gen_loss       : 0.016350863873958586
2025-01-21 11:52:05,171 - trainer - INFO -     val_loss       : 19.177213598042727
2025-01-21 11:52:05,171 - trainer - INFO -     val_sim_loss   : 19.138954162597656
2025-01-21 11:52:05,171 - trainer - INFO -     val_gen_loss   : 0.03825987130403519
2025-01-21 11:52:05,171 - trainer - INFO -     val_perplexity : -94.54987335205078
2025-01-21 11:52:05,171 - trainer - INFO -     val_embedding_sim: 0.07103611528873444
2025-01-21 11:52:05,171 - trainer - INFO - ================================================================================
2025-01-21 11:52:05,171 - trainer - INFO - Starting epoch 34 at 2025-01-21 11:52:05
2025-01-21 11:52:09,068 - trainer - INFO - Epoch 34 completed at 2025-01-21 11:52:09
2025-01-21 11:52:09,068 - trainer - INFO -     epoch          : 34
2025-01-21 11:52:09,068 - trainer - INFO -     elapsed time   : 3.896892547607422
2025-01-21 11:52:09,068 - trainer - INFO -     loss           : 32.725842761993405
2025-01-21 11:52:09,068 - trainer - INFO -     sim_loss       : 32.70589179992676
2025-01-21 11:52:09,068 - trainer - INFO -     gen_loss       : 0.019951063208281994
2025-01-21 11:52:09,068 - trainer - INFO -     val_loss       : 15.437181528657675
2025-01-21 11:52:09,068 - trainer - INFO -     val_sim_loss   : 15.391555786132812
2025-01-21 11:52:09,068 - trainer - INFO -     val_gen_loss   : 0.045625774189829826
2025-01-21 11:52:09,068 - trainer - INFO -     val_perplexity : -92.03047943115234
2025-01-21 11:52:09,069 - trainer - INFO -     val_embedding_sim: 0.06092827022075653
2025-01-21 11:52:09,069 - trainer - INFO - ================================================================================
2025-01-21 11:52:09,069 - trainer - INFO - Starting epoch 35 at 2025-01-21 11:52:09
2025-01-21 11:52:12,963 - trainer - INFO - Epoch 35 completed at 2025-01-21 11:52:12
2025-01-21 11:52:12,964 - trainer - INFO -     epoch          : 35
2025-01-21 11:52:12,964 - trainer - INFO -     elapsed time   : 3.8946521282196045
2025-01-21 11:52:12,964 - trainer - INFO -     loss           : 24.28780589103699
2025-01-21 11:52:12,964 - trainer - INFO -     sim_loss       : 24.26863751411438
2025-01-21 11:52:12,964 - trainer - INFO -     gen_loss       : 0.01916806763038039
2025-01-21 11:52:12,964 - trainer - INFO -     val_loss       : 12.491840202361345
2025-01-21 11:52:12,964 - trainer - INFO -     val_sim_loss   : 12.438762664794922
2025-01-21 11:52:12,964 - trainer - INFO -     val_gen_loss   : 0.0530775748193264
2025-01-21 11:52:12,964 - trainer - INFO -     val_perplexity : -95.71533966064453
2025-01-21 11:52:12,964 - trainer - INFO -     val_embedding_sim: 0.05733130872249603
2025-01-21 11:52:18,239 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 11:52:18,239 - trainer - INFO - ================================================================================
2025-01-21 11:52:18,239 - trainer - INFO - Starting epoch 36 at 2025-01-21 11:52:18
2025-01-21 11:52:22,188 - trainer - INFO - Epoch 36 completed at 2025-01-21 11:52:22
2025-01-21 11:52:22,188 - trainer - INFO -     epoch          : 36
2025-01-21 11:52:22,188 - trainer - INFO -     elapsed time   : 3.948146343231201
2025-01-21 11:52:22,188 - trainer - INFO -     loss           : 30.777527618408204
2025-01-21 11:52:22,188 - trainer - INFO -     sim_loss       : 30.762746620178223
2025-01-21 11:52:22,188 - trainer - INFO -     gen_loss       : 0.014780783094465733
2025-01-21 11:52:22,188 - trainer - INFO -     val_loss       : 11.536327369394712
2025-01-21 11:52:22,188 - trainer - INFO -     val_sim_loss   : 11.514755249023438
2025-01-21 11:52:22,188 - trainer - INFO -     val_gen_loss   : 0.021572379278950393
2025-01-21 11:52:22,188 - trainer - INFO -     val_perplexity : -95.53611755371094
2025-01-21 11:52:22,188 - trainer - INFO -     val_embedding_sim: 0.060254424810409546
2025-01-21 11:52:22,188 - trainer - INFO - ================================================================================
2025-01-21 11:52:22,188 - trainer - INFO - Starting epoch 37 at 2025-01-21 11:52:22
2025-01-21 11:52:26,100 - trainer - INFO - Epoch 37 completed at 2025-01-21 11:52:26
2025-01-21 11:52:26,100 - trainer - INFO -     epoch          : 37
2025-01-21 11:52:26,100 - trainer - INFO -     elapsed time   : 3.911811351776123
2025-01-21 11:52:26,100 - trainer - INFO -     loss           : 29.85238540172577
2025-01-21 11:52:26,100 - trainer - INFO -     sim_loss       : 29.83835995197296
2025-01-21 11:52:26,100 - trainer - INFO -     gen_loss       : 0.01402612291276455
2025-01-21 11:52:26,100 - trainer - INFO -     val_loss       : 18.780222083325498
2025-01-21 11:52:26,100 - trainer - INFO -     val_sim_loss   : 18.759592056274414
2025-01-21 11:52:26,100 - trainer - INFO -     val_gen_loss   : 0.020630921120755374
2025-01-21 11:52:26,101 - trainer - INFO -     val_perplexity : -95.70291137695312
2025-01-21 11:52:26,101 - trainer - INFO -     val_embedding_sim: 0.07264772057533264
2025-01-21 11:52:26,101 - trainer - INFO - ================================================================================
2025-01-21 11:52:26,101 - trainer - INFO - Starting epoch 38 at 2025-01-21 11:52:26
2025-01-21 11:52:30,004 - trainer - INFO - Epoch 38 completed at 2025-01-21 11:52:30
2025-01-21 11:52:30,004 - trainer - INFO -     epoch          : 38
2025-01-21 11:52:30,004 - trainer - INFO -     elapsed time   : 3.903465747833252
2025-01-21 11:52:30,005 - trainer - INFO -     loss           : 33.43204636573792
2025-01-21 11:52:30,005 - trainer - INFO -     sim_loss       : 33.418861103057864
2025-01-21 11:52:30,005 - trainer - INFO -     gen_loss       : 0.013185984082520008
2025-01-21 11:52:30,005 - trainer - INFO -     val_loss       : 13.388448398909532
2025-01-21 11:52:30,005 - trainer - INFO -     val_sim_loss   : 13.366644859313965
2025-01-21 11:52:30,005 - trainer - INFO -     val_gen_loss   : 0.021803966141305864
2025-01-21 11:52:30,005 - trainer - INFO -     val_perplexity : -94.91703796386719
2025-01-21 11:52:30,005 - trainer - INFO -     val_embedding_sim: 0.06266912817955017
2025-01-21 11:52:30,005 - trainer - INFO - ================================================================================
2025-01-21 11:52:30,005 - trainer - INFO - Starting epoch 39 at 2025-01-21 11:52:30
2025-01-21 11:52:33,908 - trainer - INFO - Epoch 39 completed at 2025-01-21 11:52:33
2025-01-21 11:52:33,908 - trainer - INFO -     epoch          : 39
2025-01-21 11:52:33,908 - trainer - INFO -     elapsed time   : 3.903014659881592
2025-01-21 11:52:33,908 - trainer - INFO -     loss           : 31.657656955718995
2025-01-21 11:52:33,908 - trainer - INFO -     sim_loss       : 31.643390369415282
2025-01-21 11:52:33,908 - trainer - INFO -     gen_loss       : 0.014266535826027393
2025-01-21 11:52:33,908 - trainer - INFO -     val_loss       : 13.432576306164265
2025-01-21 11:52:33,908 - trainer - INFO -     val_sim_loss   : 13.345195770263672
2025-01-21 11:52:33,908 - trainer - INFO -     val_gen_loss   : 0.08738020621240139
2025-01-21 11:52:33,908 - trainer - INFO -     val_perplexity : -95.52434539794922
2025-01-21 11:52:33,909 - trainer - INFO -     val_embedding_sim: 0.0947808176279068
2025-01-21 11:52:33,909 - trainer - INFO - ================================================================================
2025-01-21 11:52:33,909 - trainer - INFO - Starting epoch 40 at 2025-01-21 11:52:33
2025-01-21 11:52:37,813 - trainer - INFO - Epoch 40 completed at 2025-01-21 11:52:37
2025-01-21 11:52:37,813 - trainer - INFO -     epoch          : 40
2025-01-21 11:52:37,813 - trainer - INFO -     elapsed time   : 3.903888702392578
2025-01-21 11:52:37,813 - trainer - INFO -     loss           : 30.47818880081177
2025-01-21 11:52:37,813 - trainer - INFO -     sim_loss       : 30.465201568603515
2025-01-21 11:52:37,813 - trainer - INFO -     gen_loss       : 0.012987371347844601
2025-01-21 11:52:37,813 - trainer - INFO -     val_loss       : 16.515475504100323
2025-01-21 11:52:37,813 - trainer - INFO -     val_sim_loss   : 16.381811141967773
2025-01-21 11:52:37,813 - trainer - INFO -     val_gen_loss   : 0.13366440031677485
2025-01-21 11:52:37,813 - trainer - INFO -     val_perplexity : -96.27654266357422
2025-01-21 11:52:37,813 - trainer - INFO -     val_embedding_sim: 0.054801277816295624
2025-01-21 11:52:43,087 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 11:52:43,088 - trainer - INFO - ================================================================================
2025-01-21 11:52:43,088 - trainer - INFO - Starting epoch 41 at 2025-01-21 11:52:43
2025-01-21 11:52:46,995 - trainer - INFO - Epoch 41 completed at 2025-01-21 11:52:46
2025-01-21 11:52:46,995 - trainer - INFO -     epoch          : 41
2025-01-21 11:52:46,995 - trainer - INFO -     elapsed time   : 3.9072039127349854
2025-01-21 11:52:46,995 - trainer - INFO -     loss           : 31.082333374023438
2025-01-21 11:52:46,995 - trainer - INFO -     sim_loss       : 31.070472717285156
2025-01-21 11:52:46,995 - trainer - INFO -     gen_loss       : 0.011860198620706797
2025-01-21 11:52:46,996 - trainer - INFO -     val_loss       : 19.71790815674467
2025-01-21 11:52:46,996 - trainer - INFO -     val_sim_loss   : 19.698619842529297
2025-01-21 11:52:46,996 - trainer - INFO -     val_gen_loss   : 0.019288519106339663
2025-01-21 11:52:46,996 - trainer - INFO -     val_perplexity : -96.6195297241211
2025-01-21 11:52:46,996 - trainer - INFO -     val_embedding_sim: 0.08980619162321091
2025-01-21 11:52:46,996 - trainer - INFO - ================================================================================
2025-01-21 11:52:46,996 - trainer - INFO - Starting epoch 42 at 2025-01-21 11:52:46
2025-01-21 11:52:50,892 - trainer - INFO - Epoch 42 completed at 2025-01-21 11:52:50
2025-01-21 11:52:50,893 - trainer - INFO -     epoch          : 42
2025-01-21 11:52:50,893 - trainer - INFO -     elapsed time   : 3.8964672088623047
2025-01-21 11:52:50,893 - trainer - INFO -     loss           : 37.8219087600708
2025-01-21 11:52:50,893 - trainer - INFO -     sim_loss       : 37.81076192855835
2025-01-21 11:52:50,893 - trainer - INFO -     gen_loss       : 0.011146936053410172
2025-01-21 11:52:50,893 - trainer - INFO -     val_loss       : 28.004133337177336
2025-01-21 11:52:50,893 - trainer - INFO -     val_sim_loss   : 27.97384262084961
2025-01-21 11:52:50,893 - trainer - INFO -     val_gen_loss   : 0.030291647650301456
2025-01-21 11:52:50,893 - trainer - INFO -     val_perplexity : -96.0151138305664
2025-01-21 11:52:50,893 - trainer - INFO -     val_embedding_sim: 0.057402536273002625
2025-01-21 11:52:50,893 - trainer - INFO - ================================================================================
2025-01-21 11:52:50,893 - trainer - INFO - Starting epoch 43 at 2025-01-21 11:52:50
2025-01-21 11:52:54,793 - trainer - INFO - Epoch 43 completed at 2025-01-21 11:52:54
2025-01-21 11:52:54,793 - trainer - INFO -     epoch          : 43
2025-01-21 11:52:54,793 - trainer - INFO -     elapsed time   : 3.8999855518341064
2025-01-21 11:52:54,793 - trainer - INFO -     loss           : 34.16982831954956
2025-01-21 11:52:54,793 - trainer - INFO -     sim_loss       : 34.15919227600098
2025-01-21 11:52:54,793 - trainer - INFO -     gen_loss       : 0.010635840380564332
2025-01-21 11:52:54,793 - trainer - INFO -     val_loss       : 12.197145380079746
2025-01-21 11:52:54,794 - trainer - INFO -     val_sim_loss   : 12.158343315124512
2025-01-21 11:52:54,794 - trainer - INFO -     val_gen_loss   : 0.0388024877756834
2025-01-21 11:52:54,794 - trainer - INFO -     val_perplexity : -95.7686538696289
2025-01-21 11:52:54,794 - trainer - INFO -     val_embedding_sim: 0.08723728358745575
2025-01-21 11:52:54,794 - trainer - INFO - ================================================================================
2025-01-21 11:52:54,794 - trainer - INFO - Starting epoch 44 at 2025-01-21 11:52:54
2025-01-21 11:52:58,666 - trainer - INFO - Epoch 44 completed at 2025-01-21 11:52:58
2025-01-21 11:52:58,666 - trainer - INFO -     epoch          : 44
2025-01-21 11:52:58,666 - trainer - INFO -     elapsed time   : 3.871786594390869
2025-01-21 11:52:58,666 - trainer - INFO -     loss           : 26.384681129455565
2025-01-21 11:52:58,666 - trainer - INFO -     sim_loss       : 26.374573135375975
2025-01-21 11:52:58,666 - trainer - INFO -     gen_loss       : 0.010107945278286934
2025-01-21 11:52:58,666 - trainer - INFO -     val_loss       : 20.898814157233573
2025-01-21 11:52:58,666 - trainer - INFO -     val_sim_loss   : 20.880126953125
2025-01-21 11:52:58,666 - trainer - INFO -     val_gen_loss   : 0.018686425522901118
2025-01-21 11:52:58,666 - trainer - INFO -     val_perplexity : -96.96234130859375
2025-01-21 11:52:58,666 - trainer - INFO -     val_embedding_sim: 0.09471063315868378
2025-01-21 11:52:58,666 - trainer - INFO - ================================================================================
2025-01-21 11:52:58,666 - trainer - INFO - Starting epoch 45 at 2025-01-21 11:52:58
2025-01-21 11:53:02,565 - trainer - INFO - Epoch 45 completed at 2025-01-21 11:53:02
2025-01-21 11:53:02,566 - trainer - INFO -     epoch          : 45
2025-01-21 11:53:02,566 - trainer - INFO -     elapsed time   : 3.8989851474761963
2025-01-21 11:53:02,566 - trainer - INFO -     loss           : 29.711887931823732
2025-01-21 11:53:02,566 - trainer - INFO -     sim_loss       : 29.701689624786376
2025-01-21 11:53:02,566 - trainer - INFO -     gen_loss       : 0.010198363801464438
2025-01-21 11:53:02,566 - trainer - INFO -     val_loss       : 13.244429506943561
2025-01-21 11:53:02,566 - trainer - INFO -     val_sim_loss   : 13.225859642028809
2025-01-21 11:53:02,566 - trainer - INFO -     val_gen_loss   : 0.018569401116110384
2025-01-21 11:53:02,566 - trainer - INFO -     val_perplexity : -97.44154357910156
2025-01-21 11:53:02,566 - trainer - INFO -     val_embedding_sim: 0.07159268110990524
2025-01-21 11:53:07,842 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 11:53:13,109 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:53:13,109 - trainer - INFO - ================================================================================
2025-01-21 11:53:13,109 - trainer - INFO - Starting epoch 46 at 2025-01-21 11:53:13
2025-01-21 11:53:17,063 - trainer - INFO - Epoch 46 completed at 2025-01-21 11:53:17
2025-01-21 11:53:17,063 - trainer - INFO -     epoch          : 46
2025-01-21 11:53:17,063 - trainer - INFO -     elapsed time   : 3.953911542892456
2025-01-21 11:53:17,063 - trainer - INFO -     loss           : 27.963156509399415
2025-01-21 11:53:17,063 - trainer - INFO -     sim_loss       : 27.95329818725586
2025-01-21 11:53:17,063 - trainer - INFO -     gen_loss       : 0.00985832531005144
2025-01-21 11:53:17,063 - trainer - INFO -     val_loss       : 18.499168537557125
2025-01-21 11:53:17,063 - trainer - INFO -     val_sim_loss   : 18.479251861572266
2025-01-21 11:53:17,064 - trainer - INFO -     val_gen_loss   : 0.019916769117116928
2025-01-21 11:53:17,064 - trainer - INFO -     val_perplexity : -97.6274642944336
2025-01-21 11:53:17,064 - trainer - INFO -     val_embedding_sim: 0.08653715252876282
2025-01-21 11:53:17,064 - trainer - INFO - ================================================================================
2025-01-21 11:53:17,064 - trainer - INFO - Starting epoch 47 at 2025-01-21 11:53:17
2025-01-21 11:53:20,976 - trainer - INFO - Epoch 47 completed at 2025-01-21 11:53:20
2025-01-21 11:53:20,976 - trainer - INFO -     epoch          : 47
2025-01-21 11:53:20,976 - trainer - INFO -     elapsed time   : 3.9118664264678955
2025-01-21 11:53:20,976 - trainer - INFO -     loss           : 30.26607828140259
2025-01-21 11:53:20,976 - trainer - INFO -     sim_loss       : 30.257024621963502
2025-01-21 11:53:20,976 - trainer - INFO -     gen_loss       : 0.009053645143285393
2025-01-21 11:53:20,976 - trainer - INFO -     val_loss       : 10.762315448373556
2025-01-21 11:53:20,976 - trainer - INFO -     val_sim_loss   : 10.701005935668945
2025-01-21 11:53:20,976 - trainer - INFO -     val_gen_loss   : 0.06130998022854328
2025-01-21 11:53:20,976 - trainer - INFO -     val_perplexity : -97.39750671386719
2025-01-21 11:53:20,976 - trainer - INFO -     val_embedding_sim: 0.07428492605686188
2025-01-21 11:53:20,976 - trainer - INFO - ================================================================================
2025-01-21 11:53:20,976 - trainer - INFO - Starting epoch 48 at 2025-01-21 11:53:20
2025-01-21 11:53:24,868 - trainer - INFO - Epoch 48 completed at 2025-01-21 11:53:24
2025-01-21 11:53:24,869 - trainer - INFO -     epoch          : 48
2025-01-21 11:53:24,869 - trainer - INFO -     elapsed time   : 3.8920042514801025
2025-01-21 11:53:24,869 - trainer - INFO -     loss           : 27.32369809150696
2025-01-21 11:53:24,869 - trainer - INFO -     sim_loss       : 27.314593029022216
2025-01-21 11:53:24,869 - trainer - INFO -     gen_loss       : 0.00910515240393579
2025-01-21 11:53:24,869 - trainer - INFO -     val_loss       : 15.118005494470708
2025-01-21 11:53:24,869 - trainer - INFO -     val_sim_loss   : 15.100126266479492
2025-01-21 11:53:24,869 - trainer - INFO -     val_gen_loss   : 0.01787926524411887
2025-01-21 11:53:24,869 - trainer - INFO -     val_perplexity : -96.8548355102539
2025-01-21 11:53:24,869 - trainer - INFO -     val_embedding_sim: 0.07651431113481522
2025-01-21 11:53:24,869 - trainer - INFO - ================================================================================
2025-01-21 11:53:24,869 - trainer - INFO - Starting epoch 49 at 2025-01-21 11:53:24
2025-01-21 11:53:28,783 - trainer - INFO - Epoch 49 completed at 2025-01-21 11:53:28
2025-01-21 11:53:28,783 - trainer - INFO -     epoch          : 49
2025-01-21 11:53:28,783 - trainer - INFO -     elapsed time   : 3.9134764671325684
2025-01-21 11:53:28,783 - trainer - INFO -     loss           : 31.867244052886964
2025-01-21 11:53:28,783 - trainer - INFO -     sim_loss       : 31.858334732055663
2025-01-21 11:53:28,783 - trainer - INFO -     gen_loss       : 0.008909356035292148
2025-01-21 11:53:28,783 - trainer - INFO -     val_loss       : 14.454676871246193
2025-01-21 11:53:28,783 - trainer - INFO -     val_sim_loss   : 14.436752319335938
2025-01-21 11:53:28,783 - trainer - INFO -     val_gen_loss   : 0.017924130952451378
2025-01-21 11:53:28,783 - trainer - INFO -     val_perplexity : -96.93452453613281
2025-01-21 11:53:28,783 - trainer - INFO -     val_embedding_sim: 0.08205990493297577
2025-01-21 11:53:28,783 - trainer - INFO - ================================================================================
2025-01-21 11:53:28,783 - trainer - INFO - Starting epoch 50 at 2025-01-21 11:53:28
2025-01-21 11:53:32,674 - trainer - INFO - Epoch 50 completed at 2025-01-21 11:53:32
2025-01-21 11:53:32,674 - trainer - INFO -     epoch          : 50
2025-01-21 11:53:32,674 - trainer - INFO -     elapsed time   : 3.8906095027923584
2025-01-21 11:53:32,674 - trainer - INFO -     loss           : 29.15652723312378
2025-01-21 11:53:32,674 - trainer - INFO -     sim_loss       : 29.147779369354247
2025-01-21 11:53:32,674 - trainer - INFO -     gen_loss       : 0.008747894037514924
2025-01-21 11:53:32,674 - trainer - INFO -     val_loss       : 11.472297230240656
2025-01-21 11:53:32,674 - trainer - INFO -     val_sim_loss   : 11.454873085021973
2025-01-21 11:53:32,674 - trainer - INFO -     val_gen_loss   : 0.017423688870621845
2025-01-21 11:53:32,675 - trainer - INFO -     val_perplexity : -98.23210144042969
2025-01-21 11:53:32,675 - trainer - INFO -     val_embedding_sim: 0.04941945895552635
2025-01-21 11:53:37,960 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 11:53:43,233 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:53:43,233 - trainer - INFO - ================================================================================
2025-01-21 11:53:43,233 - trainer - INFO - Starting epoch 51 at 2025-01-21 11:53:43
2025-01-21 11:53:47,192 - trainer - INFO - Epoch 51 completed at 2025-01-21 11:53:47
2025-01-21 11:53:47,192 - trainer - INFO -     epoch          : 51
2025-01-21 11:53:47,192 - trainer - INFO -     elapsed time   : 3.9586076736450195
2025-01-21 11:53:47,192 - trainer - INFO -     loss           : 30.3489896774292
2025-01-21 11:53:47,192 - trainer - INFO -     sim_loss       : 30.340015029907228
2025-01-21 11:53:47,192 - trainer - INFO -     gen_loss       : 0.00897468444891274
2025-01-21 11:53:47,192 - trainer - INFO -     val_loss       : 16.42683448176831
2025-01-21 11:53:47,192 - trainer - INFO -     val_sim_loss   : 16.399837493896484
2025-01-21 11:53:47,192 - trainer - INFO -     val_gen_loss   : 0.026996507309377193
2025-01-21 11:53:47,192 - trainer - INFO -     val_perplexity : -96.92826843261719
2025-01-21 11:53:47,192 - trainer - INFO -     val_embedding_sim: 0.08207973837852478
2025-01-21 11:53:47,192 - trainer - INFO - ================================================================================
2025-01-21 11:53:47,192 - trainer - INFO - Starting epoch 52 at 2025-01-21 11:53:47
2025-01-21 11:53:51,097 - trainer - INFO - Epoch 52 completed at 2025-01-21 11:53:51
2025-01-21 11:53:51,097 - trainer - INFO -     epoch          : 52
2025-01-21 11:53:51,098 - trainer - INFO -     elapsed time   : 3.904672145843506
2025-01-21 11:53:51,098 - trainer - INFO -     loss           : 29.9003342628479
2025-01-21 11:53:51,098 - trainer - INFO -     sim_loss       : 29.891957473754882
2025-01-21 11:53:51,098 - trainer - INFO -     gen_loss       : 0.008376457635313273
2025-01-21 11:53:51,098 - trainer - INFO -     val_loss       : 16.414608296006918
2025-01-21 11:53:51,098 - trainer - INFO -     val_sim_loss   : 16.379894256591797
2025-01-21 11:53:51,098 - trainer - INFO -     val_gen_loss   : 0.03471328876912594
2025-01-21 11:53:51,098 - trainer - INFO -     val_perplexity : -96.65775299072266
2025-01-21 11:53:51,098 - trainer - INFO -     val_embedding_sim: 0.06843233108520508
2025-01-21 11:53:51,098 - trainer - INFO - ================================================================================
2025-01-21 11:53:51,098 - trainer - INFO - Starting epoch 53 at 2025-01-21 11:53:51
2025-01-21 11:53:54,994 - trainer - INFO - Epoch 53 completed at 2025-01-21 11:53:54
2025-01-21 11:53:54,994 - trainer - INFO -     epoch          : 53
2025-01-21 11:53:54,994 - trainer - INFO -     elapsed time   : 3.8961353302001953
2025-01-21 11:53:54,994 - trainer - INFO -     loss           : 32.31778497695923
2025-01-21 11:53:54,994 - trainer - INFO -     sim_loss       : 32.3095477104187
2025-01-21 11:53:54,995 - trainer - INFO -     gen_loss       : 0.008237113850191236
2025-01-21 11:53:54,995 - trainer - INFO -     val_loss       : 13.502086088061333
2025-01-21 11:53:54,995 - trainer - INFO -     val_sim_loss   : 13.413003921508789
2025-01-21 11:53:54,995 - trainer - INFO -     val_gen_loss   : 0.08908258844166994
2025-01-21 11:53:54,995 - trainer - INFO -     val_perplexity : -98.42794799804688
2025-01-21 11:53:54,995 - trainer - INFO -     val_embedding_sim: 0.08025024831295013
2025-01-21 11:53:54,995 - trainer - INFO - ================================================================================
2025-01-21 11:53:54,995 - trainer - INFO - Starting epoch 54 at 2025-01-21 11:53:54
2025-01-21 11:53:58,874 - trainer - INFO - Epoch 54 completed at 2025-01-21 11:53:58
2025-01-21 11:53:58,874 - trainer - INFO -     epoch          : 54
2025-01-21 11:53:58,874 - trainer - INFO -     elapsed time   : 3.878844976425171
2025-01-21 11:53:58,874 - trainer - INFO -     loss           : 26.118489265441895
2025-01-21 11:53:58,874 - trainer - INFO -     sim_loss       : 26.110236740112306
2025-01-21 11:53:58,874 - trainer - INFO -     gen_loss       : 0.008252619532868266
2025-01-21 11:53:58,874 - trainer - INFO -     val_loss       : 9.618736855685711
2025-01-21 11:53:58,874 - trainer - INFO -     val_sim_loss   : 9.591964721679688
2025-01-21 11:53:58,874 - trainer - INFO -     val_gen_loss   : 0.02677181363105774
2025-01-21 11:53:58,874 - trainer - INFO -     val_perplexity : -97.07592010498047
2025-01-21 11:53:58,874 - trainer - INFO -     val_embedding_sim: 0.0747486874461174
2025-01-21 11:53:58,874 - trainer - INFO - ================================================================================
2025-01-21 11:53:58,874 - trainer - INFO - Starting epoch 55 at 2025-01-21 11:53:58
2025-01-21 11:54:02,789 - trainer - INFO - Epoch 55 completed at 2025-01-21 11:54:02
2025-01-21 11:54:02,789 - trainer - INFO -     epoch          : 55
2025-01-21 11:54:02,790 - trainer - INFO -     elapsed time   : 3.914808750152588
2025-01-21 11:54:02,790 - trainer - INFO -     loss           : 31.85823745727539
2025-01-21 11:54:02,790 - trainer - INFO -     sim_loss       : 31.84910945892334
2025-01-21 11:54:02,790 - trainer - INFO -     gen_loss       : 0.009128350252285599
2025-01-21 11:54:02,790 - trainer - INFO -     val_loss       : 25.01062996778637
2025-01-21 11:54:02,790 - trainer - INFO -     val_sim_loss   : 24.98314666748047
2025-01-21 11:54:02,790 - trainer - INFO -     val_gen_loss   : 0.027483071200549603
2025-01-21 11:54:02,790 - trainer - INFO -     val_perplexity : -96.73407745361328
2025-01-21 11:54:02,790 - trainer - INFO -     val_embedding_sim: 0.07279527187347412
2025-01-21 11:54:08,083 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch55.pth ...
2025-01-21 11:54:08,083 - trainer - INFO - ================================================================================
2025-01-21 11:54:08,083 - trainer - INFO - Starting epoch 56 at 2025-01-21 11:54:08
2025-01-21 11:54:12,012 - trainer - INFO - Epoch 56 completed at 2025-01-21 11:54:12
2025-01-21 11:54:12,012 - trainer - INFO -     epoch          : 56
2025-01-21 11:54:12,012 - trainer - INFO -     elapsed time   : 3.9282217025756836
2025-01-21 11:54:12,012 - trainer - INFO -     loss           : 26.877238273620605
2025-01-21 11:54:12,012 - trainer - INFO -     sim_loss       : 26.868187713623048
2025-01-21 11:54:12,012 - trainer - INFO -     gen_loss       : 0.009050215501338244
2025-01-21 11:54:12,012 - trainer - INFO -     val_loss       : 18.28651539608836
2025-01-21 11:54:12,012 - trainer - INFO -     val_sim_loss   : 18.23130989074707
2025-01-21 11:54:12,012 - trainer - INFO -     val_gen_loss   : 0.0552054550498724
2025-01-21 11:54:12,012 - trainer - INFO -     val_perplexity : -96.81558990478516
2025-01-21 11:54:12,012 - trainer - INFO -     val_embedding_sim: 0.07760320603847504
2025-01-21 11:54:12,012 - trainer - INFO - ================================================================================
2025-01-21 11:54:12,012 - trainer - INFO - Starting epoch 57 at 2025-01-21 11:54:12
2025-01-21 11:54:15,903 - trainer - INFO - Epoch 57 completed at 2025-01-21 11:54:15
2025-01-21 11:54:15,903 - trainer - INFO -     epoch          : 57
2025-01-21 11:54:15,903 - trainer - INFO -     elapsed time   : 3.890566825866699
2025-01-21 11:54:15,903 - trainer - INFO -     loss           : 31.07525873184204
2025-01-21 11:54:15,903 - trainer - INFO -     sim_loss       : 31.06683521270752
2025-01-21 11:54:15,903 - trainer - INFO -     gen_loss       : 0.008423247421160341
2025-01-21 11:54:15,903 - trainer - INFO -     val_loss       : 12.775156415445963
2025-01-21 11:54:15,903 - trainer - INFO -     val_sim_loss   : 12.758456230163574
2025-01-21 11:54:15,903 - trainer - INFO -     val_gen_loss   : 0.016700546635547653
2025-01-21 11:54:15,904 - trainer - INFO -     val_perplexity : -97.32709503173828
2025-01-21 11:54:15,904 - trainer - INFO -     val_embedding_sim: 0.07773232460021973
2025-01-21 11:54:15,904 - trainer - INFO - ================================================================================
2025-01-21 11:54:15,904 - trainer - INFO - Starting epoch 58 at 2025-01-21 11:54:15
2025-01-21 11:54:19,806 - trainer - INFO - Epoch 58 completed at 2025-01-21 11:54:19
2025-01-21 11:54:19,806 - trainer - INFO -     epoch          : 58
2025-01-21 11:54:19,806 - trainer - INFO -     elapsed time   : 3.9023706912994385
2025-01-21 11:54:19,806 - trainer - INFO -     loss           : 31.33300886154175
2025-01-21 11:54:19,806 - trainer - INFO -     sim_loss       : 31.32413215637207
2025-01-21 11:54:19,806 - trainer - INFO -     gen_loss       : 0.008876388054341077
2025-01-21 11:54:19,806 - trainer - INFO -     val_loss       : 20.48719285588595
2025-01-21 11:54:19,807 - trainer - INFO -     val_sim_loss   : 20.470890045166016
2025-01-21 11:54:19,807 - trainer - INFO -     val_gen_loss   : 0.01630345146986656
2025-01-21 11:54:19,807 - trainer - INFO -     val_perplexity : -97.1338119506836
2025-01-21 11:54:19,807 - trainer - INFO -     val_embedding_sim: 0.08008161932229996
2025-01-21 11:54:19,807 - trainer - INFO - ================================================================================
2025-01-21 11:54:19,807 - trainer - INFO - Starting epoch 59 at 2025-01-21 11:54:19
2025-01-21 11:54:23,690 - trainer - INFO - Epoch 59 completed at 2025-01-21 11:54:23
2025-01-21 11:54:23,690 - trainer - INFO -     epoch          : 59
2025-01-21 11:54:23,690 - trainer - INFO -     elapsed time   : 3.882612705230713
2025-01-21 11:54:23,690 - trainer - INFO -     loss           : 36.29386863708496
2025-01-21 11:54:23,690 - trainer - INFO -     sim_loss       : 36.2761947631836
2025-01-21 11:54:23,690 - trainer - INFO -     gen_loss       : 0.017674107942730187
2025-01-21 11:54:23,690 - trainer - INFO -     val_loss       : 16.79463137651328
2025-01-21 11:54:23,690 - trainer - INFO -     val_sim_loss   : 16.75943374633789
2025-01-21 11:54:23,690 - trainer - INFO -     val_gen_loss   : 0.035198367782868445
2025-01-21 11:54:23,690 - trainer - INFO -     val_perplexity : -91.66515350341797
2025-01-21 11:54:23,690 - trainer - INFO -     val_embedding_sim: 0.06472600251436234
2025-01-21 11:54:23,690 - trainer - INFO - ================================================================================
2025-01-21 11:54:23,690 - trainer - INFO - Starting epoch 60 at 2025-01-21 11:54:23
2025-01-21 11:54:27,582 - trainer - INFO - Epoch 60 completed at 2025-01-21 11:54:27
2025-01-21 11:54:27,582 - trainer - INFO -     epoch          : 60
2025-01-21 11:54:27,582 - trainer - INFO -     elapsed time   : 3.891752243041992
2025-01-21 11:54:27,582 - trainer - INFO -     loss           : 30.083482265472412
2025-01-21 11:54:27,582 - trainer - INFO -     sim_loss       : 30.066366481781007
2025-01-21 11:54:27,582 - trainer - INFO -     gen_loss       : 0.017115797847509384
2025-01-21 11:54:27,582 - trainer - INFO -     val_loss       : 9.962255293445196
2025-01-21 11:54:27,582 - trainer - INFO -     val_sim_loss   : 9.942180633544922
2025-01-21 11:54:27,582 - trainer - INFO -     val_gen_loss   : 0.020075028704013675
2025-01-21 11:54:27,582 - trainer - INFO -     val_perplexity : -96.91425323486328
2025-01-21 11:54:27,583 - trainer - INFO -     val_embedding_sim: 0.07975725829601288
2025-01-21 11:54:32,862 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch60.pth ...
2025-01-21 11:54:32,862 - trainer - INFO - ================================================================================
2025-01-21 11:54:32,862 - trainer - INFO - Starting epoch 61 at 2025-01-21 11:54:32
2025-01-21 11:54:36,831 - trainer - INFO - Epoch 61 completed at 2025-01-21 11:54:36
2025-01-21 11:54:36,831 - trainer - INFO -     epoch          : 61
2025-01-21 11:54:36,831 - trainer - INFO -     elapsed time   : 3.96886944770813
2025-01-21 11:54:36,831 - trainer - INFO -     loss           : 29.073707580566406
2025-01-21 11:54:36,831 - trainer - INFO -     sim_loss       : 29.06476469039917
2025-01-21 11:54:36,831 - trainer - INFO -     gen_loss       : 0.008942991541698576
2025-01-21 11:54:36,831 - trainer - INFO -     val_loss       : 16.74105130729731
2025-01-21 11:54:36,831 - trainer - INFO -     val_sim_loss   : 16.72237777709961
2025-01-21 11:54:36,831 - trainer - INFO -     val_gen_loss   : 0.018673949292860925
2025-01-21 11:54:36,831 - trainer - INFO -     val_perplexity : -96.57526397705078
2025-01-21 11:54:36,832 - trainer - INFO -     val_embedding_sim: 0.0732831209897995
2025-01-21 11:54:36,832 - trainer - INFO - ================================================================================
2025-01-21 11:54:36,832 - trainer - INFO - Starting epoch 62 at 2025-01-21 11:54:36
2025-01-21 11:54:40,732 - trainer - INFO - Epoch 62 completed at 2025-01-21 11:54:40
2025-01-21 11:54:40,732 - trainer - INFO -     epoch          : 62
2025-01-21 11:54:40,732 - trainer - INFO -     elapsed time   : 3.8998117446899414
2025-01-21 11:54:40,732 - trainer - INFO -     loss           : 26.139719581604005
2025-01-21 11:54:40,732 - trainer - INFO -     sim_loss       : 26.13196496963501
2025-01-21 11:54:40,732 - trainer - INFO -     gen_loss       : 0.007754769036546349
2025-01-21 11:54:40,732 - trainer - INFO -     val_loss       : 17.122685361653566
2025-01-21 11:54:40,732 - trainer - INFO -     val_sim_loss   : 17.049924850463867
2025-01-21 11:54:40,732 - trainer - INFO -     val_gen_loss   : 0.07276124227792025
2025-01-21 11:54:40,732 - trainer - INFO -     val_perplexity : -98.54287719726562
2025-01-21 11:54:40,732 - trainer - INFO -     val_embedding_sim: 0.08298732340335846
2025-01-21 11:54:40,732 - trainer - INFO - ================================================================================
2025-01-21 11:54:40,732 - trainer - INFO - Starting epoch 63 at 2025-01-21 11:54:40
2025-01-21 11:54:44,625 - trainer - INFO - Epoch 63 completed at 2025-01-21 11:54:44
2025-01-21 11:54:44,626 - trainer - INFO -     epoch          : 63
2025-01-21 11:54:44,626 - trainer - INFO -     elapsed time   : 3.893066883087158
2025-01-21 11:54:44,626 - trainer - INFO -     loss           : 33.226307487487794
2025-01-21 11:54:44,626 - trainer - INFO -     sim_loss       : 33.219168519973756
2025-01-21 11:54:44,626 - trainer - INFO -     gen_loss       : 0.007139326957985759
2025-01-21 11:54:44,626 - trainer - INFO -     val_loss       : 20.807558295404306
2025-01-21 11:54:44,626 - trainer - INFO -     val_sim_loss   : 20.790937423706055
2025-01-21 11:54:44,626 - trainer - INFO -     val_gen_loss   : 0.016621354123344645
2025-01-21 11:54:44,626 - trainer - INFO -     val_perplexity : -97.31587982177734
2025-01-21 11:54:44,626 - trainer - INFO -     val_embedding_sim: 0.07892406731843948
2025-01-21 11:54:44,626 - trainer - INFO - ================================================================================
2025-01-21 11:54:44,626 - trainer - INFO - Starting epoch 64 at 2025-01-21 11:54:44
2025-01-21 11:54:48,524 - trainer - INFO - Epoch 64 completed at 2025-01-21 11:54:48
2025-01-21 11:54:48,524 - trainer - INFO -     epoch          : 64
2025-01-21 11:54:48,524 - trainer - INFO -     elapsed time   : 3.898038864135742
2025-01-21 11:54:48,524 - trainer - INFO -     loss           : 27.550445365905762
2025-01-21 11:54:48,524 - trainer - INFO -     sim_loss       : 27.543497943878172
2025-01-21 11:54:48,524 - trainer - INFO -     gen_loss       : 0.006946759857237339
2025-01-21 11:54:48,524 - trainer - INFO -     val_loss       : 13.32403878873447
2025-01-21 11:54:48,525 - trainer - INFO -     val_sim_loss   : 13.307512283325195
2025-01-21 11:54:48,525 - trainer - INFO -     val_gen_loss   : 0.016526492370758206
2025-01-21 11:54:48,525 - trainer - INFO -     val_perplexity : -97.39246368408203
2025-01-21 11:54:48,525 - trainer - INFO -     val_embedding_sim: 0.07348346710205078
2025-01-21 11:54:48,525 - trainer - INFO - ================================================================================
2025-01-21 11:54:48,525 - trainer - INFO - Starting epoch 65 at 2025-01-21 11:54:48
2025-01-21 11:54:52,401 - trainer - INFO - Epoch 65 completed at 2025-01-21 11:54:52
2025-01-21 11:54:52,401 - trainer - INFO -     epoch          : 65
2025-01-21 11:54:52,401 - trainer - INFO -     elapsed time   : 3.8757741451263428
2025-01-21 11:54:52,401 - trainer - INFO -     loss           : 26.2968469619751
2025-01-21 11:54:52,401 - trainer - INFO -     sim_loss       : 26.290646743774413
2025-01-21 11:54:52,401 - trainer - INFO -     gen_loss       : 0.006200411124154925
2025-01-21 11:54:52,401 - trainer - INFO -     val_loss       : 19.583898248150945
2025-01-21 11:54:52,401 - trainer - INFO -     val_sim_loss   : 19.546680450439453
2025-01-21 11:54:52,401 - trainer - INFO -     val_gen_loss   : 0.03721818886697292
2025-01-21 11:54:52,401 - trainer - INFO -     val_perplexity : -99.64078521728516
2025-01-21 11:54:52,401 - trainer - INFO -     val_embedding_sim: 0.0637853592634201
2025-01-21 11:54:57,707 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch65.pth ...
2025-01-21 11:54:57,707 - trainer - INFO - ================================================================================
2025-01-21 11:54:57,707 - trainer - INFO - Starting epoch 66 at 2025-01-21 11:54:57
2025-01-21 11:55:01,793 - trainer - INFO - Epoch 66 completed at 2025-01-21 11:55:01
2025-01-21 11:55:01,793 - trainer - INFO -     epoch          : 66
2025-01-21 11:55:01,793 - trainer - INFO -     elapsed time   : 4.08557391166687
2025-01-21 11:55:01,793 - trainer - INFO -     loss           : 26.329309749603272
2025-01-21 11:55:01,793 - trainer - INFO -     sim_loss       : 26.323484182357788
2025-01-21 11:55:01,793 - trainer - INFO -     gen_loss       : 0.005825490271672606
2025-01-21 11:55:01,793 - trainer - INFO -     val_loss       : 29.193779199384153
2025-01-21 11:55:01,793 - trainer - INFO -     val_sim_loss   : 29.16728973388672
2025-01-21 11:55:01,793 - trainer - INFO -     val_gen_loss   : 0.026489345356822014
2025-01-21 11:55:01,793 - trainer - INFO -     val_perplexity : -98.48888397216797
2025-01-21 11:55:01,794 - trainer - INFO -     val_embedding_sim: 0.0788998007774353
2025-01-21 11:55:01,794 - trainer - INFO - ================================================================================
2025-01-21 11:55:01,794 - trainer - INFO - Starting epoch 67 at 2025-01-21 11:55:01
2025-01-21 11:55:05,684 - trainer - INFO - Epoch 67 completed at 2025-01-21 11:55:05
2025-01-21 11:55:05,684 - trainer - INFO -     epoch          : 67
2025-01-21 11:55:05,684 - trainer - INFO -     elapsed time   : 3.8898143768310547
2025-01-21 11:55:05,684 - trainer - INFO -     loss           : 31.062275886535645
2025-01-21 11:55:05,684 - trainer - INFO -     sim_loss       : 31.056505966186524
2025-01-21 11:55:05,684 - trainer - INFO -     gen_loss       : 0.005770064285025
2025-01-21 11:55:05,684 - trainer - INFO -     val_loss       : 20.43229456851259
2025-01-21 11:55:05,684 - trainer - INFO -     val_sim_loss   : 20.40991973876953
2025-01-21 11:55:05,684 - trainer - INFO -     val_gen_loss   : 0.022374846506863832
2025-01-21 11:55:05,684 - trainer - INFO -     val_perplexity : -98.7743148803711
2025-01-21 11:55:05,684 - trainer - INFO -     val_embedding_sim: 0.0485561341047287
2025-01-21 11:55:05,684 - trainer - INFO - ================================================================================
2025-01-21 11:55:05,684 - trainer - INFO - Starting epoch 68 at 2025-01-21 11:55:05
2025-01-21 11:55:09,581 - trainer - INFO - Epoch 68 completed at 2025-01-21 11:55:09
2025-01-21 11:55:09,581 - trainer - INFO -     epoch          : 68
2025-01-21 11:55:09,581 - trainer - INFO -     elapsed time   : 3.8965303897857666
2025-01-21 11:55:09,581 - trainer - INFO -     loss           : 33.40623960494995
2025-01-21 11:55:09,581 - trainer - INFO -     sim_loss       : 33.40050373077393
2025-01-21 11:55:09,581 - trainer - INFO -     gen_loss       : 0.005735903605818748
2025-01-21 11:55:09,581 - trainer - INFO -     val_loss       : 18.543320916593075
2025-01-21 11:55:09,581 - trainer - INFO -     val_sim_loss   : 18.450504302978516
2025-01-21 11:55:09,581 - trainer - INFO -     val_gen_loss   : 0.09281621035188437
2025-01-21 11:55:09,581 - trainer - INFO -     val_perplexity : -99.32418060302734
2025-01-21 11:55:09,581 - trainer - INFO -     val_embedding_sim: 0.09016657620668411
2025-01-21 11:55:09,581 - trainer - INFO - ================================================================================
2025-01-21 11:55:09,581 - trainer - INFO - Starting epoch 69 at 2025-01-21 11:55:09
2025-01-21 11:55:13,470 - trainer - INFO - Epoch 69 completed at 2025-01-21 11:55:13
2025-01-21 11:55:13,471 - trainer - INFO -     epoch          : 69
2025-01-21 11:55:13,471 - trainer - INFO -     elapsed time   : 3.888801097869873
2025-01-21 11:55:13,471 - trainer - INFO -     loss           : 30.71482410430908
2025-01-21 11:55:13,471 - trainer - INFO -     sim_loss       : 30.7093377828598
2025-01-21 11:55:13,471 - trainer - INFO -     gen_loss       : 0.005486330250278115
2025-01-21 11:55:13,471 - trainer - INFO -     val_loss       : 18.19931569136679
2025-01-21 11:55:13,471 - trainer - INFO -     val_sim_loss   : 18.160551071166992
2025-01-21 11:55:13,471 - trainer - INFO -     val_gen_loss   : 0.038765364326536655
2025-01-21 11:55:13,471 - trainer - INFO -     val_perplexity : -99.13573455810547
2025-01-21 11:55:13,471 - trainer - INFO -     val_embedding_sim: 0.07644347846508026
2025-01-21 11:55:13,471 - trainer - INFO - ================================================================================
2025-01-21 11:55:13,471 - trainer - INFO - Starting epoch 70 at 2025-01-21 11:55:13
2025-01-21 11:55:17,364 - trainer - INFO - Epoch 70 completed at 2025-01-21 11:55:17
2025-01-21 11:55:17,364 - trainer - INFO -     epoch          : 70
2025-01-21 11:55:17,364 - trainer - INFO -     elapsed time   : 3.8926634788513184
2025-01-21 11:55:17,364 - trainer - INFO -     loss           : 28.48235230445862
2025-01-21 11:55:17,364 - trainer - INFO -     sim_loss       : 28.476871490478516
2025-01-21 11:55:17,364 - trainer - INFO -     gen_loss       : 0.00548078422434628
2025-01-21 11:55:17,364 - trainer - INFO -     val_loss       : 22.312752957368502
2025-01-21 11:55:17,364 - trainer - INFO -     val_sim_loss   : 22.2972412109375
2025-01-21 11:55:17,364 - trainer - INFO -     val_gen_loss   : 0.01551082349033095
2025-01-21 11:55:17,364 - trainer - INFO -     val_perplexity : -99.87149810791016
2025-01-21 11:55:17,364 - trainer - INFO -     val_embedding_sim: 0.06822231411933899
2025-01-21 11:55:22,651 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch70.pth ...
2025-01-21 11:55:27,919 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:55:27,919 - trainer - INFO - ================================================================================
2025-01-21 11:55:27,919 - trainer - INFO - Starting epoch 71 at 2025-01-21 11:55:27
2025-01-21 11:55:31,865 - trainer - INFO - Epoch 71 completed at 2025-01-21 11:55:31
2025-01-21 11:55:31,865 - trainer - INFO -     epoch          : 71
2025-01-21 11:55:31,866 - trainer - INFO -     elapsed time   : 3.9457623958587646
2025-01-21 11:55:31,866 - trainer - INFO -     loss           : 30.047163486480713
2025-01-21 11:55:31,866 - trainer - INFO -     sim_loss       : 30.041805839538576
2025-01-21 11:55:31,866 - trainer - INFO -     gen_loss       : 0.005357508920133114
2025-01-21 11:55:31,866 - trainer - INFO -     val_loss       : 16.52009641987388
2025-01-21 11:55:31,866 - trainer - INFO -     val_sim_loss   : 16.50481414794922
2025-01-21 11:55:31,866 - trainer - INFO -     val_gen_loss   : 0.01528168239747174
2025-01-21 11:55:31,866 - trainer - INFO -     val_perplexity : -100.09325408935547
2025-01-21 11:55:31,866 - trainer - INFO -     val_embedding_sim: 0.07215818017721176
2025-01-21 11:55:31,866 - trainer - INFO - ================================================================================
2025-01-21 11:55:31,866 - trainer - INFO - Starting epoch 72 at 2025-01-21 11:55:31
2025-01-21 11:55:35,765 - trainer - INFO - Epoch 72 completed at 2025-01-21 11:55:35
2025-01-21 11:55:35,765 - trainer - INFO -     epoch          : 72
2025-01-21 11:55:35,765 - trainer - INFO -     elapsed time   : 3.8991787433624268
2025-01-21 11:55:35,765 - trainer - INFO -     loss           : 30.614873123168945
2025-01-21 11:55:35,765 - trainer - INFO -     sim_loss       : 30.609442234039307
2025-01-21 11:55:35,766 - trainer - INFO -     gen_loss       : 0.005431100213900209
2025-01-21 11:55:35,766 - trainer - INFO -     val_loss       : 13.100252347066998
2025-01-21 11:55:35,766 - trainer - INFO -     val_sim_loss   : 13.061885833740234
2025-01-21 11:55:35,766 - trainer - INFO -     val_gen_loss   : 0.0383663410320878
2025-01-21 11:55:35,766 - trainer - INFO -     val_perplexity : -99.49093627929688
2025-01-21 11:55:35,766 - trainer - INFO -     val_embedding_sim: 0.07879456877708435
2025-01-21 11:55:35,766 - trainer - INFO - ================================================================================
2025-01-21 11:55:35,766 - trainer - INFO - Starting epoch 73 at 2025-01-21 11:55:35
2025-01-21 11:55:39,658 - trainer - INFO - Epoch 73 completed at 2025-01-21 11:55:39
2025-01-21 11:55:39,659 - trainer - INFO -     epoch          : 73
2025-01-21 11:55:39,659 - trainer - INFO -     elapsed time   : 3.8925058841705322
2025-01-21 11:55:39,659 - trainer - INFO -     loss           : 29.61671085357666
2025-01-21 11:55:39,659 - trainer - INFO -     sim_loss       : 29.61141929626465
2025-01-21 11:55:39,659 - trainer - INFO -     gen_loss       : 0.005291146179661155
2025-01-21 11:55:39,659 - trainer - INFO -     val_loss       : 13.273455033486243
2025-01-21 11:55:39,659 - trainer - INFO -     val_sim_loss   : 13.25838851928711
2025-01-21 11:55:39,659 - trainer - INFO -     val_gen_loss   : 0.015066826192196459
2025-01-21 11:55:39,659 - trainer - INFO -     val_perplexity : -100.47855377197266
2025-01-21 11:55:39,659 - trainer - INFO -     val_embedding_sim: 0.07478009164333344
2025-01-21 11:55:39,659 - trainer - INFO - ================================================================================
2025-01-21 11:55:39,659 - trainer - INFO - Starting epoch 74 at 2025-01-21 11:55:39
2025-01-21 11:55:43,553 - trainer - INFO - Epoch 74 completed at 2025-01-21 11:55:43
2025-01-21 11:55:43,553 - trainer - INFO -     epoch          : 74
2025-01-21 11:55:43,553 - trainer - INFO -     elapsed time   : 3.8937630653381348
2025-01-21 11:55:43,553 - trainer - INFO -     loss           : 28.128499889373778
2025-01-21 11:55:43,553 - trainer - INFO -     sim_loss       : 28.123323249816895
2025-01-21 11:55:43,553 - trainer - INFO -     gen_loss       : 0.005176624143496155
2025-01-21 11:55:43,553 - trainer - INFO -     val_loss       : 9.624069617129862
2025-01-21 11:55:43,553 - trainer - INFO -     val_sim_loss   : 9.598031997680664
2025-01-21 11:55:43,553 - trainer - INFO -     val_gen_loss   : 0.026037595234811306
2025-01-21 11:55:43,553 - trainer - INFO -     val_perplexity : -99.3877182006836
2025-01-21 11:55:43,553 - trainer - INFO -     val_embedding_sim: 0.06528209149837494
2025-01-21 11:55:43,554 - trainer - INFO - ================================================================================
2025-01-21 11:55:43,554 - trainer - INFO - Starting epoch 75 at 2025-01-21 11:55:43
2025-01-21 11:55:47,449 - trainer - INFO - Epoch 75 completed at 2025-01-21 11:55:47
2025-01-21 11:55:47,449 - trainer - INFO -     epoch          : 75
2025-01-21 11:55:47,449 - trainer - INFO -     elapsed time   : 3.894845485687256
2025-01-21 11:55:47,449 - trainer - INFO -     loss           : 36.048431968688966
2025-01-21 11:55:47,449 - trainer - INFO -     sim_loss       : 36.043486785888675
2025-01-21 11:55:47,449 - trainer - INFO -     gen_loss       : 0.004945446108467877
2025-01-21 11:55:47,449 - trainer - INFO -     val_loss       : 22.147027048107702
2025-01-21 11:55:47,449 - trainer - INFO -     val_sim_loss   : 22.131717681884766
2025-01-21 11:55:47,449 - trainer - INFO -     val_gen_loss   : 0.015309506852645427
2025-01-21 11:55:47,449 - trainer - INFO -     val_perplexity : -98.86967468261719
2025-01-21 11:55:47,449 - trainer - INFO -     val_embedding_sim: 0.06389930844306946
2025-01-21 11:55:52,690 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch75.pth ...
2025-01-21 11:55:52,690 - trainer - INFO - ================================================================================
2025-01-21 11:55:52,690 - trainer - INFO - Starting epoch 76 at 2025-01-21 11:55:52
2025-01-21 11:55:56,648 - trainer - INFO - Epoch 76 completed at 2025-01-21 11:55:56
2025-01-21 11:55:56,648 - trainer - INFO -     epoch          : 76
2025-01-21 11:55:56,648 - trainer - INFO -     elapsed time   : 3.9570443630218506
2025-01-21 11:55:56,648 - trainer - INFO -     loss           : 30.593903923034667
2025-01-21 11:55:56,648 - trainer - INFO -     sim_loss       : 30.58898820877075
2025-01-21 11:55:56,648 - trainer - INFO -     gen_loss       : 0.004915618663653731
2025-01-21 11:55:56,648 - trainer - INFO -     val_loss       : 12.538069511589129
2025-01-21 11:55:56,648 - trainer - INFO -     val_sim_loss   : 12.522928237915039
2025-01-21 11:55:56,648 - trainer - INFO -     val_gen_loss   : 0.015141174022573978
2025-01-21 11:55:56,648 - trainer - INFO -     val_perplexity : -99.4205093383789
2025-01-21 11:55:56,648 - trainer - INFO -     val_embedding_sim: 0.08248312026262283
2025-01-21 11:55:56,648 - trainer - INFO - ================================================================================
2025-01-21 11:55:56,648 - trainer - INFO - Starting epoch 77 at 2025-01-21 11:55:56
2025-01-21 11:56:00,544 - trainer - INFO - Epoch 77 completed at 2025-01-21 11:56:00
2025-01-21 11:56:00,545 - trainer - INFO -     epoch          : 77
2025-01-21 11:56:00,545 - trainer - INFO -     elapsed time   : 3.896113157272339
2025-01-21 11:56:00,545 - trainer - INFO -     loss           : 30.447144794464112
2025-01-21 11:56:00,545 - trainer - INFO -     sim_loss       : 30.44235782623291
2025-01-21 11:56:00,545 - trainer - INFO -     gen_loss       : 0.004786384757608175
2025-01-21 11:56:00,545 - trainer - INFO -     val_loss       : 12.392625648528337
2025-01-21 11:56:00,545 - trainer - INFO -     val_sim_loss   : 12.348916053771973
2025-01-21 11:56:00,545 - trainer - INFO -     val_gen_loss   : 0.043709528632462025
2025-01-21 11:56:00,545 - trainer - INFO -     val_perplexity : -99.32551574707031
2025-01-21 11:56:00,545 - trainer - INFO -     val_embedding_sim: 0.05454942584037781
2025-01-21 11:56:00,545 - trainer - INFO - ================================================================================
2025-01-21 11:56:00,545 - trainer - INFO - Starting epoch 78 at 2025-01-21 11:56:00
2025-01-21 11:56:04,399 - trainer - INFO - Epoch 78 completed at 2025-01-21 11:56:04
2025-01-21 11:56:04,399 - trainer - INFO -     epoch          : 78
2025-01-21 11:56:04,399 - trainer - INFO -     elapsed time   : 3.853386878967285
2025-01-21 11:56:04,399 - trainer - INFO -     loss           : 28.373423385620118
2025-01-21 11:56:04,399 - trainer - INFO -     sim_loss       : 28.36870708465576
2025-01-21 11:56:04,399 - trainer - INFO -     gen_loss       : 0.004716042568907142
2025-01-21 11:56:04,399 - trainer - INFO -     val_loss       : 20.95112376753241
2025-01-21 11:56:04,399 - trainer - INFO -     val_sim_loss   : 20.923606872558594
2025-01-21 11:56:04,399 - trainer - INFO -     val_gen_loss   : 0.027516325004398823
2025-01-21 11:56:04,399 - trainer - INFO -     val_perplexity : -99.58145904541016
2025-01-21 11:56:04,399 - trainer - INFO -     val_embedding_sim: 0.08604145795106888
2025-01-21 11:56:04,399 - trainer - INFO - ================================================================================
2025-01-21 11:56:04,399 - trainer - INFO - Starting epoch 79 at 2025-01-21 11:56:04
2025-01-21 11:56:08,294 - trainer - INFO - Epoch 79 completed at 2025-01-21 11:56:08
2025-01-21 11:56:08,294 - trainer - INFO -     epoch          : 79
2025-01-21 11:56:08,294 - trainer - INFO -     elapsed time   : 3.8945908546447754
2025-01-21 11:56:08,294 - trainer - INFO -     loss           : 28.88063325881958
2025-01-21 11:56:08,294 - trainer - INFO -     sim_loss       : 28.87584071159363
2025-01-21 11:56:08,294 - trainer - INFO -     gen_loss       : 0.004792346828617155
2025-01-21 11:56:08,294 - trainer - INFO -     val_loss       : 18.96219014498638
2025-01-21 11:56:08,294 - trainer - INFO -     val_sim_loss   : 18.94721221923828
2025-01-21 11:56:08,294 - trainer - INFO -     val_gen_loss   : 0.014978394203353673
2025-01-21 11:56:08,294 - trainer - INFO -     val_perplexity : -99.69127655029297
2025-01-21 11:56:08,294 - trainer - INFO -     val_embedding_sim: 0.06988323479890823
2025-01-21 11:56:08,294 - trainer - INFO - ================================================================================
2025-01-21 11:56:08,294 - trainer - INFO - Starting epoch 80 at 2025-01-21 11:56:08
2025-01-21 11:56:12,193 - trainer - INFO - Epoch 80 completed at 2025-01-21 11:56:12
2025-01-21 11:56:12,193 - trainer - INFO -     epoch          : 80
2025-01-21 11:56:12,194 - trainer - INFO -     elapsed time   : 3.8987016677856445
2025-01-21 11:56:12,194 - trainer - INFO -     loss           : 28.999637413024903
2025-01-21 11:56:12,194 - trainer - INFO -     sim_loss       : 28.99506115913391
2025-01-21 11:56:12,194 - trainer - INFO -     gen_loss       : 0.00457630748860538
2025-01-21 11:56:12,194 - trainer - INFO -     val_loss       : 15.354024071304593
2025-01-21 11:56:12,194 - trainer - INFO -     val_sim_loss   : 15.33883285522461
2025-01-21 11:56:12,194 - trainer - INFO -     val_gen_loss   : 0.01519081654259935
2025-01-21 11:56:12,194 - trainer - INFO -     val_perplexity : -99.27310180664062
2025-01-21 11:56:12,194 - trainer - INFO -     val_embedding_sim: 0.04407228156924248
2025-01-21 11:56:17,445 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch80.pth ...
2025-01-21 11:56:17,445 - trainer - INFO - ================================================================================
2025-01-21 11:56:17,446 - trainer - INFO - Starting epoch 81 at 2025-01-21 11:56:17
2025-01-21 11:56:21,400 - trainer - INFO - Epoch 81 completed at 2025-01-21 11:56:21
2025-01-21 11:56:21,400 - trainer - INFO -     epoch          : 81
2025-01-21 11:56:21,401 - trainer - INFO -     elapsed time   : 3.954596996307373
2025-01-21 11:56:21,401 - trainer - INFO -     loss           : 31.56046314239502
2025-01-21 11:56:21,401 - trainer - INFO -     sim_loss       : 31.555957221984862
2025-01-21 11:56:21,401 - trainer - INFO -     gen_loss       : 0.004505955195054412
2025-01-21 11:56:21,401 - trainer - INFO -     val_loss       : 14.073594942427007
2025-01-21 11:56:21,401 - trainer - INFO -     val_sim_loss   : 14.058708190917969
2025-01-21 11:56:21,401 - trainer - INFO -     val_gen_loss   : 0.01488711658748798
2025-01-21 11:56:21,401 - trainer - INFO -     val_perplexity : -100.68364715576172
2025-01-21 11:56:21,401 - trainer - INFO -     val_embedding_sim: 0.08188460767269135
2025-01-21 11:56:21,401 - trainer - INFO - ================================================================================
2025-01-21 11:56:21,401 - trainer - INFO - Starting epoch 82 at 2025-01-21 11:56:21
2025-01-21 11:56:25,309 - trainer - INFO - Epoch 82 completed at 2025-01-21 11:56:25
2025-01-21 11:56:25,309 - trainer - INFO -     epoch          : 82
2025-01-21 11:56:25,309 - trainer - INFO -     elapsed time   : 3.9080522060394287
2025-01-21 11:56:25,309 - trainer - INFO -     loss           : 29.64969437122345
2025-01-21 11:56:25,309 - trainer - INFO -     sim_loss       : 29.645043277740477
2025-01-21 11:56:25,309 - trainer - INFO -     gen_loss       : 0.004651166358962655
2025-01-21 11:56:25,309 - trainer - INFO -     val_loss       : 14.467599676921964
2025-01-21 11:56:25,309 - trainer - INFO -     val_sim_loss   : 14.432644844055176
2025-01-21 11:56:25,309 - trainer - INFO -     val_gen_loss   : 0.03495463449507952
2025-01-21 11:56:25,310 - trainer - INFO -     val_perplexity : -99.66482543945312
2025-01-21 11:56:25,310 - trainer - INFO -     val_embedding_sim: 0.07204962521791458
2025-01-21 11:56:25,310 - trainer - INFO - ================================================================================
2025-01-21 11:56:25,310 - trainer - INFO - Starting epoch 83 at 2025-01-21 11:56:25
2025-01-21 11:56:29,204 - trainer - INFO - Epoch 83 completed at 2025-01-21 11:56:29
2025-01-21 11:56:29,204 - trainer - INFO -     epoch          : 83
2025-01-21 11:56:29,204 - trainer - INFO -     elapsed time   : 3.893742084503174
2025-01-21 11:56:29,204 - trainer - INFO -     loss           : 28.762673830986024
2025-01-21 11:56:29,204 - trainer - INFO -     sim_loss       : 28.757976388931276
2025-01-21 11:56:29,204 - trainer - INFO -     gen_loss       : 0.0046971516450867055
2025-01-21 11:56:29,204 - trainer - INFO -     val_loss       : 19.86748532229103
2025-01-21 11:56:29,204 - trainer - INFO -     val_sim_loss   : 19.84958267211914
2025-01-21 11:56:29,204 - trainer - INFO -     val_gen_loss   : 0.017902720952406526
2025-01-21 11:56:29,204 - trainer - INFO -     val_perplexity : -100.98565673828125
2025-01-21 11:56:29,204 - trainer - INFO -     val_embedding_sim: 0.07760241627693176
2025-01-21 11:56:29,204 - trainer - INFO - ================================================================================
2025-01-21 11:56:29,204 - trainer - INFO - Starting epoch 84 at 2025-01-21 11:56:29
2025-01-21 11:56:33,048 - trainer - INFO - Epoch 84 completed at 2025-01-21 11:56:33
2025-01-21 11:56:33,048 - trainer - INFO -     epoch          : 84
2025-01-21 11:56:33,048 - trainer - INFO -     elapsed time   : 3.843507766723633
2025-01-21 11:56:33,048 - trainer - INFO -     loss           : 26.465289306640624
2025-01-21 11:56:33,048 - trainer - INFO -     sim_loss       : 26.460539722442626
2025-01-21 11:56:33,048 - trainer - INFO -     gen_loss       : 0.004749849415384233
2025-01-21 11:56:33,048 - trainer - INFO -     val_loss       : 25.125480605755
2025-01-21 11:56:33,048 - trainer - INFO -     val_sim_loss   : 25.108108520507812
2025-01-21 11:56:33,048 - trainer - INFO -     val_gen_loss   : 0.017372953239828348
2025-01-21 11:56:33,048 - trainer - INFO -     val_perplexity : -99.0363540649414
2025-01-21 11:56:33,048 - trainer - INFO -     val_embedding_sim: 0.08207200467586517
2025-01-21 11:56:33,048 - trainer - INFO - ================================================================================
2025-01-21 11:56:33,048 - trainer - INFO - Starting epoch 85 at 2025-01-21 11:56:33
2025-01-21 11:56:37,119 - trainer - INFO - Epoch 85 completed at 2025-01-21 11:56:37
2025-01-21 11:56:37,119 - trainer - INFO -     epoch          : 85
2025-01-21 11:56:37,119 - trainer - INFO -     elapsed time   : 4.069951772689819
2025-01-21 11:56:37,119 - trainer - INFO -     loss           : 32.53796262741089
2025-01-21 11:56:37,119 - trainer - INFO -     sim_loss       : 32.5337327003479
2025-01-21 11:56:37,119 - trainer - INFO -     gen_loss       : 0.004229511739686132
2025-01-21 11:56:37,119 - trainer - INFO -     val_loss       : 22.419026226969436
2025-01-21 11:56:37,119 - trainer - INFO -     val_sim_loss   : 22.401453018188477
2025-01-21 11:56:37,119 - trainer - INFO -     val_gen_loss   : 0.01757378620095551
2025-01-21 11:56:37,119 - trainer - INFO -     val_perplexity : -101.39568328857422
2025-01-21 11:56:37,119 - trainer - INFO -     val_embedding_sim: 0.07094278931617737
2025-01-21 11:56:42,433 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch85.pth ...
2025-01-21 11:56:42,434 - trainer - INFO - ================================================================================
2025-01-21 11:56:42,434 - trainer - INFO - Starting epoch 86 at 2025-01-21 11:56:42
2025-01-21 11:56:46,384 - trainer - INFO - Epoch 86 completed at 2025-01-21 11:56:46
2025-01-21 11:56:46,385 - trainer - INFO -     epoch          : 86
2025-01-21 11:56:46,385 - trainer - INFO -     elapsed time   : 3.9505250453948975
2025-01-21 11:56:46,385 - trainer - INFO -     loss           : 31.33023624420166
2025-01-21 11:56:46,385 - trainer - INFO -     sim_loss       : 31.326203918457033
2025-01-21 11:56:46,385 - trainer - INFO -     gen_loss       : 0.004032204276882112
2025-01-21 11:56:46,385 - trainer - INFO -     val_loss       : 19.16060178540647
2025-01-21 11:56:46,385 - trainer - INFO -     val_sim_loss   : 19.119253158569336
2025-01-21 11:56:46,385 - trainer - INFO -     val_gen_loss   : 0.04134858213365078
2025-01-21 11:56:46,385 - trainer - INFO -     val_perplexity : -99.97608184814453
2025-01-21 11:56:46,385 - trainer - INFO -     val_embedding_sim: 0.053180430084466934
2025-01-21 11:56:46,385 - trainer - INFO - ================================================================================
2025-01-21 11:56:46,385 - trainer - INFO - Starting epoch 87 at 2025-01-21 11:56:46
2025-01-21 11:56:50,283 - trainer - INFO - Epoch 87 completed at 2025-01-21 11:56:50
2025-01-21 11:56:50,283 - trainer - INFO -     epoch          : 87
2025-01-21 11:56:50,283 - trainer - INFO -     elapsed time   : 3.8979597091674805
2025-01-21 11:56:50,283 - trainer - INFO -     loss           : 29.601616501808167
2025-01-21 11:56:50,283 - trainer - INFO -     sim_loss       : 29.59755907058716
2025-01-21 11:56:50,283 - trainer - INFO -     gen_loss       : 0.00405721329152584
2025-01-21 11:56:50,284 - trainer - INFO -     val_loss       : 16.734974772916758
2025-01-21 11:56:50,284 - trainer - INFO -     val_sim_loss   : 16.720447540283203
2025-01-21 11:56:50,284 - trainer - INFO -     val_gen_loss   : 0.014528045678162016
2025-01-21 11:56:50,284 - trainer - INFO -     val_perplexity : -101.38993835449219
2025-01-21 11:56:50,284 - trainer - INFO -     val_embedding_sim: 0.059420522302389145
2025-01-21 11:56:50,284 - trainer - INFO - ================================================================================
2025-01-21 11:56:50,284 - trainer - INFO - Starting epoch 88 at 2025-01-21 11:56:50
2025-01-21 11:56:54,184 - trainer - INFO - Epoch 88 completed at 2025-01-21 11:56:54
2025-01-21 11:56:54,184 - trainer - INFO -     epoch          : 88
2025-01-21 11:56:54,184 - trainer - INFO -     elapsed time   : 3.8998658657073975
2025-01-21 11:56:54,184 - trainer - INFO -     loss           : 33.230179405212404
2025-01-21 11:56:54,184 - trainer - INFO -     sim_loss       : 33.22562084197998
2025-01-21 11:56:54,184 - trainer - INFO -     gen_loss       : 0.004558558436110615
2025-01-21 11:56:54,184 - trainer - INFO -     val_loss       : 16.842401331668952
2025-01-21 11:56:54,184 - trainer - INFO -     val_sim_loss   : 16.82585906982422
2025-01-21 11:56:54,184 - trainer - INFO -     val_gen_loss   : 0.016541347285965458
2025-01-21 11:56:54,184 - trainer - INFO -     val_perplexity : -98.83623504638672
2025-01-21 11:56:54,184 - trainer - INFO -     val_embedding_sim: 0.08317628502845764
2025-01-21 11:56:54,184 - trainer - INFO - ================================================================================
2025-01-21 11:56:54,184 - trainer - INFO - Starting epoch 89 at 2025-01-21 11:56:54
2025-01-21 11:56:58,082 - trainer - INFO - Epoch 89 completed at 2025-01-21 11:56:58
2025-01-21 11:56:58,082 - trainer - INFO -     epoch          : 89
2025-01-21 11:56:58,082 - trainer - INFO -     elapsed time   : 3.8976891040802
2025-01-21 11:56:58,082 - trainer - INFO -     loss           : 27.599650859832764
2025-01-21 11:56:58,082 - trainer - INFO -     sim_loss       : 27.594974327087403
2025-01-21 11:56:58,082 - trainer - INFO -     gen_loss       : 0.0046767901163548235
2025-01-21 11:56:58,083 - trainer - INFO -     val_loss       : 22.553696967690485
2025-01-21 11:56:58,083 - trainer - INFO -     val_sim_loss   : 22.537832260131836
2025-01-21 11:56:58,083 - trainer - INFO -     val_gen_loss   : 0.015864924556808546
2025-01-21 11:56:58,083 - trainer - INFO -     val_perplexity : -100.62272644042969
2025-01-21 11:56:58,083 - trainer - INFO -     val_embedding_sim: 0.07631796598434448
2025-01-21 11:56:58,083 - trainer - INFO - ================================================================================
2025-01-21 11:56:58,083 - trainer - INFO - Starting epoch 90 at 2025-01-21 11:56:58
2025-01-21 11:57:01,972 - trainer - INFO - Epoch 90 completed at 2025-01-21 11:57:01
2025-01-21 11:57:01,972 - trainer - INFO -     epoch          : 90
2025-01-21 11:57:01,972 - trainer - INFO -     elapsed time   : 3.889204502105713
2025-01-21 11:57:01,972 - trainer - INFO -     loss           : 29.14898338317871
2025-01-21 11:57:01,972 - trainer - INFO -     sim_loss       : 29.144661521911623
2025-01-21 11:57:01,972 - trainer - INFO -     gen_loss       : 0.004321899847127497
2025-01-21 11:57:01,972 - trainer - INFO -     val_loss       : 13.474524972814834
2025-01-21 11:57:01,973 - trainer - INFO -     val_sim_loss   : 13.459478378295898
2025-01-21 11:57:01,973 - trainer - INFO -     val_gen_loss   : 0.015046984743094072
2025-01-21 11:57:01,973 - trainer - INFO -     val_perplexity : -100.82109832763672
2025-01-21 11:57:01,973 - trainer - INFO -     val_embedding_sim: 0.061577022075653076
2025-01-21 11:57:07,266 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch90.pth ...
2025-01-21 11:57:07,266 - trainer - INFO - ================================================================================
2025-01-21 11:57:07,266 - trainer - INFO - Starting epoch 91 at 2025-01-21 11:57:07
2025-01-21 11:57:11,221 - trainer - INFO - Epoch 91 completed at 2025-01-21 11:57:11
2025-01-21 11:57:11,221 - trainer - INFO -     epoch          : 91
2025-01-21 11:57:11,222 - trainer - INFO -     elapsed time   : 3.955132246017456
2025-01-21 11:57:11,222 - trainer - INFO -     loss           : 27.197546195983886
2025-01-21 11:57:11,222 - trainer - INFO -     sim_loss       : 27.1938072681427
2025-01-21 11:57:11,222 - trainer - INFO -     gen_loss       : 0.0037388592259958386
2025-01-21 11:57:11,222 - trainer - INFO -     val_loss       : 17.499240921606543
2025-01-21 11:57:11,222 - trainer - INFO -     val_sim_loss   : 17.48462677001953
2025-01-21 11:57:11,222 - trainer - INFO -     val_gen_loss   : 0.014614699204685166
2025-01-21 11:57:11,222 - trainer - INFO -     val_perplexity : -101.07683563232422
2025-01-21 11:57:11,222 - trainer - INFO -     val_embedding_sim: 0.08532288670539856
2025-01-21 11:57:11,222 - trainer - INFO - ================================================================================
2025-01-21 11:57:11,222 - trainer - INFO - Starting epoch 92 at 2025-01-21 11:57:11
2025-01-21 11:57:15,134 - trainer - INFO - Epoch 92 completed at 2025-01-21 11:57:15
2025-01-21 11:57:15,135 - trainer - INFO -     epoch          : 92
2025-01-21 11:57:15,135 - trainer - INFO -     elapsed time   : 3.912412643432617
2025-01-21 11:57:15,135 - trainer - INFO -     loss           : 29.22322015762329
2025-01-21 11:57:15,135 - trainer - INFO -     sim_loss       : 29.219418144226076
2025-01-21 11:57:15,135 - trainer - INFO -     gen_loss       : 0.0038019486470147966
2025-01-21 11:57:15,135 - trainer - INFO -     val_loss       : 21.805637359808316
2025-01-21 11:57:15,135 - trainer - INFO -     val_sim_loss   : 21.79139518737793
2025-01-21 11:57:15,135 - trainer - INFO -     val_gen_loss   : 0.01424132772081066
2025-01-21 11:57:15,135 - trainer - INFO -     val_perplexity : -101.71099090576172
2025-01-21 11:57:15,135 - trainer - INFO -     val_embedding_sim: 0.08775878697633743
2025-01-21 11:57:15,135 - trainer - INFO - ================================================================================
2025-01-21 11:57:15,135 - trainer - INFO - Starting epoch 93 at 2025-01-21 11:57:15
2025-01-21 11:57:19,030 - trainer - INFO - Epoch 93 completed at 2025-01-21 11:57:19
2025-01-21 11:57:19,031 - trainer - INFO -     epoch          : 93
2025-01-21 11:57:19,031 - trainer - INFO -     elapsed time   : 3.8951454162597656
2025-01-21 11:57:19,031 - trainer - INFO -     loss           : 27.26576805114746
2025-01-21 11:57:19,031 - trainer - INFO -     sim_loss       : 27.262022829055788
2025-01-21 11:57:19,031 - trainer - INFO -     gen_loss       : 0.0037453413009643556
2025-01-21 11:57:19,031 - trainer - INFO -     val_loss       : 14.470826614648104
2025-01-21 11:57:19,031 - trainer - INFO -     val_sim_loss   : 14.400784492492676
2025-01-21 11:57:19,031 - trainer - INFO -     val_gen_loss   : 0.0700420206412673
2025-01-21 11:57:19,031 - trainer - INFO -     val_perplexity : -101.96958923339844
2025-01-21 11:57:19,031 - trainer - INFO -     val_embedding_sim: 0.060271382331848145
2025-01-21 11:57:19,031 - trainer - INFO - ================================================================================
2025-01-21 11:57:19,031 - trainer - INFO - Starting epoch 94 at 2025-01-21 11:57:19
2025-01-21 11:57:22,930 - trainer - INFO - Epoch 94 completed at 2025-01-21 11:57:22
2025-01-21 11:57:22,930 - trainer - INFO -     epoch          : 94
2025-01-21 11:57:22,930 - trainer - INFO -     elapsed time   : 3.8990397453308105
2025-01-21 11:57:22,930 - trainer - INFO -     loss           : 32.72031242847443
2025-01-21 11:57:22,930 - trainer - INFO -     sim_loss       : 32.71674137115478
2025-01-21 11:57:22,930 - trainer - INFO -     gen_loss       : 0.0035710041178390385
2025-01-21 11:57:22,930 - trainer - INFO -     val_loss       : 15.262705471366644
2025-01-21 11:57:22,930 - trainer - INFO -     val_sim_loss   : 15.236576080322266
2025-01-21 11:57:22,931 - trainer - INFO -     val_gen_loss   : 0.02612939104437828
2025-01-21 11:57:22,931 - trainer - INFO -     val_perplexity : -100.86279296875
2025-01-21 11:57:22,931 - trainer - INFO -     val_embedding_sim: 0.07926639169454575
2025-01-21 11:57:22,931 - trainer - INFO - ================================================================================
2025-01-21 11:57:22,931 - trainer - INFO - Starting epoch 95 at 2025-01-21 11:57:22
2025-01-21 11:57:26,835 - trainer - INFO - Epoch 95 completed at 2025-01-21 11:57:26
2025-01-21 11:57:26,835 - trainer - INFO -     epoch          : 95
2025-01-21 11:57:26,835 - trainer - INFO -     elapsed time   : 3.9037017822265625
2025-01-21 11:57:26,835 - trainer - INFO -     loss           : 28.810173654556273
2025-01-21 11:57:26,835 - trainer - INFO -     sim_loss       : 28.8063494682312
2025-01-21 11:57:26,835 - trainer - INFO -     gen_loss       : 0.0038243916817009447
2025-01-21 11:57:26,835 - trainer - INFO -     val_loss       : 17.13110239058733
2025-01-21 11:57:26,835 - trainer - INFO -     val_sim_loss   : 17.035255432128906
2025-01-21 11:57:26,835 - trainer - INFO -     val_gen_loss   : 0.09584789257496595
2025-01-21 11:57:26,835 - trainer - INFO -     val_perplexity : -101.34757995605469
2025-01-21 11:57:26,835 - trainer - INFO -     val_embedding_sim: 0.05900600552558899
2025-01-21 11:57:32,147 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch95.pth ...
2025-01-21 11:57:32,147 - trainer - INFO - ================================================================================
2025-01-21 11:57:32,147 - trainer - INFO - Starting epoch 96 at 2025-01-21 11:57:32
2025-01-21 11:57:36,118 - trainer - INFO - Epoch 96 completed at 2025-01-21 11:57:36
2025-01-21 11:57:36,118 - trainer - INFO -     epoch          : 96
2025-01-21 11:57:36,118 - trainer - INFO -     elapsed time   : 3.9707560539245605
2025-01-21 11:57:36,118 - trainer - INFO -     loss           : 28.954691791534422
2025-01-21 11:57:36,119 - trainer - INFO -     sim_loss       : 28.951195192337035
2025-01-21 11:57:36,119 - trainer - INFO -     gen_loss       : 0.0034965533996000886
2025-01-21 11:57:36,119 - trainer - INFO -     val_loss       : 22.808905887504807
2025-01-21 11:57:36,119 - trainer - INFO -     val_sim_loss   : 22.79509735107422
2025-01-21 11:57:36,119 - trainer - INFO -     val_gen_loss   : 0.013809273106744513
2025-01-21 11:57:36,119 - trainer - INFO -     val_perplexity : -101.61658477783203
2025-01-21 11:57:36,119 - trainer - INFO -     val_embedding_sim: 0.06283999234437943
2025-01-21 11:57:36,119 - trainer - INFO - ================================================================================
2025-01-21 11:57:36,119 - trainer - INFO - Starting epoch 97 at 2025-01-21 11:57:36
2025-01-21 11:57:40,020 - trainer - INFO - Epoch 97 completed at 2025-01-21 11:57:40
2025-01-21 11:57:40,020 - trainer - INFO -     epoch          : 97
2025-01-21 11:57:40,020 - trainer - INFO -     elapsed time   : 3.9009482860565186
2025-01-21 11:57:40,020 - trainer - INFO -     loss           : 34.61363220214844
2025-01-21 11:57:40,020 - trainer - INFO -     sim_loss       : 34.61014537811279
2025-01-21 11:57:40,020 - trainer - INFO -     gen_loss       : 0.0034868867602199315
2025-01-21 11:57:40,020 - trainer - INFO -     val_loss       : 17.169834901142167
2025-01-21 11:57:40,020 - trainer - INFO -     val_sim_loss   : 17.155914306640625
2025-01-21 11:57:40,020 - trainer - INFO -     val_gen_loss   : 0.013919758173869923
2025-01-21 11:57:40,020 - trainer - INFO -     val_perplexity : -102.26441955566406
2025-01-21 11:57:40,020 - trainer - INFO -     val_embedding_sim: 0.0926923006772995
2025-01-21 11:57:40,020 - trainer - INFO - ================================================================================
2025-01-21 11:57:40,020 - trainer - INFO - Starting epoch 98 at 2025-01-21 11:57:40
2025-01-21 11:57:43,916 - trainer - INFO - Epoch 98 completed at 2025-01-21 11:57:43
2025-01-21 11:57:43,916 - trainer - INFO -     epoch          : 98
2025-01-21 11:57:43,917 - trainer - INFO -     elapsed time   : 3.8956806659698486
2025-01-21 11:57:43,917 - trainer - INFO -     loss           : 30.10832223892212
2025-01-21 11:57:43,917 - trainer - INFO -     sim_loss       : 30.104819774627686
2025-01-21 11:57:43,917 - trainer - INFO -     gen_loss       : 0.0035023795906454326
2025-01-21 11:57:43,917 - trainer - INFO -     val_loss       : 16.44295412977226
2025-01-21 11:57:43,917 - trainer - INFO -     val_sim_loss   : 16.426551818847656
2025-01-21 11:57:43,917 - trainer - INFO -     val_gen_loss   : 0.01640205760486424
2025-01-21 11:57:43,917 - trainer - INFO -     val_perplexity : -100.26681518554688
2025-01-21 11:57:43,917 - trainer - INFO -     val_embedding_sim: 0.06201648712158203
2025-01-21 11:57:43,917 - trainer - INFO - ================================================================================
2025-01-21 11:57:43,917 - trainer - INFO - Starting epoch 99 at 2025-01-21 11:57:43
2025-01-21 11:57:47,775 - trainer - INFO - Epoch 99 completed at 2025-01-21 11:57:47
2025-01-21 11:57:47,776 - trainer - INFO -     epoch          : 99
2025-01-21 11:57:47,776 - trainer - INFO -     elapsed time   : 3.8583052158355713
2025-01-21 11:57:47,776 - trainer - INFO -     loss           : 30.901832580566406
2025-01-21 11:57:47,776 - trainer - INFO -     sim_loss       : 30.89858474731445
2025-01-21 11:57:47,776 - trainer - INFO -     gen_loss       : 0.003248248831368983
2025-01-21 11:57:47,776 - trainer - INFO -     val_loss       : 17.95648088399321
2025-01-21 11:57:47,776 - trainer - INFO -     val_sim_loss   : 17.937236785888672
2025-01-21 11:57:47,776 - trainer - INFO -     val_gen_loss   : 0.019245043396949768
2025-01-21 11:57:47,776 - trainer - INFO -     val_perplexity : -101.04077911376953
2025-01-21 11:57:47,776 - trainer - INFO -     val_embedding_sim: 0.11518369615077972
2025-01-21 11:57:47,776 - trainer - INFO - ================================================================================
2025-01-21 11:57:47,776 - trainer - INFO - Starting epoch 100 at 2025-01-21 11:57:47
2025-01-21 11:57:51,674 - trainer - INFO - Epoch 100 completed at 2025-01-21 11:57:51
2025-01-21 11:57:51,674 - trainer - INFO -     epoch          : 100
2025-01-21 11:57:51,674 - trainer - INFO -     elapsed time   : 3.8981032371520996
2025-01-21 11:57:51,674 - trainer - INFO -     loss           : 34.256461238861085
2025-01-21 11:57:51,675 - trainer - INFO -     sim_loss       : 34.25314259529114
2025-01-21 11:57:51,675 - trainer - INFO -     gen_loss       : 0.0033184906002134084
2025-01-21 11:57:51,675 - trainer - INFO -     val_loss       : 20.836234099406283
2025-01-21 11:57:51,675 - trainer - INFO -     val_sim_loss   : 20.82260513305664
2025-01-21 11:57:51,675 - trainer - INFO -     val_gen_loss   : 0.013629000808577985
2025-01-21 11:57:51,675 - trainer - INFO -     val_perplexity : -101.890380859375
2025-01-21 11:57:51,675 - trainer - INFO -     val_embedding_sim: 0.07759417593479156
2025-01-21 11:57:56,983 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch100.pth ...
2025-01-21 11:58:02,278 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:58:02,278 - trainer - INFO - ================================================================================
2025-01-21 11:58:02,278 - trainer - INFO - Starting epoch 101 at 2025-01-21 11:58:02
2025-01-21 11:58:06,238 - trainer - INFO - Epoch 101 completed at 2025-01-21 11:58:06
2025-01-21 11:58:06,238 - trainer - INFO -     epoch          : 101
2025-01-21 11:58:06,238 - trainer - INFO -     elapsed time   : 3.9594411849975586
2025-01-21 11:58:06,238 - trainer - INFO -     loss           : 27.33246965408325
2025-01-21 11:58:06,238 - trainer - INFO -     sim_loss       : 27.32898941040039
2025-01-21 11:58:06,238 - trainer - INFO -     gen_loss       : 0.0034798675449565055
2025-01-21 11:58:06,238 - trainer - INFO -     val_loss       : 25.89591790283157
2025-01-21 11:58:06,238 - trainer - INFO -     val_sim_loss   : 25.882137298583984
2025-01-21 11:58:06,238 - trainer - INFO -     val_gen_loss   : 0.013781140689388849
2025-01-21 11:58:06,238 - trainer - INFO -     val_perplexity : -102.19259643554688
2025-01-21 11:58:06,238 - trainer - INFO -     val_embedding_sim: 0.04776162654161453
2025-01-21 11:58:06,238 - trainer - INFO - ================================================================================
2025-01-21 11:58:06,238 - trainer - INFO - Starting epoch 102 at 2025-01-21 11:58:06
2025-01-21 11:58:10,134 - trainer - INFO - Epoch 102 completed at 2025-01-21 11:58:10
2025-01-21 11:58:10,134 - trainer - INFO -     epoch          : 102
2025-01-21 11:58:10,134 - trainer - INFO -     elapsed time   : 3.8957736492156982
2025-01-21 11:58:10,134 - trainer - INFO -     loss           : 27.88441228866577
2025-01-21 11:58:10,134 - trainer - INFO -     sim_loss       : 27.88114728927612
2025-01-21 11:58:10,134 - trainer - INFO -     gen_loss       : 0.003265193710103631
2025-01-21 11:58:10,135 - trainer - INFO -     val_loss       : 22.45573430508375
2025-01-21 11:58:10,135 - trainer - INFO -     val_sim_loss   : 22.373611450195312
2025-01-21 11:58:10,135 - trainer - INFO -     val_gen_loss   : 0.08212214801460505
2025-01-21 11:58:10,135 - trainer - INFO -     val_perplexity : -102.02849578857422
2025-01-21 11:58:10,135 - trainer - INFO -     val_embedding_sim: 0.06460153311491013
2025-01-21 11:58:10,135 - trainer - INFO - ================================================================================
2025-01-21 11:58:10,135 - trainer - INFO - Starting epoch 103 at 2025-01-21 11:58:10
2025-01-21 11:58:14,027 - trainer - INFO - Epoch 103 completed at 2025-01-21 11:58:14
2025-01-21 11:58:14,027 - trainer - INFO -     epoch          : 103
2025-01-21 11:58:14,027 - trainer - INFO -     elapsed time   : 3.891819477081299
2025-01-21 11:58:14,027 - trainer - INFO -     loss           : 25.753753089904784
2025-01-21 11:58:14,027 - trainer - INFO -     sim_loss       : 25.750542831420898
2025-01-21 11:58:14,027 - trainer - INFO -     gen_loss       : 0.003210203116759658
2025-01-21 11:58:14,027 - trainer - INFO -     val_loss       : 12.511789405718446
2025-01-21 11:58:14,027 - trainer - INFO -     val_sim_loss   : 12.493722915649414
2025-01-21 11:58:14,027 - trainer - INFO -     val_gen_loss   : 0.01806673686951399
2025-01-21 11:58:14,027 - trainer - INFO -     val_perplexity : -101.80152130126953
2025-01-21 11:58:14,027 - trainer - INFO -     val_embedding_sim: 0.06296482682228088
2025-01-21 11:58:14,027 - trainer - INFO - ================================================================================
2025-01-21 11:58:14,027 - trainer - INFO - Starting epoch 104 at 2025-01-21 11:58:14
2025-01-21 11:58:17,922 - trainer - INFO - Epoch 104 completed at 2025-01-21 11:58:17
2025-01-21 11:58:17,923 - trainer - INFO -     epoch          : 104
2025-01-21 11:58:17,923 - trainer - INFO -     elapsed time   : 3.894925117492676
2025-01-21 11:58:17,923 - trainer - INFO -     loss           : 30.934727692604064
2025-01-21 11:58:17,923 - trainer - INFO -     sim_loss       : 30.931626319885254
2025-01-21 11:58:17,923 - trainer - INFO -     gen_loss       : 0.0031019155168905852
2025-01-21 11:58:17,923 - trainer - INFO -     val_loss       : 24.83676005086454
2025-01-21 11:58:17,923 - trainer - INFO -     val_sim_loss   : 24.82366180419922
2025-01-21 11:58:17,923 - trainer - INFO -     val_gen_loss   : 0.013097665520035662
2025-01-21 11:58:17,923 - trainer - INFO -     val_perplexity : -101.60905456542969
2025-01-21 11:58:17,923 - trainer - INFO -     val_embedding_sim: 0.0682542473077774
2025-01-21 11:58:17,923 - trainer - INFO - ================================================================================
2025-01-21 11:58:17,923 - trainer - INFO - Starting epoch 105 at 2025-01-21 11:58:17
2025-01-21 11:58:21,828 - trainer - INFO - Epoch 105 completed at 2025-01-21 11:58:21
2025-01-21 11:58:21,829 - trainer - INFO -     epoch          : 105
2025-01-21 11:58:21,829 - trainer - INFO -     elapsed time   : 3.9053430557250977
2025-01-21 11:58:21,829 - trainer - INFO -     loss           : 25.80115203857422
2025-01-21 11:58:21,829 - trainer - INFO -     sim_loss       : 25.79810380935669
2025-01-21 11:58:21,829 - trainer - INFO -     gen_loss       : 0.0030483630253002048
2025-01-21 11:58:21,829 - trainer - INFO -     val_loss       : 18.93686301703565
2025-01-21 11:58:21,829 - trainer - INFO -     val_sim_loss   : 18.922863006591797
2025-01-21 11:58:21,829 - trainer - INFO -     val_gen_loss   : 0.01399950566701591
2025-01-21 11:58:21,829 - trainer - INFO -     val_perplexity : -102.9940414428711
2025-01-21 11:58:21,829 - trainer - INFO -     val_embedding_sim: 0.08933848142623901
2025-01-21 11:58:27,142 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch105.pth ...
2025-01-21 11:58:27,142 - trainer - INFO - ================================================================================
2025-01-21 11:58:27,142 - trainer - INFO - Starting epoch 106 at 2025-01-21 11:58:27
2025-01-21 11:58:31,085 - trainer - INFO - Epoch 106 completed at 2025-01-21 11:58:31
2025-01-21 11:58:31,085 - trainer - INFO -     epoch          : 106
2025-01-21 11:58:31,085 - trainer - INFO -     elapsed time   : 3.9427688121795654
2025-01-21 11:58:31,086 - trainer - INFO -     loss           : 33.28225040435791
2025-01-21 11:58:31,086 - trainer - INFO -     sim_loss       : 33.27933292388916
2025-01-21 11:58:31,086 - trainer - INFO -     gen_loss       : 0.0029173931805416943
2025-01-21 11:58:31,086 - trainer - INFO -     val_loss       : 17.239872300822753
2025-01-21 11:58:31,086 - trainer - INFO -     val_sim_loss   : 17.22648811340332
2025-01-21 11:58:31,086 - trainer - INFO -     val_gen_loss   : 0.013385072175879031
2025-01-21 11:58:31,086 - trainer - INFO -     val_perplexity : -101.20948791503906
2025-01-21 11:58:31,086 - trainer - INFO -     val_embedding_sim: 0.07102407515048981
2025-01-21 11:58:31,086 - trainer - INFO - ================================================================================
2025-01-21 11:58:31,086 - trainer - INFO - Starting epoch 107 at 2025-01-21 11:58:31
2025-01-21 11:58:34,985 - trainer - INFO - Epoch 107 completed at 2025-01-21 11:58:34
2025-01-21 11:58:34,985 - trainer - INFO -     epoch          : 107
2025-01-21 11:58:34,985 - trainer - INFO -     elapsed time   : 3.898857355117798
2025-01-21 11:58:34,985 - trainer - INFO -     loss           : 28.861744976043703
2025-01-21 11:58:34,985 - trainer - INFO -     sim_loss       : 28.858817291259765
2025-01-21 11:58:34,985 - trainer - INFO -     gen_loss       : 0.002927538100630045
2025-01-21 11:58:34,985 - trainer - INFO -     val_loss       : 18.995835373178124
2025-01-21 11:58:34,985 - trainer - INFO -     val_sim_loss   : 18.961524963378906
2025-01-21 11:58:34,985 - trainer - INFO -     val_gen_loss   : 0.034310873597860336
2025-01-21 11:58:34,985 - trainer - INFO -     val_perplexity : -101.57836151123047
2025-01-21 11:58:34,985 - trainer - INFO -     val_embedding_sim: 0.07467752695083618
2025-01-21 11:58:34,985 - trainer - INFO - ================================================================================
2025-01-21 11:58:34,985 - trainer - INFO - Starting epoch 108 at 2025-01-21 11:58:34
2025-01-21 11:58:38,882 - trainer - INFO - Epoch 108 completed at 2025-01-21 11:58:38
2025-01-21 11:58:38,882 - trainer - INFO -     epoch          : 108
2025-01-21 11:58:38,882 - trainer - INFO -     elapsed time   : 3.896456480026245
2025-01-21 11:58:38,882 - trainer - INFO -     loss           : 33.62697343826294
2025-01-21 11:58:38,882 - trainer - INFO -     sim_loss       : 33.62403964996338
2025-01-21 11:58:38,882 - trainer - INFO -     gen_loss       : 0.002933615748770535
2025-01-21 11:58:38,882 - trainer - INFO -     val_loss       : 17.725371516367886
2025-01-21 11:58:38,882 - trainer - INFO -     val_sim_loss   : 17.711774826049805
2025-01-21 11:58:38,882 - trainer - INFO -     val_gen_loss   : 0.013597218377981335
2025-01-21 11:58:38,882 - trainer - INFO -     val_perplexity : -103.1270751953125
2025-01-21 11:58:38,882 - trainer - INFO -     val_embedding_sim: 0.062326546758413315
2025-01-21 11:58:38,883 - trainer - INFO - ================================================================================
2025-01-21 11:58:38,883 - trainer - INFO - Starting epoch 109 at 2025-01-21 11:58:38
2025-01-21 11:58:42,783 - trainer - INFO - Epoch 109 completed at 2025-01-21 11:58:42
2025-01-21 11:58:42,783 - trainer - INFO -     epoch          : 109
2025-01-21 11:58:42,783 - trainer - INFO -     elapsed time   : 3.9001026153564453
2025-01-21 11:58:42,783 - trainer - INFO -     loss           : 32.55311508178711
2025-01-21 11:58:42,783 - trainer - INFO -     sim_loss       : 32.55020637512207
2025-01-21 11:58:42,783 - trainer - INFO -     gen_loss       : 0.0029084845213219524
2025-01-21 11:58:42,783 - trainer - INFO -     val_loss       : 16.279898211359978
2025-01-21 11:58:42,783 - trainer - INFO -     val_sim_loss   : 16.166044235229492
2025-01-21 11:58:42,783 - trainer - INFO -     val_gen_loss   : 0.11385348066687584
2025-01-21 11:58:42,783 - trainer - INFO -     val_perplexity : -102.55950927734375
2025-01-21 11:58:42,783 - trainer - INFO -     val_embedding_sim: 0.06824256479740143
2025-01-21 11:58:42,783 - trainer - INFO - ================================================================================
2025-01-21 11:58:42,783 - trainer - INFO - Starting epoch 110 at 2025-01-21 11:58:42
2025-01-21 11:58:46,689 - trainer - INFO - Epoch 110 completed at 2025-01-21 11:58:46
2025-01-21 11:58:46,689 - trainer - INFO -     epoch          : 110
2025-01-21 11:58:46,689 - trainer - INFO -     elapsed time   : 3.9056575298309326
2025-01-21 11:58:46,689 - trainer - INFO -     loss           : 33.3652307510376
2025-01-21 11:58:46,689 - trainer - INFO -     sim_loss       : 33.36241436004639
2025-01-21 11:58:46,689 - trainer - INFO -     gen_loss       : 0.0028164645889773967
2025-01-21 11:58:46,689 - trainer - INFO -     val_loss       : 16.43597734719515
2025-01-21 11:58:46,689 - trainer - INFO -     val_sim_loss   : 16.419193267822266
2025-01-21 11:58:46,690 - trainer - INFO -     val_gen_loss   : 0.01678462792187929
2025-01-21 11:58:46,690 - trainer - INFO -     val_perplexity : -102.06098937988281
2025-01-21 11:58:46,690 - trainer - INFO -     val_embedding_sim: 0.06595131754875183
2025-01-21 11:58:52,003 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch110.pth ...
2025-01-21 11:58:52,003 - trainer - INFO - ================================================================================
2025-01-21 11:58:52,003 - trainer - INFO - Starting epoch 111 at 2025-01-21 11:58:52
2025-01-21 11:58:55,966 - trainer - INFO - Epoch 111 completed at 2025-01-21 11:58:55
2025-01-21 11:58:55,967 - trainer - INFO -     epoch          : 111
2025-01-21 11:58:55,967 - trainer - INFO -     elapsed time   : 3.962728977203369
2025-01-21 11:58:55,967 - trainer - INFO -     loss           : 29.46332335472107
2025-01-21 11:58:55,967 - trainer - INFO -     sim_loss       : 29.460435390472412
2025-01-21 11:58:55,967 - trainer - INFO -     gen_loss       : 0.002888125507161021
2025-01-21 11:58:55,967 - trainer - INFO -     val_loss       : 20.07146630427451
2025-01-21 11:58:55,967 - trainer - INFO -     val_sim_loss   : 20.058597564697266
2025-01-21 11:58:55,967 - trainer - INFO -     val_gen_loss   : 0.01286963644088246
2025-01-21 11:58:55,967 - trainer - INFO -     val_perplexity : -103.13343811035156
2025-01-21 11:58:55,967 - trainer - INFO -     val_embedding_sim: 0.06015980616211891
2025-01-21 11:58:55,967 - trainer - INFO - ================================================================================
2025-01-21 11:58:55,967 - trainer - INFO - Starting epoch 112 at 2025-01-21 11:58:55
2025-01-21 11:58:59,857 - trainer - INFO - Epoch 112 completed at 2025-01-21 11:58:59
2025-01-21 11:58:59,857 - trainer - INFO -     epoch          : 112
2025-01-21 11:58:59,857 - trainer - INFO -     elapsed time   : 3.8898963928222656
2025-01-21 11:58:59,857 - trainer - INFO -     loss           : 32.83826198577881
2025-01-21 11:58:59,857 - trainer - INFO -     sim_loss       : 32.83541049957275
2025-01-21 11:58:59,857 - trainer - INFO -     gen_loss       : 0.002851111930795014
2025-01-21 11:58:59,857 - trainer - INFO -     val_loss       : 15.276950315572321
2025-01-21 11:58:59,857 - trainer - INFO -     val_sim_loss   : 15.252562522888184
2025-01-21 11:58:59,857 - trainer - INFO -     val_gen_loss   : 0.024387543089687824
2025-01-21 11:58:59,857 - trainer - INFO -     val_perplexity : -103.52391052246094
2025-01-21 11:58:59,858 - trainer - INFO -     val_embedding_sim: 0.060596417635679245
2025-01-21 11:58:59,858 - trainer - INFO - ================================================================================
2025-01-21 11:58:59,858 - trainer - INFO - Starting epoch 113 at 2025-01-21 11:58:59
2025-01-21 11:59:03,764 - trainer - INFO - Epoch 113 completed at 2025-01-21 11:59:03
2025-01-21 11:59:03,764 - trainer - INFO -     epoch          : 113
2025-01-21 11:59:03,764 - trainer - INFO -     elapsed time   : 3.906484603881836
2025-01-21 11:59:03,764 - trainer - INFO -     loss           : 29.488924407958983
2025-01-21 11:59:03,764 - trainer - INFO -     sim_loss       : 29.486124801635743
2025-01-21 11:59:03,765 - trainer - INFO -     gen_loss       : 0.002800006349571049
2025-01-21 11:59:03,765 - trainer - INFO -     val_loss       : 15.24138635583222
2025-01-21 11:59:03,765 - trainer - INFO -     val_sim_loss   : 15.208639144897461
2025-01-21 11:59:03,765 - trainer - INFO -     val_gen_loss   : 0.032747029326856136
2025-01-21 11:59:03,765 - trainer - INFO -     val_perplexity : -101.90956115722656
2025-01-21 11:59:03,765 - trainer - INFO -     val_embedding_sim: 0.06564618647098541
2025-01-21 11:59:03,765 - trainer - INFO - ================================================================================
2025-01-21 11:59:03,765 - trainer - INFO - Starting epoch 114 at 2025-01-21 11:59:03
2025-01-21 11:59:07,640 - trainer - INFO - Epoch 114 completed at 2025-01-21 11:59:07
2025-01-21 11:59:07,640 - trainer - INFO -     epoch          : 114
2025-01-21 11:59:07,640 - trainer - INFO -     elapsed time   : 3.8753044605255127
2025-01-21 11:59:07,640 - trainer - INFO -     loss           : 31.421919345855713
2025-01-21 11:59:07,641 - trainer - INFO -     sim_loss       : 31.41924123764038
2025-01-21 11:59:07,641 - trainer - INFO -     gen_loss       : 0.0026779569685459136
2025-01-21 11:59:07,641 - trainer - INFO -     val_loss       : 17.847375761717558
2025-01-21 11:59:07,641 - trainer - INFO -     val_sim_loss   : 17.78768539428711
2025-01-21 11:59:07,641 - trainer - INFO -     val_gen_loss   : 0.05969065986573696
2025-01-21 11:59:07,641 - trainer - INFO -     val_perplexity : -103.46654510498047
2025-01-21 11:59:07,641 - trainer - INFO -     val_embedding_sim: 0.0556880421936512
2025-01-21 11:59:07,641 - trainer - INFO - ================================================================================
2025-01-21 11:59:07,641 - trainer - INFO - Starting epoch 115 at 2025-01-21 11:59:07
2025-01-21 11:59:11,543 - trainer - INFO - Epoch 115 completed at 2025-01-21 11:59:11
2025-01-21 11:59:11,543 - trainer - INFO -     epoch          : 115
2025-01-21 11:59:11,543 - trainer - INFO -     elapsed time   : 3.9022316932678223
2025-01-21 11:59:11,543 - trainer - INFO -     loss           : 28.425543308258057
2025-01-21 11:59:11,543 - trainer - INFO -     sim_loss       : 28.42282943725586
2025-01-21 11:59:11,544 - trainer - INFO -     gen_loss       : 0.002713622944429517
2025-01-21 11:59:11,544 - trainer - INFO -     val_loss       : 15.446751844137907
2025-01-21 11:59:11,544 - trainer - INFO -     val_sim_loss   : 15.434076309204102
2025-01-21 11:59:11,544 - trainer - INFO -     val_gen_loss   : 0.012675578705966473
2025-01-21 11:59:11,544 - trainer - INFO -     val_perplexity : -102.87188720703125
2025-01-21 11:59:11,544 - trainer - INFO -     val_embedding_sim: 0.07134224474430084
2025-01-21 11:59:16,850 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch115.pth ...
2025-01-21 11:59:22,114 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 11:59:22,114 - trainer - INFO - ================================================================================
2025-01-21 11:59:22,114 - trainer - INFO - Starting epoch 116 at 2025-01-21 11:59:22
2025-01-21 11:59:26,085 - trainer - INFO - Epoch 116 completed at 2025-01-21 11:59:26
2025-01-21 11:59:26,085 - trainer - INFO -     epoch          : 116
2025-01-21 11:59:26,085 - trainer - INFO -     elapsed time   : 3.9704842567443848
2025-01-21 11:59:26,085 - trainer - INFO -     loss           : 32.783325576782225
2025-01-21 11:59:26,085 - trainer - INFO -     sim_loss       : 32.780578422546384
2025-01-21 11:59:26,085 - trainer - INFO -     gen_loss       : 0.0027469436405226587
2025-01-21 11:59:26,085 - trainer - INFO -     val_loss       : 16.484121155488538
2025-01-21 11:59:26,085 - trainer - INFO -     val_sim_loss   : 16.471216201782227
2025-01-21 11:59:26,085 - trainer - INFO -     val_gen_loss   : 0.01290432972018607
2025-01-21 11:59:26,085 - trainer - INFO -     val_perplexity : -102.25749206542969
2025-01-21 11:59:26,085 - trainer - INFO -     val_embedding_sim: 0.06658843159675598
2025-01-21 11:59:26,085 - trainer - INFO - ================================================================================
2025-01-21 11:59:26,085 - trainer - INFO - Starting epoch 117 at 2025-01-21 11:59:26
2025-01-21 11:59:29,983 - trainer - INFO - Epoch 117 completed at 2025-01-21 11:59:29
2025-01-21 11:59:29,984 - trainer - INFO -     epoch          : 117
2025-01-21 11:59:29,984 - trainer - INFO -     elapsed time   : 3.897766351699829
2025-01-21 11:59:29,984 - trainer - INFO -     loss           : 30.17551894187927
2025-01-21 11:59:29,984 - trainer - INFO -     sim_loss       : 30.172906494140626
2025-01-21 11:59:29,984 - trainer - INFO -     gen_loss       : 0.002612693258561194
2025-01-21 11:59:29,984 - trainer - INFO -     val_loss       : 13.023262994829565
2025-01-21 11:59:29,984 - trainer - INFO -     val_sim_loss   : 13.009237289428711
2025-01-21 11:59:29,984 - trainer - INFO -     val_gen_loss   : 0.01402557035908103
2025-01-21 11:59:29,984 - trainer - INFO -     val_perplexity : -104.19134521484375
2025-01-21 11:59:29,984 - trainer - INFO -     val_embedding_sim: 0.07215152680873871
2025-01-21 11:59:29,984 - trainer - INFO - ================================================================================
2025-01-21 11:59:29,984 - trainer - INFO - Starting epoch 118 at 2025-01-21 11:59:29
2025-01-21 11:59:33,874 - trainer - INFO - Epoch 118 completed at 2025-01-21 11:59:33
2025-01-21 11:59:33,874 - trainer - INFO -     epoch          : 118
2025-01-21 11:59:33,874 - trainer - INFO -     elapsed time   : 3.8894875049591064
2025-01-21 11:59:33,874 - trainer - INFO -     loss           : 33.03697123527527
2025-01-21 11:59:33,874 - trainer - INFO -     sim_loss       : 33.03391380310059
2025-01-21 11:59:33,874 - trainer - INFO -     gen_loss       : 0.0030571613926440476
2025-01-21 11:59:33,874 - trainer - INFO -     val_loss       : 17.905771307006944
2025-01-21 11:59:33,874 - trainer - INFO -     val_sim_loss   : 17.89120101928711
2025-01-21 11:59:33,874 - trainer - INFO -     val_gen_loss   : 0.01457070029573515
2025-01-21 11:59:33,874 - trainer - INFO -     val_perplexity : -100.2885971069336
2025-01-21 11:59:33,874 - trainer - INFO -     val_embedding_sim: 0.05115022882819176
2025-01-21 11:59:33,874 - trainer - INFO - ================================================================================
2025-01-21 11:59:33,874 - trainer - INFO - Starting epoch 119 at 2025-01-21 11:59:33
2025-01-21 11:59:37,788 - trainer - INFO - Epoch 119 completed at 2025-01-21 11:59:37
2025-01-21 11:59:37,788 - trainer - INFO -     epoch          : 119
2025-01-21 11:59:37,788 - trainer - INFO -     elapsed time   : 3.9136769771575928
2025-01-21 11:59:37,788 - trainer - INFO -     loss           : 31.76159610748291
2025-01-21 11:59:37,788 - trainer - INFO -     sim_loss       : 31.7581579208374
2025-01-21 11:59:37,788 - trainer - INFO -     gen_loss       : 0.0034379144432023167
2025-01-21 11:59:37,788 - trainer - INFO -     val_loss       : 19.37706096380134
2025-01-21 11:59:37,788 - trainer - INFO -     val_sim_loss   : 19.36330795288086
2025-01-21 11:59:37,788 - trainer - INFO -     val_gen_loss   : 0.013752462371485308
2025-01-21 11:59:37,789 - trainer - INFO -     val_perplexity : -102.33817291259766
2025-01-21 11:59:37,789 - trainer - INFO -     val_embedding_sim: 0.08689838647842407
2025-01-21 11:59:37,789 - trainer - INFO - ================================================================================
2025-01-21 11:59:37,789 - trainer - INFO - Starting epoch 120 at 2025-01-21 11:59:37
2025-01-21 11:59:41,686 - trainer - INFO - Epoch 120 completed at 2025-01-21 11:59:41
2025-01-21 11:59:41,686 - trainer - INFO -     epoch          : 120
2025-01-21 11:59:41,686 - trainer - INFO -     elapsed time   : 3.897332191467285
2025-01-21 11:59:41,686 - trainer - INFO -     loss           : 29.747482299804688
2025-01-21 11:59:41,686 - trainer - INFO -     sim_loss       : 29.744390344619752
2025-01-21 11:59:41,686 - trainer - INFO -     gen_loss       : 0.00309166198130697
2025-01-21 11:59:41,686 - trainer - INFO -     val_loss       : 15.156275110319257
2025-01-21 11:59:41,687 - trainer - INFO -     val_sim_loss   : 15.121456146240234
2025-01-21 11:59:41,687 - trainer - INFO -     val_gen_loss   : 0.034818717278540134
2025-01-21 11:59:41,687 - trainer - INFO -     val_perplexity : -101.696044921875
2025-01-21 11:59:41,687 - trainer - INFO -     val_embedding_sim: 0.0680542141199112
2025-01-21 11:59:46,992 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch120.pth ...
2025-01-21 11:59:46,992 - trainer - INFO - ================================================================================
2025-01-21 11:59:46,992 - trainer - INFO - Starting epoch 121 at 2025-01-21 11:59:46
2025-01-21 11:59:50,961 - trainer - INFO - Epoch 121 completed at 2025-01-21 11:59:50
2025-01-21 11:59:50,962 - trainer - INFO -     epoch          : 121
2025-01-21 11:59:50,962 - trainer - INFO -     elapsed time   : 3.9689455032348633
2025-01-21 11:59:50,962 - trainer - INFO -     loss           : 28.746476316452025
2025-01-21 11:59:50,962 - trainer - INFO -     sim_loss       : 28.743709754943847
2025-01-21 11:59:50,962 - trainer - INFO -     gen_loss       : 0.002766443067230284
2025-01-21 11:59:50,962 - trainer - INFO -     val_loss       : 13.296617325395346
2025-01-21 11:59:50,962 - trainer - INFO -     val_sim_loss   : 13.264350891113281
2025-01-21 11:59:50,962 - trainer - INFO -     val_gen_loss   : 0.03226642124354839
2025-01-21 11:59:50,962 - trainer - INFO -     val_perplexity : -102.11505889892578
2025-01-21 11:59:50,962 - trainer - INFO -     val_embedding_sim: 0.06505559384822845
2025-01-21 11:59:50,962 - trainer - INFO - ================================================================================
2025-01-21 11:59:50,962 - trainer - INFO - Starting epoch 122 at 2025-01-21 11:59:50
2025-01-21 11:59:54,864 - trainer - INFO - Epoch 122 completed at 2025-01-21 11:59:54
2025-01-21 11:59:54,864 - trainer - INFO -     epoch          : 122
2025-01-21 11:59:54,865 - trainer - INFO -     elapsed time   : 3.902228832244873
2025-01-21 11:59:54,865 - trainer - INFO -     loss           : 30.418770790100098
2025-01-21 11:59:54,865 - trainer - INFO -     sim_loss       : 30.416240882873534
2025-01-21 11:59:54,865 - trainer - INFO -     gen_loss       : 0.0025299467844888566
2025-01-21 11:59:54,865 - trainer - INFO -     val_loss       : 17.295095220208168
2025-01-21 11:59:54,865 - trainer - INFO -     val_sim_loss   : 17.26917266845703
2025-01-21 11:59:54,865 - trainer - INFO -     val_gen_loss   : 0.025921756401658058
2025-01-21 11:59:54,865 - trainer - INFO -     val_perplexity : -102.39599609375
2025-01-21 11:59:54,865 - trainer - INFO -     val_embedding_sim: 0.05234719440340996
2025-01-21 11:59:54,865 - trainer - INFO - ================================================================================
2025-01-21 11:59:54,865 - trainer - INFO - Starting epoch 123 at 2025-01-21 11:59:54
2025-01-21 11:59:58,759 - trainer - INFO - Epoch 123 completed at 2025-01-21 11:59:58
2025-01-21 11:59:58,759 - trainer - INFO -     epoch          : 123
2025-01-21 11:59:58,759 - trainer - INFO -     elapsed time   : 3.893454074859619
2025-01-21 11:59:58,759 - trainer - INFO -     loss           : 31.265575313568114
2025-01-21 11:59:58,759 - trainer - INFO -     sim_loss       : 31.26316738128662
2025-01-21 11:59:58,759 - trainer - INFO -     gen_loss       : 0.00240757743595168
2025-01-21 11:59:58,759 - trainer - INFO -     val_loss       : 17.9491419903934
2025-01-21 11:59:58,759 - trainer - INFO -     val_sim_loss   : 17.93421745300293
2025-01-21 11:59:58,759 - trainer - INFO -     val_gen_loss   : 0.014924326911568642
2025-01-21 11:59:58,759 - trainer - INFO -     val_perplexity : -103.79456329345703
2025-01-21 11:59:58,759 - trainer - INFO -     val_embedding_sim: 0.06480249762535095
2025-01-21 11:59:58,759 - trainer - INFO - ================================================================================
2025-01-21 11:59:58,759 - trainer - INFO - Starting epoch 124 at 2025-01-21 11:59:58
2025-01-21 12:00:02,663 - trainer - INFO - Epoch 124 completed at 2025-01-21 12:00:02
2025-01-21 12:00:02,663 - trainer - INFO -     epoch          : 124
2025-01-21 12:00:02,663 - trainer - INFO -     elapsed time   : 3.903754472732544
2025-01-21 12:00:02,663 - trainer - INFO -     loss           : 31.771202945709227
2025-01-21 12:00:02,663 - trainer - INFO -     sim_loss       : 31.768813371658325
2025-01-21 12:00:02,663 - trainer - INFO -     gen_loss       : 0.0023895572870969773
2025-01-21 12:00:02,663 - trainer - INFO -     val_loss       : 23.995633550919592
2025-01-21 12:00:02,663 - trainer - INFO -     val_sim_loss   : 23.974136352539062
2025-01-21 12:00:02,663 - trainer - INFO -     val_gen_loss   : 0.0214976379647851
2025-01-21 12:00:02,664 - trainer - INFO -     val_perplexity : -102.02142333984375
2025-01-21 12:00:02,664 - trainer - INFO -     val_embedding_sim: 0.06916476786136627
2025-01-21 12:00:02,664 - trainer - INFO - ================================================================================
2025-01-21 12:00:02,664 - trainer - INFO - Starting epoch 125 at 2025-01-21 12:00:02
2025-01-21 12:00:06,614 - trainer - INFO - Epoch 125 completed at 2025-01-21 12:00:06
2025-01-21 12:00:06,614 - trainer - INFO -     epoch          : 125
2025-01-21 12:00:06,614 - trainer - INFO -     elapsed time   : 3.950202465057373
2025-01-21 12:00:06,614 - trainer - INFO -     loss           : 28.367828607559204
2025-01-21 12:00:06,614 - trainer - INFO -     sim_loss       : 28.365390157699586
2025-01-21 12:00:06,614 - trainer - INFO -     gen_loss       : 0.0024381390772759914
2025-01-21 12:00:06,614 - trainer - INFO -     val_loss       : 12.753567916341126
2025-01-21 12:00:06,614 - trainer - INFO -     val_sim_loss   : 12.737427711486816
2025-01-21 12:00:06,614 - trainer - INFO -     val_gen_loss   : 0.01614009030163288
2025-01-21 12:00:06,614 - trainer - INFO -     val_perplexity : -102.87361907958984
2025-01-21 12:00:06,614 - trainer - INFO -     val_embedding_sim: 0.06683734059333801
2025-01-21 12:00:11,920 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch125.pth ...
2025-01-21 12:00:11,920 - trainer - INFO - ================================================================================
2025-01-21 12:00:11,920 - trainer - INFO - Starting epoch 126 at 2025-01-21 12:00:11
2025-01-21 12:00:15,883 - trainer - INFO - Epoch 126 completed at 2025-01-21 12:00:15
2025-01-21 12:00:15,883 - trainer - INFO -     epoch          : 126
2025-01-21 12:00:15,883 - trainer - INFO -     elapsed time   : 3.9628915786743164
2025-01-21 12:00:15,883 - trainer - INFO -     loss           : 32.44722290039063
2025-01-21 12:00:15,883 - trainer - INFO -     sim_loss       : 32.444827461242674
2025-01-21 12:00:15,883 - trainer - INFO -     gen_loss       : 0.0023955574026331304
2025-01-21 12:00:15,883 - trainer - INFO -     val_loss       : 15.890381934827019
2025-01-21 12:00:15,884 - trainer - INFO -     val_sim_loss   : 15.877716064453125
2025-01-21 12:00:15,884 - trainer - INFO -     val_gen_loss   : 0.012665514608670492
2025-01-21 12:00:15,884 - trainer - INFO -     val_perplexity : -103.93897247314453
2025-01-21 12:00:15,884 - trainer - INFO -     val_embedding_sim: 0.05896003544330597
2025-01-21 12:00:15,884 - trainer - INFO - ================================================================================
2025-01-21 12:00:15,884 - trainer - INFO - Starting epoch 127 at 2025-01-21 12:00:15
2025-01-21 12:00:19,776 - trainer - INFO - Epoch 127 completed at 2025-01-21 12:00:19
2025-01-21 12:00:19,776 - trainer - INFO -     epoch          : 127
2025-01-21 12:00:19,776 - trainer - INFO -     elapsed time   : 3.8922958374023438
2025-01-21 12:00:19,776 - trainer - INFO -     loss           : 31.591206645965578
2025-01-21 12:00:19,776 - trainer - INFO -     sim_loss       : 31.588920450210573
2025-01-21 12:00:19,776 - trainer - INFO -     gen_loss       : 0.002286033413838595
2025-01-21 12:00:19,777 - trainer - INFO -     val_loss       : 15.7299993801862
2025-01-21 12:00:19,777 - trainer - INFO -     val_sim_loss   : 15.700004577636719
2025-01-21 12:00:19,777 - trainer - INFO -     val_gen_loss   : 0.02999467682093382
2025-01-21 12:00:19,777 - trainer - INFO -     val_perplexity : -103.19398498535156
2025-01-21 12:00:19,777 - trainer - INFO -     val_embedding_sim: 0.05455717071890831
2025-01-21 12:00:19,777 - trainer - INFO - ================================================================================
2025-01-21 12:00:19,777 - trainer - INFO - Starting epoch 128 at 2025-01-21 12:00:19
2025-01-21 12:00:23,671 - trainer - INFO - Epoch 128 completed at 2025-01-21 12:00:23
2025-01-21 12:00:23,671 - trainer - INFO -     epoch          : 128
2025-01-21 12:00:23,671 - trainer - INFO -     elapsed time   : 3.8941609859466553
2025-01-21 12:00:23,671 - trainer - INFO -     loss           : 34.195265769958496
2025-01-21 12:00:23,671 - trainer - INFO -     sim_loss       : 34.19303331375122
2025-01-21 12:00:23,671 - trainer - INFO -     gen_loss       : 0.0022321075201034548
2025-01-21 12:00:23,671 - trainer - INFO -     val_loss       : 19.085598427802324
2025-01-21 12:00:23,671 - trainer - INFO -     val_sim_loss   : 19.063861846923828
2025-01-21 12:00:23,671 - trainer - INFO -     val_gen_loss   : 0.021736251190304756
2025-01-21 12:00:23,672 - trainer - INFO -     val_perplexity : -102.37554168701172
2025-01-21 12:00:23,672 - trainer - INFO -     val_embedding_sim: 0.07546690106391907
2025-01-21 12:00:23,672 - trainer - INFO - ================================================================================
2025-01-21 12:00:23,672 - trainer - INFO - Starting epoch 129 at 2025-01-21 12:00:23
2025-01-21 12:00:27,566 - trainer - INFO - Epoch 129 completed at 2025-01-21 12:00:27
2025-01-21 12:00:27,566 - trainer - INFO -     epoch          : 129
2025-01-21 12:00:27,566 - trainer - INFO -     elapsed time   : 3.8942928314208984
2025-01-21 12:00:27,566 - trainer - INFO -     loss           : 30.301458835601807
2025-01-21 12:00:27,566 - trainer - INFO -     sim_loss       : 30.2990421295166
2025-01-21 12:00:27,566 - trainer - INFO -     gen_loss       : 0.0024165366776287556
2025-01-21 12:00:27,566 - trainer - INFO -     val_loss       : 17.48992344805447
2025-01-21 12:00:27,566 - trainer - INFO -     val_sim_loss   : 17.476713180541992
2025-01-21 12:00:27,566 - trainer - INFO -     val_gen_loss   : 0.013210267512477003
2025-01-21 12:00:27,567 - trainer - INFO -     val_perplexity : -102.61710357666016
2025-01-21 12:00:27,567 - trainer - INFO -     val_embedding_sim: 0.05831582471728325
2025-01-21 12:00:27,567 - trainer - INFO - ================================================================================
2025-01-21 12:00:27,567 - trainer - INFO - Starting epoch 130 at 2025-01-21 12:00:27
2025-01-21 12:00:31,467 - trainer - INFO - Epoch 130 completed at 2025-01-21 12:00:31
2025-01-21 12:00:31,467 - trainer - INFO -     epoch          : 130
2025-01-21 12:00:31,467 - trainer - INFO -     elapsed time   : 3.900057315826416
2025-01-21 12:00:31,467 - trainer - INFO -     loss           : 29.30853581428528
2025-01-21 12:00:31,467 - trainer - INFO -     sim_loss       : 29.306094360351562
2025-01-21 12:00:31,467 - trainer - INFO -     gen_loss       : 0.0024413950508460403
2025-01-21 12:00:31,467 - trainer - INFO -     val_loss       : 16.88211214641342
2025-01-21 12:00:31,467 - trainer - INFO -     val_sim_loss   : 16.869186401367188
2025-01-21 12:00:31,467 - trainer - INFO -     val_gen_loss   : 0.012926115712616593
2025-01-21 12:00:31,467 - trainer - INFO -     val_perplexity : -104.02532196044922
2025-01-21 12:00:31,467 - trainer - INFO -     val_embedding_sim: 0.0934920608997345
2025-01-21 12:00:36,775 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch130.pth ...
2025-01-21 12:00:36,776 - trainer - INFO - ================================================================================
2025-01-21 12:00:36,776 - trainer - INFO - Starting epoch 131 at 2025-01-21 12:00:36
2025-01-21 12:00:40,741 - trainer - INFO - Epoch 131 completed at 2025-01-21 12:00:40
2025-01-21 12:00:40,741 - trainer - INFO -     epoch          : 131
2025-01-21 12:00:40,741 - trainer - INFO -     elapsed time   : 3.964683771133423
2025-01-21 12:00:40,741 - trainer - INFO -     loss           : 30.19346466064453
2025-01-21 12:00:40,741 - trainer - INFO -     sim_loss       : 30.19110984802246
2025-01-21 12:00:40,741 - trainer - INFO -     gen_loss       : 0.0023548893514089286
2025-01-21 12:00:40,741 - trainer - INFO -     val_loss       : 15.528153272658528
2025-01-21 12:00:40,741 - trainer - INFO -     val_sim_loss   : 15.515920639038086
2025-01-21 12:00:40,741 - trainer - INFO -     val_gen_loss   : 0.012232370987476315
2025-01-21 12:00:40,741 - trainer - INFO -     val_perplexity : -102.94660949707031
2025-01-21 12:00:40,741 - trainer - INFO -     val_embedding_sim: 0.08351840078830719
2025-01-21 12:00:40,741 - trainer - INFO - ================================================================================
2025-01-21 12:00:40,741 - trainer - INFO - Starting epoch 132 at 2025-01-21 12:00:40
2025-01-21 12:00:44,640 - trainer - INFO - Epoch 132 completed at 2025-01-21 12:00:44
2025-01-21 12:00:44,640 - trainer - INFO -     epoch          : 132
2025-01-21 12:00:44,640 - trainer - INFO -     elapsed time   : 3.8983709812164307
2025-01-21 12:00:44,640 - trainer - INFO -     loss           : 29.989267539978027
2025-01-21 12:00:44,640 - trainer - INFO -     sim_loss       : 29.986735153198243
2025-01-21 12:00:44,640 - trainer - INFO -     gen_loss       : 0.002532501134555787
2025-01-21 12:00:44,640 - trainer - INFO -     val_loss       : 11.558685940224677
2025-01-21 12:00:44,640 - trainer - INFO -     val_sim_loss   : 11.545854568481445
2025-01-21 12:00:44,640 - trainer - INFO -     val_gen_loss   : 0.012831196654587984
2025-01-21 12:00:44,640 - trainer - INFO -     val_perplexity : -101.85482788085938
2025-01-21 12:00:44,640 - trainer - INFO -     val_embedding_sim: 0.06547130644321442
2025-01-21 12:00:44,640 - trainer - INFO - ================================================================================
2025-01-21 12:00:44,640 - trainer - INFO - Starting epoch 133 at 2025-01-21 12:00:44
2025-01-21 12:00:48,538 - trainer - INFO - Epoch 133 completed at 2025-01-21 12:00:48
2025-01-21 12:00:48,538 - trainer - INFO -     epoch          : 133
2025-01-21 12:00:48,538 - trainer - INFO -     elapsed time   : 3.8974475860595703
2025-01-21 12:00:48,538 - trainer - INFO -     loss           : 27.875493907928465
2025-01-21 12:00:48,538 - trainer - INFO -     sim_loss       : 27.873202896118165
2025-01-21 12:00:48,538 - trainer - INFO -     gen_loss       : 0.0022912918240763245
2025-01-21 12:00:48,538 - trainer - INFO -     val_loss       : 17.052747752459254
2025-01-21 12:00:48,538 - trainer - INFO -     val_sim_loss   : 17.040157318115234
2025-01-21 12:00:48,538 - trainer - INFO -     val_gen_loss   : 0.012591294886078686
2025-01-21 12:00:48,538 - trainer - INFO -     val_perplexity : -104.16057586669922
2025-01-21 12:00:48,538 - trainer - INFO -     val_embedding_sim: 0.06571876257658005
2025-01-21 12:00:48,538 - trainer - INFO - ================================================================================
2025-01-21 12:00:48,538 - trainer - INFO - Starting epoch 134 at 2025-01-21 12:00:48
2025-01-21 12:00:52,436 - trainer - INFO - Epoch 134 completed at 2025-01-21 12:00:52
2025-01-21 12:00:52,436 - trainer - INFO -     epoch          : 134
2025-01-21 12:00:52,436 - trainer - INFO -     elapsed time   : 3.8976075649261475
2025-01-21 12:00:52,436 - trainer - INFO -     loss           : 31.352259349822997
2025-01-21 12:00:52,436 - trainer - INFO -     sim_loss       : 31.350095176696776
2025-01-21 12:00:52,436 - trainer - INFO -     gen_loss       : 0.0021644636522978543
2025-01-21 12:00:52,436 - trainer - INFO -     val_loss       : 11.999813603018993
2025-01-21 12:00:52,437 - trainer - INFO -     val_sim_loss   : 11.987444877624512
2025-01-21 12:00:52,437 - trainer - INFO -     val_gen_loss   : 0.012369174291961826
2025-01-21 12:00:52,437 - trainer - INFO -     val_perplexity : -104.39874267578125
2025-01-21 12:00:52,437 - trainer - INFO -     val_embedding_sim: 0.0658709928393364
2025-01-21 12:00:52,437 - trainer - INFO - ================================================================================
2025-01-21 12:00:52,437 - trainer - INFO - Starting epoch 135 at 2025-01-21 12:00:52
2025-01-21 12:00:56,332 - trainer - INFO - Epoch 135 completed at 2025-01-21 12:00:56
2025-01-21 12:00:56,332 - trainer - INFO -     epoch          : 135
2025-01-21 12:00:56,332 - trainer - INFO -     elapsed time   : 3.895413398742676
2025-01-21 12:00:56,333 - trainer - INFO -     loss           : 29.429118728637697
2025-01-21 12:00:56,333 - trainer - INFO -     sim_loss       : 29.4269718170166
2025-01-21 12:00:56,333 - trainer - INFO -     gen_loss       : 0.0021469059865921736
2025-01-21 12:00:56,333 - trainer - INFO -     val_loss       : 11.263319854995643
2025-01-21 12:00:56,333 - trainer - INFO -     val_sim_loss   : 11.250959396362305
2025-01-21 12:00:56,333 - trainer - INFO -     val_gen_loss   : 0.012360811604594346
2025-01-21 12:00:56,333 - trainer - INFO -     val_perplexity : -103.98878479003906
2025-01-21 12:00:56,333 - trainer - INFO -     val_embedding_sim: 0.08698972314596176
2025-01-21 12:01:01,642 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch135.pth ...
2025-01-21 12:01:01,642 - trainer - INFO - ================================================================================
2025-01-21 12:01:01,642 - trainer - INFO - Starting epoch 136 at 2025-01-21 12:01:01
2025-01-21 12:01:05,554 - trainer - INFO - Epoch 136 completed at 2025-01-21 12:01:05
2025-01-21 12:01:05,554 - trainer - INFO -     epoch          : 136
2025-01-21 12:01:05,554 - trainer - INFO -     elapsed time   : 3.9118640422821045
2025-01-21 12:01:05,555 - trainer - INFO -     loss           : 30.012141466140747
2025-01-21 12:01:05,555 - trainer - INFO -     sim_loss       : 30.010082721710205
2025-01-21 12:01:05,555 - trainer - INFO -     gen_loss       : 0.002058803045656532
2025-01-21 12:01:05,555 - trainer - INFO -     val_loss       : 13.88370037637651
2025-01-21 12:01:05,555 - trainer - INFO -     val_sim_loss   : 13.852457046508789
2025-01-21 12:01:05,555 - trainer - INFO -     val_gen_loss   : 0.031243499368429184
2025-01-21 12:01:05,555 - trainer - INFO -     val_perplexity : -103.25859832763672
2025-01-21 12:01:05,555 - trainer - INFO -     val_embedding_sim: 0.10487771034240723
2025-01-21 12:01:05,555 - trainer - INFO - ================================================================================
2025-01-21 12:01:05,555 - trainer - INFO - Starting epoch 137 at 2025-01-21 12:01:05
2025-01-21 12:01:09,443 - trainer - INFO - Epoch 137 completed at 2025-01-21 12:01:09
2025-01-21 12:01:09,443 - trainer - INFO -     epoch          : 137
2025-01-21 12:01:09,443 - trainer - INFO -     elapsed time   : 3.887638568878174
2025-01-21 12:01:09,443 - trainer - INFO -     loss           : 29.876580047607423
2025-01-21 12:01:09,443 - trainer - INFO -     sim_loss       : 29.87459526062012
2025-01-21 12:01:09,443 - trainer - INFO -     gen_loss       : 0.001984434120822698
2025-01-21 12:01:09,443 - trainer - INFO -     val_loss       : 13.634877580130706
2025-01-21 12:01:09,443 - trainer - INFO -     val_sim_loss   : 13.622289657592773
2025-01-21 12:01:09,443 - trainer - INFO -     val_gen_loss   : 0.01258820845396258
2025-01-21 12:01:09,443 - trainer - INFO -     val_perplexity : -102.99382781982422
2025-01-21 12:01:09,443 - trainer - INFO -     val_embedding_sim: 0.06989841163158417
2025-01-21 12:01:09,443 - trainer - INFO - ================================================================================
2025-01-21 12:01:09,443 - trainer - INFO - Starting epoch 138 at 2025-01-21 12:01:09
2025-01-21 12:01:13,347 - trainer - INFO - Epoch 138 completed at 2025-01-21 12:01:13
2025-01-21 12:01:13,347 - trainer - INFO -     epoch          : 138
2025-01-21 12:01:13,347 - trainer - INFO -     elapsed time   : 3.9035942554473877
2025-01-21 12:01:13,347 - trainer - INFO -     loss           : 30.580592584609985
2025-01-21 12:01:13,347 - trainer - INFO -     sim_loss       : 30.578589296340944
2025-01-21 12:01:13,347 - trainer - INFO -     gen_loss       : 0.0020032863947562875
2025-01-21 12:01:13,347 - trainer - INFO -     val_loss       : 9.65141161851352
2025-01-21 12:01:13,347 - trainer - INFO -     val_sim_loss   : 9.639249801635742
2025-01-21 12:01:13,347 - trainer - INFO -     val_gen_loss   : 0.012162213621195406
2025-01-21 12:01:13,347 - trainer - INFO -     val_perplexity : -104.82521057128906
2025-01-21 12:01:13,347 - trainer - INFO -     val_embedding_sim: 0.09006496518850327
2025-01-21 12:01:13,347 - trainer - INFO - ================================================================================
2025-01-21 12:01:13,348 - trainer - INFO - Starting epoch 139 at 2025-01-21 12:01:13
2025-01-21 12:01:17,253 - trainer - INFO - Epoch 139 completed at 2025-01-21 12:01:17
2025-01-21 12:01:17,254 - trainer - INFO -     epoch          : 139
2025-01-21 12:01:17,254 - trainer - INFO -     elapsed time   : 3.9057888984680176
2025-01-21 12:01:17,254 - trainer - INFO -     loss           : 31.359154844284056
2025-01-21 12:01:17,254 - trainer - INFO -     sim_loss       : 31.357127952575684
2025-01-21 12:01:17,254 - trainer - INFO -     gen_loss       : 0.0020266697509214284
2025-01-21 12:01:17,254 - trainer - INFO -     val_loss       : 11.478078160434961
2025-01-21 12:01:17,254 - trainer - INFO -     val_sim_loss   : 11.450201034545898
2025-01-21 12:01:17,254 - trainer - INFO -     val_gen_loss   : 0.027876747772097588
2025-01-21 12:01:17,254 - trainer - INFO -     val_perplexity : -103.69717407226562
2025-01-21 12:01:17,254 - trainer - INFO -     val_embedding_sim: 0.07164645195007324
2025-01-21 12:01:17,254 - trainer - INFO - ================================================================================
2025-01-21 12:01:17,254 - trainer - INFO - Starting epoch 140 at 2025-01-21 12:01:17
2025-01-21 12:01:21,132 - trainer - INFO - Epoch 140 completed at 2025-01-21 12:01:21
2025-01-21 12:01:21,132 - trainer - INFO -     epoch          : 140
2025-01-21 12:01:21,132 - trainer - INFO -     elapsed time   : 3.877397060394287
2025-01-21 12:01:21,132 - trainer - INFO -     loss           : 30.658935403823854
2025-01-21 12:01:21,132 - trainer - INFO -     sim_loss       : 30.656999588012695
2025-01-21 12:01:21,132 - trainer - INFO -     gen_loss       : 0.0019359431345947087
2025-01-21 12:01:21,132 - trainer - INFO -     val_loss       : 17.127501838374883
2025-01-21 12:01:21,132 - trainer - INFO -     val_sim_loss   : 17.111000061035156
2025-01-21 12:01:21,132 - trainer - INFO -     val_gen_loss   : 0.016501909587532282
2025-01-21 12:01:21,132 - trainer - INFO -     val_perplexity : -103.46629333496094
2025-01-21 12:01:21,132 - trainer - INFO -     val_embedding_sim: 0.07072634994983673
2025-01-21 12:01:26,442 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch140.pth ...
2025-01-21 12:01:26,443 - trainer - INFO - ================================================================================
2025-01-21 12:01:26,443 - trainer - INFO - Starting epoch 141 at 2025-01-21 12:01:26
2025-01-21 12:01:30,426 - trainer - INFO - Epoch 141 completed at 2025-01-21 12:01:30
2025-01-21 12:01:30,426 - trainer - INFO -     epoch          : 141
2025-01-21 12:01:30,426 - trainer - INFO -     elapsed time   : 3.9828522205352783
2025-01-21 12:01:30,426 - trainer - INFO -     loss           : 32.27988338470459
2025-01-21 12:01:30,426 - trainer - INFO -     sim_loss       : 32.27789249420166
2025-01-21 12:01:30,426 - trainer - INFO -     gen_loss       : 0.0019912639167159797
2025-01-21 12:01:30,426 - trainer - INFO -     val_loss       : 15.511842479856568
2025-01-21 12:01:30,426 - trainer - INFO -     val_sim_loss   : 15.499565124511719
2025-01-21 12:01:30,426 - trainer - INFO -     val_gen_loss   : 0.01227761984046083
2025-01-21 12:01:30,426 - trainer - INFO -     val_perplexity : -103.65740203857422
2025-01-21 12:01:30,426 - trainer - INFO -     val_embedding_sim: 0.09438122808933258
2025-01-21 12:01:30,426 - trainer - INFO - ================================================================================
2025-01-21 12:01:30,426 - trainer - INFO - Starting epoch 142 at 2025-01-21 12:01:30
2025-01-21 12:01:34,332 - trainer - INFO - Epoch 142 completed at 2025-01-21 12:01:34
2025-01-21 12:01:34,332 - trainer - INFO -     epoch          : 142
2025-01-21 12:01:34,332 - trainer - INFO -     elapsed time   : 3.9053633213043213
2025-01-21 12:01:34,332 - trainer - INFO -     loss           : 28.28722815513611
2025-01-21 12:01:34,332 - trainer - INFO -     sim_loss       : 28.285285234451294
2025-01-21 12:01:34,332 - trainer - INFO -     gen_loss       : 0.0019427701598033309
2025-01-21 12:01:34,332 - trainer - INFO -     val_loss       : 14.70960405562073
2025-01-21 12:01:34,332 - trainer - INFO -     val_sim_loss   : 14.684293746948242
2025-01-21 12:01:34,332 - trainer - INFO -     val_gen_loss   : 0.025310441851615906
2025-01-21 12:01:34,332 - trainer - INFO -     val_perplexity : -103.68791961669922
2025-01-21 12:01:34,333 - trainer - INFO -     val_embedding_sim: 0.1005084291100502
2025-01-21 12:01:34,333 - trainer - INFO - ================================================================================
2025-01-21 12:01:34,333 - trainer - INFO - Starting epoch 143 at 2025-01-21 12:01:34
2025-01-21 12:01:38,240 - trainer - INFO - Epoch 143 completed at 2025-01-21 12:01:38
2025-01-21 12:01:38,240 - trainer - INFO -     epoch          : 143
2025-01-21 12:01:38,240 - trainer - INFO -     elapsed time   : 3.9071974754333496
2025-01-21 12:01:38,240 - trainer - INFO -     loss           : 31.850289821624756
2025-01-21 12:01:38,240 - trainer - INFO -     sim_loss       : 31.84839153289795
2025-01-21 12:01:38,240 - trainer - INFO -     gen_loss       : 0.0018980419845320284
2025-01-21 12:01:38,240 - trainer - INFO -     val_loss       : 12.128783859312534
2025-01-21 12:01:38,240 - trainer - INFO -     val_sim_loss   : 12.103471755981445
2025-01-21 12:01:38,240 - trainer - INFO -     val_gen_loss   : 0.02531203906983137
2025-01-21 12:01:38,240 - trainer - INFO -     val_perplexity : -103.79103088378906
2025-01-21 12:01:38,240 - trainer - INFO -     val_embedding_sim: 0.07211025059223175
2025-01-21 12:01:38,240 - trainer - INFO - ================================================================================
2025-01-21 12:01:38,240 - trainer - INFO - Starting epoch 144 at 2025-01-21 12:01:38
2025-01-21 12:01:42,139 - trainer - INFO - Epoch 144 completed at 2025-01-21 12:01:42
2025-01-21 12:01:42,139 - trainer - INFO -     epoch          : 144
2025-01-21 12:01:42,139 - trainer - INFO -     elapsed time   : 3.8981494903564453
2025-01-21 12:01:42,139 - trainer - INFO -     loss           : 27.591489124298096
2025-01-21 12:01:42,139 - trainer - INFO -     sim_loss       : 27.589566802978517
2025-01-21 12:01:42,139 - trainer - INFO -     gen_loss       : 0.0019219780806452036
2025-01-21 12:01:42,139 - trainer - INFO -     val_loss       : 18.59516881183663
2025-01-21 12:01:42,139 - trainer - INFO -     val_sim_loss   : 18.582988739013672
2025-01-21 12:01:42,139 - trainer - INFO -     val_gen_loss   : 0.012180839301436208
2025-01-21 12:01:42,139 - trainer - INFO -     val_perplexity : -105.15059661865234
2025-01-21 12:01:42,139 - trainer - INFO -     val_embedding_sim: 0.08034288883209229
2025-01-21 12:01:42,139 - trainer - INFO - ================================================================================
2025-01-21 12:01:42,139 - trainer - INFO - Starting epoch 145 at 2025-01-21 12:01:42
2025-01-21 12:01:46,040 - trainer - INFO - Epoch 145 completed at 2025-01-21 12:01:46
2025-01-21 12:01:46,040 - trainer - INFO -     epoch          : 145
2025-01-21 12:01:46,040 - trainer - INFO -     elapsed time   : 3.9002339839935303
2025-01-21 12:01:46,040 - trainer - INFO -     loss           : 30.424525499343872
2025-01-21 12:01:46,040 - trainer - INFO -     sim_loss       : 30.422628021240236
2025-01-21 12:01:46,040 - trainer - INFO -     gen_loss       : 0.001897885394282639
2025-01-21 12:01:46,040 - trainer - INFO -     val_loss       : 10.643319140886888
2025-01-21 12:01:46,040 - trainer - INFO -     val_sim_loss   : 10.629252433776855
2025-01-21 12:01:46,040 - trainer - INFO -     val_gen_loss   : 0.014066240517422557
2025-01-21 12:01:46,040 - trainer - INFO -     val_perplexity : -105.29051208496094
2025-01-21 12:01:46,040 - trainer - INFO -     val_embedding_sim: 0.07455082982778549
2025-01-21 12:01:51,343 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch145.pth ...
2025-01-21 12:01:51,343 - trainer - INFO - ================================================================================
2025-01-21 12:01:51,343 - trainer - INFO - Starting epoch 146 at 2025-01-21 12:01:51
2025-01-21 12:01:55,323 - trainer - INFO - Epoch 146 completed at 2025-01-21 12:01:55
2025-01-21 12:01:55,323 - trainer - INFO -     epoch          : 146
2025-01-21 12:01:55,323 - trainer - INFO -     elapsed time   : 3.979353189468384
2025-01-21 12:01:55,323 - trainer - INFO -     loss           : 28.299777221679687
2025-01-21 12:01:55,323 - trainer - INFO -     sim_loss       : 28.297870254516603
2025-01-21 12:01:55,323 - trainer - INFO -     gen_loss       : 0.00190726057626307
2025-01-21 12:01:55,323 - trainer - INFO -     val_loss       : 13.050076983869076
2025-01-21 12:01:55,323 - trainer - INFO -     val_sim_loss   : 13.030252456665039
2025-01-21 12:01:55,323 - trainer - INFO -     val_gen_loss   : 0.019824611954391003
2025-01-21 12:01:55,323 - trainer - INFO -     val_perplexity : -103.27958679199219
2025-01-21 12:01:55,323 - trainer - INFO -     val_embedding_sim: 0.06537802517414093
2025-01-21 12:01:55,323 - trainer - INFO - ================================================================================
2025-01-21 12:01:55,323 - trainer - INFO - Starting epoch 147 at 2025-01-21 12:01:55
2025-01-21 12:01:59,226 - trainer - INFO - Epoch 147 completed at 2025-01-21 12:01:59
2025-01-21 12:01:59,226 - trainer - INFO -     epoch          : 147
2025-01-21 12:01:59,226 - trainer - INFO -     elapsed time   : 3.9021756649017334
2025-01-21 12:01:59,226 - trainer - INFO -     loss           : 29.62638521194458
2025-01-21 12:01:59,226 - trainer - INFO -     sim_loss       : 29.62435989379883
2025-01-21 12:01:59,226 - trainer - INFO -     gen_loss       : 0.0020249985973350704
2025-01-21 12:01:59,226 - trainer - INFO -     val_loss       : 16.369318578203092
2025-01-21 12:01:59,226 - trainer - INFO -     val_sim_loss   : 16.357608795166016
2025-01-21 12:01:59,226 - trainer - INFO -     val_gen_loss   : 0.011710166741977446
2025-01-21 12:01:59,226 - trainer - INFO -     val_perplexity : -104.63484954833984
2025-01-21 12:01:59,226 - trainer - INFO -     val_embedding_sim: 0.09929976612329483
2025-01-21 12:01:59,226 - trainer - INFO - ================================================================================
2025-01-21 12:01:59,226 - trainer - INFO - Starting epoch 148 at 2025-01-21 12:01:59
2025-01-21 12:02:03,109 - trainer - INFO - Epoch 148 completed at 2025-01-21 12:02:03
2025-01-21 12:02:03,109 - trainer - INFO -     epoch          : 148
2025-01-21 12:02:03,109 - trainer - INFO -     elapsed time   : 3.8823704719543457
2025-01-21 12:02:03,109 - trainer - INFO -     loss           : 33.79717149734497
2025-01-21 12:02:03,109 - trainer - INFO -     sim_loss       : 33.795286083221434
2025-01-21 12:02:03,109 - trainer - INFO -     gen_loss       : 0.0018855244969017803
2025-01-21 12:02:03,109 - trainer - INFO -     val_loss       : 14.921769158914685
2025-01-21 12:02:03,109 - trainer - INFO -     val_sim_loss   : 14.8944730758667
2025-01-21 12:02:03,109 - trainer - INFO -     val_gen_loss   : 0.027296549640595913
2025-01-21 12:02:03,109 - trainer - INFO -     val_perplexity : -104.4251937866211
2025-01-21 12:02:03,109 - trainer - INFO -     val_embedding_sim: 0.07496768981218338
2025-01-21 12:02:03,109 - trainer - INFO - ================================================================================
2025-01-21 12:02:03,109 - trainer - INFO - Starting epoch 149 at 2025-01-21 12:02:03
2025-01-21 12:02:07,010 - trainer - INFO - Epoch 149 completed at 2025-01-21 12:02:07
2025-01-21 12:02:07,010 - trainer - INFO -     epoch          : 149
2025-01-21 12:02:07,010 - trainer - INFO -     elapsed time   : 3.900657892227173
2025-01-21 12:02:07,010 - trainer - INFO -     loss           : 31.714997863769533
2025-01-21 12:02:07,010 - trainer - INFO -     sim_loss       : 31.713235473632814
2025-01-21 12:02:07,010 - trainer - INFO -     gen_loss       : 0.0017626378801651299
2025-01-21 12:02:07,010 - trainer - INFO -     val_loss       : 14.32582088187337
2025-01-21 12:02:07,010 - trainer - INFO -     val_sim_loss   : 14.269857406616211
2025-01-21 12:02:07,010 - trainer - INFO -     val_gen_loss   : 0.05596391670405865
2025-01-21 12:02:07,010 - trainer - INFO -     val_perplexity : -104.85414123535156
2025-01-21 12:02:07,011 - trainer - INFO -     val_embedding_sim: 0.07490445673465729
2025-01-21 12:02:07,011 - trainer - INFO - ================================================================================
2025-01-21 12:02:07,011 - trainer - INFO - Starting epoch 150 at 2025-01-21 12:02:07
2025-01-21 12:02:10,910 - trainer - INFO - Epoch 150 completed at 2025-01-21 12:02:10
2025-01-21 12:02:10,910 - trainer - INFO -     epoch          : 150
2025-01-21 12:02:10,910 - trainer - INFO -     elapsed time   : 3.8995423316955566
2025-01-21 12:02:10,911 - trainer - INFO -     loss           : 33.18263416290283
2025-01-21 12:02:10,911 - trainer - INFO -     sim_loss       : 33.180904960632326
2025-01-21 12:02:10,911 - trainer - INFO -     gen_loss       : 0.0017296671285293996
2025-01-21 12:02:10,911 - trainer - INFO -     val_loss       : 15.682968456298113
2025-01-21 12:02:10,911 - trainer - INFO -     val_sim_loss   : 15.668428421020508
2025-01-21 12:02:10,911 - trainer - INFO -     val_gen_loss   : 0.014540494419634342
2025-01-21 12:02:10,911 - trainer - INFO -     val_perplexity : -104.29109191894531
2025-01-21 12:02:10,911 - trainer - INFO -     val_embedding_sim: 0.07810290902853012
2025-01-21 12:02:16,225 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch150.pth ...
2025-01-21 12:02:16,226 - trainer - INFO - ================================================================================
2025-01-21 12:02:16,226 - trainer - INFO - Starting epoch 151 at 2025-01-21 12:02:16
2025-01-21 12:02:20,174 - trainer - INFO - Epoch 151 completed at 2025-01-21 12:02:20
2025-01-21 12:02:20,174 - trainer - INFO -     epoch          : 151
2025-01-21 12:02:20,174 - trainer - INFO -     elapsed time   : 3.9476845264434814
2025-01-21 12:02:20,174 - trainer - INFO -     loss           : 32.98502101898193
2025-01-21 12:02:20,174 - trainer - INFO -     sim_loss       : 32.983261299133304
2025-01-21 12:02:20,174 - trainer - INFO -     gen_loss       : 0.001759718160610646
2025-01-21 12:02:20,174 - trainer - INFO -     val_loss       : 16.85276948560204
2025-01-21 12:02:20,174 - trainer - INFO -     val_sim_loss   : 16.84096908569336
2025-01-21 12:02:20,174 - trainer - INFO -     val_gen_loss   : 0.011800187567132525
2025-01-21 12:02:20,174 - trainer - INFO -     val_perplexity : -104.18050384521484
2025-01-21 12:02:20,174 - trainer - INFO -     val_embedding_sim: 0.09260527789592743
2025-01-21 12:02:20,174 - trainer - INFO - ================================================================================
2025-01-21 12:02:20,174 - trainer - INFO - Starting epoch 152 at 2025-01-21 12:02:20
2025-01-21 12:02:24,071 - trainer - INFO - Epoch 152 completed at 2025-01-21 12:02:24
2025-01-21 12:02:24,071 - trainer - INFO -     epoch          : 152
2025-01-21 12:02:24,071 - trainer - INFO -     elapsed time   : 3.896466016769409
2025-01-21 12:02:24,071 - trainer - INFO -     loss           : 29.853687524795532
2025-01-21 12:02:24,071 - trainer - INFO -     sim_loss       : 29.851953411102294
2025-01-21 12:02:24,071 - trainer - INFO -     gen_loss       : 0.0017337500234134496
2025-01-21 12:02:24,071 - trainer - INFO -     val_loss       : 28.479505342897028
2025-01-21 12:02:24,071 - trainer - INFO -     val_sim_loss   : 28.467296600341797
2025-01-21 12:02:24,071 - trainer - INFO -     val_gen_loss   : 0.012208175379782915
2025-01-21 12:02:24,071 - trainer - INFO -     val_perplexity : -105.60030364990234
2025-01-21 12:02:24,071 - trainer - INFO -     val_embedding_sim: 0.07543687522411346
2025-01-21 12:02:24,071 - trainer - INFO - ================================================================================
2025-01-21 12:02:24,071 - trainer - INFO - Starting epoch 153 at 2025-01-21 12:02:24
2025-01-21 12:02:27,963 - trainer - INFO - Epoch 153 completed at 2025-01-21 12:02:27
2025-01-21 12:02:27,963 - trainer - INFO -     epoch          : 153
2025-01-21 12:02:27,963 - trainer - INFO -     elapsed time   : 3.891789674758911
2025-01-21 12:02:27,963 - trainer - INFO -     loss           : 25.161406993865967
2025-01-21 12:02:27,963 - trainer - INFO -     sim_loss       : 25.15974340438843
2025-01-21 12:02:27,963 - trainer - INFO -     gen_loss       : 0.0016638022265397013
2025-01-21 12:02:27,963 - trainer - INFO -     val_loss       : 13.988971276208758
2025-01-21 12:02:27,963 - trainer - INFO -     val_sim_loss   : 13.9623384475708
2025-01-21 12:02:27,964 - trainer - INFO -     val_gen_loss   : 0.02663244493305683
2025-01-21 12:02:27,964 - trainer - INFO -     val_perplexity : -104.60975646972656
2025-01-21 12:02:27,964 - trainer - INFO -     val_embedding_sim: 0.07261417806148529
2025-01-21 12:02:27,964 - trainer - INFO - ================================================================================
2025-01-21 12:02:27,964 - trainer - INFO - Starting epoch 154 at 2025-01-21 12:02:27
2025-01-21 12:02:31,861 - trainer - INFO - Epoch 154 completed at 2025-01-21 12:02:31
2025-01-21 12:02:31,862 - trainer - INFO -     epoch          : 154
2025-01-21 12:02:31,862 - trainer - INFO -     elapsed time   : 3.897569417953491
2025-01-21 12:02:31,862 - trainer - INFO -     loss           : 28.341568660736083
2025-01-21 12:02:31,862 - trainer - INFO -     sim_loss       : 28.33987741470337
2025-01-21 12:02:31,862 - trainer - INFO -     gen_loss       : 0.0016916135558858515
2025-01-21 12:02:31,862 - trainer - INFO -     val_loss       : 13.119364976635552
2025-01-21 12:02:31,862 - trainer - INFO -     val_sim_loss   : 13.10789966583252
2025-01-21 12:02:31,862 - trainer - INFO -     val_gen_loss   : 0.011465116156614386
2025-01-21 12:02:31,862 - trainer - INFO -     val_perplexity : -104.92735290527344
2025-01-21 12:02:31,862 - trainer - INFO -     val_embedding_sim: 0.09535597264766693
2025-01-21 12:02:31,862 - trainer - INFO - ================================================================================
2025-01-21 12:02:31,862 - trainer - INFO - Starting epoch 155 at 2025-01-21 12:02:31
2025-01-21 12:02:35,748 - trainer - INFO - Epoch 155 completed at 2025-01-21 12:02:35
2025-01-21 12:02:35,748 - trainer - INFO -     epoch          : 155
2025-01-21 12:02:35,748 - trainer - INFO -     elapsed time   : 3.8856678009033203
2025-01-21 12:02:35,748 - trainer - INFO -     loss           : 34.0069818019867
2025-01-21 12:02:35,748 - trainer - INFO -     sim_loss       : 34.0052752494812
2025-01-21 12:02:35,748 - trainer - INFO -     gen_loss       : 0.0017061935388483108
2025-01-21 12:02:35,748 - trainer - INFO -     val_loss       : 14.055117920041084
2025-01-21 12:02:35,748 - trainer - INFO -     val_sim_loss   : 14.04056167602539
2025-01-21 12:02:35,748 - trainer - INFO -     val_gen_loss   : 0.014555844478309155
2025-01-21 12:02:35,748 - trainer - INFO -     val_perplexity : -104.63957214355469
2025-01-21 12:02:35,748 - trainer - INFO -     val_embedding_sim: 0.09495403617620468
2025-01-21 12:02:41,064 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch155.pth ...
2025-01-21 12:02:41,064 - trainer - INFO - ================================================================================
2025-01-21 12:02:41,064 - trainer - INFO - Starting epoch 156 at 2025-01-21 12:02:41
2025-01-21 12:02:45,038 - trainer - INFO - Epoch 156 completed at 2025-01-21 12:02:45
2025-01-21 12:02:45,038 - trainer - INFO -     epoch          : 156
2025-01-21 12:02:45,038 - trainer - INFO -     elapsed time   : 3.9735970497131348
2025-01-21 12:02:45,038 - trainer - INFO -     loss           : 33.542083215713504
2025-01-21 12:02:45,038 - trainer - INFO -     sim_loss       : 33.540468502044675
2025-01-21 12:02:45,038 - trainer - INFO -     gen_loss       : 0.0016146224224939942
2025-01-21 12:02:45,038 - trainer - INFO -     val_loss       : 16.927649173885584
2025-01-21 12:02:45,038 - trainer - INFO -     val_sim_loss   : 16.874177932739258
2025-01-21 12:02:45,038 - trainer - INFO -     val_gen_loss   : 0.05347066093236208
2025-01-21 12:02:45,038 - trainer - INFO -     val_perplexity : -105.76518249511719
2025-01-21 12:02:45,038 - trainer - INFO -     val_embedding_sim: 0.07118041068315506
2025-01-21 12:02:45,038 - trainer - INFO - ================================================================================
2025-01-21 12:02:45,038 - trainer - INFO - Starting epoch 157 at 2025-01-21 12:02:45
2025-01-21 12:02:48,947 - trainer - INFO - Epoch 157 completed at 2025-01-21 12:02:48
2025-01-21 12:02:48,947 - trainer - INFO -     epoch          : 157
2025-01-21 12:02:48,947 - trainer - INFO -     elapsed time   : 3.9088501930236816
2025-01-21 12:02:48,948 - trainer - INFO -     loss           : 31.560856294631957
2025-01-21 12:02:48,948 - trainer - INFO -     sim_loss       : 31.559197092056273
2025-01-21 12:02:48,948 - trainer - INFO -     gen_loss       : 0.0016592257306911051
2025-01-21 12:02:48,948 - trainer - INFO -     val_loss       : 14.790131241330528
2025-01-21 12:02:48,948 - trainer - INFO -     val_sim_loss   : 14.778369903564453
2025-01-21 12:02:48,948 - trainer - INFO -     val_gen_loss   : 0.01176144766213838
2025-01-21 12:02:48,948 - trainer - INFO -     val_perplexity : -103.93983459472656
2025-01-21 12:02:48,948 - trainer - INFO -     val_embedding_sim: 0.07614731788635254
2025-01-21 12:02:48,948 - trainer - INFO - ================================================================================
2025-01-21 12:02:48,948 - trainer - INFO - Starting epoch 158 at 2025-01-21 12:02:48
2025-01-21 12:02:52,850 - trainer - INFO - Epoch 158 completed at 2025-01-21 12:02:52
2025-01-21 12:02:52,850 - trainer - INFO -     epoch          : 158
2025-01-21 12:02:52,850 - trainer - INFO -     elapsed time   : 3.9019808769226074
2025-01-21 12:02:52,850 - trainer - INFO -     loss           : 30.831036615371705
2025-01-21 12:02:52,850 - trainer - INFO -     sim_loss       : 30.82930130958557
2025-01-21 12:02:52,850 - trainer - INFO -     gen_loss       : 0.001734858052805066
2025-01-21 12:02:52,850 - trainer - INFO -     val_loss       : 16.170146623742767
2025-01-21 12:02:52,850 - trainer - INFO -     val_sim_loss   : 16.15671157836914
2025-01-21 12:02:52,850 - trainer - INFO -     val_gen_loss   : 0.013435194385237992
2025-01-21 12:02:52,850 - trainer - INFO -     val_perplexity : -105.77430725097656
2025-01-21 12:02:52,850 - trainer - INFO -     val_embedding_sim: 0.07928940653800964
2025-01-21 12:02:52,850 - trainer - INFO - ================================================================================
2025-01-21 12:02:52,850 - trainer - INFO - Starting epoch 159 at 2025-01-21 12:02:52
2025-01-21 12:02:56,743 - trainer - INFO - Epoch 159 completed at 2025-01-21 12:02:56
2025-01-21 12:02:56,743 - trainer - INFO -     epoch          : 159
2025-01-21 12:02:56,743 - trainer - INFO -     elapsed time   : 3.8922877311706543
2025-01-21 12:02:56,743 - trainer - INFO -     loss           : 26.512013053894044
2025-01-21 12:02:56,743 - trainer - INFO -     sim_loss       : 26.510261154174806
2025-01-21 12:02:56,743 - trainer - INFO -     gen_loss       : 0.0017514013103209435
2025-01-21 12:02:56,743 - trainer - INFO -     val_loss       : 24.758733505383134
2025-01-21 12:02:56,743 - trainer - INFO -     val_sim_loss   : 24.729856491088867
2025-01-21 12:02:56,743 - trainer - INFO -     val_gen_loss   : 0.028876714408397675
2025-01-21 12:02:56,743 - trainer - INFO -     val_perplexity : -104.3665771484375
2025-01-21 12:02:56,743 - trainer - INFO -     val_embedding_sim: 0.038776807487010956
2025-01-21 12:02:56,743 - trainer - INFO - ================================================================================
2025-01-21 12:02:56,744 - trainer - INFO - Starting epoch 160 at 2025-01-21 12:02:56
2025-01-21 12:03:00,608 - trainer - INFO - Epoch 160 completed at 2025-01-21 12:03:00
2025-01-21 12:03:00,608 - trainer - INFO -     epoch          : 160
2025-01-21 12:03:00,608 - trainer - INFO -     elapsed time   : 3.864403247833252
2025-01-21 12:03:00,608 - trainer - INFO -     loss           : 30.309137964248656
2025-01-21 12:03:00,608 - trainer - INFO -     sim_loss       : 30.307505798339843
2025-01-21 12:03:00,608 - trainer - INFO -     gen_loss       : 0.001631909317802638
2025-01-21 12:03:00,608 - trainer - INFO -     val_loss       : 14.702749978750944
2025-01-21 12:03:00,608 - trainer - INFO -     val_sim_loss   : 14.682292938232422
2025-01-21 12:03:00,608 - trainer - INFO -     val_gen_loss   : 0.02045744936913252
2025-01-21 12:03:00,609 - trainer - INFO -     val_perplexity : -105.99565124511719
2025-01-21 12:03:00,609 - trainer - INFO -     val_embedding_sim: 0.10469065606594086
2025-01-21 12:03:05,910 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch160.pth ...
2025-01-21 12:03:05,911 - trainer - INFO - ================================================================================
2025-01-21 12:03:05,911 - trainer - INFO - Starting epoch 161 at 2025-01-21 12:03:05
2025-01-21 12:03:09,910 - trainer - INFO - Epoch 161 completed at 2025-01-21 12:03:09
2025-01-21 12:03:09,910 - trainer - INFO -     epoch          : 161
2025-01-21 12:03:09,910 - trainer - INFO -     elapsed time   : 3.998955726623535
2025-01-21 12:03:09,910 - trainer - INFO -     loss           : 28.37103705406189
2025-01-21 12:03:09,910 - trainer - INFO -     sim_loss       : 28.36945757865906
2025-01-21 12:03:09,910 - trainer - INFO -     gen_loss       : 0.0015792874502949417
2025-01-21 12:03:09,910 - trainer - INFO -     val_loss       : 23.714742314070463
2025-01-21 12:03:09,910 - trainer - INFO -     val_sim_loss   : 23.652692794799805
2025-01-21 12:03:09,910 - trainer - INFO -     val_gen_loss   : 0.06205027177929878
2025-01-21 12:03:09,910 - trainer - INFO -     val_perplexity : -105.38656616210938
2025-01-21 12:03:09,910 - trainer - INFO -     val_embedding_sim: 0.08069218695163727
2025-01-21 12:03:09,910 - trainer - INFO - ================================================================================
2025-01-21 12:03:09,911 - trainer - INFO - Starting epoch 162 at 2025-01-21 12:03:09
2025-01-21 12:03:13,819 - trainer - INFO - Epoch 162 completed at 2025-01-21 12:03:13
2025-01-21 12:03:13,819 - trainer - INFO -     epoch          : 162
2025-01-21 12:03:13,819 - trainer - INFO -     elapsed time   : 3.9080793857574463
2025-01-21 12:03:13,819 - trainer - INFO -     loss           : 31.770415687561034
2025-01-21 12:03:13,819 - trainer - INFO -     sim_loss       : 31.768829250335692
2025-01-21 12:03:13,819 - trainer - INFO -     gen_loss       : 0.0015866185538470745
2025-01-21 12:03:13,819 - trainer - INFO -     val_loss       : 14.370088752359152
2025-01-21 12:03:13,819 - trainer - INFO -     val_sim_loss   : 14.344453811645508
2025-01-21 12:03:13,819 - trainer - INFO -     val_gen_loss   : 0.0256348829716444
2025-01-21 12:03:13,819 - trainer - INFO -     val_perplexity : -105.00164794921875
2025-01-21 12:03:13,819 - trainer - INFO -     val_embedding_sim: 0.07030491530895233
2025-01-21 12:03:13,819 - trainer - INFO - ================================================================================
2025-01-21 12:03:13,819 - trainer - INFO - Starting epoch 163 at 2025-01-21 12:03:13
2025-01-21 12:03:17,724 - trainer - INFO - Epoch 163 completed at 2025-01-21 12:03:17
2025-01-21 12:03:17,724 - trainer - INFO -     epoch          : 163
2025-01-21 12:03:17,724 - trainer - INFO -     elapsed time   : 3.9042351245880127
2025-01-21 12:03:17,724 - trainer - INFO -     loss           : 30.777704334259035
2025-01-21 12:03:17,724 - trainer - INFO -     sim_loss       : 30.776099729537965
2025-01-21 12:03:17,724 - trainer - INFO -     gen_loss       : 0.0016048608580604196
2025-01-21 12:03:17,724 - trainer - INFO -     val_loss       : 14.97430963953957
2025-01-21 12:03:17,724 - trainer - INFO -     val_sim_loss   : 14.961372375488281
2025-01-21 12:03:17,724 - trainer - INFO -     val_gen_loss   : 0.012936880346387625
2025-01-21 12:03:17,724 - trainer - INFO -     val_perplexity : -106.11337280273438
2025-01-21 12:03:17,724 - trainer - INFO -     val_embedding_sim: 0.07610344886779785
2025-01-21 12:03:17,724 - trainer - INFO - ================================================================================
2025-01-21 12:03:17,724 - trainer - INFO - Starting epoch 164 at 2025-01-21 12:03:17
2025-01-21 12:03:21,616 - trainer - INFO - Epoch 164 completed at 2025-01-21 12:03:21
2025-01-21 12:03:21,616 - trainer - INFO -     epoch          : 164
2025-01-21 12:03:21,616 - trainer - INFO -     elapsed time   : 3.891409158706665
2025-01-21 12:03:21,616 - trainer - INFO -     loss           : 32.75773148536682
2025-01-21 12:03:21,616 - trainer - INFO -     sim_loss       : 32.7562029838562
2025-01-21 12:03:21,616 - trainer - INFO -     gen_loss       : 0.001528190728276968
2025-01-21 12:03:21,616 - trainer - INFO -     val_loss       : 17.730534902890213
2025-01-21 12:03:21,616 - trainer - INFO -     val_sim_loss   : 17.718482971191406
2025-01-21 12:03:21,616 - trainer - INFO -     val_gen_loss   : 0.012051961501128972
2025-01-21 12:03:21,616 - trainer - INFO -     val_perplexity : -106.81475067138672
2025-01-21 12:03:21,616 - trainer - INFO -     val_embedding_sim: 0.06615392863750458
2025-01-21 12:03:21,616 - trainer - INFO - ================================================================================
2025-01-21 12:03:21,616 - trainer - INFO - Starting epoch 165 at 2025-01-21 12:03:21
2025-01-21 12:03:25,518 - trainer - INFO - Epoch 165 completed at 2025-01-21 12:03:25
2025-01-21 12:03:25,518 - trainer - INFO -     epoch          : 165
2025-01-21 12:03:25,518 - trainer - INFO -     elapsed time   : 3.9015557765960693
2025-01-21 12:03:25,518 - trainer - INFO -     loss           : 26.89329652786255
2025-01-21 12:03:25,518 - trainer - INFO -     sim_loss       : 26.89179368019104
2025-01-21 12:03:25,518 - trainer - INFO -     gen_loss       : 0.0015027562621980906
2025-01-21 12:03:25,519 - trainer - INFO -     val_loss       : 11.430995093658566
2025-01-21 12:03:25,519 - trainer - INFO -     val_sim_loss   : 11.40388298034668
2025-01-21 12:03:25,519 - trainer - INFO -     val_gen_loss   : 0.027111788280308247
2025-01-21 12:03:25,519 - trainer - INFO -     val_perplexity : -104.66111755371094
2025-01-21 12:03:25,519 - trainer - INFO -     val_embedding_sim: 0.07807724177837372
2025-01-21 12:03:30,830 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch165.pth ...
2025-01-21 12:03:30,830 - trainer - INFO - ================================================================================
2025-01-21 12:03:30,830 - trainer - INFO - Starting epoch 166 at 2025-01-21 12:03:30
2025-01-21 12:03:34,804 - trainer - INFO - Epoch 166 completed at 2025-01-21 12:03:34
2025-01-21 12:03:34,804 - trainer - INFO -     epoch          : 166
2025-01-21 12:03:34,805 - trainer - INFO -     elapsed time   : 3.97367787361145
2025-01-21 12:03:34,805 - trainer - INFO -     loss           : 26.864732456207275
2025-01-21 12:03:34,805 - trainer - INFO -     sim_loss       : 26.86304416656494
2025-01-21 12:03:34,805 - trainer - INFO -     gen_loss       : 0.001688327849842608
2025-01-21 12:03:34,805 - trainer - INFO -     val_loss       : 19.125246373863774
2025-01-21 12:03:34,805 - trainer - INFO -     val_sim_loss   : 19.113082885742188
2025-01-21 12:03:34,805 - trainer - INFO -     val_gen_loss   : 0.01216279149230104
2025-01-21 12:03:34,805 - trainer - INFO -     val_perplexity : -104.74839782714844
2025-01-21 12:03:34,805 - trainer - INFO -     val_embedding_sim: 0.059326522052288055
2025-01-21 12:03:34,805 - trainer - INFO - ================================================================================
2025-01-21 12:03:34,805 - trainer - INFO - Starting epoch 167 at 2025-01-21 12:03:34
2025-01-21 12:03:38,697 - trainer - INFO - Epoch 167 completed at 2025-01-21 12:03:38
2025-01-21 12:03:38,697 - trainer - INFO -     epoch          : 167
2025-01-21 12:03:38,697 - trainer - INFO -     elapsed time   : 3.8920505046844482
2025-01-21 12:03:38,697 - trainer - INFO -     loss           : 31.891022205352783
2025-01-21 12:03:38,697 - trainer - INFO -     sim_loss       : 31.889143180847167
2025-01-21 12:03:38,697 - trainer - INFO -     gen_loss       : 0.00187875812407583
2025-01-21 12:03:38,697 - trainer - INFO -     val_loss       : 8.914701951667666
2025-01-21 12:03:38,697 - trainer - INFO -     val_sim_loss   : 8.899667739868164
2025-01-21 12:03:38,697 - trainer - INFO -     val_gen_loss   : 0.015034325420856476
2025-01-21 12:03:38,698 - trainer - INFO -     val_perplexity : -104.06458282470703
2025-01-21 12:03:38,698 - trainer - INFO -     val_embedding_sim: 0.07664396613836288
2025-01-21 12:03:38,698 - trainer - INFO - ================================================================================
2025-01-21 12:03:38,698 - trainer - INFO - Starting epoch 168 at 2025-01-21 12:03:38
2025-01-21 12:03:42,595 - trainer - INFO - Epoch 168 completed at 2025-01-21 12:03:42
2025-01-21 12:03:42,595 - trainer - INFO -     epoch          : 168
2025-01-21 12:03:42,596 - trainer - INFO -     elapsed time   : 3.897548198699951
2025-01-21 12:03:42,596 - trainer - INFO -     loss           : 27.62136039733887
2025-01-21 12:03:42,596 - trainer - INFO -     sim_loss       : 27.619731140136718
2025-01-21 12:03:42,596 - trainer - INFO -     gen_loss       : 0.0016291564214043319
2025-01-21 12:03:42,596 - trainer - INFO -     val_loss       : 19.67648259550333
2025-01-21 12:03:42,596 - trainer - INFO -     val_sim_loss   : 19.652557373046875
2025-01-21 12:03:42,596 - trainer - INFO -     val_gen_loss   : 0.02392584178596735
2025-01-21 12:03:42,596 - trainer - INFO -     val_perplexity : -105.02645111083984
2025-01-21 12:03:42,596 - trainer - INFO -     val_embedding_sim: 0.06555357575416565
2025-01-21 12:03:42,596 - trainer - INFO - ================================================================================
2025-01-21 12:03:42,596 - trainer - INFO - Starting epoch 169 at 2025-01-21 12:03:42
2025-01-21 12:03:46,497 - trainer - INFO - Epoch 169 completed at 2025-01-21 12:03:46
2025-01-21 12:03:46,497 - trainer - INFO -     epoch          : 169
2025-01-21 12:03:46,497 - trainer - INFO -     elapsed time   : 3.900886058807373
2025-01-21 12:03:46,497 - trainer - INFO -     loss           : 31.91024652719498
2025-01-21 12:03:46,497 - trainer - INFO -     sim_loss       : 31.908761143684387
2025-01-21 12:03:46,497 - trainer - INFO -     gen_loss       : 0.0014855327550321817
2025-01-21 12:03:46,497 - trainer - INFO -     val_loss       : 15.469933351683721
2025-01-21 12:03:46,497 - trainer - INFO -     val_sim_loss   : 15.45903491973877
2025-01-21 12:03:46,497 - trainer - INFO -     val_gen_loss   : 0.01089810691337334
2025-01-21 12:03:46,497 - trainer - INFO -     val_perplexity : -106.18257141113281
2025-01-21 12:03:46,497 - trainer - INFO -     val_embedding_sim: 0.08975455164909363
2025-01-21 12:03:46,497 - trainer - INFO - ================================================================================
2025-01-21 12:03:46,497 - trainer - INFO - Starting epoch 170 at 2025-01-21 12:03:46
2025-01-21 12:03:50,369 - trainer - INFO - Epoch 170 completed at 2025-01-21 12:03:50
2025-01-21 12:03:50,369 - trainer - INFO -     epoch          : 170
2025-01-21 12:03:50,369 - trainer - INFO -     elapsed time   : 3.8710973262786865
2025-01-21 12:03:50,369 - trainer - INFO -     loss           : 29.29076156616211
2025-01-21 12:03:50,369 - trainer - INFO -     sim_loss       : 29.289137840270996
2025-01-21 12:03:50,369 - trainer - INFO -     gen_loss       : 0.0016235836781561374
2025-01-21 12:03:50,369 - trainer - INFO -     val_loss       : 13.320141887990758
2025-01-21 12:03:50,369 - trainer - INFO -     val_sim_loss   : 13.305588722229004
2025-01-21 12:03:50,369 - trainer - INFO -     val_gen_loss   : 0.014553329674527049
2025-01-21 12:03:50,369 - trainer - INFO -     val_perplexity : -103.9935531616211
2025-01-21 12:03:50,369 - trainer - INFO -     val_embedding_sim: 0.06515894085168839
2025-01-21 12:03:55,682 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch170.pth ...
2025-01-21 12:03:55,682 - trainer - INFO - ================================================================================
2025-01-21 12:03:55,682 - trainer - INFO - Starting epoch 171 at 2025-01-21 12:03:55
2025-01-21 12:03:59,643 - trainer - INFO - Epoch 171 completed at 2025-01-21 12:03:59
2025-01-21 12:03:59,643 - trainer - INFO -     epoch          : 171
2025-01-21 12:03:59,643 - trainer - INFO -     elapsed time   : 3.9605677127838135
2025-01-21 12:03:59,643 - trainer - INFO -     loss           : 28.875340938568115
2025-01-21 12:03:59,643 - trainer - INFO -     sim_loss       : 28.873533916473388
2025-01-21 12:03:59,643 - trainer - INFO -     gen_loss       : 0.001807462051510811
2025-01-21 12:03:59,643 - trainer - INFO -     val_loss       : 13.04642204940319
2025-01-21 12:03:59,643 - trainer - INFO -     val_sim_loss   : 13.021621704101562
2025-01-21 12:03:59,643 - trainer - INFO -     val_gen_loss   : 0.024800327606499195
2025-01-21 12:03:59,643 - trainer - INFO -     val_perplexity : -104.19336700439453
2025-01-21 12:03:59,643 - trainer - INFO -     val_embedding_sim: 0.07333521544933319
2025-01-21 12:03:59,643 - trainer - INFO - ================================================================================
2025-01-21 12:03:59,644 - trainer - INFO - Starting epoch 172 at 2025-01-21 12:03:59
2025-01-21 12:04:03,498 - trainer - INFO - Epoch 172 completed at 2025-01-21 12:04:03
2025-01-21 12:04:03,499 - trainer - INFO -     epoch          : 172
2025-01-21 12:04:03,499 - trainer - INFO -     elapsed time   : 3.854783296585083
2025-01-21 12:04:03,499 - trainer - INFO -     loss           : 26.415783071517943
2025-01-21 12:04:03,499 - trainer - INFO -     sim_loss       : 26.41427364349365
2025-01-21 12:04:03,499 - trainer - INFO -     gen_loss       : 0.0015091332723386585
2025-01-21 12:04:03,499 - trainer - INFO -     val_loss       : 21.76756542424846
2025-01-21 12:04:03,499 - trainer - INFO -     val_sim_loss   : 21.756258010864258
2025-01-21 12:04:03,499 - trainer - INFO -     val_gen_loss   : 0.011308252505841665
2025-01-21 12:04:03,499 - trainer - INFO -     val_perplexity : -105.94700622558594
2025-01-21 12:04:03,499 - trainer - INFO -     val_embedding_sim: 0.08970329165458679
2025-01-21 12:04:03,499 - trainer - INFO - ================================================================================
2025-01-21 12:04:03,499 - trainer - INFO - Starting epoch 173 at 2025-01-21 12:04:03
2025-01-21 12:04:07,388 - trainer - INFO - Epoch 173 completed at 2025-01-21 12:04:07
2025-01-21 12:04:07,388 - trainer - INFO -     epoch          : 173
2025-01-21 12:04:07,388 - trainer - INFO -     elapsed time   : 3.889096260070801
2025-01-21 12:04:07,389 - trainer - INFO -     loss           : 36.13447542190552
2025-01-21 12:04:07,389 - trainer - INFO -     sim_loss       : 36.13299121856689
2025-01-21 12:04:07,389 - trainer - INFO -     gen_loss       : 0.001484658574918285
2025-01-21 12:04:07,389 - trainer - INFO -     val_loss       : 12.672835304867476
2025-01-21 12:04:07,389 - trainer - INFO -     val_sim_loss   : 12.654751777648926
2025-01-21 12:04:07,389 - trainer - INFO -     val_gen_loss   : 0.018083210568875074
2025-01-21 12:04:07,389 - trainer - INFO -     val_perplexity : -104.3519058227539
2025-01-21 12:04:07,389 - trainer - INFO -     val_embedding_sim: 0.08029373735189438
2025-01-21 12:04:07,389 - trainer - INFO - ================================================================================
2025-01-21 12:04:07,389 - trainer - INFO - Starting epoch 174 at 2025-01-21 12:04:07
2025-01-21 12:04:11,294 - trainer - INFO - Epoch 174 completed at 2025-01-21 12:04:11
2025-01-21 12:04:11,294 - trainer - INFO -     epoch          : 174
2025-01-21 12:04:11,294 - trainer - INFO -     elapsed time   : 3.905122995376587
2025-01-21 12:04:11,294 - trainer - INFO -     loss           : 27.501386070251463
2025-01-21 12:04:11,294 - trainer - INFO -     sim_loss       : 27.499975967407227
2025-01-21 12:04:11,294 - trainer - INFO -     gen_loss       : 0.0014097737381234764
2025-01-21 12:04:11,294 - trainer - INFO -     val_loss       : 17.953398537341855
2025-01-21 12:04:11,295 - trainer - INFO -     val_sim_loss   : 17.942380905151367
2025-01-21 12:04:11,295 - trainer - INFO -     val_gen_loss   : 0.011018061530194245
2025-01-21 12:04:11,295 - trainer - INFO -     val_perplexity : -105.8263168334961
2025-01-21 12:04:11,295 - trainer - INFO -     val_embedding_sim: 0.05867844820022583
2025-01-21 12:04:11,295 - trainer - INFO - ================================================================================
2025-01-21 12:04:11,295 - trainer - INFO - Starting epoch 175 at 2025-01-21 12:04:11
2025-01-21 12:04:15,187 - trainer - INFO - Epoch 175 completed at 2025-01-21 12:04:15
2025-01-21 12:04:15,187 - trainer - INFO -     epoch          : 175
2025-01-21 12:04:15,187 - trainer - INFO -     elapsed time   : 3.891746759414673
2025-01-21 12:04:15,187 - trainer - INFO -     loss           : 30.950193405151367
2025-01-21 12:04:15,187 - trainer - INFO -     sim_loss       : 30.94882526397705
2025-01-21 12:04:15,187 - trainer - INFO -     gen_loss       : 0.0013684540172107518
2025-01-21 12:04:15,187 - trainer - INFO -     val_loss       : 12.871675873102504
2025-01-21 12:04:15,187 - trainer - INFO -     val_sim_loss   : 12.86099910736084
2025-01-21 12:04:15,187 - trainer - INFO -     val_gen_loss   : 0.010676698686438613
2025-01-21 12:04:15,187 - trainer - INFO -     val_perplexity : -106.39573669433594
2025-01-21 12:04:15,187 - trainer - INFO -     val_embedding_sim: 0.09234943985939026
2025-01-21 12:04:20,497 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch175.pth ...
2025-01-21 12:04:25,759 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 12:04:25,759 - trainer - INFO - ================================================================================
2025-01-21 12:04:25,759 - trainer - INFO - Starting epoch 176 at 2025-01-21 12:04:25
2025-01-21 12:04:29,719 - trainer - INFO - Epoch 176 completed at 2025-01-21 12:04:29
2025-01-21 12:04:29,719 - trainer - INFO -     epoch          : 176
2025-01-21 12:04:29,720 - trainer - INFO -     elapsed time   : 3.9599077701568604
2025-01-21 12:04:29,720 - trainer - INFO -     loss           : 29.82857518196106
2025-01-21 12:04:29,720 - trainer - INFO -     sim_loss       : 29.827246332168578
2025-01-21 12:04:29,720 - trainer - INFO -     gen_loss       : 0.0013287983369082213
2025-01-21 12:04:29,720 - trainer - INFO -     val_loss       : 12.226663578650914
2025-01-21 12:04:29,720 - trainer - INFO -     val_sim_loss   : 12.214900970458984
2025-01-21 12:04:29,720 - trainer - INFO -     val_gen_loss   : 0.011762819602154195
2025-01-21 12:04:29,720 - trainer - INFO -     val_perplexity : -107.31637573242188
2025-01-21 12:04:29,720 - trainer - INFO -     val_embedding_sim: 0.07881754636764526
2025-01-21 12:04:29,720 - trainer - INFO - ================================================================================
2025-01-21 12:04:29,720 - trainer - INFO - Starting epoch 177 at 2025-01-21 12:04:29
2025-01-21 12:04:33,621 - trainer - INFO - Epoch 177 completed at 2025-01-21 12:04:33
2025-01-21 12:04:33,621 - trainer - INFO -     epoch          : 177
2025-01-21 12:04:33,621 - trainer - INFO -     elapsed time   : 3.900702476501465
2025-01-21 12:04:33,621 - trainer - INFO -     loss           : 31.771638226509094
2025-01-21 12:04:33,621 - trainer - INFO -     sim_loss       : 31.770318961143495
2025-01-21 12:04:33,621 - trainer - INFO -     gen_loss       : 0.0013194799306802452
2025-01-21 12:04:33,621 - trainer - INFO -     val_loss       : 15.622873349348083
2025-01-21 12:04:33,621 - trainer - INFO -     val_sim_loss   : 15.610136985778809
2025-01-21 12:04:33,621 - trainer - INFO -     val_gen_loss   : 0.01273611863143742
2025-01-21 12:04:33,621 - trainer - INFO -     val_perplexity : -104.39852142333984
2025-01-21 12:04:33,621 - trainer - INFO -     val_embedding_sim: 0.07661646604537964
2025-01-21 12:04:33,621 - trainer - INFO - ================================================================================
2025-01-21 12:04:33,621 - trainer - INFO - Starting epoch 178 at 2025-01-21 12:04:33
2025-01-21 12:04:37,516 - trainer - INFO - Epoch 178 completed at 2025-01-21 12:04:37
2025-01-21 12:04:37,516 - trainer - INFO -     epoch          : 178
2025-01-21 12:04:37,516 - trainer - INFO -     elapsed time   : 3.894806385040283
2025-01-21 12:04:37,516 - trainer - INFO -     loss           : 24.815549087524413
2025-01-21 12:04:37,517 - trainer - INFO -     sim_loss       : 24.814203357696535
2025-01-21 12:04:37,517 - trainer - INFO -     gen_loss       : 0.001345795253291726
2025-01-21 12:04:37,517 - trainer - INFO -     val_loss       : 16.594220508355647
2025-01-21 12:04:37,517 - trainer - INFO -     val_sim_loss   : 16.575510025024414
2025-01-21 12:04:37,517 - trainer - INFO -     val_gen_loss   : 0.0187112451530993
2025-01-21 12:04:37,517 - trainer - INFO -     val_perplexity : -104.59212493896484
2025-01-21 12:04:37,517 - trainer - INFO -     val_embedding_sim: 0.0719832330942154
2025-01-21 12:04:37,517 - trainer - INFO - ================================================================================
2025-01-21 12:04:37,517 - trainer - INFO - Starting epoch 179 at 2025-01-21 12:04:37
2025-01-21 12:04:41,417 - trainer - INFO - Epoch 179 completed at 2025-01-21 12:04:41
2025-01-21 12:04:41,417 - trainer - INFO -     epoch          : 179
2025-01-21 12:04:41,417 - trainer - INFO -     elapsed time   : 3.9001612663269043
2025-01-21 12:04:41,417 - trainer - INFO -     loss           : 29.39543390274048
2025-01-21 12:04:41,417 - trainer - INFO -     sim_loss       : 29.394039344787597
2025-01-21 12:04:41,417 - trainer - INFO -     gen_loss       : 0.0013948853360489012
2025-01-21 12:04:41,417 - trainer - INFO -     val_loss       : 12.047850845163339
2025-01-21 12:04:41,418 - trainer - INFO -     val_sim_loss   : 12.035938262939453
2025-01-21 12:04:41,418 - trainer - INFO -     val_gen_loss   : 0.011913003181689419
2025-01-21 12:04:41,418 - trainer - INFO -     val_perplexity : -106.52656555175781
2025-01-21 12:04:41,418 - trainer - INFO -     val_embedding_sim: 0.07488429546356201
2025-01-21 12:04:41,418 - trainer - INFO - ================================================================================
2025-01-21 12:04:41,418 - trainer - INFO - Starting epoch 180 at 2025-01-21 12:04:41
2025-01-21 12:04:45,308 - trainer - INFO - Epoch 180 completed at 2025-01-21 12:04:45
2025-01-21 12:04:45,308 - trainer - INFO -     epoch          : 180
2025-01-21 12:04:45,308 - trainer - INFO -     elapsed time   : 3.88964581489563
2025-01-21 12:04:45,308 - trainer - INFO -     loss           : 31.430800914764404
2025-01-21 12:04:45,308 - trainer - INFO -     sim_loss       : 31.429504299163817
2025-01-21 12:04:45,308 - trainer - INFO -     gen_loss       : 0.0012968272203579545
2025-01-21 12:04:45,308 - trainer - INFO -     val_loss       : 13.781735172728077
2025-01-21 12:04:45,308 - trainer - INFO -     val_sim_loss   : 13.769302368164062
2025-01-21 12:04:45,308 - trainer - INFO -     val_gen_loss   : 0.012433106312528253
2025-01-21 12:04:45,308 - trainer - INFO -     val_perplexity : -106.90320587158203
2025-01-21 12:04:45,308 - trainer - INFO -     val_embedding_sim: 0.07183319330215454
2025-01-21 12:04:50,611 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch180.pth ...
2025-01-21 12:04:50,611 - trainer - INFO - ================================================================================
2025-01-21 12:04:50,611 - trainer - INFO - Starting epoch 181 at 2025-01-21 12:04:50
2025-01-21 12:04:54,561 - trainer - INFO - Epoch 181 completed at 2025-01-21 12:04:54
2025-01-21 12:04:54,561 - trainer - INFO -     epoch          : 181
2025-01-21 12:04:54,562 - trainer - INFO -     elapsed time   : 3.949808120727539
2025-01-21 12:04:54,562 - trainer - INFO -     loss           : 33.03628978729248
2025-01-21 12:04:54,562 - trainer - INFO -     sim_loss       : 33.0350284576416
2025-01-21 12:04:54,562 - trainer - INFO -     gen_loss       : 0.0012612559949047863
2025-01-21 12:04:54,562 - trainer - INFO -     val_loss       : 14.834181156478735
2025-01-21 12:04:54,562 - trainer - INFO -     val_sim_loss   : 14.822701454162598
2025-01-21 12:04:54,562 - trainer - INFO -     val_gen_loss   : 0.011479450859042117
2025-01-21 12:04:54,562 - trainer - INFO -     val_perplexity : -106.79937744140625
2025-01-21 12:04:54,562 - trainer - INFO -     val_embedding_sim: 0.07246987521648407
2025-01-21 12:04:54,562 - trainer - INFO - ================================================================================
2025-01-21 12:04:54,562 - trainer - INFO - Starting epoch 182 at 2025-01-21 12:04:54
2025-01-21 12:04:58,473 - trainer - INFO - Epoch 182 completed at 2025-01-21 12:04:58
2025-01-21 12:04:58,473 - trainer - INFO -     epoch          : 182
2025-01-21 12:04:58,473 - trainer - INFO -     elapsed time   : 3.910607099533081
2025-01-21 12:04:58,473 - trainer - INFO -     loss           : 32.99225506782532
2025-01-21 12:04:58,473 - trainer - INFO -     sim_loss       : 32.9910171508789
2025-01-21 12:04:58,473 - trainer - INFO -     gen_loss       : 0.0012379560444969683
2025-01-21 12:04:58,473 - trainer - INFO -     val_loss       : 10.826773278298788
2025-01-21 12:04:58,473 - trainer - INFO -     val_sim_loss   : 10.814645767211914
2025-01-21 12:04:58,473 - trainer - INFO -     val_gen_loss   : 0.012127829599194229
2025-01-21 12:04:58,473 - trainer - INFO -     val_perplexity : -107.03768920898438
2025-01-21 12:04:58,473 - trainer - INFO -     val_embedding_sim: 0.06493139266967773
2025-01-21 12:04:58,473 - trainer - INFO - ================================================================================
2025-01-21 12:04:58,473 - trainer - INFO - Starting epoch 183 at 2025-01-21 12:04:58
2025-01-21 12:05:02,366 - trainer - INFO - Epoch 183 completed at 2025-01-21 12:05:02
2025-01-21 12:05:02,366 - trainer - INFO -     epoch          : 183
2025-01-21 12:05:02,366 - trainer - INFO -     elapsed time   : 3.892162561416626
2025-01-21 12:05:02,366 - trainer - INFO -     loss           : 32.02564902305603
2025-01-21 12:05:02,366 - trainer - INFO -     sim_loss       : 32.02441568374634
2025-01-21 12:05:02,366 - trainer - INFO -     gen_loss       : 0.001233431964647025
2025-01-21 12:05:02,366 - trainer - INFO -     val_loss       : 14.292112621595152
2025-01-21 12:05:02,366 - trainer - INFO -     val_sim_loss   : 14.280099868774414
2025-01-21 12:05:02,366 - trainer - INFO -     val_gen_loss   : 0.01201275095809251
2025-01-21 12:05:02,366 - trainer - INFO -     val_perplexity : -107.08135223388672
2025-01-21 12:05:02,366 - trainer - INFO -     val_embedding_sim: 0.08719602227210999
2025-01-21 12:05:02,366 - trainer - INFO - ================================================================================
2025-01-21 12:05:02,366 - trainer - INFO - Starting epoch 184 at 2025-01-21 12:05:02
2025-01-21 12:05:06,261 - trainer - INFO - Epoch 184 completed at 2025-01-21 12:05:06
2025-01-21 12:05:06,261 - trainer - INFO -     epoch          : 184
2025-01-21 12:05:06,261 - trainer - INFO -     elapsed time   : 3.894245147705078
2025-01-21 12:05:06,261 - trainer - INFO -     loss           : 29.590679836273193
2025-01-21 12:05:06,261 - trainer - INFO -     sim_loss       : 29.589418792724608
2025-01-21 12:05:06,261 - trainer - INFO -     gen_loss       : 0.0012609189958311617
2025-01-21 12:05:06,261 - trainer - INFO -     val_loss       : 18.772135347127914
2025-01-21 12:05:06,261 - trainer - INFO -     val_sim_loss   : 18.631206512451172
2025-01-21 12:05:06,261 - trainer - INFO -     val_gen_loss   : 0.1409285687841475
2025-01-21 12:05:06,261 - trainer - INFO -     val_perplexity : -106.5443344116211
2025-01-21 12:05:06,261 - trainer - INFO -     val_embedding_sim: 0.07730336487293243
2025-01-21 12:05:06,261 - trainer - INFO - ================================================================================
2025-01-21 12:05:06,261 - trainer - INFO - Starting epoch 185 at 2025-01-21 12:05:06
2025-01-21 12:05:10,170 - trainer - INFO - Epoch 185 completed at 2025-01-21 12:05:10
2025-01-21 12:05:10,171 - trainer - INFO -     epoch          : 185
2025-01-21 12:05:10,171 - trainer - INFO -     elapsed time   : 3.909214735031128
2025-01-21 12:05:10,171 - trainer - INFO -     loss           : 27.549123525619507
2025-01-21 12:05:10,171 - trainer - INFO -     sim_loss       : 27.547832345962526
2025-01-21 12:05:10,171 - trainer - INFO -     gen_loss       : 0.001291724294424057
2025-01-21 12:05:10,171 - trainer - INFO -     val_loss       : 12.545231838652398
2025-01-21 12:05:10,171 - trainer - INFO -     val_sim_loss   : 12.533462524414062
2025-01-21 12:05:10,171 - trainer - INFO -     val_gen_loss   : 0.011769408301915973
2025-01-21 12:05:10,171 - trainer - INFO -     val_perplexity : -106.54754638671875
2025-01-21 12:05:10,171 - trainer - INFO -     val_embedding_sim: 0.07539702951908112
2025-01-21 12:05:15,490 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch185.pth ...
2025-01-21 12:05:15,490 - trainer - INFO - ================================================================================
2025-01-21 12:05:15,490 - trainer - INFO - Starting epoch 186 at 2025-01-21 12:05:15
2025-01-21 12:05:19,439 - trainer - INFO - Epoch 186 completed at 2025-01-21 12:05:19
2025-01-21 12:05:19,440 - trainer - INFO -     epoch          : 186
2025-01-21 12:05:19,440 - trainer - INFO -     elapsed time   : 3.9491195678710938
2025-01-21 12:05:19,440 - trainer - INFO -     loss           : 26.676162719726562
2025-01-21 12:05:19,440 - trainer - INFO -     sim_loss       : 26.674921321868897
2025-01-21 12:05:19,440 - trainer - INFO -     gen_loss       : 0.0012415129924193025
2025-01-21 12:05:19,440 - trainer - INFO -     val_loss       : 23.560274787523667
2025-01-21 12:05:19,440 - trainer - INFO -     val_sim_loss   : 23.548507690429688
2025-01-21 12:05:19,440 - trainer - INFO -     val_gen_loss   : 0.011767843083362095
2025-01-21 12:05:19,440 - trainer - INFO -     val_perplexity : -106.60337829589844
2025-01-21 12:05:19,440 - trainer - INFO -     val_embedding_sim: 0.04592199623584747
2025-01-21 12:05:19,440 - trainer - INFO - ================================================================================
2025-01-21 12:05:19,440 - trainer - INFO - Starting epoch 187 at 2025-01-21 12:05:19
2025-01-21 12:05:23,345 - trainer - INFO - Epoch 187 completed at 2025-01-21 12:05:23
2025-01-21 12:05:23,345 - trainer - INFO -     epoch          : 187
2025-01-21 12:05:23,345 - trainer - INFO -     elapsed time   : 3.905074119567871
2025-01-21 12:05:23,346 - trainer - INFO -     loss           : 30.110676956176757
2025-01-21 12:05:23,346 - trainer - INFO -     sim_loss       : 30.109496307373046
2025-01-21 12:05:23,346 - trainer - INFO -     gen_loss       : 0.0011802098946645857
2025-01-21 12:05:23,346 - trainer - INFO -     val_loss       : 20.164181863932754
2025-01-21 12:05:23,346 - trainer - INFO -     val_sim_loss   : 20.152267456054688
2025-01-21 12:05:23,346 - trainer - INFO -     val_gen_loss   : 0.011913466310943477
2025-01-21 12:05:23,346 - trainer - INFO -     val_perplexity : -105.43280029296875
2025-01-21 12:05:23,346 - trainer - INFO -     val_embedding_sim: 0.05723854526877403
2025-01-21 12:05:23,346 - trainer - INFO - ================================================================================
2025-01-21 12:05:23,346 - trainer - INFO - Starting epoch 188 at 2025-01-21 12:05:23
2025-01-21 12:05:27,231 - trainer - INFO - Epoch 188 completed at 2025-01-21 12:05:27
2025-01-21 12:05:27,231 - trainer - INFO -     epoch          : 188
2025-01-21 12:05:27,231 - trainer - INFO -     elapsed time   : 3.884582281112671
2025-01-21 12:05:27,231 - trainer - INFO -     loss           : 29.01303548812866
2025-01-21 12:05:27,231 - trainer - INFO -     sim_loss       : 29.011870193481446
2025-01-21 12:05:27,231 - trainer - INFO -     gen_loss       : 0.001164988987147808
2025-01-21 12:05:27,231 - trainer - INFO -     val_loss       : 18.030405953526497
2025-01-21 12:05:27,231 - trainer - INFO -     val_sim_loss   : 18.01143455505371
2025-01-21 12:05:27,231 - trainer - INFO -     val_gen_loss   : 0.018971574492752552
2025-01-21 12:05:27,231 - trainer - INFO -     val_perplexity : -107.52445983886719
2025-01-21 12:05:27,231 - trainer - INFO -     val_embedding_sim: 0.07563462853431702
2025-01-21 12:05:27,231 - trainer - INFO - ================================================================================
2025-01-21 12:05:27,231 - trainer - INFO - Starting epoch 189 at 2025-01-21 12:05:27
2025-01-21 12:05:31,140 - trainer - INFO - Epoch 189 completed at 2025-01-21 12:05:31
2025-01-21 12:05:31,140 - trainer - INFO -     epoch          : 189
2025-01-21 12:05:31,140 - trainer - INFO -     elapsed time   : 3.9088056087493896
2025-01-21 12:05:31,140 - trainer - INFO -     loss           : 26.30895528793335
2025-01-21 12:05:31,140 - trainer - INFO -     sim_loss       : 26.30776357650757
2025-01-21 12:05:31,140 - trainer - INFO -     gen_loss       : 0.0011917564668692648
2025-01-21 12:05:31,140 - trainer - INFO -     val_loss       : 23.82716837110638
2025-01-21 12:05:31,141 - trainer - INFO -     val_sim_loss   : 23.815868377685547
2025-01-21 12:05:31,141 - trainer - INFO -     val_gen_loss   : 0.011300926606054418
2025-01-21 12:05:31,141 - trainer - INFO -     val_perplexity : -107.25520324707031
2025-01-21 12:05:31,141 - trainer - INFO -     val_embedding_sim: 0.07031212747097015
2025-01-21 12:05:31,141 - trainer - INFO - ================================================================================
2025-01-21 12:05:31,141 - trainer - INFO - Starting epoch 190 at 2025-01-21 12:05:31
2025-01-21 12:05:35,031 - trainer - INFO - Epoch 190 completed at 2025-01-21 12:05:35
2025-01-21 12:05:35,031 - trainer - INFO -     epoch          : 190
2025-01-21 12:05:35,031 - trainer - INFO -     elapsed time   : 3.889760732650757
2025-01-21 12:05:35,031 - trainer - INFO -     loss           : 30.192186450958253
2025-01-21 12:05:35,031 - trainer - INFO -     sim_loss       : 30.191023445129396
2025-01-21 12:05:35,031 - trainer - INFO -     gen_loss       : 0.0011631364293862134
2025-01-21 12:05:35,031 - trainer - INFO -     val_loss       : 13.06758512929082
2025-01-21 12:05:35,031 - trainer - INFO -     val_sim_loss   : 13.01702880859375
2025-01-21 12:05:35,031 - trainer - INFO -     val_gen_loss   : 0.05055613350123167
2025-01-21 12:05:35,031 - trainer - INFO -     val_perplexity : -107.40338897705078
2025-01-21 12:05:35,031 - trainer - INFO -     val_embedding_sim: 0.09099045395851135
2025-01-21 12:05:40,327 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch190.pth ...
2025-01-21 12:05:40,328 - trainer - INFO - ================================================================================
2025-01-21 12:05:40,328 - trainer - INFO - Starting epoch 191 at 2025-01-21 12:05:40
2025-01-21 12:05:44,295 - trainer - INFO - Epoch 191 completed at 2025-01-21 12:05:44
2025-01-21 12:05:44,295 - trainer - INFO -     epoch          : 191
2025-01-21 12:05:44,295 - trainer - INFO -     elapsed time   : 3.9674081802368164
2025-01-21 12:05:44,296 - trainer - INFO -     loss           : 26.531469058990478
2025-01-21 12:05:44,296 - trainer - INFO -     sim_loss       : 26.53032546043396
2025-01-21 12:05:44,296 - trainer - INFO -     gen_loss       : 0.0011437293083872645
2025-01-21 12:05:44,296 - trainer - INFO -     val_loss       : 14.863223149441183
2025-01-21 12:05:44,296 - trainer - INFO -     val_sim_loss   : 14.840715408325195
2025-01-21 12:05:44,296 - trainer - INFO -     val_gen_loss   : 0.022507761605083942
2025-01-21 12:05:44,296 - trainer - INFO -     val_perplexity : -106.08659362792969
2025-01-21 12:05:44,296 - trainer - INFO -     val_embedding_sim: 0.08620066195726395
2025-01-21 12:05:44,296 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
2025-01-21 12:10:51,297 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:10:53,706 - trainer - INFO - ================================================================================
2025-01-21 12:10:53,706 - trainer - INFO - Starting epoch 1 at 2025-01-21 12:10:53
2025-01-21 12:10:58,921 - trainer - INFO - Epoch 1 completed at 2025-01-21 12:10:58
2025-01-21 12:10:58,921 - trainer - INFO -     epoch          : 1
2025-01-21 12:10:58,921 - trainer - INFO -     elapsed time   : 5.215071439743042
2025-01-21 12:10:58,921 - trainer - INFO -     loss           : 5.341168928146362
2025-01-21 12:10:58,921 - trainer - INFO -     sim_loss       : 6.128888440132141
2025-01-21 12:10:58,921 - trainer - INFO -     gen_loss       : 5.003574728965759
2025-01-21 12:10:58,921 - trainer - INFO -     val_loss       : 5.397758483886719
2025-01-21 12:10:58,921 - trainer - INFO -     val_sim_loss   : 3.6939802169799805
2025-01-21 12:10:58,921 - trainer - INFO -     val_gen_loss   : 1.7037782669067383
2025-01-21 12:10:58,922 - trainer - INFO -     val_perplexity : -54.21035385131836
2025-01-21 12:10:58,922 - trainer - INFO -     val_embedding_sim: 0.09437890350818634
2025-01-21 12:10:58,922 - trainer - INFO - ================================================================================
2025-01-21 12:10:58,922 - trainer - INFO - Starting epoch 2 at 2025-01-21 12:10:58
2025-01-21 12:11:02,805 - trainer - INFO - Epoch 2 completed at 2025-01-21 12:11:02
2025-01-21 12:11:02,805 - trainer - INFO -     epoch          : 2
2025-01-21 12:11:02,806 - trainer - INFO -     elapsed time   : 3.883568048477173
2025-01-21 12:11:02,806 - trainer - INFO -     loss           : 2.136891543865204
2025-01-21 12:11:02,806 - trainer - INFO -     sim_loss       : 2.0332702577114103
2025-01-21 12:11:02,806 - trainer - INFO -     gen_loss       : 2.181300711631775
2025-01-21 12:11:02,806 - trainer - INFO -     val_loss       : 1.9728686213493347
2025-01-21 12:11:02,806 - trainer - INFO -     val_sim_loss   : 0.6180433598347008
2025-01-21 12:11:02,806 - trainer - INFO -     val_gen_loss   : 1.35482519865036
2025-01-21 12:11:02,806 - trainer - INFO -     val_perplexity : -64.30159759521484
2025-01-21 12:11:02,806 - trainer - INFO -     val_embedding_sim: 0.07889963686466217
2025-01-21 12:11:02,806 - trainer - INFO - ================================================================================
2025-01-21 12:11:02,806 - trainer - INFO - Starting epoch 3 at 2025-01-21 12:11:02
2025-01-21 12:11:06,696 - trainer - INFO - Epoch 3 completed at 2025-01-21 12:11:06
2025-01-21 12:11:06,696 - trainer - INFO -     epoch          : 3
2025-01-21 12:11:06,696 - trainer - INFO -     elapsed time   : 3.890178680419922
2025-01-21 12:11:06,696 - trainer - INFO -     loss           : 1.099144321680069
2025-01-21 12:11:06,696 - trainer - INFO -     sim_loss       : 1.0205663681030273
2025-01-21 12:11:06,697 - trainer - INFO -     gen_loss       : 1.1328205943107605
2025-01-21 12:11:06,697 - trainer - INFO -     val_loss       : 2.270417481660843
2025-01-21 12:11:06,697 - trainer - INFO -     val_sim_loss   : 1.2385704219341278
2025-01-21 12:11:06,697 - trainer - INFO -     val_gen_loss   : 1.031847059726715
2025-01-21 12:11:06,697 - trainer - INFO -     val_perplexity : -71.88446044921875
2025-01-21 12:11:06,697 - trainer - INFO -     val_embedding_sim: 0.06567853689193726
2025-01-21 12:11:06,697 - trainer - INFO - ================================================================================
2025-01-21 12:11:06,697 - trainer - INFO - Starting epoch 4 at 2025-01-21 12:11:06
2025-01-21 12:11:10,593 - trainer - INFO - Epoch 4 completed at 2025-01-21 12:11:10
2025-01-21 12:11:10,593 - trainer - INFO -     epoch          : 4
2025-01-21 12:11:10,593 - trainer - INFO -     elapsed time   : 3.895932197570801
2025-01-21 12:11:10,593 - trainer - INFO -     loss           : 0.5976681023836136
2025-01-21 12:11:10,593 - trainer - INFO -     sim_loss       : 0.6265895530581475
2025-01-21 12:11:10,593 - trainer - INFO -     gen_loss       : 0.5852731913328171
2025-01-21 12:11:10,593 - trainer - INFO -     val_loss       : 0.973514586687088
2025-01-21 12:11:10,593 - trainer - INFO -     val_sim_loss   : 0.6255628764629364
2025-01-21 12:11:10,593 - trainer - INFO -     val_gen_loss   : 0.3479517251253128
2025-01-21 12:11:10,593 - trainer - INFO -     val_perplexity : -77.10440063476562
2025-01-21 12:11:10,593 - trainer - INFO -     val_embedding_sim: 0.0741296038031578
2025-01-21 12:11:10,593 - trainer - INFO - ================================================================================
2025-01-21 12:11:10,593 - trainer - INFO - Starting epoch 5 at 2025-01-21 12:11:10
2025-01-21 12:11:14,492 - trainer - INFO - Epoch 5 completed at 2025-01-21 12:11:14
2025-01-21 12:11:14,492 - trainer - INFO -     epoch          : 5
2025-01-21 12:11:14,492 - trainer - INFO -     elapsed time   : 3.898348093032837
2025-01-21 12:11:14,492 - trainer - INFO -     loss           : 0.4419865220785141
2025-01-21 12:11:14,492 - trainer - INFO -     sim_loss       : 0.7306307386606932
2025-01-21 12:11:14,492 - trainer - INFO -     gen_loss       : 0.31828186213970183
2025-01-21 12:11:14,492 - trainer - INFO -     val_loss       : 0.4597795307636261
2025-01-21 12:11:14,492 - trainer - INFO -     val_sim_loss   : 0.1269730776157303
2025-01-21 12:11:14,492 - trainer - INFO -     val_gen_loss   : 0.33280645310878754
2025-01-21 12:11:14,492 - trainer - INFO -     val_perplexity : -81.19180297851562
2025-01-21 12:11:14,492 - trainer - INFO -     val_embedding_sim: 0.08979909867048264
2025-01-21 12:11:19,721 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 12:11:24,940 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 12:11:24,940 - trainer - INFO - ================================================================================
2025-01-21 12:11:24,940 - trainer - INFO - Starting epoch 6 at 2025-01-21 12:11:24
2025-01-21 12:11:28,903 - trainer - INFO - Epoch 6 completed at 2025-01-21 12:11:28
2025-01-21 12:11:28,903 - trainer - INFO -     epoch          : 6
2025-01-21 12:11:28,903 - trainer - INFO -     elapsed time   : 3.9625601768493652
2025-01-21 12:11:28,903 - trainer - INFO -     loss           : 0.3219709128141403
2025-01-21 12:11:28,903 - trainer - INFO -     sim_loss       : 0.5778303399682045
2025-01-21 12:11:28,903 - trainer - INFO -     gen_loss       : 0.21231685876846312
2025-01-21 12:11:28,903 - trainer - INFO -     val_loss       : 1.3949602991342545
2025-01-21 12:11:28,903 - trainer - INFO -     val_sim_loss   : 1.284208357334137
2025-01-21 12:11:28,903 - trainer - INFO -     val_gen_loss   : 0.11075196787714958
2025-01-21 12:11:28,904 - trainer - INFO -     val_perplexity : -83.62957763671875
2025-01-21 12:11:28,904 - trainer - INFO -     val_embedding_sim: 0.0801287442445755
2025-01-21 12:11:28,904 - trainer - INFO - ================================================================================
2025-01-21 12:11:28,904 - trainer - INFO - Starting epoch 7 at 2025-01-21 12:11:28
2025-01-21 12:11:32,798 - trainer - INFO - Epoch 7 completed at 2025-01-21 12:11:32
2025-01-21 12:11:32,798 - trainer - INFO -     epoch          : 7
2025-01-21 12:11:32,798 - trainer - INFO -     elapsed time   : 3.8941948413848877
2025-01-21 12:11:32,798 - trainer - INFO -     loss           : 0.2753296375274658
2025-01-21 12:11:32,798 - trainer - INFO -     sim_loss       : 0.6603968411684036
2025-01-21 12:11:32,798 - trainer - INFO -     gen_loss       : 0.1103008195757866
2025-01-21 12:11:32,798 - trainer - INFO -     val_loss       : 0.7174658551812172
2025-01-21 12:11:32,798 - trainer - INFO -     val_sim_loss   : 0.618072378798388
2025-01-21 12:11:32,798 - trainer - INFO -     val_gen_loss   : 0.09939345717430115
2025-01-21 12:11:32,798 - trainer - INFO -     val_perplexity : -86.1916732788086
2025-01-21 12:11:32,798 - trainer - INFO -     val_embedding_sim: 0.07037758082151413
2025-01-21 12:11:32,798 - trainer - INFO - ================================================================================
2025-01-21 12:11:32,799 - trainer - INFO - Starting epoch 8 at 2025-01-21 12:11:32
2025-01-21 12:11:36,690 - trainer - INFO - Epoch 8 completed at 2025-01-21 12:11:36
2025-01-21 12:11:36,690 - trainer - INFO -     epoch          : 8
2025-01-21 12:11:36,690 - trainer - INFO -     elapsed time   : 3.891051769256592
2025-01-21 12:11:36,690 - trainer - INFO -     loss           : 0.2063307821750641
2025-01-21 12:11:36,690 - trainer - INFO -     sim_loss       : 0.521308072656393
2025-01-21 12:11:36,690 - trainer - INFO -     gen_loss       : 0.07134050838649272
2025-01-21 12:11:36,690 - trainer - INFO -     val_loss       : 0.2656639814376831
2025-01-21 12:11:36,690 - trainer - INFO -     val_sim_loss   : 0.22401082515716553
2025-01-21 12:11:36,690 - trainer - INFO -     val_gen_loss   : 0.04165315814316273
2025-01-21 12:11:36,690 - trainer - INFO -     val_perplexity : -87.14735412597656
2025-01-21 12:11:36,690 - trainer - INFO -     val_embedding_sim: 0.07523588091135025
2025-01-21 12:11:36,690 - trainer - INFO - ================================================================================
2025-01-21 12:11:36,690 - trainer - INFO - Starting epoch 9 at 2025-01-21 12:11:36
2025-01-21 12:11:40,587 - trainer - INFO - Epoch 9 completed at 2025-01-21 12:11:40
2025-01-21 12:11:40,587 - trainer - INFO -     epoch          : 9
2025-01-21 12:11:40,587 - trainer - INFO -     elapsed time   : 3.8964858055114746
2025-01-21 12:11:40,587 - trainer - INFO -     loss           : 0.24354695677757263
2025-01-21 12:11:40,587 - trainer - INFO -     sim_loss       : 0.6928392708301544
2025-01-21 12:11:40,587 - trainer - INFO -     gen_loss       : 0.050993097573518754
2025-01-21 12:11:40,587 - trainer - INFO -     val_loss       : 0.2931906655430794
2025-01-21 12:11:40,587 - trainer - INFO -     val_sim_loss   : 0.17728814006841276
2025-01-21 12:11:40,587 - trainer - INFO -     val_gen_loss   : 0.11590252071619034
2025-01-21 12:11:40,587 - trainer - INFO -     val_perplexity : -89.91282653808594
2025-01-21 12:11:40,587 - trainer - INFO -     val_embedding_sim: 0.06346090137958527
2025-01-21 12:11:40,587 - trainer - INFO - ================================================================================
2025-01-21 12:11:40,588 - trainer - INFO - Starting epoch 10 at 2025-01-21 12:11:40
2025-01-21 12:11:44,487 - trainer - INFO - Epoch 10 completed at 2025-01-21 12:11:44
2025-01-21 12:11:44,487 - trainer - INFO -     epoch          : 10
2025-01-21 12:11:44,487 - trainer - INFO -     elapsed time   : 3.8988895416259766
2025-01-21 12:11:44,487 - trainer - INFO -     loss           : 0.20318650752305983
2025-01-21 12:11:44,487 - trainer - INFO -     sim_loss       : 0.5907328024506568
2025-01-21 12:11:44,487 - trainer - INFO -     gen_loss       : 0.03709522634744644
2025-01-21 12:11:44,487 - trainer - INFO -     val_loss       : 0.4368624985218048
2025-01-21 12:11:44,487 - trainer - INFO -     val_sim_loss   : 0.2913265087408945
2025-01-21 12:11:44,487 - trainer - INFO -     val_gen_loss   : 0.14553598687052727
2025-01-21 12:11:44,487 - trainer - INFO -     val_perplexity : -90.32327270507812
2025-01-21 12:11:44,487 - trainer - INFO -     val_embedding_sim: 0.07708511501550674
2025-01-21 12:11:49,723 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 12:11:49,723 - trainer - INFO - ================================================================================
2025-01-21 12:11:49,723 - trainer - INFO - Starting epoch 11 at 2025-01-21 12:11:49
2025-01-21 12:11:53,663 - trainer - INFO - Epoch 11 completed at 2025-01-21 12:11:53
2025-01-21 12:11:53,663 - trainer - INFO -     epoch          : 11
2025-01-21 12:11:53,663 - trainer - INFO -     elapsed time   : 3.9397289752960205
2025-01-21 12:11:53,663 - trainer - INFO -     loss           : 0.1994538977742195
2025-01-21 12:11:53,663 - trainer - INFO -     sim_loss       : 0.5927569657564163
2025-01-21 12:11:53,663 - trainer - INFO -     gen_loss       : 0.03089542593806982
2025-01-21 12:11:53,663 - trainer - INFO -     val_loss       : 1.1324623823165894
2025-01-21 12:11:53,663 - trainer - INFO -     val_sim_loss   : 1.0577428974211216
2025-01-21 12:11:53,663 - trainer - INFO -     val_gen_loss   : 0.07471949234604836
2025-01-21 12:11:53,663 - trainer - INFO -     val_perplexity : -91.17506408691406
2025-01-21 12:11:53,663 - trainer - INFO -     val_embedding_sim: 0.08595772087574005
2025-01-21 12:11:53,663 - trainer - INFO - ================================================================================
2025-01-21 12:11:53,663 - trainer - INFO - Starting epoch 12 at 2025-01-21 12:11:53
2025-01-21 12:11:57,567 - trainer - INFO - Epoch 12 completed at 2025-01-21 12:11:57
2025-01-21 12:11:57,568 - trainer - INFO -     epoch          : 12
2025-01-21 12:11:57,568 - trainer - INFO -     elapsed time   : 3.903759717941284
2025-01-21 12:11:57,568 - trainer - INFO -     loss           : 0.10182676129043103
2025-01-21 12:11:57,568 - trainer - INFO -     sim_loss       : 0.28120823111385107
2025-01-21 12:11:57,568 - trainer - INFO -     gen_loss       : 0.024948985874652864
2025-01-21 12:11:57,568 - trainer - INFO -     val_loss       : 0.3519907556474209
2025-01-21 12:11:57,568 - trainer - INFO -     val_sim_loss   : 0.2819696366786104
2025-01-21 12:11:57,568 - trainer - INFO -     val_gen_loss   : 0.07002110593020916
2025-01-21 12:11:57,568 - trainer - INFO -     val_perplexity : -91.71878051757812
2025-01-21 12:11:57,568 - trainer - INFO -     val_embedding_sim: 0.08768518269062042
2025-01-21 12:11:57,568 - trainer - INFO - ================================================================================
2025-01-21 12:11:57,568 - trainer - INFO - Starting epoch 13 at 2025-01-21 12:11:57
2025-01-21 12:12:01,485 - trainer - INFO - Epoch 13 completed at 2025-01-21 12:12:01
2025-01-21 12:12:01,485 - trainer - INFO -     epoch          : 13
2025-01-21 12:12:01,485 - trainer - INFO -     elapsed time   : 3.9165377616882324
2025-01-21 12:12:01,485 - trainer - INFO -     loss           : 0.1694307502359152
2025-01-21 12:12:01,485 - trainer - INFO -     sim_loss       : 0.5132811896502971
2025-01-21 12:12:01,485 - trainer - INFO -     gen_loss       : 0.022066266648471354
2025-01-21 12:12:01,485 - trainer - INFO -     val_loss       : 0.277335359249264
2025-01-21 12:12:01,485 - trainer - INFO -     val_sim_loss   : 0.2517641602898948
2025-01-21 12:12:01,485 - trainer - INFO -     val_gen_loss   : 0.0255712007638067
2025-01-21 12:12:01,485 - trainer - INFO -     val_perplexity : -91.68193054199219
2025-01-21 12:12:01,485 - trainer - INFO -     val_embedding_sim: 0.07668820768594742
2025-01-21 12:12:01,485 - trainer - INFO - ================================================================================
2025-01-21 12:12:01,485 - trainer - INFO - Starting epoch 14 at 2025-01-21 12:12:01
2025-01-21 12:12:05,379 - trainer - INFO - Epoch 14 completed at 2025-01-21 12:12:05
2025-01-21 12:12:05,380 - trainer - INFO -     epoch          : 14
2025-01-21 12:12:05,380 - trainer - INFO -     elapsed time   : 3.8941049575805664
2025-01-21 12:12:05,380 - trainer - INFO -     loss           : 0.13090800810605288
2025-01-21 12:12:05,380 - trainer - INFO -     sim_loss       : 0.3931477803736925
2025-01-21 12:12:05,380 - trainer - INFO -     gen_loss       : 0.01851952951401472
2025-01-21 12:12:05,380 - trainer - INFO -     val_loss       : 0.26826322521083057
2025-01-21 12:12:05,380 - trainer - INFO -     val_sim_loss   : 0.2462548165640328
2025-01-21 12:12:05,380 - trainer - INFO -     val_gen_loss   : 0.022008421714417636
2025-01-21 12:12:05,380 - trainer - INFO -     val_perplexity : -94.09852600097656
2025-01-21 12:12:05,380 - trainer - INFO -     val_embedding_sim: 0.09333021938800812
2025-01-21 12:12:05,380 - trainer - INFO - ================================================================================
2025-01-21 12:12:05,380 - trainer - INFO - Starting epoch 15 at 2025-01-21 12:12:05
2025-01-21 12:12:09,278 - trainer - INFO - Epoch 15 completed at 2025-01-21 12:12:09
2025-01-21 12:12:09,279 - trainer - INFO -     epoch          : 15
2025-01-21 12:12:09,279 - trainer - INFO -     elapsed time   : 3.898224115371704
2025-01-21 12:12:09,279 - trainer - INFO -     loss           : 0.11527680568397045
2025-01-21 12:12:09,279 - trainer - INFO -     sim_loss       : 0.3505104064941406
2025-01-21 12:12:09,279 - trainer - INFO -     gen_loss       : 0.014462401159107685
2025-01-21 12:12:09,279 - trainer - INFO -     val_loss       : 0.13237472996115685
2025-01-21 12:12:09,279 - trainer - INFO -     val_sim_loss   : 0.09878953953739256
2025-01-21 12:12:09,279 - trainer - INFO -     val_gen_loss   : 0.033585190773010254
2025-01-21 12:12:09,279 - trainer - INFO -     val_perplexity : -94.67144012451172
2025-01-21 12:12:09,279 - trainer - INFO -     val_embedding_sim: 0.07095103710889816
2025-01-21 12:12:14,503 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 12:12:14,503 - trainer - INFO - ================================================================================
2025-01-21 12:12:14,503 - trainer - INFO - Starting epoch 16 at 2025-01-21 12:12:14
2025-01-21 12:12:18,431 - trainer - INFO - Epoch 16 completed at 2025-01-21 12:12:18
2025-01-21 12:12:18,432 - trainer - INFO -     epoch          : 16
2025-01-21 12:12:18,432 - trainer - INFO -     elapsed time   : 3.927996873855591
2025-01-21 12:12:18,432 - trainer - INFO -     loss           : 0.11363349054008723
2025-01-21 12:12:18,432 - trainer - INFO -     sim_loss       : 0.34937668829225005
2025-01-21 12:12:18,432 - trainer - INFO -     gen_loss       : 0.0126006830483675
2025-01-21 12:12:18,432 - trainer - INFO -     val_loss       : 0.2460076409042813
2025-01-21 12:12:18,432 - trainer - INFO -     val_sim_loss   : 0.22638769447803142
2025-01-21 12:12:18,432 - trainer - INFO -     val_gen_loss   : 0.019619953876826912
2025-01-21 12:12:18,432 - trainer - INFO -     val_perplexity : -95.77152252197266
2025-01-21 12:12:18,432 - trainer - INFO -     val_embedding_sim: 0.08085618913173676
2025-01-21 12:12:18,432 - trainer - INFO - ================================================================================
2025-01-21 12:12:18,432 - trainer - INFO - Starting epoch 17 at 2025-01-21 12:12:18
2025-01-21 12:12:22,341 - trainer - INFO - Epoch 17 completed at 2025-01-21 12:12:22
2025-01-21 12:12:22,341 - trainer - INFO -     epoch          : 17
2025-01-21 12:12:22,341 - trainer - INFO -     elapsed time   : 3.908710241317749
2025-01-21 12:12:22,341 - trainer - INFO -     loss           : 0.13941328898072242
2025-01-21 12:12:22,341 - trainer - INFO -     sim_loss       : 0.4423758462071419
2025-01-21 12:12:22,341 - trainer - INFO -     gen_loss       : 0.009572184877470136
2025-01-21 12:12:22,341 - trainer - INFO -     val_loss       : 0.34885579347610474
2025-01-21 12:12:22,341 - trainer - INFO -     val_sim_loss   : 0.25605371582423686
2025-01-21 12:12:22,341 - trainer - INFO -     val_gen_loss   : 0.09280209243297577
2025-01-21 12:12:22,341 - trainer - INFO -     val_perplexity : -95.98399353027344
2025-01-21 12:12:22,341 - trainer - INFO -     val_embedding_sim: 0.06909100711345673
2025-01-21 12:12:22,341 - trainer - INFO - ================================================================================
2025-01-21 12:12:22,341 - trainer - INFO - Starting epoch 18 at 2025-01-21 12:12:22
2025-01-21 12:12:26,247 - trainer - INFO - Epoch 18 completed at 2025-01-21 12:12:26
2025-01-21 12:12:26,247 - trainer - INFO -     epoch          : 18
2025-01-21 12:12:26,247 - trainer - INFO -     elapsed time   : 3.9052774906158447
2025-01-21 12:12:26,247 - trainer - INFO -     loss           : 0.1252253253478557
2025-01-21 12:12:26,247 - trainer - INFO -     sim_loss       : 0.39871415089437506
2025-01-21 12:12:26,247 - trainer - INFO -     gen_loss       : 0.008015824342146515
2025-01-21 12:12:26,247 - trainer - INFO -     val_loss       : 0.3401609229913447
2025-01-21 12:12:26,247 - trainer - INFO -     val_sim_loss   : 0.3224233982637088
2025-01-21 12:12:26,247 - trainer - INFO -     val_gen_loss   : 0.017737515416229144
2025-01-21 12:12:26,247 - trainer - INFO -     val_perplexity : -96.99784851074219
2025-01-21 12:12:26,247 - trainer - INFO -     val_embedding_sim: 0.07792039215564728
2025-01-21 12:12:26,247 - trainer - INFO - ================================================================================
2025-01-21 12:12:26,247 - trainer - INFO - Starting epoch 19 at 2025-01-21 12:12:26
2025-01-21 12:12:30,145 - trainer - INFO - Epoch 19 completed at 2025-01-21 12:12:30
2025-01-21 12:12:30,146 - trainer - INFO -     epoch          : 19
2025-01-21 12:12:30,146 - trainer - INFO -     elapsed time   : 3.8978710174560547
2025-01-21 12:12:30,146 - trainer - INFO -     loss           : 0.10561499618925155
2025-01-21 12:12:30,146 - trainer - INFO -     sim_loss       : 0.33573523032828234
2025-01-21 12:12:30,146 - trainer - INFO -     gen_loss       : 0.0069920306093990804
2025-01-21 12:12:30,146 - trainer - INFO -     val_loss       : 0.120519008487463
2025-01-21 12:12:30,146 - trainer - INFO -     val_sim_loss   : 0.0803491622200454
2025-01-21 12:12:30,146 - trainer - INFO -     val_gen_loss   : 0.04016984533518553
2025-01-21 12:12:30,146 - trainer - INFO -     val_perplexity : -96.21949768066406
2025-01-21 12:12:30,146 - trainer - INFO -     val_embedding_sim: 0.08145536482334137
2025-01-21 12:12:30,146 - trainer - INFO - ================================================================================
2025-01-21 12:12:30,146 - trainer - INFO - Starting epoch 20 at 2025-01-21 12:12:30
2025-01-21 12:12:34,048 - trainer - INFO - Epoch 20 completed at 2025-01-21 12:12:34
2025-01-21 12:12:34,048 - trainer - INFO -     epoch          : 20
2025-01-21 12:12:34,048 - trainer - INFO -     elapsed time   : 3.901958703994751
2025-01-21 12:12:34,048 - trainer - INFO -     loss           : 0.08907974464818835
2025-01-21 12:12:34,048 - trainer - INFO -     sim_loss       : 0.28284096729476005
2025-01-21 12:12:34,048 - trainer - INFO -     gen_loss       : 0.006039216229692101
2025-01-21 12:12:34,048 - trainer - INFO -     val_loss       : 0.2195114989299327
2025-01-21 12:12:34,048 - trainer - INFO -     val_sim_loss   : 0.20340394973300135
2025-01-21 12:12:34,048 - trainer - INFO -     val_gen_loss   : 0.016107543604448438
2025-01-21 12:12:34,049 - trainer - INFO -     val_perplexity : -98.08927917480469
2025-01-21 12:12:34,049 - trainer - INFO -     val_embedding_sim: 0.07465847581624985
2025-01-21 12:12:39,274 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 12:12:44,534 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 12:12:44,534 - trainer - INFO - ================================================================================
2025-01-21 12:12:44,534 - trainer - INFO - Starting epoch 21 at 2025-01-21 12:12:44
2025-01-21 12:12:48,500 - trainer - INFO - Epoch 21 completed at 2025-01-21 12:12:48
2025-01-21 12:12:48,501 - trainer - INFO -     epoch          : 21
2025-01-21 12:12:48,501 - trainer - INFO -     elapsed time   : 3.966010570526123
2025-01-21 12:12:48,501 - trainer - INFO -     loss           : 0.07607133786659688
2025-01-21 12:12:48,501 - trainer - INFO -     sim_loss       : 0.24096471873344855
2025-01-21 12:12:48,501 - trainer - INFO -     gen_loss       : 0.005402742978185415
2025-01-21 12:12:48,501 - trainer - INFO -     val_loss       : 0.3982806336134672
2025-01-21 12:12:48,501 - trainer - INFO -     val_sim_loss   : 0.3705004407092929
2025-01-21 12:12:48,501 - trainer - INFO -     val_gen_loss   : 0.027780205011367798
2025-01-21 12:12:48,501 - trainer - INFO -     val_perplexity : -98.01578521728516
2025-01-21 12:12:48,501 - trainer - INFO -     val_embedding_sim: 0.06933072954416275
2025-01-21 12:12:48,501 - trainer - INFO - ================================================================================
2025-01-21 12:12:48,501 - trainer - INFO - Starting epoch 22 at 2025-01-21 12:12:48
2025-01-21 12:12:52,401 - trainer - INFO - Epoch 22 completed at 2025-01-21 12:12:52
2025-01-21 12:12:52,401 - trainer - INFO -     epoch          : 22
2025-01-21 12:12:52,402 - trainer - INFO -     elapsed time   : 3.9001927375793457
2025-01-21 12:12:52,402 - trainer - INFO -     loss           : 0.11359833555761725
2025-01-21 12:12:52,402 - trainer - INFO -     sim_loss       : 0.3677470655471552
2025-01-21 12:12:52,402 - trainer - INFO -     gen_loss       : 0.00467744714114815
2025-01-21 12:12:52,402 - trainer - INFO -     val_loss       : 0.24227239191532135
2025-01-21 12:12:52,402 - trainer - INFO -     val_sim_loss   : 0.18193183724724804
2025-01-21 12:12:52,402 - trainer - INFO -     val_gen_loss   : 0.06034055072814226
2025-01-21 12:12:52,402 - trainer - INFO -     val_perplexity : -99.44400787353516
2025-01-21 12:12:52,402 - trainer - INFO -     val_embedding_sim: 0.07742491364479065
2025-01-21 12:12:52,402 - trainer - INFO - ================================================================================
2025-01-21 12:12:52,402 - trainer - INFO - Starting epoch 23 at 2025-01-21 12:12:52
2025-01-21 12:12:56,310 - trainer - INFO - Epoch 23 completed at 2025-01-21 12:12:56
2025-01-21 12:12:56,310 - trainer - INFO -     epoch          : 23
2025-01-21 12:12:56,310 - trainer - INFO -     elapsed time   : 3.908125638961792
2025-01-21 12:12:56,310 - trainer - INFO -     loss           : 0.04964150080922991
2025-01-21 12:12:56,310 - trainer - INFO -     sim_loss       : 0.15591814707731827
2025-01-21 12:12:56,310 - trainer - INFO -     gen_loss       : 0.004094364447519183
2025-01-21 12:12:56,310 - trainer - INFO -     val_loss       : 0.06142064565210603
2025-01-21 12:12:56,311 - trainer - INFO -     val_sim_loss   : 0.04644852131445987
2025-01-21 12:12:56,311 - trainer - INFO -     val_gen_loss   : 0.014972124336054549
2025-01-21 12:12:56,311 - trainer - INFO -     val_perplexity : -100.42593383789062
2025-01-21 12:12:56,311 - trainer - INFO -     val_embedding_sim: 0.09230077266693115
2025-01-21 12:12:56,311 - trainer - INFO - ================================================================================
2025-01-21 12:12:56,311 - trainer - INFO - Starting epoch 24 at 2025-01-21 12:12:56
2025-01-21 12:13:00,220 - trainer - INFO - Epoch 24 completed at 2025-01-21 12:13:00
2025-01-21 12:13:00,220 - trainer - INFO -     epoch          : 24
2025-01-21 12:13:00,220 - trainer - INFO -     elapsed time   : 3.908968448638916
2025-01-21 12:13:00,220 - trainer - INFO -     loss           : 0.1245105143636465
2025-01-21 12:13:00,220 - trainer - INFO -     sim_loss       : 0.406358477473259
2025-01-21 12:13:00,220 - trainer - INFO -     gen_loss       : 0.003718521911650896
2025-01-21 12:13:00,220 - trainer - INFO -     val_loss       : 0.12459060549736023
2025-01-21 12:13:00,220 - trainer - INFO -     val_sim_loss   : 0.06790729612021096
2025-01-21 12:13:00,220 - trainer - INFO -     val_gen_loss   : 0.0566833084449172
2025-01-21 12:13:00,220 - trainer - INFO -     val_perplexity : -100.27384185791016
2025-01-21 12:13:00,220 - trainer - INFO -     val_embedding_sim: 0.08629430830478668
2025-01-21 12:13:00,220 - trainer - INFO - ================================================================================
2025-01-21 12:13:00,220 - trainer - INFO - Starting epoch 25 at 2025-01-21 12:13:00
2025-01-21 12:13:04,118 - trainer - INFO - Epoch 25 completed at 2025-01-21 12:13:04
2025-01-21 12:13:04,119 - trainer - INFO -     epoch          : 25
2025-01-21 12:13:04,119 - trainer - INFO -     elapsed time   : 3.8978660106658936
2025-01-21 12:13:04,119 - trainer - INFO -     loss           : 0.08409492187201976
2025-01-21 12:13:04,119 - trainer - INFO -     sim_loss       : 0.2724552839994431
2025-01-21 12:13:04,119 - trainer - INFO -     gen_loss       : 0.0033690472366288303
2025-01-21 12:13:04,119 - trainer - INFO -     val_loss       : 0.11760901845991611
2025-01-21 12:13:04,119 - trainer - INFO -     val_sim_loss   : 0.099778898059526
2025-01-21 12:13:04,119 - trainer - INFO -     val_gen_loss   : 0.017830122262239456
2025-01-21 12:13:04,119 - trainer - INFO -     val_perplexity : -99.16069793701172
2025-01-21 12:13:04,119 - trainer - INFO -     val_embedding_sim: 0.08128579705953598
2025-01-21 12:13:09,341 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 12:13:09,341 - trainer - INFO - ================================================================================
2025-01-21 12:13:09,341 - trainer - INFO - Starting epoch 26 at 2025-01-21 12:13:09
2025-01-21 12:13:13,291 - trainer - INFO - Epoch 26 completed at 2025-01-21 12:13:13
2025-01-21 12:13:13,291 - trainer - INFO -     epoch          : 26
2025-01-21 12:13:13,291 - trainer - INFO -     elapsed time   : 3.9494340419769287
2025-01-21 12:13:13,291 - trainer - INFO -     loss           : 0.13589797653257846
2025-01-21 12:13:13,291 - trainer - INFO -     sim_loss       : 0.44560627453029156
2025-01-21 12:13:13,291 - trainer - INFO -     gen_loss       : 0.0031658435938879846
2025-01-21 12:13:13,291 - trainer - INFO -     val_loss       : 1.9670298099517822
2025-01-21 12:13:13,291 - trainer - INFO -     val_sim_loss   : 1.9524856805801392
2025-01-21 12:13:13,291 - trainer - INFO -     val_gen_loss   : 0.014544071338605136
2025-01-21 12:13:13,291 - trainer - INFO -     val_perplexity : -101.10338592529297
2025-01-21 12:13:13,291 - trainer - INFO -     val_embedding_sim: 0.08707506954669952
2025-01-21 12:13:13,291 - trainer - INFO - ================================================================================
2025-01-21 12:13:13,291 - trainer - INFO - Starting epoch 27 at 2025-01-21 12:13:13
2025-01-21 12:13:17,185 - trainer - INFO - Epoch 27 completed at 2025-01-21 12:13:17
2025-01-21 12:13:17,185 - trainer - INFO -     epoch          : 27
2025-01-21 12:13:17,185 - trainer - INFO -     elapsed time   : 3.893681764602661
2025-01-21 12:13:17,185 - trainer - INFO -     loss           : 0.08427019780501724
2025-01-21 12:13:17,185 - trainer - INFO -     sim_loss       : 0.27330460473895074
2025-01-21 12:13:17,185 - trainer - INFO -     gen_loss       : 0.0032554466975852846
2025-01-21 12:13:17,185 - trainer - INFO -     val_loss       : 0.1795575561336591
2025-01-21 12:13:17,185 - trainer - INFO -     val_sim_loss   : 0.1644700762190041
2025-01-21 12:13:17,185 - trainer - INFO -     val_gen_loss   : 0.015087480845977552
2025-01-21 12:13:17,185 - trainer - INFO -     val_perplexity : -101.6922607421875
2025-01-21 12:13:17,185 - trainer - INFO -     val_embedding_sim: 0.09194288402795792
2025-01-21 12:13:17,186 - trainer - INFO - ================================================================================
2025-01-21 12:13:17,186 - trainer - INFO - Starting epoch 28 at 2025-01-21 12:13:17
2025-01-21 12:13:21,087 - trainer - INFO - Epoch 28 completed at 2025-01-21 12:13:21
2025-01-21 12:13:21,087 - trainer - INFO -     epoch          : 28
2025-01-21 12:13:21,088 - trainer - INFO -     elapsed time   : 3.901585340499878
2025-01-21 12:13:21,088 - trainer - INFO -     loss           : 0.0942124248482287
2025-01-21 12:13:21,088 - trainer - INFO -     sim_loss       : 0.30756683718645944
2025-01-21 12:13:21,088 - trainer - INFO -     gen_loss       : 0.0027748151449486615
2025-01-21 12:13:21,088 - trainer - INFO -     val_loss       : 0.16993570869090036
2025-01-21 12:13:21,088 - trainer - INFO -     val_sim_loss   : 0.15518347917259234
2025-01-21 12:13:21,088 - trainer - INFO -     val_gen_loss   : 0.014752224858966656
2025-01-21 12:13:21,088 - trainer - INFO -     val_perplexity : -102.18008422851562
2025-01-21 12:13:21,088 - trainer - INFO -     val_embedding_sim: 0.08571742475032806
2025-01-21 12:13:21,088 - trainer - INFO - ================================================================================
2025-01-21 12:13:21,088 - trainer - INFO - Starting epoch 29 at 2025-01-21 12:13:21
2025-01-21 12:13:24,984 - trainer - INFO - Epoch 29 completed at 2025-01-21 12:13:24
2025-01-21 12:13:24,984 - trainer - INFO -     epoch          : 29
2025-01-21 12:13:24,984 - trainer - INFO -     elapsed time   : 3.8956139087677
2025-01-21 12:13:24,984 - trainer - INFO -     loss           : 0.12239559842273592
2025-01-21 12:13:24,984 - trainer - INFO -     sim_loss       : 0.4021961329330225
2025-01-21 12:13:24,984 - trainer - INFO -     gen_loss       : 0.002481073944363743
2025-01-21 12:13:24,984 - trainer - INFO -     val_loss       : 0.1668421641807072
2025-01-21 12:13:24,984 - trainer - INFO -     val_sim_loss   : 0.15261143439875013
2025-01-21 12:13:24,984 - trainer - INFO -     val_gen_loss   : 0.014230729779228568
2025-01-21 12:13:24,984 - trainer - INFO -     val_perplexity : -102.72940063476562
2025-01-21 12:13:24,984 - trainer - INFO -     val_embedding_sim: 0.0769110843539238
2025-01-21 12:13:24,984 - trainer - INFO - ================================================================================
2025-01-21 12:13:24,984 - trainer - INFO - Starting epoch 30 at 2025-01-21 12:13:24
2025-01-21 12:13:28,886 - trainer - INFO - Epoch 30 completed at 2025-01-21 12:13:28
2025-01-21 12:13:28,886 - trainer - INFO -     epoch          : 30
2025-01-21 12:13:28,886 - trainer - INFO -     elapsed time   : 3.901378870010376
2025-01-21 12:13:28,886 - trainer - INFO -     loss           : 0.10120213970076293
2025-01-21 12:13:28,886 - trainer - INFO -     sim_loss       : 0.33174478879664093
2025-01-21 12:13:28,886 - trainer - INFO -     gen_loss       : 0.0023981429520063104
2025-01-21 12:13:28,886 - trainer - INFO -     val_loss       : 0.09950484521687031
2025-01-21 12:13:28,886 - trainer - INFO -     val_sim_loss   : 0.0654469281398633
2025-01-21 12:13:28,886 - trainer - INFO -     val_gen_loss   : 0.034057920798659325
2025-01-21 12:13:28,886 - trainer - INFO -     val_perplexity : -103.36029052734375
2025-01-21 12:13:28,886 - trainer - INFO -     val_embedding_sim: 0.07830098271369934
2025-01-21 12:13:34,113 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 12:13:34,113 - trainer - INFO - ================================================================================
2025-01-21 12:13:34,113 - trainer - INFO - Starting epoch 31 at 2025-01-21 12:13:34
2025-01-21 12:13:38,066 - trainer - INFO - Epoch 31 completed at 2025-01-21 12:13:38
2025-01-21 12:13:38,066 - trainer - INFO -     epoch          : 31
2025-01-21 12:13:38,066 - trainer - INFO -     elapsed time   : 3.952497959136963
2025-01-21 12:13:38,066 - trainer - INFO -     loss           : 0.07985430570552125
2025-01-21 12:13:38,066 - trainer - INFO -     sim_loss       : 0.2611012098030187
2025-01-21 12:13:38,066 - trainer - INFO -     gen_loss       : 0.002177054586354643
2025-01-21 12:13:38,066 - trainer - INFO -     val_loss       : 0.014893395476974547
2025-01-21 12:13:38,066 - trainer - INFO -     val_sim_loss   : 0.00015293712567654438
2025-01-21 12:13:38,066 - trainer - INFO -     val_gen_loss   : 0.014740458456799388
2025-01-21 12:13:38,066 - trainer - INFO -     val_perplexity : -103.43579864501953
2025-01-21 12:13:38,066 - trainer - INFO -     val_embedding_sim: 0.08557770401239395
2025-01-21 12:13:38,066 - trainer - INFO - ================================================================================
2025-01-21 12:13:38,066 - trainer - INFO - Starting epoch 32 at 2025-01-21 12:13:38
2025-01-21 12:13:41,968 - trainer - INFO - Epoch 32 completed at 2025-01-21 12:13:41
2025-01-21 12:13:41,968 - trainer - INFO -     epoch          : 32
2025-01-21 12:13:41,968 - trainer - INFO -     elapsed time   : 3.9009408950805664
2025-01-21 12:13:41,968 - trainer - INFO -     loss           : 0.09062484316527844
2025-01-21 12:13:41,968 - trainer - INFO -     sim_loss       : 0.29727536663413046
2025-01-21 12:13:41,968 - trainer - INFO -     gen_loss       : 0.0020603257813490926
2025-01-21 12:13:41,968 - trainer - INFO -     val_loss       : 0.04170721294940449
2025-01-21 12:13:41,968 - trainer - INFO -     val_sim_loss   : 0.028234099969253634
2025-01-21 12:13:41,968 - trainer - INFO -     val_gen_loss   : 0.013473113911459222
2025-01-21 12:13:41,968 - trainer - INFO -     val_perplexity : -103.60649108886719
2025-01-21 12:13:41,968 - trainer - INFO -     val_embedding_sim: 0.09819119423627853
2025-01-21 12:13:41,968 - trainer - INFO - ================================================================================
2025-01-21 12:13:41,968 - trainer - INFO - Starting epoch 33 at 2025-01-21 12:13:41
2025-01-21 12:13:45,866 - trainer - INFO - Epoch 33 completed at 2025-01-21 12:13:45
2025-01-21 12:13:45,867 - trainer - INFO -     epoch          : 33
2025-01-21 12:13:45,867 - trainer - INFO -     elapsed time   : 3.8981995582580566
2025-01-21 12:13:45,867 - trainer - INFO -     loss           : 0.10610741637647152
2025-01-21 12:13:45,867 - trainer - INFO -     sim_loss       : 0.3492312986403704
2025-01-21 12:13:45,867 - trainer - INFO -     gen_loss       : 0.0019114630063995718
2025-01-21 12:13:45,867 - trainer - INFO -     val_loss       : 0.06623178953304887
2025-01-21 12:13:45,867 - trainer - INFO -     val_sim_loss   : 0.0505924559529376
2025-01-21 12:13:45,867 - trainer - INFO -     val_gen_loss   : 0.01563933165743947
2025-01-21 12:13:45,867 - trainer - INFO -     val_perplexity : -102.96623992919922
2025-01-21 12:13:45,867 - trainer - INFO -     val_embedding_sim: 0.08498138189315796
2025-01-21 12:13:45,867 - trainer - INFO - ================================================================================
2025-01-21 12:13:45,867 - trainer - INFO - Starting epoch 34 at 2025-01-21 12:13:45
2025-01-21 12:13:49,769 - trainer - INFO - Epoch 34 completed at 2025-01-21 12:13:49
2025-01-21 12:13:49,769 - trainer - INFO -     epoch          : 34
2025-01-21 12:13:49,769 - trainer - INFO -     elapsed time   : 3.9014549255371094
2025-01-21 12:13:49,769 - trainer - INFO -     loss           : 0.08798686633817851
2025-01-21 12:13:49,769 - trainer - INFO -     sim_loss       : 0.28913729891646656
2025-01-21 12:13:49,769 - trainer - INFO -     gen_loss       : 0.0017795303836464881
2025-01-21 12:13:49,769 - trainer - INFO -     val_loss       : 0.11709105037152767
2025-01-21 12:13:49,769 - trainer - INFO -     val_sim_loss   : 0.07548584043342998
2025-01-21 12:13:49,769 - trainer - INFO -     val_gen_loss   : 0.041605209931731224
2025-01-21 12:13:49,769 - trainer - INFO -     val_perplexity : -102.9183349609375
2025-01-21 12:13:49,769 - trainer - INFO -     val_embedding_sim: 0.06759732216596603
2025-01-21 12:13:49,769 - trainer - INFO - ================================================================================
2025-01-21 12:13:49,769 - trainer - INFO - Starting epoch 35 at 2025-01-21 12:13:49
2025-01-21 12:13:53,663 - trainer - INFO - Epoch 35 completed at 2025-01-21 12:13:53
2025-01-21 12:13:53,663 - trainer - INFO -     epoch          : 35
2025-01-21 12:13:53,663 - trainer - INFO -     elapsed time   : 3.8937063217163086
2025-01-21 12:13:53,663 - trainer - INFO -     loss           : 0.09455824811011553
2025-01-21 12:13:53,663 - trainer - INFO -     sim_loss       : 0.3110155303031206
2025-01-21 12:13:53,663 - trainer - INFO -     gen_loss       : 0.0017908348934724927
2025-01-21 12:13:53,663 - trainer - INFO -     val_loss       : 0.27884843572974205
2025-01-21 12:13:53,663 - trainer - INFO -     val_sim_loss   : 0.24875271320343018
2025-01-21 12:13:53,663 - trainer - INFO -     val_gen_loss   : 0.030095715075731277
2025-01-21 12:13:53,663 - trainer - INFO -     val_perplexity : -104.68647003173828
2025-01-21 12:13:53,663 - trainer - INFO -     val_embedding_sim: 0.06622803211212158
2025-01-21 12:13:58,891 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 12:13:58,892 - trainer - INFO - ================================================================================
2025-01-21 12:13:58,892 - trainer - INFO - Starting epoch 36 at 2025-01-21 12:13:58
2025-01-21 12:14:02,871 - trainer - INFO - Epoch 36 completed at 2025-01-21 12:14:02
2025-01-21 12:14:02,871 - trainer - INFO -     epoch          : 36
2025-01-21 12:14:02,871 - trainer - INFO -     elapsed time   : 3.978708267211914
2025-01-21 12:14:02,871 - trainer - INFO -     loss           : 0.101466144900769
2025-01-21 12:14:02,871 - trainer - INFO -     sim_loss       : 0.334393048658967
2025-01-21 12:14:02,871 - trainer - INFO -     gen_loss       : 0.0016403208952397107
2025-01-21 12:14:02,871 - trainer - INFO -     val_loss       : 0.09117621346376836
2025-01-21 12:14:02,871 - trainer - INFO -     val_sim_loss   : 0.07720126828644425
2025-01-21 12:14:02,871 - trainer - INFO -     val_gen_loss   : 0.013974941401102114
2025-01-21 12:14:02,871 - trainer - INFO -     val_perplexity : -104.4770278930664
2025-01-21 12:14:02,871 - trainer - INFO -     val_embedding_sim: 0.09812134504318237
2025-01-21 12:14:02,871 - trainer - INFO - ================================================================================
2025-01-21 12:14:02,871 - trainer - INFO - Starting epoch 37 at 2025-01-21 12:14:02
2025-01-21 12:14:06,761 - trainer - INFO - Epoch 37 completed at 2025-01-21 12:14:06
2025-01-21 12:14:06,761 - trainer - INFO -     epoch          : 37
2025-01-21 12:14:06,761 - trainer - INFO -     elapsed time   : 3.889690399169922
2025-01-21 12:14:06,761 - trainer - INFO -     loss           : 0.10234915539622307
2025-01-21 12:14:06,761 - trainer - INFO -     sim_loss       : 0.33765407353639604
2025-01-21 12:14:06,761 - trainer - INFO -     gen_loss       : 0.001504187216050923
2025-01-21 12:14:06,761 - trainer - INFO -     val_loss       : 0.18173967923939927
2025-01-21 12:14:06,761 - trainer - INFO -     val_sim_loss   : 0.16827958818112165
2025-01-21 12:14:06,761 - trainer - INFO -     val_gen_loss   : 0.013460091060551349
2025-01-21 12:14:06,761 - trainer - INFO -     val_perplexity : -104.15864562988281
2025-01-21 12:14:06,761 - trainer - INFO -     val_embedding_sim: 0.07227444648742676
2025-01-21 12:14:06,761 - trainer - INFO - ================================================================================
2025-01-21 12:14:06,762 - trainer - INFO - Starting epoch 38 at 2025-01-21 12:14:06
2025-01-21 12:14:10,673 - trainer - INFO - Epoch 38 completed at 2025-01-21 12:14:10
2025-01-21 12:14:10,674 - trainer - INFO -     epoch          : 38
2025-01-21 12:14:10,674 - trainer - INFO -     elapsed time   : 3.9117140769958496
2025-01-21 12:14:10,674 - trainer - INFO -     loss           : 0.10462225507944822
2025-01-21 12:14:10,674 - trainer - INFO -     sim_loss       : 0.34534977823495866
2025-01-21 12:14:10,674 - trainer - INFO -     gen_loss       : 0.0014533105306327343
2025-01-21 12:14:10,674 - trainer - INFO -     val_loss       : 0.014454301046498585
2025-01-21 12:14:10,674 - trainer - INFO -     val_sim_loss   : 0.0007949376474698511
2025-01-21 12:14:10,674 - trainer - INFO -     val_gen_loss   : 0.013659363226906862
2025-01-21 12:14:10,674 - trainer - INFO -     val_perplexity : -104.41584777832031
2025-01-21 12:14:10,674 - trainer - INFO -     val_embedding_sim: 0.06641793251037598
2025-01-21 12:14:10,674 - trainer - INFO - ================================================================================
2025-01-21 12:14:10,674 - trainer - INFO - Starting epoch 39 at 2025-01-21 12:14:10
2025-01-21 12:14:14,572 - trainer - INFO - Epoch 39 completed at 2025-01-21 12:14:14
2025-01-21 12:14:14,572 - trainer - INFO -     epoch          : 39
2025-01-21 12:14:14,572 - trainer - INFO -     elapsed time   : 3.8977692127227783
2025-01-21 12:14:14,572 - trainer - INFO -     loss           : 0.09332378040999174
2025-01-21 12:14:14,572 - trainer - INFO -     sim_loss       : 0.3077847920358181
2025-01-21 12:14:14,572 - trainer - INFO -     gen_loss       : 0.001411914301570505
2025-01-21 12:14:14,572 - trainer - INFO -     val_loss       : 0.35216622054576874
2025-01-21 12:14:14,572 - trainer - INFO -     val_sim_loss   : 0.21270285544278522
2025-01-21 12:14:14,572 - trainer - INFO -     val_gen_loss   : 0.13946336694061756
2025-01-21 12:14:14,572 - trainer - INFO -     val_perplexity : -104.86077117919922
2025-01-21 12:14:14,572 - trainer - INFO -     val_embedding_sim: 0.08482655137777328
2025-01-21 12:14:14,572 - trainer - INFO - ================================================================================
2025-01-21 12:14:14,572 - trainer - INFO - Starting epoch 40 at 2025-01-21 12:14:14
2025-01-21 12:14:18,474 - trainer - INFO - Epoch 40 completed at 2025-01-21 12:14:18
2025-01-21 12:14:18,474 - trainer - INFO -     epoch          : 40
2025-01-21 12:14:18,474 - trainer - INFO -     elapsed time   : 3.901560068130493
2025-01-21 12:14:18,474 - trainer - INFO -     loss           : 0.14628748539835215
2025-01-21 12:14:18,474 - trainer - INFO -     sim_loss       : 0.4844687541946769
2025-01-21 12:14:18,474 - trainer - INFO -     gen_loss       : 0.0013526513939723372
2025-01-21 12:14:18,474 - trainer - INFO -     val_loss       : 0.4011995904147625
2025-01-21 12:14:18,475 - trainer - INFO -     val_sim_loss   : 0.35940319299697876
2025-01-21 12:14:18,475 - trainer - INFO -     val_gen_loss   : 0.04179640952497721
2025-01-21 12:14:18,475 - trainer - INFO -     val_perplexity : -104.95860290527344
2025-01-21 12:14:18,475 - trainer - INFO -     val_embedding_sim: 0.07748822867870331
2025-01-21 12:14:23,708 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 12:14:23,708 - trainer - INFO - ================================================================================
2025-01-21 12:14:23,708 - trainer - INFO - Starting epoch 41 at 2025-01-21 12:14:23
2025-01-21 12:14:27,644 - trainer - INFO - Epoch 41 completed at 2025-01-21 12:14:27
2025-01-21 12:14:27,644 - trainer - INFO -     epoch          : 41
2025-01-21 12:14:27,644 - trainer - INFO -     elapsed time   : 3.935396909713745
2025-01-21 12:14:27,644 - trainer - INFO -     loss           : 0.10000293226912618
2025-01-21 12:14:27,644 - trainer - INFO -     sim_loss       : 0.3302703820168972
2025-01-21 12:14:27,644 - trainer - INFO -     gen_loss       : 0.0013168762321583926
2025-01-21 12:14:27,644 - trainer - INFO -     val_loss       : 0.14070225728937658
2025-01-21 12:14:27,644 - trainer - INFO -     val_sim_loss   : 0.1270534991654131
2025-01-21 12:14:27,644 - trainer - INFO -     val_gen_loss   : 0.013648762782395352
2025-01-21 12:14:27,644 - trainer - INFO -     val_perplexity : -104.9841079711914
2025-01-21 12:14:27,644 - trainer - INFO -     val_embedding_sim: 0.07378402352333069
2025-01-21 12:14:27,644 - trainer - INFO - ================================================================================
2025-01-21 12:14:27,644 - trainer - INFO - Starting epoch 42 at 2025-01-21 12:14:27
2025-01-21 12:14:31,537 - trainer - INFO - Epoch 42 completed at 2025-01-21 12:14:31
2025-01-21 12:14:31,537 - trainer - INFO -     epoch          : 42
2025-01-21 12:14:31,537 - trainer - INFO -     elapsed time   : 3.892854928970337
2025-01-21 12:14:31,537 - trainer - INFO -     loss           : 0.10411776704713702
2025-01-21 12:14:31,537 - trainer - INFO -     sim_loss       : 0.34427304603159425
2025-01-21 12:14:31,537 - trainer - INFO -     gen_loss       : 0.0011940697848331183
2025-01-21 12:14:31,537 - trainer - INFO -     val_loss       : 5.296781942248344
2025-01-21 12:14:31,537 - trainer - INFO -     val_sim_loss   : 5.279278188943863
2025-01-21 12:14:31,537 - trainer - INFO -     val_gen_loss   : 0.017503748182207346
2025-01-21 12:14:31,538 - trainer - INFO -     val_perplexity : -104.54052734375
2025-01-21 12:14:31,538 - trainer - INFO -     val_embedding_sim: 0.06941412389278412
2025-01-21 12:14:31,538 - trainer - INFO - ================================================================================
2025-01-21 12:14:31,538 - trainer - INFO - Starting epoch 43 at 2025-01-21 12:14:31
2025-01-21 12:14:35,436 - trainer - INFO - Epoch 43 completed at 2025-01-21 12:14:35
2025-01-21 12:14:35,437 - trainer - INFO -     epoch          : 43
2025-01-21 12:14:35,437 - trainer - INFO -     elapsed time   : 3.898655652999878
2025-01-21 12:14:35,437 - trainer - INFO -     loss           : 0.10186524195596576
2025-01-21 12:14:35,437 - trainer - INFO -     sim_loss       : 0.3368681099265814
2025-01-21 12:14:35,437 - trainer - INFO -     gen_loss       : 0.0011497245053760708
2025-01-21 12:14:35,437 - trainer - INFO -     val_loss       : 0.1357298344373703
2025-01-21 12:14:35,437 - trainer - INFO -     val_sim_loss   : 0.11242485046386719
2025-01-21 12:14:35,437 - trainer - INFO -     val_gen_loss   : 0.023304983042180538
2025-01-21 12:14:35,437 - trainer - INFO -     val_perplexity : -104.533203125
2025-01-21 12:14:35,437 - trainer - INFO -     val_embedding_sim: 0.0852239653468132
2025-01-21 12:14:35,437 - trainer - INFO - ================================================================================
2025-01-21 12:14:35,437 - trainer - INFO - Starting epoch 44 at 2025-01-21 12:14:35
2025-01-21 12:14:39,345 - trainer - INFO - Epoch 44 completed at 2025-01-21 12:14:39
2025-01-21 12:14:39,346 - trainer - INFO -     epoch          : 44
2025-01-21 12:14:39,346 - trainer - INFO -     elapsed time   : 3.9083030223846436
2025-01-21 12:14:39,346 - trainer - INFO -     loss           : 0.10605226382613182
2025-01-21 12:14:39,346 - trainer - INFO -     sim_loss       : 0.35101559534668925
2025-01-21 12:14:39,346 - trainer - INFO -     gen_loss       : 0.0010679699538741262
2025-01-21 12:14:39,346 - trainer - INFO -     val_loss       : 0.030446465243585408
2025-01-21 12:14:39,346 - trainer - INFO -     val_sim_loss   : 0.017232485040040046
2025-01-21 12:14:39,346 - trainer - INFO -     val_gen_loss   : 0.013213980204454856
2025-01-21 12:14:39,346 - trainer - INFO -     val_perplexity : -105.85009765625
2025-01-21 12:14:39,346 - trainer - INFO -     val_embedding_sim: 0.09950023889541626
2025-01-21 12:14:39,346 - trainer - INFO - ================================================================================
2025-01-21 12:14:39,346 - trainer - INFO - Starting epoch 45 at 2025-01-21 12:14:39
2025-01-21 12:14:43,257 - trainer - INFO - Epoch 45 completed at 2025-01-21 12:14:43
2025-01-21 12:14:43,257 - trainer - INFO -     epoch          : 45
2025-01-21 12:14:43,257 - trainer - INFO -     elapsed time   : 3.9105584621429443
2025-01-21 12:14:43,257 - trainer - INFO -     loss           : 0.07690741530386731
2025-01-21 12:14:43,257 - trainer - INFO -     sim_loss       : 0.25402462800266223
2025-01-21 12:14:43,257 - trainer - INFO -     gen_loss       : 0.0010000329930335283
2025-01-21 12:14:43,257 - trainer - INFO -     val_loss       : 0.930978674441576
2025-01-21 12:14:43,257 - trainer - INFO -     val_sim_loss   : 0.918201943859458
2025-01-21 12:14:43,257 - trainer - INFO -     val_gen_loss   : 0.012776743500580778
2025-01-21 12:14:43,257 - trainer - INFO -     val_perplexity : -106.64859008789062
2025-01-21 12:14:43,257 - trainer - INFO -     val_embedding_sim: 0.08278533071279526
2025-01-21 12:14:48,475 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 12:14:53,752 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 12:14:53,752 - trainer - INFO - ================================================================================
2025-01-21 12:14:53,752 - trainer - INFO - Starting epoch 46 at 2025-01-21 12:14:53
2025-01-21 12:14:57,720 - trainer - INFO - Epoch 46 completed at 2025-01-21 12:14:57
2025-01-21 12:14:57,720 - trainer - INFO -     epoch          : 46
2025-01-21 12:14:57,720 - trainer - INFO -     elapsed time   : 3.9676687717437744
2025-01-21 12:14:57,720 - trainer - INFO -     loss           : 0.08549233861267566
2025-01-21 12:14:57,720 - trainer - INFO -     sim_loss       : 0.28270194977521895
2025-01-21 12:14:57,720 - trainer - INFO -     gen_loss       : 0.0009739296103361994
2025-01-21 12:14:57,720 - trainer - INFO -     val_loss       : 0.08617198708816431
2025-01-21 12:14:57,720 - trainer - INFO -     val_sim_loss   : 0.07342188781694858
2025-01-21 12:14:57,720 - trainer - INFO -     val_gen_loss   : 0.012750102061545476
2025-01-21 12:14:57,720 - trainer - INFO -     val_perplexity : -106.75439453125
2025-01-21 12:14:57,721 - trainer - INFO -     val_embedding_sim: 0.07271942496299744
2025-01-21 12:14:57,721 - trainer - INFO - ================================================================================
2025-01-21 12:14:57,721 - trainer - INFO - Starting epoch 47 at 2025-01-21 12:14:57
2025-01-21 12:15:01,618 - trainer - INFO - Epoch 47 completed at 2025-01-21 12:15:01
2025-01-21 12:15:01,618 - trainer - INFO -     epoch          : 47
2025-01-21 12:15:01,618 - trainer - INFO -     elapsed time   : 3.8974575996398926
2025-01-21 12:15:01,618 - trainer - INFO -     loss           : 0.07078784908517263
2025-01-21 12:15:01,618 - trainer - INFO -     sim_loss       : 0.2337655614814139
2025-01-21 12:15:01,618 - trainer - INFO -     gen_loss       : 0.0009402521187439561
2025-01-21 12:15:01,619 - trainer - INFO -     val_loss       : 0.4964383542537689
2025-01-21 12:15:01,619 - trainer - INFO -     val_sim_loss   : 0.4283808171749115
2025-01-21 12:15:01,619 - trainer - INFO -     val_gen_loss   : 0.0680575454607606
2025-01-21 12:15:01,619 - trainer - INFO -     val_perplexity : -106.57011413574219
2025-01-21 12:15:01,619 - trainer - INFO -     val_embedding_sim: 0.08886032551527023
2025-01-21 12:15:01,619 - trainer - INFO - ================================================================================
2025-01-21 12:15:01,619 - trainer - INFO - Starting epoch 48 at 2025-01-21 12:15:01
2025-01-21 12:15:05,522 - trainer - INFO - Epoch 48 completed at 2025-01-21 12:15:05
2025-01-21 12:15:05,522 - trainer - INFO -     epoch          : 48
2025-01-21 12:15:05,522 - trainer - INFO -     elapsed time   : 3.903137683868408
2025-01-21 12:15:05,522 - trainer - INFO -     loss           : 0.10048966910690069
2025-01-21 12:15:05,522 - trainer - INFO -     sim_loss       : 0.33278617560863494
2025-01-21 12:15:05,522 - trainer - INFO -     gen_loss       : 0.0009340168151538819
2025-01-21 12:15:05,522 - trainer - INFO -     val_loss       : 0.059834770698216744
2025-01-21 12:15:05,522 - trainer - INFO -     val_sim_loss   : 0.046997951099911006
2025-01-21 12:15:05,522 - trainer - INFO -     val_gen_loss   : 0.012836820533266291
2025-01-21 12:15:05,523 - trainer - INFO -     val_perplexity : -105.8727798461914
2025-01-21 12:15:05,523 - trainer - INFO -     val_embedding_sim: 0.08594706654548645
2025-01-21 12:15:05,523 - trainer - INFO - ================================================================================
2025-01-21 12:15:05,523 - trainer - INFO - Starting epoch 49 at 2025-01-21 12:15:05
2025-01-21 12:15:09,424 - trainer - INFO - Epoch 49 completed at 2025-01-21 12:15:09
2025-01-21 12:15:09,424 - trainer - INFO -     epoch          : 49
2025-01-21 12:15:09,424 - trainer - INFO -     elapsed time   : 3.9008092880249023
2025-01-21 12:15:09,424 - trainer - INFO -     loss           : 0.11182742677628994
2025-01-21 12:15:09,424 - trainer - INFO -     sim_loss       : 0.3706013672053814
2025-01-21 12:15:09,424 - trainer - INFO -     gen_loss       : 0.0009243049134965986
2025-01-21 12:15:09,424 - trainer - INFO -     val_loss       : 1.6253209710121155
2025-01-21 12:15:09,424 - trainer - INFO -     val_sim_loss   : 1.6121951341629028
2025-01-21 12:15:09,424 - trainer - INFO -     val_gen_loss   : 0.01312579926889157
2025-01-21 12:15:09,424 - trainer - INFO -     val_perplexity : -106.04853820800781
2025-01-21 12:15:09,424 - trainer - INFO -     val_embedding_sim: 0.06751499325037003
2025-01-21 12:15:09,424 - trainer - INFO - ================================================================================
2025-01-21 12:15:09,424 - trainer - INFO - Starting epoch 50 at 2025-01-21 12:15:09
2025-01-21 12:15:13,319 - trainer - INFO - Epoch 50 completed at 2025-01-21 12:15:13
2025-01-21 12:15:13,319 - trainer - INFO -     epoch          : 50
2025-01-21 12:15:13,319 - trainer - INFO -     elapsed time   : 3.8943300247192383
2025-01-21 12:15:13,319 - trainer - INFO -     loss           : 0.15110469185747205
2025-01-21 12:15:13,319 - trainer - INFO -     sim_loss       : 0.5016250717897492
2025-01-21 12:15:13,319 - trainer - INFO -     gen_loss       : 0.0008816571906208992
2025-01-21 12:15:13,319 - trainer - INFO -     val_loss       : 0.2284568458344438
2025-01-21 12:15:13,319 - trainer - INFO -     val_sim_loss   : 0.21560394763946533
2025-01-21 12:15:13,319 - trainer - INFO -     val_gen_loss   : 0.012852904714236502
2025-01-21 12:15:13,319 - trainer - INFO -     val_perplexity : -107.47711181640625
2025-01-21 12:15:13,319 - trainer - INFO -     val_embedding_sim: 0.11606642603874207
2025-01-21 12:15:18,547 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 12:15:18,548 - trainer - INFO - ================================================================================
2025-01-21 12:15:18,548 - trainer - INFO - Starting epoch 51 at 2025-01-21 12:15:18
2025-01-21 12:15:22,493 - trainer - INFO - Epoch 51 completed at 2025-01-21 12:15:22
2025-01-21 12:15:22,493 - trainer - INFO -     epoch          : 51
2025-01-21 12:15:22,493 - trainer - INFO -     elapsed time   : 3.944819688796997
2025-01-21 12:15:22,493 - trainer - INFO -     loss           : 0.07840444723842666
2025-01-21 12:15:22,493 - trainer - INFO -     sim_loss       : 0.2593628507223912
2025-01-21 12:15:22,493 - trainer - INFO -     gen_loss       : 0.0008508368453476578
2025-01-21 12:15:22,493 - trainer - INFO -     val_loss       : 0.4795803427696228
2025-01-21 12:15:22,493 - trainer - INFO -     val_sim_loss   : 0.4618219695985317
2025-01-21 12:15:22,493 - trainer - INFO -     val_gen_loss   : 0.01775836292654276
2025-01-21 12:15:22,493 - trainer - INFO -     val_perplexity : -106.11956024169922
2025-01-21 12:15:22,493 - trainer - INFO -     val_embedding_sim: 0.048791415989398956
2025-01-21 12:15:22,493 - trainer - INFO - ================================================================================
2025-01-21 12:15:22,493 - trainer - INFO - Starting epoch 52 at 2025-01-21 12:15:22
2025-01-21 12:15:26,391 - trainer - INFO - Epoch 52 completed at 2025-01-21 12:15:26
2025-01-21 12:15:26,391 - trainer - INFO -     epoch          : 52
2025-01-21 12:15:26,391 - trainer - INFO -     elapsed time   : 3.897181510925293
2025-01-21 12:15:26,391 - trainer - INFO -     loss           : 0.09184882100671529
2025-01-21 12:15:26,391 - trainer - INFO -     sim_loss       : 0.30424755476415155
2025-01-21 12:15:26,391 - trainer - INFO -     gen_loss       : 0.000820787443080917
2025-01-21 12:15:26,391 - trainer - INFO -     val_loss       : 0.3344759000465274
2025-01-21 12:15:26,391 - trainer - INFO -     val_sim_loss   : 0.31275448203064116
2025-01-21 12:15:26,391 - trainer - INFO -     val_gen_loss   : 0.021721430122852325
2025-01-21 12:15:26,391 - trainer - INFO -     val_perplexity : -105.93647003173828
2025-01-21 12:15:26,391 - trainer - INFO -     val_embedding_sim: 0.08586350083351135
2025-01-21 12:15:26,391 - trainer - INFO - ================================================================================
2025-01-21 12:15:26,391 - trainer - INFO - Starting epoch 53 at 2025-01-21 12:15:26
2025-01-21 12:15:30,299 - trainer - INFO - Epoch 53 completed at 2025-01-21 12:15:30
2025-01-21 12:15:30,299 - trainer - INFO -     epoch          : 53
2025-01-21 12:15:30,299 - trainer - INFO -     elapsed time   : 3.907573938369751
2025-01-21 12:15:30,299 - trainer - INFO -     loss           : 0.0788644099724479
2025-01-21 12:15:30,299 - trainer - INFO -     sim_loss       : 0.2611421449313639
2025-01-21 12:15:30,299 - trainer - INFO -     gen_loss       : 0.0007453750004060566
2025-01-21 12:15:30,299 - trainer - INFO -     val_loss       : 1.1950251758098602
2025-01-21 12:15:30,299 - trainer - INFO -     val_sim_loss   : 1.1299535781145096
2025-01-21 12:15:30,299 - trainer - INFO -     val_gen_loss   : 0.06507164612412453
2025-01-21 12:15:30,299 - trainer - INFO -     val_perplexity : -108.12197875976562
2025-01-21 12:15:30,299 - trainer - INFO -     val_embedding_sim: 0.07133626937866211
2025-01-21 12:15:30,300 - trainer - INFO - ================================================================================
2025-01-21 12:15:30,300 - trainer - INFO - Starting epoch 54 at 2025-01-21 12:15:30
2025-01-21 12:15:34,193 - trainer - INFO - Epoch 54 completed at 2025-01-21 12:15:34
2025-01-21 12:15:34,193 - trainer - INFO -     epoch          : 54
2025-01-21 12:15:34,193 - trainer - INFO -     elapsed time   : 3.892934799194336
2025-01-21 12:15:34,193 - trainer - INFO -     loss           : 0.07634898833930492
2025-01-21 12:15:34,193 - trainer - INFO -     sim_loss       : 0.2526446938514709
2025-01-21 12:15:34,193 - trainer - INFO -     gen_loss       : 0.0007936807291116565
2025-01-21 12:15:34,193 - trainer - INFO -     val_loss       : 0.185197401791811
2025-01-21 12:15:34,193 - trainer - INFO -     val_sim_loss   : 0.16809307841322152
2025-01-21 12:15:34,193 - trainer - INFO -     val_gen_loss   : 0.017104326281696558
2025-01-21 12:15:34,193 - trainer - INFO -     val_perplexity : -106.63566589355469
2025-01-21 12:15:34,193 - trainer - INFO -     val_embedding_sim: 0.08894482254981995
2025-01-21 12:15:34,193 - trainer - INFO - ================================================================================
2025-01-21 12:15:34,193 - trainer - INFO - Starting epoch 55 at 2025-01-21 12:15:34
2025-01-21 12:15:38,081 - trainer - INFO - Epoch 55 completed at 2025-01-21 12:15:38
2025-01-21 12:15:38,081 - trainer - INFO -     epoch          : 55
2025-01-21 12:15:38,081 - trainer - INFO -     elapsed time   : 3.887786865234375
2025-01-21 12:15:38,081 - trainer - INFO -     loss           : 0.07783324718475342
2025-01-21 12:15:38,081 - trainer - INFO -     sim_loss       : 0.2577426411211491
2025-01-21 12:15:38,081 - trainer - INFO -     gen_loss       : 0.0007292151509318501
2025-01-21 12:15:38,081 - trainer - INFO -     val_loss       : 0.16960915690287948
2025-01-21 12:15:38,082 - trainer - INFO -     val_sim_loss   : 0.15564817190161762
2025-01-21 12:15:38,082 - trainer - INFO -     val_gen_loss   : 0.013960991520434618
2025-01-21 12:15:38,082 - trainer - INFO -     val_perplexity : -107.2146987915039
2025-01-21 12:15:38,082 - trainer - INFO -     val_embedding_sim: 0.0844593495130539
2025-01-21 12:15:43,317 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch55.pth ...
2025-01-21 12:15:43,317 - trainer - INFO - ================================================================================
2025-01-21 12:15:43,317 - trainer - INFO - Starting epoch 56 at 2025-01-21 12:15:43
2025-01-21 12:15:47,258 - trainer - INFO - Epoch 56 completed at 2025-01-21 12:15:47
2025-01-21 12:15:47,258 - trainer - INFO -     epoch          : 56
2025-01-21 12:15:47,258 - trainer - INFO -     elapsed time   : 3.940178394317627
2025-01-21 12:15:47,258 - trainer - INFO -     loss           : 0.11708678789436817
2025-01-21 12:15:47,258 - trainer - INFO -     sim_loss       : 0.3886065687984228
2025-01-21 12:15:47,258 - trainer - INFO -     gen_loss       : 0.0007211593503598124
2025-01-21 12:15:47,258 - trainer - INFO -     val_loss       : 0.13565531093627214
2025-01-21 12:15:47,258 - trainer - INFO -     val_sim_loss   : 0.10851269207978476
2025-01-21 12:15:47,258 - trainer - INFO -     val_gen_loss   : 0.027142619714140892
2025-01-21 12:15:47,258 - trainer - INFO -     val_perplexity : -106.96465301513672
2025-01-21 12:15:47,258 - trainer - INFO -     val_embedding_sim: 0.06536082923412323
2025-01-21 12:15:47,258 - trainer - INFO - ================================================================================
2025-01-21 12:15:47,258 - trainer - INFO - Starting epoch 57 at 2025-01-21 12:15:47
2025-01-21 12:15:51,156 - trainer - INFO - Epoch 57 completed at 2025-01-21 12:15:51
2025-01-21 12:15:51,156 - trainer - INFO -     epoch          : 57
2025-01-21 12:15:51,156 - trainer - INFO -     elapsed time   : 3.897728204727173
2025-01-21 12:15:51,156 - trainer - INFO -     loss           : 0.06849413535092026
2025-01-21 12:15:51,156 - trainer - INFO -     sim_loss       : 0.2267177666812131
2025-01-21 12:15:51,156 - trainer - INFO -     gen_loss       : 0.0006840054469648748
2025-01-21 12:15:51,156 - trainer - INFO -     val_loss       : 0.030134679516777396
2025-01-21 12:15:51,157 - trainer - INFO -     val_sim_loss   : 0.017322467640042305
2025-01-21 12:15:51,157 - trainer - INFO -     val_gen_loss   : 0.012812212808057666
2025-01-21 12:15:51,157 - trainer - INFO -     val_perplexity : -107.8714828491211
2025-01-21 12:15:51,157 - trainer - INFO -     val_embedding_sim: 0.06675321608781815
2025-01-21 12:15:51,157 - trainer - INFO - ================================================================================
2025-01-21 12:15:51,157 - trainer - INFO - Starting epoch 58 at 2025-01-21 12:15:51
2025-01-21 12:15:55,055 - trainer - INFO - Epoch 58 completed at 2025-01-21 12:15:55
2025-01-21 12:15:55,055 - trainer - INFO -     epoch          : 58
2025-01-21 12:15:55,055 - trainer - INFO -     elapsed time   : 3.8978333473205566
2025-01-21 12:15:55,055 - trainer - INFO -     loss           : 0.06882718292763457
2025-01-21 12:15:55,055 - trainer - INFO -     sim_loss       : 0.2278847918729298
2025-01-21 12:15:55,055 - trainer - INFO -     gen_loss       : 0.0006596347433514893
2025-01-21 12:15:55,055 - trainer - INFO -     val_loss       : 1.2656963095068932
2025-01-21 12:15:55,055 - trainer - INFO -     val_sim_loss   : 1.252673052251339
2025-01-21 12:15:55,055 - trainer - INFO -     val_gen_loss   : 0.01302322703122627
2025-01-21 12:15:55,055 - trainer - INFO -     val_perplexity : -107.35318756103516
2025-01-21 12:15:55,055 - trainer - INFO -     val_embedding_sim: 0.059762537479400635
2025-01-21 12:15:55,055 - trainer - INFO - ================================================================================
2025-01-21 12:15:55,055 - trainer - INFO - Starting epoch 59 at 2025-01-21 12:15:55
2025-01-21 12:15:58,958 - trainer - INFO - Epoch 59 completed at 2025-01-21 12:15:58
2025-01-21 12:15:58,959 - trainer - INFO -     epoch          : 59
2025-01-21 12:15:58,959 - trainer - INFO -     elapsed time   : 3.9029409885406494
2025-01-21 12:15:58,959 - trainer - INFO -     loss           : 0.12296505191770848
2025-01-21 12:15:58,959 - trainer - INFO -     sim_loss       : 0.40838865384030215
2025-01-21 12:15:58,959 - trainer - INFO -     gen_loss       : 0.0006406450585927815
2025-01-21 12:15:58,959 - trainer - INFO -     val_loss       : 1.60134819149971
2025-01-21 12:15:58,959 - trainer - INFO -     val_sim_loss   : 1.58853417634964
2025-01-21 12:15:58,959 - trainer - INFO -     val_gen_loss   : 0.012814067049475852
2025-01-21 12:15:58,959 - trainer - INFO -     val_perplexity : -108.8591537475586
2025-01-21 12:15:58,959 - trainer - INFO -     val_embedding_sim: 0.08580271899700165
2025-01-21 12:15:58,959 - trainer - INFO - ================================================================================
2025-01-21 12:15:58,959 - trainer - INFO - Starting epoch 60 at 2025-01-21 12:15:58
2025-01-21 12:16:02,870 - trainer - INFO - Epoch 60 completed at 2025-01-21 12:16:02
2025-01-21 12:16:02,871 - trainer - INFO -     epoch          : 60
2025-01-21 12:16:02,871 - trainer - INFO -     elapsed time   : 3.91129469871521
2025-01-21 12:16:02,871 - trainer - INFO -     loss           : 0.12126964665949344
2025-01-21 12:16:02,871 - trainer - INFO -     sim_loss       : 0.4027796447277069
2025-01-21 12:16:02,871 - trainer - INFO -     gen_loss       : 0.0006224931974429637
2025-01-21 12:16:02,871 - trainer - INFO -     val_loss       : 0.11345502228141413
2025-01-21 12:16:02,871 - trainer - INFO -     val_sim_loss   : 0.10066629946231842
2025-01-21 12:16:02,871 - trainer - INFO -     val_gen_loss   : 0.01278872281909571
2025-01-21 12:16:02,871 - trainer - INFO -     val_perplexity : -108.92328643798828
2025-01-21 12:16:02,871 - trainer - INFO -     val_embedding_sim: 0.09953527897596359
2025-01-21 12:16:08,099 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch60.pth ...
2025-01-21 12:16:08,100 - trainer - INFO - ================================================================================
2025-01-21 12:16:08,100 - trainer - INFO - Starting epoch 61 at 2025-01-21 12:16:08
2025-01-21 12:16:12,037 - trainer - INFO - Epoch 61 completed at 2025-01-21 12:16:12
2025-01-21 12:16:12,037 - trainer - INFO -     epoch          : 61
2025-01-21 12:16:12,037 - trainer - INFO -     elapsed time   : 3.937443971633911
2025-01-21 12:16:12,038 - trainer - INFO -     loss           : 0.06578544341027737
2025-01-21 12:16:12,038 - trainer - INFO -     sim_loss       : 0.2178322948515415
2025-01-21 12:16:12,038 - trainer - INFO -     gen_loss       : 0.0006225030694622547
2025-01-21 12:16:12,038 - trainer - INFO -     val_loss       : 0.21209682737389812
2025-01-21 12:16:12,038 - trainer - INFO -     val_sim_loss   : 0.19910509884351768
2025-01-21 12:16:12,038 - trainer - INFO -     val_gen_loss   : 0.01299173504958162
2025-01-21 12:16:12,038 - trainer - INFO -     val_perplexity : -107.70469665527344
2025-01-21 12:16:12,038 - trainer - INFO -     val_embedding_sim: 0.07472479343414307
2025-01-21 12:16:12,038 - trainer - INFO - ================================================================================
2025-01-21 12:16:12,038 - trainer - INFO - Starting epoch 62 at 2025-01-21 12:16:12
2025-01-21 12:16:15,931 - trainer - INFO - Epoch 62 completed at 2025-01-21 12:16:15
2025-01-21 12:16:15,931 - trainer - INFO -     epoch          : 62
2025-01-21 12:16:15,931 - trainer - INFO -     elapsed time   : 3.8926329612731934
2025-01-21 12:16:15,931 - trainer - INFO -     loss           : 0.08363417231594213
2025-01-21 12:16:15,931 - trainer - INFO -     sim_loss       : 0.27737550257879773
2025-01-21 12:16:15,931 - trainer - INFO -     gen_loss       : 0.000602167786564678
2025-01-21 12:16:15,931 - trainer - INFO -     val_loss       : 0.37348567321896553
2025-01-21 12:16:15,931 - trainer - INFO -     val_sim_loss   : 0.30517131090164185
2025-01-21 12:16:15,931 - trainer - INFO -     val_gen_loss   : 0.06831436138600111
2025-01-21 12:16:15,931 - trainer - INFO -     val_perplexity : -109.35236358642578
2025-01-21 12:16:15,931 - trainer - INFO -     val_embedding_sim: 0.0689721405506134
2025-01-21 12:16:15,931 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
2025-01-21 12:22:23,165 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:22:25,491 - trainer - INFO - ================================================================================
2025-01-21 12:22:25,491 - trainer - INFO - Starting epoch 1 at 2025-01-21 12:22:25
2025-01-21 12:25:25,039 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:25:27,371 - trainer - INFO - ================================================================================
2025-01-21 12:25:27,371 - trainer - INFO - Starting epoch 1 at 2025-01-21 12:25:27
2025-01-21 12:25:32,330 - trainer - INFO - Epoch 1 completed at 2025-01-21 12:25:32
2025-01-21 12:25:32,330 - trainer - INFO -     epoch          : 1
2025-01-21 12:25:32,330 - trainer - INFO -     elapsed time   : 4.958337068557739
2025-01-21 12:25:32,330 - trainer - INFO -     loss           : 5.341168999671936
2025-01-21 12:25:32,330 - trainer - INFO -     sim_loss       : 6.128888416290283
2025-01-21 12:25:32,330 - trainer - INFO -     gen_loss       : 5.003574872016907
2025-01-21 12:25:32,330 - trainer - INFO -     val_val_loss   : 7.492319164854107
2025-01-21 12:25:32,330 - trainer - INFO -     val_val_sim_loss: 2.9554122867006245
2025-01-21 12:25:32,330 - trainer - INFO -     val_val_gen_loss: 9.436707684488008
2025-01-21 12:25:32,330 - trainer - INFO -     val_val_perplexity: 12973.527458422112
2025-01-21 12:25:32,330 - trainer - INFO -     val_val_embedding_sim: 0.3151333982294256
2025-01-21 12:25:32,330 - trainer - WARNING - Warning: Metric 'val_gen_loss' is not found. Model performance monitoring is disabled.
2025-01-21 12:25:32,330 - trainer - INFO - ================================================================================
2025-01-21 12:25:32,330 - trainer - INFO - Starting epoch 2 at 2025-01-21 12:25:32
2025-01-21 12:25:36,047 - trainer - INFO - Epoch 2 completed at 2025-01-21 12:25:36
2025-01-21 12:25:36,047 - trainer - INFO -     epoch          : 2
2025-01-21 12:25:36,047 - trainer - INFO -     elapsed time   : 3.716531991958618
2025-01-21 12:25:36,047 - trainer - INFO -     loss           : 2.0476513385772703
2025-01-21 12:25:36,047 - trainer - INFO -     sim_loss       : 1.9605721712112427
2025-01-21 12:25:36,047 - trainer - INFO -     gen_loss       : 2.084970939159393
2025-01-21 12:25:36,047 - trainer - INFO -     val_val_loss   : 7.917942986343846
2025-01-21 12:25:36,047 - trainer - INFO -     val_val_sim_loss: 1.5239191741654368
2025-01-21 12:25:36,047 - trainer - INFO -     val_val_gen_loss: 10.658238844438033
2025-01-21 12:25:36,047 - trainer - INFO -     val_val_perplexity: 43196.872307054924
2025-01-21 12:25:36,047 - trainer - INFO -     val_val_embedding_sim: 0.4148093570362438
2025-01-21 12:25:36,047 - trainer - INFO - ================================================================================
2025-01-21 12:25:36,047 - trainer - INFO - Starting epoch 3 at 2025-01-21 12:25:36
2025-01-21 12:25:39,779 - trainer - INFO - Epoch 3 completed at 2025-01-21 12:25:39
2025-01-21 12:25:39,780 - trainer - INFO -     epoch          : 3
2025-01-21 12:25:39,780 - trainer - INFO -     elapsed time   : 3.731781244277954
2025-01-21 12:25:39,780 - trainer - INFO -     loss           : 1.0891296446323395
2025-01-21 12:25:39,780 - trainer - INFO -     sim_loss       : 1.1533080726861953
2025-01-21 12:25:39,780 - trainer - INFO -     gen_loss       : 1.0616246342658997
2025-01-21 12:25:39,780 - trainer - INFO -     val_val_loss   : 8.440319176876184
2025-01-21 12:25:39,780 - trainer - INFO -     val_val_sim_loss: 0.6025146403434601
2025-01-21 12:25:39,780 - trainer - INFO -     val_val_gen_loss: 11.799378857468113
2025-01-21 12:25:39,780 - trainer - INFO -     val_val_perplexity: 133750.65838068182
2025-01-21 12:25:39,780 - trainer - INFO -     val_val_embedding_sim: 0.42036291685971344
2025-01-21 12:25:39,780 - trainer - INFO - ================================================================================
2025-01-21 12:25:39,780 - trainer - INFO - Starting epoch 4 at 2025-01-21 12:25:39
2025-01-21 12:25:43,503 - trainer - INFO - Epoch 4 completed at 2025-01-21 12:25:43
2025-01-21 12:25:43,503 - trainer - INFO -     epoch          : 4
2025-01-21 12:25:43,503 - trainer - INFO -     elapsed time   : 3.72281551361084
2025-01-21 12:25:43,503 - trainer - INFO -     loss           : 0.5384092330932617
2025-01-21 12:25:43,503 - trainer - INFO -     sim_loss       : 0.5714556407183409
2025-01-21 12:25:43,503 - trainer - INFO -     gen_loss       : 0.5242464900016784
2025-01-21 12:25:43,503 - trainer - INFO -     val_val_loss   : 9.682610309485232
2025-01-21 12:25:43,503 - trainer - INFO -     val_val_sim_loss: 1.3928037556734951
2025-01-21 12:25:43,503 - trainer - INFO -     val_val_gen_loss: 13.235384565411191
2025-01-21 12:25:43,503 - trainer - INFO -     val_val_perplexity: 560158.1117424242
2025-01-21 12:25:43,503 - trainer - INFO -     val_val_embedding_sim: 0.4199765143972455
2025-01-21 12:25:43,503 - trainer - INFO - ================================================================================
2025-01-21 12:25:43,503 - trainer - INFO - Starting epoch 5 at 2025-01-21 12:25:43
2025-01-21 12:25:47,228 - trainer - INFO - Epoch 5 completed at 2025-01-21 12:25:47
2025-01-21 12:25:47,228 - trainer - INFO -     epoch          : 5
2025-01-21 12:25:47,228 - trainer - INFO -     elapsed time   : 3.7245259284973145
2025-01-21 12:25:47,228 - trainer - INFO -     loss           : 0.45310341715812685
2025-01-21 12:25:47,228 - trainer - INFO -     sim_loss       : 0.5958613395690918
2025-01-21 12:25:47,228 - trainer - INFO -     gen_loss       : 0.3919214516878128
2025-01-21 12:25:47,228 - trainer - INFO -     val_val_loss   : 9.52869701385498
2025-01-21 12:25:47,229 - trainer - INFO -     val_val_sim_loss: 0.13080889518195446
2025-01-21 12:25:47,229 - trainer - INFO -     val_val_gen_loss: 13.556363365866922
2025-01-21 12:25:47,229 - trainer - INFO -     val_val_perplexity: 773430.6931818182
2025-01-21 12:25:47,229 - trainer - INFO -     val_val_embedding_sim: 0.41931615950483264
2025-01-21 12:25:52,455 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 12:25:52,455 - trainer - INFO - ================================================================================
2025-01-21 12:25:52,455 - trainer - INFO - Starting epoch 6 at 2025-01-21 12:25:52
2025-01-21 12:25:56,231 - trainer - INFO - Epoch 6 completed at 2025-01-21 12:25:56
2025-01-21 12:25:56,232 - trainer - INFO -     epoch          : 6
2025-01-21 12:25:56,232 - trainer - INFO -     elapsed time   : 3.775800943374634
2025-01-21 12:25:56,232 - trainer - INFO -     loss           : 0.31883951723575593
2025-01-21 12:25:56,232 - trainer - INFO -     sim_loss       : 0.6371089309453964
2025-01-21 12:25:56,232 - trainer - INFO -     gen_loss       : 0.18243833929300307
2025-01-21 12:25:56,232 - trainer - INFO -     val_val_loss   : 10.01799271323464
2025-01-21 12:25:56,232 - trainer - INFO -     val_val_sim_loss: 0.37448793034436123
2025-01-21 12:25:56,232 - trainer - INFO -     val_val_gen_loss: 14.150924075733531
2025-01-21 12:25:56,232 - trainer - INFO -     val_val_perplexity: 1398723.0265151516
2025-01-21 12:25:56,232 - trainer - INFO -     val_val_embedding_sim: 0.41859930663397815
2025-01-21 12:25:56,232 - trainer - INFO - ================================================================================
2025-01-21 12:25:56,232 - trainer - INFO - Starting epoch 7 at 2025-01-21 12:25:56
2025-01-21 12:25:59,959 - trainer - INFO - Epoch 7 completed at 2025-01-21 12:25:59
2025-01-21 12:25:59,959 - trainer - INFO -     epoch          : 7
2025-01-21 12:25:59,959 - trainer - INFO -     elapsed time   : 3.7271199226379395
2025-01-21 12:25:59,959 - trainer - INFO -     loss           : 0.25650141164660456
2025-01-21 12:25:59,959 - trainer - INFO -     sim_loss       : 0.5981365352869034
2025-01-21 12:25:59,960 - trainer - INFO -     gen_loss       : 0.11008635237812996
2025-01-21 12:25:59,960 - trainer - INFO -     val_val_loss   : 10.60908401373661
2025-01-21 12:25:59,960 - trainer - INFO -     val_val_sim_loss: 0.40334035440305754
2025-01-21 12:25:59,960 - trainer - INFO -     val_val_gen_loss: 14.98297491940585
2025-01-21 12:25:59,960 - trainer - INFO -     val_val_perplexity: 3220269.287878788
2025-01-21 12:25:59,960 - trainer - INFO -     val_val_embedding_sim: 0.41832167813272186
2025-01-21 12:25:59,960 - trainer - INFO - ================================================================================
2025-01-21 12:25:59,960 - trainer - INFO - Starting epoch 8 at 2025-01-21 12:25:59
2025-01-21 12:26:03,701 - trainer - INFO - Epoch 8 completed at 2025-01-21 12:26:03
2025-01-21 12:26:03,702 - trainer - INFO -     epoch          : 8
2025-01-21 12:26:03,702 - trainer - INFO -     elapsed time   : 3.7414700984954834
2025-01-21 12:26:03,702 - trainer - INFO -     loss           : 0.2190806783735752
2025-01-21 12:26:03,702 - trainer - INFO -     sim_loss       : 0.5662208706140518
2025-01-21 12:26:03,702 - trainer - INFO -     gen_loss       : 0.07030629850924015
2025-01-21 12:26:03,702 - trainer - INFO -     val_val_loss   : 10.456241549867572
2025-01-21 12:26:03,702 - trainer - INFO -     val_val_sim_loss: 0.16666479329719688
2025-01-21 12:26:03,702 - trainer - INFO -     val_val_gen_loss: 14.866060574849447
2025-01-21 12:26:03,702 - trainer - INFO -     val_val_perplexity: 2859272.0606060605
2025-01-21 12:26:03,702 - trainer - INFO -     val_val_embedding_sim: 0.417987402641412
2025-01-21 12:26:03,702 - trainer - INFO - ================================================================================
2025-01-21 12:26:03,702 - trainer - INFO - Starting epoch 9 at 2025-01-21 12:26:03
2025-01-21 12:26:07,433 - trainer - INFO - Epoch 9 completed at 2025-01-21 12:26:07
2025-01-21 12:26:07,433 - trainer - INFO -     epoch          : 9
2025-01-21 12:26:07,433 - trainer - INFO -     elapsed time   : 3.7311129570007324
2025-01-21 12:26:07,433 - trainer - INFO -     loss           : 0.1790222518146038
2025-01-21 12:26:07,433 - trainer - INFO -     sim_loss       : 0.4818746346980333
2025-01-21 12:26:07,433 - trainer - INFO -     gen_loss       : 0.04922836869955063
2025-01-21 12:26:07,434 - trainer - INFO -     val_val_loss   : 11.026799375360662
2025-01-21 12:26:07,434 - trainer - INFO -     val_val_sim_loss: 0.5466664920706094
2025-01-21 12:26:07,434 - trainer - INFO -     val_val_gen_loss: 15.51828482656768
2025-01-21 12:26:07,434 - trainer - INFO -     val_val_perplexity: 5493655.121212121
2025-01-21 12:26:07,434 - trainer - INFO -     val_val_embedding_sim: 0.4179542597496148
2025-01-21 12:26:07,434 - trainer - INFO - ================================================================================
2025-01-21 12:26:07,434 - trainer - INFO - Starting epoch 10 at 2025-01-21 12:26:07
2025-01-21 12:26:11,156 - trainer - INFO - Epoch 10 completed at 2025-01-21 12:26:11
2025-01-21 12:26:11,156 - trainer - INFO -     epoch          : 10
2025-01-21 12:26:11,156 - trainer - INFO -     elapsed time   : 3.722015142440796
2025-01-21 12:26:11,156 - trainer - INFO -     loss           : 0.14114993661642075
2025-01-21 12:26:11,156 - trainer - INFO -     sim_loss       : 0.36595588475465773
2025-01-21 12:26:11,156 - trainer - INFO -     gen_loss       : 0.0448045251891017
2025-01-21 12:26:11,156 - trainer - INFO -     val_val_loss   : 11.149478276570639
2025-01-21 12:26:11,156 - trainer - INFO -     val_val_sim_loss: 0.6974716868646669
2025-01-21 12:26:11,156 - trainer - INFO -     val_val_gen_loss: 15.628909775705049
2025-01-21 12:26:11,156 - trainer - INFO -     val_val_perplexity: 6244931.59469697
2025-01-21 12:26:11,156 - trainer - INFO -     val_val_embedding_sim: 0.4179069526267774
2025-01-21 12:26:16,386 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 12:26:16,386 - trainer - INFO - ================================================================================
2025-01-21 12:26:16,387 - trainer - INFO - Starting epoch 11 at 2025-01-21 12:26:16
2025-01-21 12:26:20,165 - trainer - INFO - Epoch 11 completed at 2025-01-21 12:26:20
2025-01-21 12:26:20,165 - trainer - INFO -     epoch          : 11
2025-01-21 12:26:20,165 - trainer - INFO -     elapsed time   : 3.7779746055603027
2025-01-21 12:26:20,165 - trainer - INFO -     loss           : 0.1781764205545187
2025-01-21 12:26:20,165 - trainer - INFO -     sim_loss       : 0.5079369135200977
2025-01-21 12:26:20,165 - trainer - INFO -     gen_loss       : 0.03685048334300518
2025-01-21 12:26:20,165 - trainer - INFO -     val_val_loss   : 10.955672061804568
2025-01-21 12:26:20,165 - trainer - INFO -     val_val_sim_loss: 0.6795891270493016
2025-01-21 12:26:20,165 - trainer - INFO -     val_val_gen_loss: 15.359708208026309
2025-01-21 12:26:20,165 - trainer - INFO -     val_val_perplexity: 4689347.303030303
2025-01-21 12:26:20,165 - trainer - INFO -     val_val_embedding_sim: 0.4210384108803489
2025-01-21 12:26:20,165 - trainer - INFO - ================================================================================
2025-01-21 12:26:20,165 - trainer - INFO - Starting epoch 12 at 2025-01-21 12:26:20
2025-01-21 12:26:23,889 - trainer - INFO - Epoch 12 completed at 2025-01-21 12:26:23
2025-01-21 12:26:23,890 - trainer - INFO -     epoch          : 12
2025-01-21 12:26:23,890 - trainer - INFO -     elapsed time   : 3.7240312099456787
2025-01-21 12:26:23,890 - trainer - INFO -     loss           : 0.14975110590457916
2025-01-21 12:26:23,890 - trainer - INFO -     sim_loss       : 0.4318826373666525
2025-01-21 12:26:23,890 - trainer - INFO -     gen_loss       : 0.02883758395910263
2025-01-21 12:26:23,890 - trainer - INFO -     val_val_loss   : 11.210848461497914
2025-01-21 12:26:23,890 - trainer - INFO -     val_val_sim_loss: 0.18734424149222445
2025-01-21 12:26:23,890 - trainer - INFO -     val_val_gen_loss: 15.935208176121566
2025-01-21 12:26:23,890 - trainer - INFO -     val_val_perplexity: 8330470.0
2025-01-21 12:26:23,890 - trainer - INFO -     val_val_embedding_sim: 0.41698358817534015
2025-01-21 12:26:23,890 - trainer - INFO - ================================================================================
2025-01-21 12:26:23,890 - trainer - INFO - Starting epoch 13 at 2025-01-21 12:26:23
2025-01-21 12:26:27,621 - trainer - INFO - Epoch 13 completed at 2025-01-21 12:26:27
2025-01-21 12:26:27,621 - trainer - INFO -     epoch          : 13
2025-01-21 12:26:27,621 - trainer - INFO -     elapsed time   : 3.7311806678771973
2025-01-21 12:26:27,621 - trainer - INFO -     loss           : 0.12706942446529865
2025-01-21 12:26:27,622 - trainer - INFO -     sim_loss       : 0.3544509392231703
2025-01-21 12:26:27,622 - trainer - INFO -     gen_loss       : 0.029620200209319592
2025-01-21 12:26:27,622 - trainer - INFO -     val_val_loss   : 11.085716420953924
2025-01-21 12:26:27,622 - trainer - INFO -     val_val_sim_loss: 0.25346805829527014
2025-01-21 12:26:27,622 - trainer - INFO -     val_val_gen_loss: 15.728109388640434
2025-01-21 12:26:27,622 - trainer - INFO -     val_val_perplexity: 6771439.621212121
2025-01-21 12:26:27,622 - trainer - INFO -     val_val_embedding_sim: 0.42041768088485254
2025-01-21 12:26:27,622 - trainer - INFO - ================================================================================
2025-01-21 12:26:27,622 - trainer - INFO - Starting epoch 14 at 2025-01-21 12:26:27
2025-01-21 12:26:31,377 - trainer - INFO - Epoch 14 completed at 2025-01-21 12:26:31
2025-01-21 12:26:31,377 - trainer - INFO -     epoch          : 14
2025-01-21 12:26:31,377 - trainer - INFO -     elapsed time   : 3.7548651695251465
2025-01-21 12:26:31,377 - trainer - INFO -     loss           : 0.21467946525663137
2025-01-21 12:26:31,377 - trainer - INFO -     sim_loss       : 0.6744469407945871
2025-01-21 12:26:31,377 - trainer - INFO -     gen_loss       : 0.017636255081743
2025-01-21 12:26:31,377 - trainer - INFO -     val_val_loss   : 11.448194937272506
2025-01-21 12:26:31,377 - trainer - INFO -     val_val_sim_loss: 0.21703194849157048
2025-01-21 12:26:31,377 - trainer - INFO -     val_val_gen_loss: 16.261550440932766
2025-01-21 12:26:31,377 - trainer - INFO -     val_val_perplexity: 12207384.363636363
2025-01-21 12:26:31,377 - trainer - INFO -     val_val_embedding_sim: 0.416662953116677
2025-01-21 12:26:31,377 - trainer - INFO - ================================================================================
2025-01-21 12:26:31,377 - trainer - INFO - Starting epoch 15 at 2025-01-21 12:26:31
2025-01-21 12:26:35,100 - trainer - INFO - Epoch 15 completed at 2025-01-21 12:26:35
2025-01-21 12:26:35,100 - trainer - INFO -     epoch          : 15
2025-01-21 12:26:35,100 - trainer - INFO -     elapsed time   : 3.7227210998535156
2025-01-21 12:26:35,100 - trainer - INFO -     loss           : 0.09221501164138317
2025-01-21 12:26:35,100 - trainer - INFO -     sim_loss       : 0.27867771653982343
2025-01-21 12:26:35,100 - trainer - INFO -     gen_loss       : 0.01230242121964693
2025-01-21 12:26:35,100 - trainer - INFO -     val_val_loss   : 11.343646858677719
2025-01-21 12:26:35,100 - trainer - INFO -     val_val_sim_loss: 0.20052129572088068
2025-01-21 12:26:35,100 - trainer - INFO -     val_val_gen_loss: 16.119272029761113
2025-01-21 12:26:35,101 - trainer - INFO -     val_val_perplexity: 10018560.878787879
2025-01-21 12:26:35,101 - trainer - INFO -     val_val_embedding_sim: 0.41898370511604077
2025-01-21 12:26:40,335 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 12:26:40,335 - trainer - INFO - ================================================================================
2025-01-21 12:26:40,335 - trainer - INFO - Starting epoch 16 at 2025-01-21 12:26:40
2025-01-21 12:26:44,105 - trainer - INFO - Epoch 16 completed at 2025-01-21 12:26:44
2025-01-21 12:26:44,105 - trainer - INFO -     epoch          : 16
2025-01-21 12:26:44,105 - trainer - INFO -     elapsed time   : 3.7695891857147217
2025-01-21 12:26:44,105 - trainer - INFO -     loss           : 0.0847912635654211
2025-01-21 12:26:44,105 - trainer - INFO -     sim_loss       : 0.2607516527175903
2025-01-21 12:26:44,105 - trainer - INFO -     gen_loss       : 0.009379662247374654
2025-01-21 12:26:44,105 - trainer - INFO -     val_val_loss   : 11.894420450383967
2025-01-21 12:26:44,106 - trainer - INFO -     val_val_sim_loss: 0.473742557294441
2025-01-21 12:26:44,106 - trainer - INFO -     val_val_gen_loss: 16.788997014363606
2025-01-21 12:26:44,106 - trainer - INFO -     val_val_perplexity: 21924527.515151516
2025-01-21 12:26:44,106 - trainer - INFO -     val_val_embedding_sim: 0.4167743641318697
2025-01-21 12:26:44,106 - trainer - INFO - ================================================================================
2025-01-21 12:26:44,106 - trainer - INFO - Starting epoch 17 at 2025-01-21 12:26:44
2025-01-21 12:26:47,833 - trainer - INFO - Epoch 17 completed at 2025-01-21 12:26:47
2025-01-21 12:26:47,833 - trainer - INFO -     epoch          : 17
2025-01-21 12:26:47,833 - trainer - INFO -     elapsed time   : 3.726768732070923
2025-01-21 12:26:47,833 - trainer - INFO -     loss           : 0.08838043319992721
2025-01-21 12:26:47,833 - trainer - INFO -     sim_loss       : 0.2763422201154754
2025-01-21 12:26:47,833 - trainer - INFO -     gen_loss       : 0.007825374929234385
2025-01-21 12:26:47,833 - trainer - INFO -     val_val_loss   : 11.988249345259232
2025-01-21 12:26:47,833 - trainer - INFO -     val_val_sim_loss: 0.06167302258086927
2025-01-21 12:26:47,833 - trainer - INFO -     val_val_gen_loss: 17.09963997927579
2025-01-21 12:26:47,833 - trainer - INFO -     val_val_perplexity: 27604411.40909091
2025-01-21 12:26:47,833 - trainer - INFO -     val_val_embedding_sim: 0.41782826998017053
2025-01-21 12:26:47,833 - trainer - INFO - ================================================================================
2025-01-21 12:26:47,833 - trainer - INFO - Starting epoch 18 at 2025-01-21 12:26:47
2025-01-21 12:26:51,552 - trainer - INFO - Epoch 18 completed at 2025-01-21 12:26:51
2025-01-21 12:26:51,552 - trainer - INFO -     epoch          : 18
2025-01-21 12:26:51,552 - trainer - INFO -     elapsed time   : 3.718430519104004
2025-01-21 12:26:51,552 - trainer - INFO -     loss           : 0.12016590870916843
2025-01-21 12:26:51,552 - trainer - INFO -     sim_loss       : 0.38583970069885254
2025-01-21 12:26:51,552 - trainer - INFO -     gen_loss       : 0.006305705336853862
2025-01-21 12:26:51,552 - trainer - INFO -     val_val_loss   : 12.127672831217447
2025-01-21 12:26:51,552 - trainer - INFO -     val_val_sim_loss: 0.35645861072098894
2025-01-21 12:26:51,552 - trainer - INFO -     val_val_gen_loss: 17.172479224927496
2025-01-21 12:26:51,552 - trainer - INFO -     val_val_perplexity: 28735093.454545453
2025-01-21 12:26:51,552 - trainer - INFO -     val_val_embedding_sim: 0.41799019502870965
2025-01-21 12:26:51,552 - trainer - INFO - ================================================================================
2025-01-21 12:26:51,552 - trainer - INFO - Starting epoch 19 at 2025-01-21 12:26:51
2025-01-21 12:26:55,285 - trainer - INFO - Epoch 19 completed at 2025-01-21 12:26:55
2025-01-21 12:26:55,285 - trainer - INFO -     epoch          : 19
2025-01-21 12:26:55,285 - trainer - INFO -     elapsed time   : 3.7321884632110596
2025-01-21 12:26:55,285 - trainer - INFO -     loss           : 0.14041336365044116
2025-01-21 12:26:55,285 - trainer - INFO -     sim_loss       : 0.4550301104784012
2025-01-21 12:26:55,285 - trainer - INFO -     gen_loss       : 0.005577606055885554
2025-01-21 12:26:55,285 - trainer - INFO -     val_val_loss   : 12.087998939282967
2025-01-21 12:26:55,285 - trainer - INFO -     val_val_sim_loss: 0.04826503791286307
2025-01-21 12:26:55,285 - trainer - INFO -     val_val_gen_loss: 17.24788489486232
2025-01-21 12:26:55,285 - trainer - INFO -     val_val_perplexity: 31883973.12121212
2025-01-21 12:26:55,285 - trainer - INFO -     val_val_embedding_sim: 0.41721050305800006
2025-01-21 12:26:55,285 - trainer - INFO - ================================================================================
2025-01-21 12:26:55,285 - trainer - INFO - Starting epoch 20 at 2025-01-21 12:26:55
2025-01-21 12:26:59,016 - trainer - INFO - Epoch 20 completed at 2025-01-21 12:26:59
2025-01-21 12:26:59,016 - trainer - INFO -     epoch          : 20
2025-01-21 12:26:59,016 - trainer - INFO -     elapsed time   : 3.7304749488830566
2025-01-21 12:26:59,016 - trainer - INFO -     loss           : 0.09526711339130997
2025-01-21 12:26:59,016 - trainer - INFO -     sim_loss       : 0.30621705055236814
2025-01-21 12:26:59,016 - trainer - INFO -     gen_loss       : 0.0048599921399727465
2025-01-21 12:26:59,016 - trainer - INFO -     val_val_loss   : 12.273117036530465
2025-01-21 12:26:59,016 - trainer - INFO -     val_val_sim_loss: 0.4986872762965504
2025-01-21 12:26:59,016 - trainer - INFO -     val_val_gen_loss: 17.319302183209043
2025-01-21 12:26:59,016 - trainer - INFO -     val_val_perplexity: 33308625.21212121
2025-01-21 12:26:59,016 - trainer - INFO -     val_val_embedding_sim: 0.41735213272499316
2025-01-21 12:27:04,234 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 12:27:04,235 - trainer - INFO - ================================================================================
2025-01-21 12:27:04,235 - trainer - INFO - Starting epoch 21 at 2025-01-21 12:27:04
2025-01-21 12:27:08,008 - trainer - INFO - Epoch 21 completed at 2025-01-21 12:27:08
2025-01-21 12:27:08,008 - trainer - INFO -     epoch          : 21
2025-01-21 12:27:08,008 - trainer - INFO -     elapsed time   : 3.772909641265869
2025-01-21 12:27:08,008 - trainer - INFO -     loss           : 0.08149084763135761
2025-01-21 12:27:08,008 - trainer - INFO -     sim_loss       : 0.2606946799511206
2025-01-21 12:27:08,008 - trainer - INFO -     gen_loss       : 0.004689202131703496
2025-01-21 12:27:08,008 - trainer - INFO -     val_val_loss   : 12.208333477829441
2025-01-21 12:27:08,008 - trainer - INFO -     val_val_sim_loss: 0.2184485274465811
2025-01-21 12:27:08,008 - trainer - INFO -     val_val_gen_loss: 17.346855741558652
2025-01-21 12:27:08,008 - trainer - INFO -     val_val_perplexity: 34187304.121212125
2025-01-21 12:27:08,008 - trainer - INFO -     val_val_embedding_sim: 0.41748282403656933
2025-01-21 12:27:08,008 - trainer - INFO - ================================================================================
2025-01-21 12:27:08,008 - trainer - INFO - Starting epoch 22 at 2025-01-21 12:27:08
2025-01-21 12:27:11,739 - trainer - INFO - Epoch 22 completed at 2025-01-21 12:27:11
2025-01-21 12:27:11,739 - trainer - INFO -     epoch          : 22
2025-01-21 12:27:11,739 - trainer - INFO -     elapsed time   : 3.7301864624023438
2025-01-21 12:27:11,739 - trainer - INFO -     loss           : 0.16750469878315927
2025-01-21 12:27:11,739 - trainer - INFO -     sim_loss       : 0.547844548523426
2025-01-21 12:27:11,739 - trainer - INFO -     gen_loss       : 0.004501899005845189
2025-01-21 12:27:11,739 - trainer - INFO -     val_val_loss   : 12.305673830436938
2025-01-21 12:27:11,739 - trainer - INFO -     val_val_sim_loss: 0.24649186567826706
2025-01-21 12:27:11,739 - trainer - INFO -     val_val_gen_loss: 17.473894610549465
2025-01-21 12:27:11,739 - trainer - INFO -     val_val_perplexity: 39873994.42424242
2025-01-21 12:27:11,739 - trainer - INFO -     val_val_embedding_sim: 0.41712467056332214
2025-01-21 12:27:11,739 - trainer - INFO - ================================================================================
2025-01-21 12:27:11,739 - trainer - INFO - Starting epoch 23 at 2025-01-21 12:27:11
2025-01-21 12:27:15,469 - trainer - INFO - Epoch 23 completed at 2025-01-21 12:27:15
2025-01-21 12:27:15,469 - trainer - INFO -     epoch          : 23
2025-01-21 12:27:15,469 - trainer - INFO -     elapsed time   : 3.7293152809143066
2025-01-21 12:27:15,469 - trainer - INFO -     loss           : 0.12217873372137547
2025-01-21 12:27:15,469 - trainer - INFO -     sim_loss       : 0.3985724329948425
2025-01-21 12:27:15,469 - trainer - INFO -     gen_loss       : 0.0037242851685732603
2025-01-21 12:27:15,469 - trainer - INFO -     val_val_loss   : 12.326761187929096
2025-01-21 12:27:15,469 - trainer - INFO -     val_val_sim_loss: 0.18248403433222626
2025-01-21 12:27:15,469 - trainer - INFO -     val_val_gen_loss: 17.53145252574574
2025-01-21 12:27:15,469 - trainer - INFO -     val_val_perplexity: 45728641.93939394
2025-01-21 12:27:15,469 - trainer - INFO -     val_val_embedding_sim: 0.4172286842808579
2025-01-21 12:27:15,469 - trainer - INFO - ================================================================================
2025-01-21 12:27:15,469 - trainer - INFO - Starting epoch 24 at 2025-01-21 12:27:15
2025-01-21 12:27:19,192 - trainer - INFO - Epoch 24 completed at 2025-01-21 12:27:19
2025-01-21 12:27:19,192 - trainer - INFO -     epoch          : 24
2025-01-21 12:27:19,192 - trainer - INFO -     elapsed time   : 3.7221524715423584
2025-01-21 12:27:19,192 - trainer - INFO -     loss           : 0.11873913519084453
2025-01-21 12:27:19,192 - trainer - INFO -     sim_loss       : 0.38759667724370955
2025-01-21 12:27:19,192 - trainer - INFO -     gen_loss       : 0.003514466085471213
2025-01-21 12:27:19,192 - trainer - INFO -     val_val_loss   : 12.468463868805856
2025-01-21 12:27:19,192 - trainer - INFO -     val_val_sim_loss: 0.3528021935260655
2025-01-21 12:27:19,192 - trainer - INFO -     val_val_gen_loss: 17.660890261332195
2025-01-21 12:27:19,192 - trainer - INFO -     val_val_perplexity: 48164279.696969695
2025-01-21 12:27:19,192 - trainer - INFO -     val_val_embedding_sim: 0.42088154590491095
2025-01-21 12:27:19,192 - trainer - INFO - ================================================================================
2025-01-21 12:27:19,192 - trainer - INFO - Starting epoch 25 at 2025-01-21 12:27:19
2025-01-21 12:27:22,929 - trainer - INFO - Epoch 25 completed at 2025-01-21 12:27:22
2025-01-21 12:27:22,929 - trainer - INFO -     epoch          : 25
2025-01-21 12:27:22,929 - trainer - INFO -     elapsed time   : 3.7370212078094482
2025-01-21 12:27:22,930 - trainer - INFO -     loss           : 0.17548583894968034
2025-01-21 12:27:22,930 - trainer - INFO -     sim_loss       : 0.5774808377027512
2025-01-21 12:27:22,930 - trainer - INFO -     gen_loss       : 0.0032022582134231927
2025-01-21 12:27:22,930 - trainer - INFO -     val_val_loss   : 12.763773744756525
2025-01-21 12:27:22,930 - trainer - INFO -     val_val_sim_loss: 1.1301574923775344
2025-01-21 12:27:22,930 - trainer - INFO -     val_val_gen_loss: 17.74960890683261
2025-01-21 12:27:22,930 - trainer - INFO -     val_val_perplexity: 53720328.13636363
2025-01-21 12:27:22,930 - trainer - INFO -     val_val_embedding_sim: 0.4181210488984079
2025-01-21 12:27:28,146 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 12:27:28,147 - trainer - INFO - ================================================================================
2025-01-21 12:27:28,147 - trainer - INFO - Starting epoch 26 at 2025-01-21 12:27:28
2025-01-21 12:27:31,926 - trainer - INFO - Epoch 26 completed at 2025-01-21 12:27:31
2025-01-21 12:27:31,927 - trainer - INFO -     epoch          : 26
2025-01-21 12:27:31,927 - trainer - INFO -     elapsed time   : 3.779542922973633
2025-01-21 12:27:31,927 - trainer - INFO -     loss           : 0.07631382264662534
2025-01-21 12:27:31,927 - trainer - INFO -     sim_loss       : 0.24728049335535615
2025-01-21 12:27:31,927 - trainer - INFO -     gen_loss       : 0.0030423894291743635
2025-01-21 12:27:31,927 - trainer - INFO -     val_val_loss   : 12.377464149937484
2025-01-21 12:27:31,927 - trainer - INFO -     val_val_sim_loss: 0.04482241110366141
2025-01-21 12:27:31,927 - trainer - INFO -     val_val_gen_loss: 17.662881446607184
2025-01-21 12:27:31,927 - trainer - INFO -     val_val_perplexity: 57704060.121212125
2025-01-21 12:27:31,927 - trainer - INFO -     val_val_embedding_sim: 0.417753512209112
2025-01-21 12:27:31,927 - trainer - INFO - ================================================================================
2025-01-21 12:27:31,927 - trainer - INFO - Starting epoch 27 at 2025-01-21 12:27:31
2025-01-21 12:27:35,640 - trainer - INFO - Epoch 27 completed at 2025-01-21 12:27:35
2025-01-21 12:27:35,640 - trainer - INFO -     epoch          : 27
2025-01-21 12:27:35,640 - trainer - INFO -     elapsed time   : 3.7130444049835205
2025-01-21 12:27:35,640 - trainer - INFO -     loss           : 0.0985460953321308
2025-01-21 12:27:35,640 - trainer - INFO -     sim_loss       : 0.32184944648761304
2025-01-21 12:27:35,640 - trainer - INFO -     gen_loss       : 0.002844653953798115
2025-01-21 12:27:35,640 - trainer - INFO -     val_val_loss   : 12.4919852921457
2025-01-21 12:27:35,640 - trainer - INFO -     val_val_sim_loss: 0.043358560764207854
2025-01-21 12:27:35,640 - trainer - INFO -     val_val_gen_loss: 17.827110290527344
2025-01-21 12:27:35,640 - trainer - INFO -     val_val_perplexity: 58912079.515151516
2025-01-21 12:27:35,640 - trainer - INFO -     val_val_embedding_sim: 0.41799906934752606
2025-01-21 12:27:35,641 - trainer - INFO - ================================================================================
2025-01-21 12:27:35,641 - trainer - INFO - Starting epoch 28 at 2025-01-21 12:27:35
2025-01-21 12:27:39,369 - trainer - INFO - Epoch 28 completed at 2025-01-21 12:27:39
2025-01-21 12:27:39,369 - trainer - INFO -     epoch          : 28
2025-01-21 12:27:39,369 - trainer - INFO -     elapsed time   : 3.7281270027160645
2025-01-21 12:27:39,369 - trainer - INFO -     loss           : 0.13333062641322613
2025-01-21 12:27:39,369 - trainer - INFO -     sim_loss       : 0.4379876881837845
2025-01-21 12:27:39,369 - trainer - INFO -     gen_loss       : 0.0027633083751425146
2025-01-21 12:27:39,369 - trainer - INFO -     val_val_loss   : 12.519819288542777
2025-01-21 12:27:39,369 - trainer - INFO -     val_val_sim_loss: 0.04259478684613868
2025-01-21 12:27:39,369 - trainer - INFO -     val_val_gen_loss: 17.867201313827977
2025-01-21 12:27:39,369 - trainer - INFO -     val_val_perplexity: 72486304.96969697
2025-01-21 12:27:39,369 - trainer - INFO -     val_val_embedding_sim: 0.41992275281385943
2025-01-21 12:27:39,369 - trainer - INFO - ================================================================================
2025-01-21 12:27:39,369 - trainer - INFO - Starting epoch 29 at 2025-01-21 12:27:39
2025-01-21 12:27:43,089 - trainer - INFO - Epoch 29 completed at 2025-01-21 12:27:43
2025-01-21 12:27:43,089 - trainer - INFO -     epoch          : 29
2025-01-21 12:27:43,089 - trainer - INFO -     elapsed time   : 3.7196671962738037
2025-01-21 12:27:43,089 - trainer - INFO -     loss           : 0.07492947587743401
2025-01-21 12:27:43,089 - trainer - INFO -     sim_loss       : 0.24402773287147284
2025-01-21 12:27:43,090 - trainer - INFO -     gen_loss       : 0.0024587919120676815
2025-01-21 12:27:43,090 - trainer - INFO -     val_val_loss   : 12.637539112206662
2025-01-21 12:27:43,090 - trainer - INFO -     val_val_sim_loss: 0.274036288443974
2025-01-21 12:27:43,090 - trainer - INFO -     val_val_gen_loss: 17.93618288907138
2025-01-21 12:27:43,090 - trainer - INFO -     val_val_perplexity: 155873295.5151515
2025-01-21 12:27:43,090 - trainer - INFO -     val_val_embedding_sim: 0.41827816764513653
2025-01-21 12:27:43,090 - trainer - INFO - ================================================================================
2025-01-21 12:27:43,090 - trainer - INFO - Starting epoch 30 at 2025-01-21 12:27:43
2025-01-21 12:27:46,818 - trainer - INFO - Epoch 30 completed at 2025-01-21 12:27:46
2025-01-21 12:27:46,818 - trainer - INFO -     epoch          : 30
2025-01-21 12:27:46,818 - trainer - INFO -     elapsed time   : 3.72834849357605
2025-01-21 12:27:46,818 - trainer - INFO -     loss           : 0.09429512701462954
2025-01-21 12:27:46,818 - trainer - INFO -     sim_loss       : 0.3091410581488162
2025-01-21 12:27:46,819 - trainer - INFO -     gen_loss       : 0.0022182936663739383
2025-01-21 12:27:46,819 - trainer - INFO -     val_val_loss   : 12.68947780493534
2025-01-21 12:27:46,819 - trainer - INFO -     val_val_sim_loss: 0.34522757746854593
2025-01-21 12:27:46,819 - trainer - INFO -     val_val_gen_loss: 17.979870304916844
2025-01-21 12:27:46,819 - trainer - INFO -     val_val_perplexity: 64487367.15151515
2025-01-21 12:27:46,819 - trainer - INFO -     val_val_embedding_sim: 0.42030594204411365
2025-01-21 12:27:52,054 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 12:27:52,054 - trainer - INFO - ================================================================================
2025-01-21 12:27:52,055 - trainer - INFO - Starting epoch 31 at 2025-01-21 12:27:52
2025-01-21 12:27:55,828 - trainer - INFO - Epoch 31 completed at 2025-01-21 12:27:55
2025-01-21 12:27:55,828 - trainer - INFO -     epoch          : 31
2025-01-21 12:27:55,828 - trainer - INFO -     elapsed time   : 3.7730233669281006
2025-01-21 12:27:55,828 - trainer - INFO -     loss           : 0.09180234726518392
2025-01-21 12:27:55,828 - trainer - INFO -     sim_loss       : 0.3012572217732668
2025-01-21 12:27:55,828 - trainer - INFO -     gen_loss       : 0.0020359698799438776
2025-01-21 12:27:55,828 - trainer - INFO -     val_val_loss   : 12.886646790937943
2025-01-21 12:27:55,828 - trainer - INFO -     val_val_sim_loss: 0.8370161887370696
2025-01-21 12:27:55,828 - trainer - INFO -     val_val_gen_loss: 18.0507737940008
2025-01-21 12:27:55,828 - trainer - INFO -     val_val_perplexity: 69785693.93939394
2025-01-21 12:27:55,828 - trainer - INFO -     val_val_embedding_sim: 0.4209820899096402
2025-01-21 12:27:55,828 - trainer - INFO - ================================================================================
2025-01-21 12:27:55,828 - trainer - INFO - Starting epoch 32 at 2025-01-21 12:27:55
2025-01-21 12:27:59,556 - trainer - INFO - Epoch 32 completed at 2025-01-21 12:27:59
2025-01-21 12:27:59,556 - trainer - INFO -     epoch          : 32
2025-01-21 12:27:59,556 - trainer - INFO -     elapsed time   : 3.7274856567382812
2025-01-21 12:27:59,556 - trainer - INFO -     loss           : 0.09128622226417064
2025-01-21 12:27:59,556 - trainer - INFO -     sim_loss       : 0.2997080996632576
2025-01-21 12:27:59,556 - trainer - INFO -     gen_loss       : 0.0019625540357083083
2025-01-21 12:27:59,556 - trainer - INFO -     val_val_loss   : 12.810934673656117
2025-01-21 12:27:59,556 - trainer - INFO -     val_val_sim_loss: 0.41163400806434575
2025-01-21 12:27:59,556 - trainer - INFO -     val_val_gen_loss: 18.124920642737187
2025-01-21 12:27:59,556 - trainer - INFO -     val_val_perplexity: 190525416.72727272
2025-01-21 12:27:59,556 - trainer - INFO -     val_val_embedding_sim: 0.4195725673978979
2025-01-21 12:27:59,556 - trainer - INFO - ================================================================================
2025-01-21 12:27:59,556 - trainer - INFO - Starting epoch 33 at 2025-01-21 12:27:59
2025-01-21 12:28:03,286 - trainer - INFO - Epoch 33 completed at 2025-01-21 12:28:03
2025-01-21 12:28:03,286 - trainer - INFO -     epoch          : 33
2025-01-21 12:28:03,286 - trainer - INFO -     elapsed time   : 3.7296504974365234
2025-01-21 12:28:03,286 - trainer - INFO -     loss           : 0.11951765280682594
2025-01-21 12:28:03,286 - trainer - INFO -     sim_loss       : 0.39419792030239476
2025-01-21 12:28:03,286 - trainer - INFO -     gen_loss       : 0.0017975275171920658
2025-01-21 12:28:03,286 - trainer - INFO -     val_val_loss   : 12.932967359369451
2025-01-21 12:28:03,286 - trainer - INFO -     val_val_sim_loss: 0.5991956031683711
2025-01-21 12:28:03,287 - trainer - INFO -     val_val_gen_loss: 18.218869238188773
2025-01-21 12:28:03,287 - trainer - INFO -     val_val_perplexity: 83002715.45454545
2025-01-21 12:28:03,287 - trainer - INFO -     val_val_embedding_sim: 0.4214392900466919
2025-01-21 12:28:03,287 - trainer - INFO - ================================================================================
2025-01-21 12:28:03,287 - trainer - INFO - Starting epoch 34 at 2025-01-21 12:28:03
2025-01-21 12:28:07,005 - trainer - INFO - Epoch 34 completed at 2025-01-21 12:28:07
2025-01-21 12:28:07,005 - trainer - INFO -     epoch          : 34
2025-01-21 12:28:07,005 - trainer - INFO -     elapsed time   : 3.7179958820343018
2025-01-21 12:28:07,005 - trainer - INFO -     loss           : 0.09183655381202697
2025-01-21 12:28:07,005 - trainer - INFO -     sim_loss       : 0.30220264121890067
2025-01-21 12:28:07,005 - trainer - INFO -     gen_loss       : 0.0016796532785519958
2025-01-21 12:28:07,005 - trainer - INFO -     val_val_loss   : 12.838830947875977
2025-01-21 12:28:07,005 - trainer - INFO -     val_val_sim_loss: 0.18911107203739724
2025-01-21 12:28:07,005 - trainer - INFO -     val_val_gen_loss: 18.260140216711797
2025-01-21 12:28:07,005 - trainer - INFO -     val_val_perplexity: 85204672.0
2025-01-21 12:28:07,005 - trainer - INFO -     val_val_embedding_sim: 0.4197241826490922
2025-01-21 12:28:07,005 - trainer - INFO - ================================================================================
2025-01-21 12:28:07,005 - trainer - INFO - Starting epoch 35 at 2025-01-21 12:28:07
2025-01-21 12:28:10,730 - trainer - INFO - Epoch 35 completed at 2025-01-21 12:28:10
2025-01-21 12:28:10,730 - trainer - INFO -     epoch          : 35
2025-01-21 12:28:10,730 - trainer - INFO -     elapsed time   : 3.724924087524414
2025-01-21 12:28:10,731 - trainer - INFO -     loss           : 0.07220796014880762
2025-01-21 12:28:10,731 - trainer - INFO -     sim_loss       : 0.23690833037908304
2025-01-21 12:28:10,731 - trainer - INFO -     gen_loss       : 0.0016220860416069627
2025-01-21 12:28:10,731 - trainer - INFO -     val_val_loss   : 12.991172299240574
2025-01-21 12:28:10,731 - trainer - INFO -     val_val_sim_loss: 0.6014274322625354
2025-01-21 12:28:10,731 - trainer - INFO -     val_val_gen_loss: 18.301062670621004
2025-01-21 12:28:10,731 - trainer - INFO -     val_val_perplexity: 88885496.24242425
2025-01-21 12:28:10,731 - trainer - INFO -     val_val_embedding_sim: 0.42004578673478327
2025-01-21 12:28:15,954 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 12:28:15,955 - trainer - INFO - ================================================================================
2025-01-21 12:28:15,955 - trainer - INFO - Starting epoch 36 at 2025-01-21 12:28:15
2025-01-21 12:28:19,732 - trainer - INFO - Epoch 36 completed at 2025-01-21 12:28:19
2025-01-21 12:28:19,733 - trainer - INFO -     epoch          : 36
2025-01-21 12:28:19,733 - trainer - INFO -     elapsed time   : 3.7774240970611572
2025-01-21 12:28:19,733 - trainer - INFO -     loss           : 0.1706830502487719
2025-01-21 12:28:19,733 - trainer - INFO -     sim_loss       : 0.5655069142580033
2025-01-21 12:28:19,733 - trainer - INFO -     gen_loss       : 0.0014728145557455718
2025-01-21 12:28:19,733 - trainer - INFO -     val_val_loss   : 12.981350523052793
2025-01-21 12:28:19,733 - trainer - INFO -     val_val_sim_loss: 0.41321288816255797
2025-01-21 12:28:19,733 - trainer - INFO -     val_val_gen_loss: 18.367696010705195
2025-01-21 12:28:19,733 - trainer - INFO -     val_val_perplexity: 125935689.6969697
2025-01-21 12:28:19,733 - trainer - INFO -     val_val_embedding_sim: 0.42194493250413373
2025-01-21 12:28:19,733 - trainer - INFO - ================================================================================
2025-01-21 12:28:19,733 - trainer - INFO - Starting epoch 37 at 2025-01-21 12:28:19
2025-01-21 12:28:23,463 - trainer - INFO - Epoch 37 completed at 2025-01-21 12:28:23
2025-01-21 12:28:23,463 - trainer - INFO -     epoch          : 37
2025-01-21 12:28:23,463 - trainer - INFO -     elapsed time   : 3.7300705909729004
2025-01-21 12:28:23,463 - trainer - INFO -     loss           : 0.12452784571796656
2025-01-21 12:28:23,463 - trainer - INFO -     sim_loss       : 0.4119572535157204
2025-01-21 12:28:23,463 - trainer - INFO -     gen_loss       : 0.0013438079040497541
2025-01-21 12:28:23,463 - trainer - INFO -     val_val_loss   : 12.873666127522787
2025-01-21 12:28:23,464 - trainer - INFO -     val_val_sim_loss: 0.05449595595850917
2025-01-21 12:28:23,464 - trainer - INFO -     val_val_gen_loss: 18.36759549921209
2025-01-21 12:28:23,464 - trainer - INFO -     val_val_perplexity: 94885392.48484848
2025-01-21 12:28:23,464 - trainer - INFO -     val_val_embedding_sim: 0.4203643491773894
2025-01-21 12:28:23,464 - trainer - INFO - ================================================================================
2025-01-21 12:28:23,464 - trainer - INFO - Starting epoch 38 at 2025-01-21 12:28:23
2025-01-21 12:28:27,214 - trainer - INFO - Epoch 38 completed at 2025-01-21 12:28:27
2025-01-21 12:28:27,215 - trainer - INFO -     epoch          : 38
2025-01-21 12:28:27,215 - trainer - INFO -     elapsed time   : 3.7506165504455566
2025-01-21 12:28:27,215 - trainer - INFO -     loss           : 0.06615207721479237
2025-01-21 12:28:27,215 - trainer - INFO -     sim_loss       : 0.21737289410084487
2025-01-21 12:28:27,215 - trainer - INFO -     gen_loss       : 0.0013431515893898905
2025-01-21 12:28:27,215 - trainer - INFO -     val_val_loss   : 13.066519766142875
2025-01-21 12:28:27,215 - trainer - INFO -     val_val_sim_loss: 0.4354191043160178
2025-01-21 12:28:27,215 - trainer - INFO -     val_val_gen_loss: 18.479849728670988
2025-01-21 12:28:27,215 - trainer - INFO -     val_val_perplexity: 106149346.42424242
2025-01-21 12:28:27,215 - trainer - INFO -     val_val_embedding_sim: 0.4222382866975033
2025-01-21 12:28:27,215 - trainer - INFO - ================================================================================
2025-01-21 12:28:27,215 - trainer - INFO - Starting epoch 39 at 2025-01-21 12:28:27
2025-01-21 12:28:30,945 - trainer - INFO - Epoch 39 completed at 2025-01-21 12:28:30
2025-01-21 12:28:30,945 - trainer - INFO -     epoch          : 39
2025-01-21 12:28:30,945 - trainer - INFO -     elapsed time   : 3.7299859523773193
2025-01-21 12:28:30,945 - trainer - INFO -     loss           : 0.12239196537993849
2025-01-21 12:28:30,945 - trainer - INFO -     sim_loss       : 0.4050284000048123
2025-01-21 12:28:30,945 - trainer - INFO -     gen_loss       : 0.0012620596098713577
2025-01-21 12:28:30,945 - trainer - INFO -     val_val_loss   : 13.162848010207668
2025-01-21 12:28:30,945 - trainer - INFO -     val_val_sim_loss: 0.6982699307528409
2025-01-21 12:28:30,946 - trainer - INFO -     val_val_gen_loss: 18.504810564445727
2025-01-21 12:28:30,946 - trainer - INFO -     val_val_perplexity: 134598306.9090909
2025-01-21 12:28:30,946 - trainer - INFO -     val_val_embedding_sim: 0.4214999151952339
2025-01-21 12:28:30,946 - trainer - INFO - ================================================================================
2025-01-21 12:28:30,946 - trainer - INFO - Starting epoch 40 at 2025-01-21 12:28:30
2025-01-21 12:28:34,678 - trainer - INFO - Epoch 40 completed at 2025-01-21 12:28:34
2025-01-21 12:28:34,678 - trainer - INFO -     epoch          : 40
2025-01-21 12:28:34,678 - trainer - INFO -     elapsed time   : 3.7318153381347656
2025-01-21 12:28:34,678 - trainer - INFO -     loss           : 0.13154149903566575
2025-01-21 12:28:34,678 - trainer - INFO -     sim_loss       : 0.4357547770683595
2025-01-21 12:28:34,678 - trainer - INFO -     gen_loss       : 0.001164370815968141
2025-01-21 12:28:34,678 - trainer - INFO -     val_val_loss   : 13.128101666768393
2025-01-21 12:28:34,678 - trainer - INFO -     val_val_sim_loss: 0.49542247887813684
2025-01-21 12:28:34,678 - trainer - INFO -     val_val_gen_loss: 18.542108073379055
2025-01-21 12:28:34,678 - trainer - INFO -     val_val_perplexity: 116168789.21212122
2025-01-21 12:28:34,678 - trainer - INFO -     val_val_embedding_sim: 0.42189464605215826
2025-01-21 12:28:39,897 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 12:28:39,897 - trainer - INFO - ================================================================================
2025-01-21 12:28:39,897 - trainer - INFO - Starting epoch 41 at 2025-01-21 12:28:39
2025-01-21 12:28:43,687 - trainer - INFO - Epoch 41 completed at 2025-01-21 12:28:43
2025-01-21 12:28:43,687 - trainer - INFO -     epoch          : 41
2025-01-21 12:28:43,687 - trainer - INFO -     elapsed time   : 3.7899343967437744
2025-01-21 12:28:43,687 - trainer - INFO -     loss           : 0.09391239918768406
2025-01-21 12:28:43,687 - trainer - INFO -     sim_loss       : 0.31036596074700357
2025-01-21 12:28:43,687 - trainer - INFO -     gen_loss       : 0.0011465832823887468
2025-01-21 12:28:43,687 - trainer - INFO -     val_val_loss   : 13.077010039127234
2025-01-21 12:28:43,688 - trainer - INFO -     val_val_sim_loss: 0.25379516861655493
2025-01-21 12:28:43,688 - trainer - INFO -     val_val_gen_loss: 18.572674028801195
2025-01-21 12:28:43,688 - trainer - INFO -     val_val_perplexity: 116449261.57575758
2025-01-21 12:28:43,688 - trainer - INFO -     val_val_embedding_sim: 0.42063184850143664
2025-01-21 12:28:43,688 - trainer - INFO - ================================================================================
2025-01-21 12:28:43,688 - trainer - INFO - Starting epoch 42 at 2025-01-21 12:28:43
2025-01-21 12:28:47,422 - trainer - INFO - Epoch 42 completed at 2025-01-21 12:28:47
2025-01-21 12:28:47,422 - trainer - INFO -     epoch          : 42
2025-01-21 12:28:47,422 - trainer - INFO -     elapsed time   : 3.7338321208953857
2025-01-21 12:28:47,422 - trainer - INFO -     loss           : 0.09770318277878687
2025-01-21 12:28:47,422 - trainer - INFO -     sim_loss       : 0.3232157527541858
2025-01-21 12:28:47,422 - trainer - INFO -     gen_loss       : 0.0010549320664722472
2025-01-21 12:28:47,422 - trainer - INFO -     val_val_loss   : 13.111068725585938
2025-01-21 12:28:47,422 - trainer - INFO -     val_val_sim_loss: 0.2814267029435458
2025-01-21 12:28:47,422 - trainer - INFO -     val_val_gen_loss: 18.60948712898023
2025-01-21 12:28:47,422 - trainer - INFO -     val_val_perplexity: 120921337.45454545
2025-01-21 12:28:47,422 - trainer - INFO -     val_val_embedding_sim: 0.42338550813270337
2025-01-21 12:28:47,422 - trainer - INFO - ================================================================================
2025-01-21 12:28:47,422 - trainer - INFO - Starting epoch 43 at 2025-01-21 12:28:47
2025-01-21 12:28:51,148 - trainer - INFO - Epoch 43 completed at 2025-01-21 12:28:51
2025-01-21 12:28:51,148 - trainer - INFO -     epoch          : 43
2025-01-21 12:28:51,148 - trainer - INFO -     elapsed time   : 3.7255377769470215
2025-01-21 12:28:51,148 - trainer - INFO -     loss           : 0.08421234907582402
2025-01-21 12:28:51,148 - trainer - INFO -     sim_loss       : 0.2783198932017058
2025-01-21 12:28:51,148 - trainer - INFO -     gen_loss       : 0.0010233961103949696
2025-01-21 12:28:51,148 - trainer - INFO -     val_val_loss   : 13.116288445212625
2025-01-21 12:28:51,148 - trainer - INFO -     val_val_sim_loss: 0.05518994186863755
2025-01-21 12:28:51,148 - trainer - INFO -     val_val_gen_loss: 18.71390180876761
2025-01-21 12:28:51,148 - trainer - INFO -     val_val_perplexity: 139263406.42424244
2025-01-21 12:28:51,148 - trainer - INFO -     val_val_embedding_sim: 0.42203972917614563
2025-01-21 12:28:51,148 - trainer - INFO - ================================================================================
2025-01-21 12:28:51,148 - trainer - INFO - Starting epoch 44 at 2025-01-21 12:28:51
2025-01-21 12:28:54,880 - trainer - INFO - Epoch 44 completed at 2025-01-21 12:28:54
2025-01-21 12:28:54,881 - trainer - INFO -     epoch          : 44
2025-01-21 12:28:54,881 - trainer - INFO -     elapsed time   : 3.731868267059326
2025-01-21 12:28:54,881 - trainer - INFO -     loss           : 0.08789943752926774
2025-01-21 12:28:54,881 - trainer - INFO -     sim_loss       : 0.2905171811871696
2025-01-21 12:28:54,881 - trainer - INFO -     gen_loss       : 0.001063260156661272
2025-01-21 12:28:54,881 - trainer - INFO -     val_val_loss   : 13.254138859835537
2025-01-21 12:28:54,881 - trainer - INFO -     val_val_sim_loss: 0.5835589896605322
2025-01-21 12:28:54,881 - trainer - INFO -     val_val_gen_loss: 18.68438784281413
2025-01-21 12:28:54,881 - trainer - INFO -     val_val_perplexity: 130265682.9090909
2025-01-21 12:28:54,881 - trainer - INFO -     val_val_embedding_sim: 0.4236431257291274
2025-01-21 12:28:54,881 - trainer - INFO - ================================================================================
2025-01-21 12:28:54,881 - trainer - INFO - Starting epoch 45 at 2025-01-21 12:28:54
2025-01-21 12:28:58,604 - trainer - INFO - Epoch 45 completed at 2025-01-21 12:28:58
2025-01-21 12:28:58,604 - trainer - INFO -     epoch          : 45
2025-01-21 12:28:58,604 - trainer - INFO -     elapsed time   : 3.7229676246643066
2025-01-21 12:28:58,604 - trainer - INFO -     loss           : 0.07019908694201149
2025-01-21 12:28:58,604 - trainer - INFO -     sim_loss       : 0.23176198348946855
2025-01-21 12:28:58,604 - trainer - INFO -     gen_loss       : 0.0009578458382748067
2025-01-21 12:28:58,604 - trainer - INFO -     val_val_loss   : 13.17916373050574
2025-01-21 12:28:58,604 - trainer - INFO -     val_val_sim_loss: 0.17739343643188477
2025-01-21 12:28:58,604 - trainer - INFO -     val_val_gen_loss: 18.751351789994672
2025-01-21 12:28:58,604 - trainer - INFO -     val_val_perplexity: 151361921.93939394
2025-01-21 12:28:58,604 - trainer - INFO -     val_val_embedding_sim: 0.4232492753953645
2025-01-21 12:29:03,837 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 12:29:03,837 - trainer - INFO - ================================================================================
2025-01-21 12:29:03,837 - trainer - INFO - Starting epoch 46 at 2025-01-21 12:29:03
2025-01-21 12:29:07,617 - trainer - INFO - Epoch 46 completed at 2025-01-21 12:29:07
2025-01-21 12:29:07,617 - trainer - INFO -     epoch          : 46
2025-01-21 12:29:07,617 - trainer - INFO -     elapsed time   : 3.7796101570129395
2025-01-21 12:29:07,617 - trainer - INFO -     loss           : 0.08485855478793383
2025-01-21 12:29:07,617 - trainer - INFO -     sim_loss       : 0.28071260675787923
2025-01-21 12:29:07,617 - trainer - INFO -     gen_loss       : 0.0009211022523231804
2025-01-21 12:29:07,617 - trainer - INFO -     val_val_loss   : 13.156347621570934
2025-01-21 12:29:07,617 - trainer - INFO -     val_val_sim_loss: 0.134245186141043
2025-01-21 12:29:07,617 - trainer - INFO -     val_val_gen_loss: 18.737249952374082
2025-01-21 12:29:07,617 - trainer - INFO -     val_val_perplexity: 152593968.4848485
2025-01-21 12:29:07,617 - trainer - INFO -     val_val_embedding_sim: 0.4221991950815374
2025-01-21 12:29:07,617 - trainer - INFO - ================================================================================
2025-01-21 12:29:07,617 - trainer - INFO - Starting epoch 47 at 2025-01-21 12:29:07
2025-01-21 12:29:11,347 - trainer - INFO - Epoch 47 completed at 2025-01-21 12:29:11
2025-01-21 12:29:11,347 - trainer - INFO -     epoch          : 47
2025-01-21 12:29:11,347 - trainer - INFO -     elapsed time   : 3.729390859603882
2025-01-21 12:29:11,347 - trainer - INFO -     loss           : 0.13218754194676877
2025-01-21 12:29:11,347 - trainer - INFO -     sim_loss       : 0.4385897845029831
2025-01-21 12:29:11,347 - trainer - INFO -     gen_loss       : 0.0008722914964891971
2025-01-21 12:29:11,347 - trainer - INFO -     val_val_loss   : 13.175952824679287
2025-01-21 12:29:11,347 - trainer - INFO -     val_val_sim_loss: 0.16421083247339333
2025-01-21 12:29:11,347 - trainer - INFO -     val_val_gen_loss: 18.75241435657848
2025-01-21 12:29:11,347 - trainer - INFO -     val_val_perplexity: 139671342.06060606
2025-01-21 12:29:11,347 - trainer - INFO -     val_val_embedding_sim: 0.4224812722567356
2025-01-21 12:29:11,347 - trainer - INFO - ================================================================================
2025-01-21 12:29:11,347 - trainer - INFO - Starting epoch 48 at 2025-01-21 12:29:11
2025-01-21 12:29:15,077 - trainer - INFO - Epoch 48 completed at 2025-01-21 12:29:15
2025-01-21 12:29:15,077 - trainer - INFO -     epoch          : 48
2025-01-21 12:29:15,077 - trainer - INFO -     elapsed time   : 3.729231357574463
2025-01-21 12:29:15,077 - trainer - INFO -     loss           : 0.09506317293271423
2025-01-21 12:29:15,077 - trainer - INFO -     sim_loss       : 0.314837933331728
2025-01-21 12:29:15,077 - trainer - INFO -     gen_loss       : 0.0008739826909732074
2025-01-21 12:29:15,077 - trainer - INFO -     val_val_loss   : 13.2847768610174
2025-01-21 12:29:15,077 - trainer - INFO -     val_val_sim_loss: 0.44153800871241733
2025-01-21 12:29:15,077 - trainer - INFO -     val_val_gen_loss: 18.789021983291164
2025-01-21 12:29:15,077 - trainer - INFO -     val_val_perplexity: 144746978.9090909
2025-01-21 12:29:15,077 - trainer - INFO -     val_val_embedding_sim: 0.4225501905788075
2025-01-21 12:29:15,077 - trainer - INFO - ================================================================================
2025-01-21 12:29:15,077 - trainer - INFO - Starting epoch 49 at 2025-01-21 12:29:15
2025-01-21 12:29:18,815 - trainer - INFO - Epoch 49 completed at 2025-01-21 12:29:18
2025-01-21 12:29:18,815 - trainer - INFO -     epoch          : 49
2025-01-21 12:29:18,815 - trainer - INFO -     elapsed time   : 3.737884521484375
2025-01-21 12:29:18,815 - trainer - INFO -     loss           : 0.04597977406810969
2025-01-21 12:29:18,815 - trainer - INFO -     sim_loss       : 0.15128927502082662
2025-01-21 12:29:18,815 - trainer - INFO -     gen_loss       : 0.000847128382883966
2025-01-21 12:29:18,815 - trainer - INFO -     val_val_loss   : 13.409561735210996
2025-01-21 12:29:18,815 - trainer - INFO -     val_val_sim_loss: 0.7940724690755209
2025-01-21 12:29:18,815 - trainer - INFO -     val_val_gen_loss: 18.81619979396011
2025-01-21 12:29:18,816 - trainer - INFO -     val_val_perplexity: 148680160.24242425
2025-01-21 12:29:18,816 - trainer - INFO -     val_val_embedding_sim: 0.42268882737015234
2025-01-21 12:29:18,816 - trainer - INFO - ================================================================================
2025-01-21 12:29:18,816 - trainer - INFO - Starting epoch 50 at 2025-01-21 12:29:18
2025-01-21 12:29:22,548 - trainer - INFO - Epoch 50 completed at 2025-01-21 12:29:22
2025-01-21 12:29:22,548 - trainer - INFO -     epoch          : 50
2025-01-21 12:29:22,548 - trainer - INFO -     elapsed time   : 3.7323944568634033
2025-01-21 12:29:22,548 - trainer - INFO -     loss           : 0.10901458524167537
2025-01-21 12:29:22,548 - trainer - INFO -     sim_loss       : 0.36150155737996104
2025-01-21 12:29:22,548 - trainer - INFO -     gen_loss       : 0.0008058759674895554
2025-01-21 12:29:22,549 - trainer - INFO -     val_val_loss   : 13.348946715846207
2025-01-21 12:29:22,549 - trainer - INFO -     val_val_sim_loss: 0.4129952770176301
2025-01-21 12:29:22,549 - trainer - INFO -     val_val_gen_loss: 18.892926302823152
2025-01-21 12:29:22,549 - trainer - INFO -     val_val_perplexity: 206538042.1818182
2025-01-21 12:29:22,549 - trainer - INFO -     val_val_embedding_sim: 0.422141205180775
2025-01-21 12:29:27,775 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 12:29:27,775 - trainer - INFO - ================================================================================
2025-01-21 12:29:27,775 - trainer - INFO - Starting epoch 51 at 2025-01-21 12:29:27
2025-01-21 12:29:31,553 - trainer - INFO - Epoch 51 completed at 2025-01-21 12:29:31
2025-01-21 12:29:31,553 - trainer - INFO -     epoch          : 51
2025-01-21 12:29:31,554 - trainer - INFO -     elapsed time   : 3.777921199798584
2025-01-21 12:29:31,554 - trainer - INFO -     loss           : 0.05689428895711899
2025-01-21 12:29:31,554 - trainer - INFO -     sim_loss       : 0.18775595501065254
2025-01-21 12:29:31,554 - trainer - INFO -     gen_loss       : 0.0008107137109618634
2025-01-21 12:29:31,554 - trainer - INFO -     val_val_loss   : 13.270802440065326
2025-01-21 12:29:31,554 - trainer - INFO -     val_val_sim_loss: 0.11181336986500713
2025-01-21 12:29:31,554 - trainer - INFO -     val_val_gen_loss: 18.910369526256215
2025-01-21 12:29:31,554 - trainer - INFO -     val_val_perplexity: 163426597.8181818
2025-01-21 12:29:31,554 - trainer - INFO -     val_val_embedding_sim: 0.4221108212615504
2025-01-21 12:29:31,554 - trainer - INFO - ================================================================================
2025-01-21 12:29:31,554 - trainer - INFO - Starting epoch 52 at 2025-01-21 12:29:31
2025-01-21 12:29:35,305 - trainer - INFO - Epoch 52 completed at 2025-01-21 12:29:35
2025-01-21 12:29:35,305 - trainer - INFO -     epoch          : 52
2025-01-21 12:29:35,305 - trainer - INFO -     elapsed time   : 3.7507712841033936
2025-01-21 12:29:35,305 - trainer - INFO -     loss           : 0.06592545312014408
2025-01-21 12:29:35,305 - trainer - INFO -     sim_loss       : 0.2180462012591306
2025-01-21 12:29:35,305 - trainer - INFO -     gen_loss       : 0.0007308440457563847
2025-01-21 12:29:35,305 - trainer - INFO -     val_val_loss   : 13.315207770376494
2025-01-21 12:29:35,305 - trainer - INFO -     val_val_sim_loss: 0.11800339005210182
2025-01-21 12:29:35,305 - trainer - INFO -     val_val_gen_loss: 18.971152103308476
2025-01-21 12:29:35,305 - trainer - INFO -     val_val_perplexity: 180348657.03030303
2025-01-21 12:29:35,305 - trainer - INFO -     val_val_embedding_sim: 0.42320764967889496
2025-01-21 12:29:35,305 - trainer - INFO - ================================================================================
2025-01-21 12:29:35,305 - trainer - INFO - Starting epoch 53 at 2025-01-21 12:29:35
2025-01-21 12:29:39,045 - trainer - INFO - Epoch 53 completed at 2025-01-21 12:29:39
2025-01-21 12:29:39,045 - trainer - INFO -     epoch          : 53
2025-01-21 12:29:39,045 - trainer - INFO -     elapsed time   : 3.7396671772003174
2025-01-21 12:29:39,045 - trainer - INFO -     loss           : 0.10652366985450498
2025-01-21 12:29:39,045 - trainer - INFO -     sim_loss       : 0.3533545994680026
2025-01-21 12:29:39,045 - trainer - INFO -     gen_loss       : 0.0007389798003714532
2025-01-21 12:29:39,045 - trainer - INFO -     val_val_loss   : 13.335595737804066
2025-01-21 12:29:39,046 - trainer - INFO -     val_val_sim_loss: 0.1710578745058945
2025-01-21 12:29:39,046 - trainer - INFO -     val_val_gen_loss: 18.977540680856414
2025-01-21 12:29:39,046 - trainer - INFO -     val_val_perplexity: 174519764.36363637
2025-01-21 12:29:39,046 - trainer - INFO -     val_val_embedding_sim: 0.42380685607592267
2025-01-21 12:29:39,046 - trainer - INFO - ================================================================================
2025-01-21 12:29:39,046 - trainer - INFO - Starting epoch 54 at 2025-01-21 12:29:39
2025-01-21 12:29:42,769 - trainer - INFO - Epoch 54 completed at 2025-01-21 12:29:42
2025-01-21 12:29:42,769 - trainer - INFO -     epoch          : 54
2025-01-21 12:29:42,769 - trainer - INFO -     elapsed time   : 3.7233102321624756
2025-01-21 12:29:42,769 - trainer - INFO -     loss           : 0.11920107509940862
2025-01-21 12:29:42,769 - trainer - INFO -     sim_loss       : 0.39565319269895555
2025-01-21 12:29:42,769 - trainer - INFO -     gen_loss       : 0.0007215904421173036
2025-01-21 12:29:42,769 - trainer - INFO -     val_val_loss   : 13.451993682167746
2025-01-21 12:29:42,769 - trainer - INFO -     val_val_sim_loss: 0.550933561090267
2025-01-21 12:29:42,770 - trainer - INFO -     val_val_gen_loss: 18.98101980035955
2025-01-21 12:29:42,770 - trainer - INFO -     val_val_perplexity: 175405827.15151516
2025-01-21 12:29:42,770 - trainer - INFO -     val_val_embedding_sim: 0.42334147655602655
2025-01-21 12:29:42,770 - trainer - INFO - ================================================================================
2025-01-21 12:29:42,770 - trainer - INFO - Starting epoch 55 at 2025-01-21 12:29:42
2025-01-21 12:29:46,491 - trainer - INFO - Epoch 55 completed at 2025-01-21 12:29:46
2025-01-21 12:29:46,491 - trainer - INFO -     epoch          : 55
2025-01-21 12:29:46,491 - trainer - INFO -     elapsed time   : 3.7210140228271484
2025-01-21 12:29:46,491 - trainer - INFO -     loss           : 0.09375923218030949
2025-01-21 12:29:46,491 - trainer - INFO -     sim_loss       : 0.3109199417829586
2025-01-21 12:29:46,491 - trainer - INFO -     gen_loss       : 0.0006903517059981823
2025-01-21 12:29:46,491 - trainer - INFO -     val_val_loss   : 13.56927322618889
2025-01-21 12:29:46,491 - trainer - INFO -     val_val_sim_loss: 0.8490603909347997
2025-01-21 12:29:46,491 - trainer - INFO -     val_val_gen_loss: 19.02079339460893
2025-01-21 12:29:46,491 - trainer - INFO -     val_val_perplexity: 185185852.6060606
2025-01-21 12:29:46,491 - trainer - INFO -     val_val_embedding_sim: 0.42431336641311646
2025-01-21 12:29:51,716 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch55.pth ...
2025-01-21 12:29:51,717 - trainer - INFO - ================================================================================
2025-01-21 12:29:51,717 - trainer - INFO - Starting epoch 56 at 2025-01-21 12:29:51
2025-01-21 12:29:55,477 - trainer - INFO - Epoch 56 completed at 2025-01-21 12:29:55
2025-01-21 12:29:55,477 - trainer - INFO -     epoch          : 56
2025-01-21 12:29:55,477 - trainer - INFO -     elapsed time   : 3.7598519325256348
2025-01-21 12:29:55,477 - trainer - INFO -     loss           : 0.06337637243559584
2025-01-21 12:29:55,477 - trainer - INFO -     sim_loss       : 0.20967450681491756
2025-01-21 12:29:55,477 - trainer - INFO -     gen_loss       : 0.0006771705637220293
2025-01-21 12:29:55,477 - trainer - INFO -     val_val_loss   : 13.395552924185088
2025-01-21 12:29:55,477 - trainer - INFO -     val_val_sim_loss: 0.25574227535328947
2025-01-21 12:29:55,477 - trainer - INFO -     val_val_gen_loss: 19.02690060933431
2025-01-21 12:29:55,477 - trainer - INFO -     val_val_perplexity: 188302644.6060606
2025-01-21 12:29:55,477 - trainer - INFO -     val_val_embedding_sim: 0.4227610104011767
2025-01-21 12:29:55,477 - trainer - INFO - ================================================================================
2025-01-21 12:29:55,477 - trainer - INFO - Starting epoch 57 at 2025-01-21 12:29:55
2025-01-21 12:29:59,200 - trainer - INFO - Epoch 57 completed at 2025-01-21 12:29:59
2025-01-21 12:29:59,200 - trainer - INFO -     epoch          : 57
2025-01-21 12:29:59,200 - trainer - INFO -     elapsed time   : 3.7222650051116943
2025-01-21 12:29:59,200 - trainer - INFO -     loss           : 0.09525541269977111
2025-01-21 12:29:59,200 - trainer - INFO -     sim_loss       : 0.3159438841317751
2025-01-21 12:29:59,200 - trainer - INFO -     gen_loss       : 0.0006746364117134363
2025-01-21 12:29:59,200 - trainer - INFO -     val_val_loss   : 13.424444429802172
2025-01-21 12:29:59,200 - trainer - INFO -     val_val_sim_loss: 0.25219909983658884
2025-01-21 12:29:59,200 - trainer - INFO -     val_val_gen_loss: 19.06969249609745
2025-01-21 12:29:59,200 - trainer - INFO -     val_val_perplexity: 250344859.15151516
2025-01-21 12:29:59,200 - trainer - INFO -     val_val_embedding_sim: 0.4246188799540202
2025-01-21 12:29:59,200 - trainer - INFO - ================================================================================
2025-01-21 12:29:59,200 - trainer - INFO - Starting epoch 58 at 2025-01-21 12:29:59
2025-01-21 12:30:02,918 - trainer - INFO - Epoch 58 completed at 2025-01-21 12:30:02
2025-01-21 12:30:02,919 - trainer - INFO -     epoch          : 58
2025-01-21 12:30:02,919 - trainer - INFO -     elapsed time   : 3.71779727935791
2025-01-21 12:30:02,919 - trainer - INFO -     loss           : 0.09663393520750105
2025-01-21 12:30:02,919 - trainer - INFO -     sim_loss       : 0.32059261485992463
2025-01-21 12:30:02,919 - trainer - INFO -     gen_loss       : 0.0006516369816381484
2025-01-21 12:30:02,919 - trainer - INFO -     val_val_loss   : 13.350351218021277
2025-01-21 12:30:02,919 - trainer - INFO -     val_val_sim_loss: 0.07534694205264025
2025-01-21 12:30:02,919 - trainer - INFO -     val_val_gen_loss: 19.039638808279328
2025-01-21 12:30:02,919 - trainer - INFO -     val_val_perplexity: 185931407.5151515
2025-01-21 12:30:02,919 - trainer - INFO -     val_val_embedding_sim: 0.4246052720329978
2025-01-21 12:30:02,919 - trainer - INFO - ================================================================================
2025-01-21 12:30:02,919 - trainer - INFO - Starting epoch 59 at 2025-01-21 12:30:02
2025-01-21 12:30:06,652 - trainer - INFO - Epoch 59 completed at 2025-01-21 12:30:06
2025-01-21 12:30:06,652 - trainer - INFO -     epoch          : 59
2025-01-21 12:30:06,652 - trainer - INFO -     elapsed time   : 3.7325797080993652
2025-01-21 12:30:06,652 - trainer - INFO -     loss           : 0.1176364116370678
2025-01-21 12:30:06,652 - trainer - INFO -     sim_loss       : 0.3906674921512604
2025-01-21 12:30:06,652 - trainer - INFO -     gen_loss       : 0.0006230866070836783
2025-01-21 12:30:06,652 - trainer - INFO -     val_val_loss   : 13.536028081720525
2025-01-21 12:30:06,652 - trainer - INFO -     val_val_sim_loss: 0.5672104503169204
2025-01-21 12:30:06,652 - trainer - INFO -     val_val_gen_loss: 19.09409326495546
2025-01-21 12:30:06,652 - trainer - INFO -     val_val_perplexity: 252724340.36363637
2025-01-21 12:30:06,652 - trainer - INFO -     val_val_embedding_sim: 0.4230015720381881
2025-01-21 12:30:06,652 - trainer - INFO - ================================================================================
2025-01-21 12:30:06,652 - trainer - INFO - Starting epoch 60 at 2025-01-21 12:30:06
2025-01-21 12:30:10,400 - trainer - INFO - Epoch 60 completed at 2025-01-21 12:30:10
2025-01-21 12:30:10,400 - trainer - INFO -     epoch          : 60
2025-01-21 12:30:10,400 - trainer - INFO -     elapsed time   : 3.7475595474243164
2025-01-21 12:30:10,400 - trainer - INFO -     loss           : 0.0983207980170846
2025-01-21 12:30:10,400 - trainer - INFO -     sim_loss       : 0.32628611475229263
2025-01-21 12:30:10,400 - trainer - INFO -     gen_loss       : 0.0006213707383722067
2025-01-21 12:30:10,400 - trainer - INFO -     val_val_loss   : 13.408547372529
2025-01-21 12:30:10,400 - trainer - INFO -     val_val_sim_loss: 0.04248666402065393
2025-01-21 12:30:10,400 - trainer - INFO -     val_val_gen_loss: 19.136859662605055
2025-01-21 12:30:10,400 - trainer - INFO -     val_val_perplexity: 265262910.06060606
2025-01-21 12:30:10,400 - trainer - INFO -     val_val_embedding_sim: 0.4245877523313869
2025-01-21 12:30:15,622 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch60.pth ...
2025-01-21 12:30:15,622 - trainer - INFO - ================================================================================
2025-01-21 12:30:15,623 - trainer - INFO - Starting epoch 61 at 2025-01-21 12:30:15
2025-01-21 12:30:19,377 - trainer - INFO - Epoch 61 completed at 2025-01-21 12:30:19
2025-01-21 12:30:19,377 - trainer - INFO -     epoch          : 61
2025-01-21 12:30:19,377 - trainer - INFO -     elapsed time   : 3.7544209957122803
2025-01-21 12:30:19,377 - trainer - INFO -     loss           : 0.07095178910531104
2025-01-21 12:30:19,377 - trainer - INFO -     sim_loss       : 0.23514072489106183
2025-01-21 12:30:19,377 - trainer - INFO -     gen_loss       : 0.0005850955203641206
2025-01-21 12:30:19,377 - trainer - INFO -     val_val_loss   : 13.407564509998668
2025-01-21 12:30:19,378 - trainer - INFO -     val_val_sim_loss: 0.06908088741880475
2025-01-21 12:30:19,378 - trainer - INFO -     val_val_gen_loss: 19.124057307387844
2025-01-21 12:30:19,378 - trainer - INFO -     val_val_perplexity: 202312744.24242425
2025-01-21 12:30:19,378 - trainer - INFO -     val_val_embedding_sim: 0.42469512513189606
2025-01-21 12:30:19,378 - trainer - INFO - ================================================================================
2025-01-21 12:30:19,378 - trainer - INFO - Starting epoch 62 at 2025-01-21 12:30:19
2025-01-21 12:30:23,110 - trainer - INFO - Epoch 62 completed at 2025-01-21 12:30:23
2025-01-21 12:30:23,110 - trainer - INFO -     epoch          : 62
2025-01-21 12:30:23,111 - trainer - INFO -     elapsed time   : 3.7324752807617188
2025-01-21 12:30:23,111 - trainer - INFO -     loss           : 0.06830049220880027
2025-01-21 12:30:23,111 - trainer - INFO -     sim_loss       : 0.22635295436120942
2025-01-21 12:30:23,111 - trainer - INFO -     gen_loss       : 0.0005637171037960797
2025-01-21 12:30:23,111 - trainer - INFO -     val_val_loss   : 13.410495440165201
2025-01-21 12:30:23,111 - trainer - INFO -     val_val_sim_loss: 3.3883799370883163e-06
2025-01-21 12:30:23,111 - trainer - INFO -     val_val_gen_loss: 19.157849051735617
2025-01-21 12:30:23,111 - trainer - INFO -     val_val_perplexity: 209001487.5151515
2025-01-21 12:30:23,111 - trainer - INFO -     val_val_embedding_sim: 0.42474962996714044
2025-01-21 12:30:23,111 - trainer - INFO - ================================================================================
2025-01-21 12:30:23,111 - trainer - INFO - Starting epoch 63 at 2025-01-21 12:30:23
2025-01-21 12:30:26,841 - trainer - INFO - Epoch 63 completed at 2025-01-21 12:30:26
2025-01-21 12:30:26,842 - trainer - INFO -     epoch          : 63
2025-01-21 12:30:26,842 - trainer - INFO -     elapsed time   : 3.7304773330688477
2025-01-21 12:30:26,842 - trainer - INFO -     loss           : 0.10881149508059025
2025-01-21 12:30:26,842 - trainer - INFO -     sim_loss       : 0.36138676255941393
2025-01-21 12:30:26,842 - trainer - INFO -     gen_loss       : 0.0005649434635415674
2025-01-21 12:30:26,842 - trainer - INFO -     val_val_loss   : 13.555266438108502
2025-01-21 12:30:26,842 - trainer - INFO -     val_val_sim_loss: 0.3953065872192383
2025-01-21 12:30:26,842 - trainer - INFO -     val_val_gen_loss: 19.195249384099785
2025-01-21 12:30:26,842 - trainer - INFO -     val_val_perplexity: 217251576.24242425
2025-01-21 12:30:26,842 - trainer - INFO -     val_val_embedding_sim: 0.42446856607090344
2025-01-21 12:30:26,842 - trainer - INFO - ================================================================================
2025-01-21 12:30:26,842 - trainer - INFO - Starting epoch 64 at 2025-01-21 12:30:26
2025-01-21 12:30:30,574 - trainer - INFO - Epoch 64 completed at 2025-01-21 12:30:30
2025-01-21 12:30:30,574 - trainer - INFO -     epoch          : 64
2025-01-21 12:30:30,574 - trainer - INFO -     elapsed time   : 3.7320804595947266
2025-01-21 12:30:30,574 - trainer - INFO -     loss           : 0.09038779325783253
2025-01-21 12:30:30,574 - trainer - INFO -     sim_loss       : 0.3000107154250145
2025-01-21 12:30:30,574 - trainer - INFO -     gen_loss       : 0.0005493903212482109
2025-01-21 12:30:30,574 - trainer - INFO -     val_val_loss   : 13.463389107675264
2025-01-21 12:30:30,575 - trainer - INFO -     val_val_sim_loss: 0.0998875372337159
2025-01-21 12:30:30,575 - trainer - INFO -     val_val_gen_loss: 19.19060435439601
2025-01-21 12:30:30,575 - trainer - INFO -     val_val_perplexity: 217911059.3939394
2025-01-21 12:30:30,575 - trainer - INFO -     val_val_embedding_sim: 0.4247696941549128
2025-01-21 12:30:30,575 - trainer - INFO - ================================================================================
2025-01-21 12:30:30,575 - trainer - INFO - Starting epoch 65 at 2025-01-21 12:30:30
2025-01-21 12:30:34,309 - trainer - INFO - Epoch 65 completed at 2025-01-21 12:30:34
2025-01-21 12:30:34,309 - trainer - INFO -     epoch          : 65
2025-01-21 12:30:34,309 - trainer - INFO -     elapsed time   : 3.7341692447662354
2025-01-21 12:30:34,309 - trainer - INFO -     loss           : 0.06552976947277785
2025-01-21 12:30:34,309 - trainer - INFO -     sim_loss       : 0.21718095988035202
2025-01-21 12:30:34,309 - trainer - INFO -     gen_loss       : 0.0005363976262742654
2025-01-21 12:30:34,309 - trainer - INFO -     val_val_loss   : 13.608195564963601
2025-01-21 12:30:34,309 - trainer - INFO -     val_val_sim_loss: 0.5011577822945334
2025-01-21 12:30:34,309 - trainer - INFO -     val_val_gen_loss: 19.225497390284684
2025-01-21 12:30:34,309 - trainer - INFO -     val_val_perplexity: 224216353.93939394
2025-01-21 12:30:34,309 - trainer - INFO -     val_val_embedding_sim: 0.4250124038168878
2025-01-21 12:30:39,534 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch65.pth ...
2025-01-21 12:30:39,534 - trainer - INFO - ================================================================================
2025-01-21 12:30:39,534 - trainer - INFO - Starting epoch 66 at 2025-01-21 12:30:39
2025-01-21 12:30:43,306 - trainer - INFO - Epoch 66 completed at 2025-01-21 12:30:43
2025-01-21 12:30:43,307 - trainer - INFO -     epoch          : 66
2025-01-21 12:30:43,307 - trainer - INFO -     elapsed time   : 3.771925210952759
2025-01-21 12:30:43,307 - trainer - INFO -     loss           : 0.06503218327998184
2025-01-21 12:30:43,307 - trainer - INFO -     sim_loss       : 0.21556696642055612
2025-01-21 12:30:43,307 - trainer - INFO -     gen_loss       : 0.0005172737292014062
2025-01-21 12:30:43,307 - trainer - INFO -     val_val_loss   : 13.59026897314823
2025-01-21 12:30:43,307 - trainer - INFO -     val_val_sim_loss: 0.3151367433139526
2025-01-21 12:30:43,307 - trainer - INFO -     val_val_gen_loss: 19.279611760919746
2025-01-21 12:30:43,307 - trainer - INFO -     val_val_perplexity: 236114183.27272728
2025-01-21 12:30:43,307 - trainer - INFO -     val_val_embedding_sim: 0.4246859893654332
2025-01-21 12:30:43,307 - trainer - INFO - ================================================================================
2025-01-21 12:30:43,307 - trainer - INFO - Starting epoch 67 at 2025-01-21 12:30:43
2025-01-21 12:30:47,034 - trainer - INFO - Epoch 67 completed at 2025-01-21 12:30:47
2025-01-21 12:30:47,034 - trainer - INFO -     epoch          : 67
2025-01-21 12:30:47,034 - trainer - INFO -     elapsed time   : 3.726520538330078
2025-01-21 12:30:47,034 - trainer - INFO -     loss           : 0.04936142790247686
2025-01-21 12:30:47,034 - trainer - INFO -     sim_loss       : 0.16336441857579304
2025-01-21 12:30:47,034 - trainer - INFO -     gen_loss       : 0.0005030020052799955
2025-01-21 12:30:47,034 - trainer - INFO -     val_val_loss   : 13.510212724859064
2025-01-21 12:30:47,034 - trainer - INFO -     val_val_sim_loss: 0.042148806832053444
2025-01-21 12:30:47,034 - trainer - INFO -     val_val_gen_loss: 19.282241185506184
2025-01-21 12:30:47,034 - trainer - INFO -     val_val_perplexity: 240382265.45454547
2025-01-21 12:30:47,034 - trainer - INFO -     val_val_embedding_sim: 0.4246720689715761
2025-01-21 12:30:47,034 - trainer - INFO - ================================================================================
2025-01-21 12:30:47,034 - trainer - INFO - Starting epoch 68 at 2025-01-21 12:30:47
2025-01-21 12:30:50,770 - trainer - INFO - Epoch 68 completed at 2025-01-21 12:30:50
2025-01-21 12:30:50,770 - trainer - INFO -     epoch          : 68
2025-01-21 12:30:50,770 - trainer - INFO -     elapsed time   : 3.7358829975128174
2025-01-21 12:30:50,771 - trainer - INFO -     loss           : 0.1038659662939608
2025-01-21 12:30:50,771 - trainer - INFO -     sim_loss       : 0.34507120996713636
2025-01-21 12:30:50,771 - trainer - INFO -     gen_loss       : 0.0004922847729176283
2025-01-21 12:30:50,771 - trainer - INFO -     val_val_loss   : 13.584289319587477
2025-01-21 12:30:50,771 - trainer - INFO -     val_val_sim_loss: 0.3265148076144097
2025-01-21 12:30:50,771 - trainer - INFO -     val_val_gen_loss: 19.2661940834739
2025-01-21 12:30:50,771 - trainer - INFO -     val_val_perplexity: 288721082.1818182
2025-01-21 12:30:50,771 - trainer - INFO -     val_val_embedding_sim: 0.42514865506779065
2025-01-21 12:30:50,771 - trainer - INFO - ================================================================================
2025-01-21 12:30:50,771 - trainer - INFO - Starting epoch 69 at 2025-01-21 12:30:50
2025-01-21 12:30:54,493 - trainer - INFO - Epoch 69 completed at 2025-01-21 12:30:54
2025-01-21 12:30:54,493 - trainer - INFO -     epoch          : 69
2025-01-21 12:30:54,493 - trainer - INFO -     elapsed time   : 3.721759796142578
2025-01-21 12:30:54,493 - trainer - INFO -     loss           : 0.12057526335120201
2025-01-21 12:30:54,493 - trainer - INFO -     sim_loss       : 0.400788002833724
2025-01-21 12:30:54,493 - trainer - INFO -     gen_loss       : 0.00048408496077172457
2025-01-21 12:30:54,493 - trainer - INFO -     val_val_loss   : 13.706209182739258
2025-01-21 12:30:54,493 - trainer - INFO -     val_val_sim_loss: 0.6296575141675544
2025-01-21 12:30:54,493 - trainer - INFO -     val_val_gen_loss: 19.310445496530242
2025-01-21 12:30:54,493 - trainer - INFO -     val_val_perplexity: 244515962.66666666
2025-01-21 12:30:54,493 - trainer - INFO -     val_val_embedding_sim: 0.4248369679306493
2025-01-21 12:30:54,493 - trainer - INFO - ================================================================================
2025-01-21 12:30:54,493 - trainer - INFO - Starting epoch 70 at 2025-01-21 12:30:54
2025-01-21 12:30:58,234 - trainer - INFO - Epoch 70 completed at 2025-01-21 12:30:58
2025-01-21 12:30:58,235 - trainer - INFO -     epoch          : 70
2025-01-21 12:30:58,235 - trainer - INFO -     elapsed time   : 3.740983486175537
2025-01-21 12:30:58,235 - trainer - INFO -     loss           : 0.0981724669225514
2025-01-21 12:30:58,235 - trainer - INFO -     sim_loss       : 0.3261278685182333
2025-01-21 12:30:58,235 - trainer - INFO -     gen_loss       : 0.0004772889369633049
2025-01-21 12:30:58,235 - trainer - INFO -     val_val_loss   : 13.56346269087358
2025-01-21 12:30:58,235 - trainer - INFO -     val_val_sim_loss: 0.033380259167062595
2025-01-21 12:30:58,235 - trainer - INFO -     val_val_gen_loss: 19.362069794625945
2025-01-21 12:30:58,235 - trainer - INFO -     val_val_perplexity: 743563295.030303
2025-01-21 12:30:58,235 - trainer - INFO -     val_val_embedding_sim: 0.4248814235130946
2025-01-21 12:31:03,462 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch70.pth ...
2025-01-21 12:31:03,462 - trainer - INFO - ================================================================================
2025-01-21 12:31:03,462 - trainer - INFO - Starting epoch 71 at 2025-01-21 12:31:03
2025-01-21 12:31:07,228 - trainer - INFO - Epoch 71 completed at 2025-01-21 12:31:07
2025-01-21 12:31:07,228 - trainer - INFO -     epoch          : 71
2025-01-21 12:31:07,228 - trainer - INFO -     elapsed time   : 3.7653632164001465
2025-01-21 12:31:07,228 - trainer - INFO -     loss           : 0.06779648209922015
2025-01-21 12:31:07,228 - trainer - INFO -     sim_loss       : 0.22488266952914274
2025-01-21 12:31:07,228 - trainer - INFO -     gen_loss       : 0.00047382487682625654
2025-01-21 12:31:07,228 - trainer - INFO -     val_val_loss   : 13.564875342629172
2025-01-21 12:31:07,228 - trainer - INFO -     val_val_sim_loss: 0.042338396563626236
2025-01-21 12:31:07,228 - trainer - INFO -     val_val_gen_loss: 19.360247640898734
2025-01-21 12:31:07,228 - trainer - INFO -     val_val_perplexity: 283775072.969697
2025-01-21 12:31:07,228 - trainer - INFO -     val_val_embedding_sim: 0.42484578941807605
2025-01-21 12:31:07,228 - trainer - INFO - ================================================================================
2025-01-21 12:31:07,228 - trainer - INFO - Starting epoch 72 at 2025-01-21 12:31:07
2025-01-21 12:31:10,961 - trainer - INFO - Epoch 72 completed at 2025-01-21 12:31:10
2025-01-21 12:31:10,961 - trainer - INFO -     epoch          : 72
2025-01-21 12:31:10,961 - trainer - INFO -     elapsed time   : 3.73250675201416
2025-01-21 12:31:10,961 - trainer - INFO -     loss           : 0.08204369992017746
2025-01-21 12:31:10,961 - trainer - INFO -     sim_loss       : 0.27240623980760575
2025-01-21 12:31:10,961 - trainer - INFO -     gen_loss       : 0.0004597477032802999
2025-01-21 12:31:10,961 - trainer - INFO -     val_val_loss   : 13.622711326136734
2025-01-21 12:31:10,961 - trainer - INFO -     val_val_sim_loss: 0.16300957130663324
2025-01-21 12:31:10,961 - trainer - INFO -     val_val_gen_loss: 19.391154433741715
2025-01-21 12:31:10,961 - trainer - INFO -     val_val_perplexity: 264905137.93939394
2025-01-21 12:31:10,961 - trainer - INFO -     val_val_embedding_sim: 0.423842859990669
2025-01-21 12:31:10,961 - trainer - INFO - ================================================================================
2025-01-21 12:31:10,961 - trainer - INFO - Starting epoch 73 at 2025-01-21 12:31:10
2025-01-21 12:31:14,689 - trainer - INFO - Epoch 73 completed at 2025-01-21 12:31:14
2025-01-21 12:31:14,689 - trainer - INFO -     epoch          : 73
2025-01-21 12:31:14,689 - trainer - INFO -     elapsed time   : 3.7274997234344482
2025-01-21 12:31:14,689 - trainer - INFO -     loss           : 0.06700149420648813
2025-01-21 12:31:14,689 - trainer - INFO -     sim_loss       : 0.222318434715271
2025-01-21 12:31:14,689 - trainer - INFO -     gen_loss       : 0.00043708883749786763
2025-01-21 12:31:14,689 - trainer - INFO -     val_val_loss   : 13.727714278481223
2025-01-21 12:31:14,689 - trainer - INFO -     val_val_sim_loss: 0.37842438437720566
2025-01-21 12:31:14,689 - trainer - INFO -     val_val_gen_loss: 19.448838378443863
2025-01-21 12:31:14,690 - trainer - INFO -     val_val_perplexity: 360542456.24242425
2025-01-21 12:31:14,690 - trainer - INFO -     val_val_embedding_sim: 0.42293600331653247
2025-01-21 12:31:14,690 - trainer - INFO - ================================================================================
2025-01-21 12:31:14,690 - trainer - INFO - Starting epoch 74 at 2025-01-21 12:31:14
2025-01-21 12:31:18,410 - trainer - INFO - Epoch 74 completed at 2025-01-21 12:31:18
2025-01-21 12:31:18,410 - trainer - INFO -     epoch          : 74
2025-01-21 12:31:18,410 - trainer - INFO -     elapsed time   : 3.720122814178467
2025-01-21 12:31:18,410 - trainer - INFO -     loss           : 0.07834425009787083
2025-01-21 12:31:18,410 - trainer - INFO -     sim_loss       : 0.2600848779082298
2025-01-21 12:31:18,410 - trainer - INFO -     gen_loss       : 0.00045540445717051625
2025-01-21 12:31:18,410 - trainer - INFO -     val_val_loss   : 13.6965413238063
2025-01-21 12:31:18,410 - trainer - INFO -     val_val_sim_loss: 0.2949464572496557
2025-01-21 12:31:18,410 - trainer - INFO -     val_val_gen_loss: 19.44008226105661
2025-01-21 12:31:18,410 - trainer - INFO -     val_val_perplexity: 277239510.3030303
2025-01-21 12:31:18,410 - trainer - INFO -     val_val_embedding_sim: 0.42306046413652826
2025-01-21 12:31:18,410 - trainer - INFO - ================================================================================
2025-01-21 12:31:18,410 - trainer - INFO - Starting epoch 75 at 2025-01-21 12:31:18
2025-01-21 12:31:22,149 - trainer - INFO - Epoch 75 completed at 2025-01-21 12:31:22
2025-01-21 12:31:22,149 - trainer - INFO -     epoch          : 75
2025-01-21 12:31:22,149 - trainer - INFO -     elapsed time   : 3.738568067550659
2025-01-21 12:31:22,149 - trainer - INFO -     loss           : 0.09603716782294214
2025-01-21 12:31:22,149 - trainer - INFO -     sim_loss       : 0.31912656306376447
2025-01-21 12:31:22,149 - trainer - INFO -     gen_loss       : 0.00042742052755784243
2025-01-21 12:31:22,149 - trainer - INFO -     val_val_loss   : 13.650276733167244
2025-01-21 12:31:22,149 - trainer - INFO -     val_val_sim_loss: 0.09776090853140638
2025-01-21 12:31:22,149 - trainer - INFO -     val_val_gen_loss: 19.45849829009085
2025-01-21 12:31:22,149 - trainer - INFO -     val_val_perplexity: 285455873.93939394
2025-01-21 12:31:22,149 - trainer - INFO -     val_val_embedding_sim: 0.4242786584478436
2025-01-21 12:31:27,361 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch75.pth ...
2025-01-21 12:31:27,361 - trainer - INFO - ================================================================================
2025-01-21 12:31:27,361 - trainer - INFO - Starting epoch 76 at 2025-01-21 12:31:27
2025-01-21 12:31:31,278 - trainer - INFO - Epoch 76 completed at 2025-01-21 12:31:31
2025-01-21 12:31:31,278 - trainer - INFO -     epoch          : 76
2025-01-21 12:31:31,278 - trainer - INFO -     elapsed time   : 3.9166061878204346
2025-01-21 12:31:31,278 - trainer - INFO -     loss           : 0.08679708726413082
2025-01-21 12:31:31,278 - trainer - INFO -     sim_loss       : 0.28834096270702503
2025-01-21 12:31:31,278 - trainer - INFO -     gen_loss       : 0.00042113400995731355
2025-01-21 12:31:31,278 - trainer - INFO -     val_val_loss   : 13.702014431808934
2025-01-21 12:31:31,278 - trainer - INFO -     val_val_sim_loss: 0.2275613907601534
2025-01-21 12:31:31,278 - trainer - INFO -     val_val_gen_loss: 19.476779186364375
2025-01-21 12:31:31,278 - trainer - INFO -     val_val_perplexity: 287955616.0
2025-01-21 12:31:31,278 - trainer - INFO -     val_val_embedding_sim: 0.4251207456444249
2025-01-21 12:31:31,278 - trainer - INFO - ================================================================================
2025-01-21 12:31:31,278 - trainer - INFO - Starting epoch 77 at 2025-01-21 12:31:31
2025-01-21 12:31:35,002 - trainer - INFO - Epoch 77 completed at 2025-01-21 12:31:35
2025-01-21 12:31:35,002 - trainer - INFO -     epoch          : 77
2025-01-21 12:31:35,002 - trainer - INFO -     elapsed time   : 3.723184108734131
2025-01-21 12:31:35,002 - trainer - INFO -     loss           : 0.09529661778360606
2025-01-21 12:31:35,002 - trainer - INFO -     sim_loss       : 0.3167161125689745
2025-01-21 12:31:35,002 - trainer - INFO -     gen_loss       : 0.0004025423055281863
2025-01-21 12:31:35,002 - trainer - INFO -     val_val_loss   : 13.750770077560887
2025-01-21 12:31:35,002 - trainer - INFO -     val_val_sim_loss: 0.2738597212415753
2025-01-21 12:31:35,002 - trainer - INFO -     val_val_gen_loss: 19.52658832434452
2025-01-21 12:31:35,002 - trainer - INFO -     val_val_perplexity: 310636534.1818182
2025-01-21 12:31:35,002 - trainer - INFO -     val_val_embedding_sim: 0.4237777590751648
2025-01-21 12:31:35,002 - trainer - INFO - ================================================================================
2025-01-21 12:31:35,002 - trainer - INFO - Starting epoch 78 at 2025-01-21 12:31:35
2025-01-21 12:31:38,733 - trainer - INFO - Epoch 78 completed at 2025-01-21 12:31:38
2025-01-21 12:31:38,733 - trainer - INFO -     epoch          : 78
2025-01-21 12:31:38,733 - trainer - INFO -     elapsed time   : 3.730236291885376
2025-01-21 12:31:38,733 - trainer - INFO -     loss           : 0.07509266552806367
2025-01-21 12:31:38,733 - trainer - INFO -     sim_loss       : 0.24938199632451868
2025-01-21 12:31:38,733 - trainer - INFO -     gen_loss       : 0.00039723289082758126
2025-01-21 12:31:38,733 - trainer - INFO -     val_val_loss   : 13.743228565562855
2025-01-21 12:31:38,733 - trainer - INFO -     val_val_sim_loss: 0.24398315302934145
2025-01-21 12:31:38,733 - trainer - INFO -     val_val_gen_loss: 19.528620344219785
2025-01-21 12:31:38,733 - trainer - INFO -     val_val_perplexity: 302916839.27272725
2025-01-21 12:31:38,733 - trainer - INFO -     val_val_embedding_sim: 0.42308119210329925
2025-01-21 12:31:38,733 - trainer - INFO - ================================================================================
2025-01-21 12:31:38,733 - trainer - INFO - Starting epoch 79 at 2025-01-21 12:31:38
2025-01-21 12:31:42,467 - trainer - INFO - Epoch 79 completed at 2025-01-21 12:31:42
2025-01-21 12:31:42,467 - trainer - INFO -     epoch          : 79
2025-01-21 12:31:42,467 - trainer - INFO -     elapsed time   : 3.733839750289917
2025-01-21 12:31:42,468 - trainer - INFO -     loss           : 0.08620585575699806
2025-01-21 12:31:42,468 - trainer - INFO -     sim_loss       : 0.2864348739385605
2025-01-21 12:31:42,468 - trainer - INFO -     gen_loss       : 0.0003934135602321476
2025-01-21 12:31:42,468 - trainer - INFO -     val_val_loss   : 13.711216406388717
2025-01-21 12:31:42,468 - trainer - INFO -     val_val_sim_loss: 0.17695575410629538
2025-01-21 12:31:42,468 - trainer - INFO -     val_val_gen_loss: 19.511613499034535
2025-01-21 12:31:42,468 - trainer - INFO -     val_val_perplexity: 298133991.75757575
2025-01-21 12:31:42,468 - trainer - INFO -     val_val_embedding_sim: 0.4232687372149843
2025-01-21 12:31:42,468 - trainer - INFO - ================================================================================
2025-01-21 12:31:42,468 - trainer - INFO - Starting epoch 80 at 2025-01-21 12:31:42
2025-01-21 12:31:46,196 - trainer - INFO - Epoch 80 completed at 2025-01-21 12:31:46
2025-01-21 12:31:46,196 - trainer - INFO -     epoch          : 80
2025-01-21 12:31:46,196 - trainer - INFO -     elapsed time   : 3.7282650470733643
2025-01-21 12:31:46,196 - trainer - INFO -     loss           : 0.11606240313558373
2025-01-21 12:31:46,196 - trainer - INFO -     sim_loss       : 0.38599931345197547
2025-01-21 12:31:46,196 - trainer - INFO -     gen_loss       : 0.0003751454933080822
2025-01-21 12:31:46,196 - trainer - INFO -     val_val_loss   : 13.826168349294951
2025-01-21 12:31:46,196 - trainer - INFO -     val_val_sim_loss: 0.49226556041022224
2025-01-21 12:31:46,197 - trainer - INFO -     val_val_gen_loss: 19.540697502367426
2025-01-21 12:31:46,197 - trainer - INFO -     val_val_perplexity: 309330269.09090906
2025-01-21 12:31:46,197 - trainer - INFO -     val_val_embedding_sim: 0.4233022314129454
2025-01-21 12:31:51,425 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch80.pth ...
2025-01-21 12:31:51,426 - trainer - INFO - ================================================================================
2025-01-21 12:31:51,426 - trainer - INFO - Starting epoch 81 at 2025-01-21 12:31:51
2025-01-21 12:31:55,198 - trainer - INFO - Epoch 81 completed at 2025-01-21 12:31:55
2025-01-21 12:31:55,198 - trainer - INFO -     epoch          : 81
2025-01-21 12:31:55,198 - trainer - INFO -     elapsed time   : 3.7721402645111084
2025-01-21 12:31:55,198 - trainer - INFO -     loss           : 0.08700565272010863
2025-01-21 12:31:55,198 - trainer - INFO -     sim_loss       : 0.2891531298017981
2025-01-21 12:31:55,198 - trainer - INFO -     gen_loss       : 0.0003710121993208304
2025-01-21 12:31:55,198 - trainer - INFO -     val_val_loss   : 13.789769259366123
2025-01-21 12:31:55,198 - trainer - INFO -     val_val_sim_loss: 0.24395668867860518
2025-01-21 12:31:55,198 - trainer - INFO -     val_val_gen_loss: 19.595117684566613
2025-01-21 12:31:55,198 - trainer - INFO -     val_val_perplexity: 418700986.1818182
2025-01-21 12:31:55,198 - trainer - INFO -     val_val_embedding_sim: 0.4230702474261775
2025-01-21 12:31:55,198 - trainer - INFO - ================================================================================
2025-01-21 12:31:55,198 - trainer - INFO - Starting epoch 82 at 2025-01-21 12:31:55
2025-01-21 12:31:58,920 - trainer - INFO - Epoch 82 completed at 2025-01-21 12:31:58
2025-01-21 12:31:58,920 - trainer - INFO -     epoch          : 82
2025-01-21 12:31:58,920 - trainer - INFO -     elapsed time   : 3.721121311187744
2025-01-21 12:31:58,920 - trainer - INFO -     loss           : 0.09115372709929943
2025-01-21 12:31:58,920 - trainer - INFO -     sim_loss       : 0.3030027441680431
2025-01-21 12:31:58,920 - trainer - INFO -     gen_loss       : 0.0003612886241171509
2025-01-21 12:31:58,920 - trainer - INFO -     val_val_loss   : 13.91495331850919
2025-01-21 12:31:58,920 - trainer - INFO -     val_val_sim_loss: 0.6658585902416343
2025-01-21 12:31:58,920 - trainer - INFO -     val_val_gen_loss: 19.59313710530599
2025-01-21 12:31:58,920 - trainer - INFO -     val_val_perplexity: 351160353.5151515
2025-01-21 12:31:58,920 - trainer - INFO -     val_val_embedding_sim: 0.42364348064769397
2025-01-21 12:31:58,920 - trainer - INFO - ================================================================================
2025-01-21 12:31:58,920 - trainer - INFO - Starting epoch 83 at 2025-01-21 12:31:58
2025-01-21 12:32:02,655 - trainer - INFO - Epoch 83 completed at 2025-01-21 12:32:02
2025-01-21 12:32:02,655 - trainer - INFO -     epoch          : 83
2025-01-21 12:32:02,655 - trainer - INFO -     elapsed time   : 3.734064817428589
2025-01-21 12:32:02,655 - trainer - INFO -     loss           : 0.07722198497795034
2025-01-21 12:32:02,655 - trainer - INFO -     sim_loss       : 0.25658139338193
2025-01-21 12:32:02,655 - trainer - INFO -     gen_loss       : 0.00035366347001399847
2025-01-21 12:32:02,655 - trainer - INFO -     val_val_loss   : 13.74812039462003
2025-01-21 12:32:02,655 - trainer - INFO -     val_val_sim_loss: 0.06678363048669064
2025-01-21 12:32:02,655 - trainer - INFO -     val_val_gen_loss: 19.61155099579782
2025-01-21 12:32:02,655 - trainer - INFO -     val_val_perplexity: 342860245.3333333
2025-01-21 12:32:02,655 - trainer - INFO -     val_val_embedding_sim: 0.423164784005194
2025-01-21 12:32:02,655 - trainer - INFO - ================================================================================
2025-01-21 12:32:02,655 - trainer - INFO - Starting epoch 84 at 2025-01-21 12:32:02
2025-01-21 12:32:06,375 - trainer - INFO - Epoch 84 completed at 2025-01-21 12:32:06
2025-01-21 12:32:06,375 - trainer - INFO -     epoch          : 84
2025-01-21 12:32:06,375 - trainer - INFO -     elapsed time   : 3.719327926635742
2025-01-21 12:32:06,375 - trainer - INFO -     loss           : 0.0856901053339243
2025-01-21 12:32:06,375 - trainer - INFO -     sim_loss       : 0.28482148349285125
2025-01-21 12:32:06,375 - trainer - INFO -     gen_loss       : 0.0003480812767520547
2025-01-21 12:32:06,375 - trainer - INFO -     val_val_loss   : 13.914940284960197
2025-01-21 12:32:06,375 - trainer - INFO -     val_val_sim_loss: 0.5041311437433417
2025-01-21 12:32:06,375 - trainer - INFO -     val_val_gen_loss: 19.662429347182766
2025-01-21 12:32:06,375 - trainer - INFO -     val_val_perplexity: 360907525.09090906
2025-01-21 12:32:06,375 - trainer - INFO -     val_val_embedding_sim: 0.42344734524235583
2025-01-21 12:32:06,375 - trainer - INFO - ================================================================================
2025-01-21 12:32:06,375 - trainer - INFO - Starting epoch 85 at 2025-01-21 12:32:06
2025-01-21 12:32:10,104 - trainer - INFO - Epoch 85 completed at 2025-01-21 12:32:10
2025-01-21 12:32:10,105 - trainer - INFO -     epoch          : 85
2025-01-21 12:32:10,105 - trainer - INFO -     elapsed time   : 3.7290964126586914
2025-01-21 12:32:10,105 - trainer - INFO -     loss           : 0.07793190623051487
2025-01-21 12:32:10,105 - trainer - INFO -     sim_loss       : 0.2589729035285927
2025-01-21 12:32:10,105 - trainer - INFO -     gen_loss       : 0.00034290369658265265
2025-01-21 12:32:10,105 - trainer - INFO -     val_val_loss   : 13.730148084235914
2025-01-21 12:32:10,105 - trainer - INFO -     val_val_sim_loss: 9.03099920502758e-08
2025-01-21 12:32:10,105 - trainer - INFO -     val_val_gen_loss: 19.614496982458867
2025-01-21 12:32:10,105 - trainer - INFO -     val_val_perplexity: 344605114.1818182
2025-01-21 12:32:10,105 - trainer - INFO -     val_val_embedding_sim: 0.4244263989455772
2025-01-21 12:32:15,354 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch85.pth ...
2025-01-21 12:32:15,354 - trainer - INFO - ================================================================================
2025-01-21 12:32:15,354 - trainer - INFO - Starting epoch 86 at 2025-01-21 12:32:15
2025-01-21 12:32:19,124 - trainer - INFO - Epoch 86 completed at 2025-01-21 12:32:19
2025-01-21 12:32:19,124 - trainer - INFO -     epoch          : 86
2025-01-21 12:32:19,124 - trainer - INFO -     elapsed time   : 3.769686222076416
2025-01-21 12:32:19,124 - trainer - INFO -     loss           : 0.0968112701550126
2025-01-21 12:32:19,124 - trainer - INFO -     sim_loss       : 0.3219158884137869
2025-01-21 12:32:19,124 - trainer - INFO -     gen_loss       : 0.0003378561435965821
2025-01-21 12:32:19,124 - trainer - INFO -     val_val_loss   : 13.844141266562723
2025-01-21 12:32:19,124 - trainer - INFO -     val_val_sim_loss: 0.27279689095237036
2025-01-21 12:32:19,124 - trainer - INFO -     val_val_gen_loss: 19.660431717381332
2025-01-21 12:32:19,124 - trainer - INFO -     val_val_perplexity: 355722236.24242425
2025-01-21 12:32:19,124 - trainer - INFO -     val_val_embedding_sim: 0.4233615615151145
2025-01-21 12:32:19,124 - trainer - INFO - ================================================================================
2025-01-21 12:32:19,124 - trainer - INFO - Starting epoch 87 at 2025-01-21 12:32:19
2025-01-21 12:32:22,853 - trainer - INFO - Epoch 87 completed at 2025-01-21 12:32:22
2025-01-21 12:32:22,853 - trainer - INFO -     epoch          : 87
2025-01-21 12:32:22,853 - trainer - INFO -     elapsed time   : 3.7285966873168945
2025-01-21 12:32:22,853 - trainer - INFO -     loss           : 0.10594863332808017
2025-01-21 12:32:22,854 - trainer - INFO -     sim_loss       : 0.3523739978671074
2025-01-21 12:32:22,854 - trainer - INFO -     gen_loss       : 0.00033775829651858655
2025-01-21 12:32:22,854 - trainer - INFO -     val_val_loss   : 13.864623734445283
2025-01-21 12:32:22,854 - trainer - INFO -     val_val_sim_loss: 0.29795845317483216
2025-01-21 12:32:22,854 - trainer - INFO -     val_val_gen_loss: 19.678908897168707
2025-01-21 12:32:22,854 - trainer - INFO -     val_val_perplexity: 361675430.7878788
2025-01-21 12:32:22,854 - trainer - INFO -     val_val_embedding_sim: 0.4225137107300036
2025-01-21 12:32:22,854 - trainer - INFO - ================================================================================
2025-01-21 12:32:22,854 - trainer - INFO - Starting epoch 88 at 2025-01-21 12:32:22
2025-01-21 12:32:26,571 - trainer - INFO - Epoch 88 completed at 2025-01-21 12:32:26
2025-01-21 12:32:26,571 - trainer - INFO -     epoch          : 88
2025-01-21 12:32:26,571 - trainer - INFO -     elapsed time   : 3.7174289226531982
2025-01-21 12:32:26,572 - trainer - INFO -     loss           : 0.10989734753966332
2025-01-21 12:32:26,572 - trainer - INFO -     sim_loss       : 0.36553832441568374
2025-01-21 12:32:26,572 - trainer - INFO -     gen_loss       : 0.000336920126574114
2025-01-21 12:32:26,572 - trainer - INFO -     val_val_loss   : 13.842821207913486
2025-01-21 12:32:26,572 - trainer - INFO -     val_val_sim_loss: 0.31525507840243255
2025-01-21 12:32:26,572 - trainer - INFO -     val_val_gen_loss: 19.640348954634234
2025-01-21 12:32:26,572 - trainer - INFO -     val_val_perplexity: 338995000.24242425
2025-01-21 12:32:26,572 - trainer - INFO -     val_val_embedding_sim: 0.4237479152101459
2025-01-21 12:32:26,572 - trainer - INFO - ================================================================================
2025-01-21 12:32:26,572 - trainer - INFO - Starting epoch 89 at 2025-01-21 12:32:26
2025-01-21 12:32:30,303 - trainer - INFO - Epoch 89 completed at 2025-01-21 12:32:30
2025-01-21 12:32:30,303 - trainer - INFO -     epoch          : 89
2025-01-21 12:32:30,303 - trainer - INFO -     elapsed time   : 3.731288194656372
2025-01-21 12:32:30,303 - trainer - INFO -     loss           : 0.07849216843460453
2025-01-21 12:32:30,303 - trainer - INFO -     sim_loss       : 0.2609139250183944
2025-01-21 12:32:30,304 - trainer - INFO -     gen_loss       : 0.0003114092192845419
2025-01-21 12:32:30,304 - trainer - INFO -     val_val_loss   : 13.829909353545219
2025-01-21 12:32:30,304 - trainer - INFO -     val_val_sim_loss: 0.12578811790003921
2025-01-21 12:32:30,304 - trainer - INFO -     val_val_gen_loss: 19.70310419256037
2025-01-21 12:32:30,304 - trainer - INFO -     val_val_perplexity: 482927166.06060606
2025-01-21 12:32:30,304 - trainer - INFO -     val_val_embedding_sim: 0.4239721745252609
2025-01-21 12:32:30,304 - trainer - INFO - ================================================================================
2025-01-21 12:32:30,304 - trainer - INFO - Starting epoch 90 at 2025-01-21 12:32:30
2025-01-21 12:32:34,022 - trainer - INFO - Epoch 90 completed at 2025-01-21 12:32:34
2025-01-21 12:32:34,022 - trainer - INFO -     epoch          : 90
2025-01-21 12:32:34,022 - trainer - INFO -     elapsed time   : 3.71815824508667
2025-01-21 12:32:34,022 - trainer - INFO -     loss           : 0.07094268107175594
2025-01-21 12:32:34,022 - trainer - INFO -     sim_loss       : 0.2357558194255489
2025-01-21 12:32:34,022 - trainer - INFO -     gen_loss       : 0.00030847615271341057
2025-01-21 12:32:34,022 - trainer - INFO -     val_val_loss   : 13.825387868014248
2025-01-21 12:32:34,022 - trainer - INFO -     val_val_sim_loss: 0.10030713225855972
2025-01-21 12:32:34,022 - trainer - INFO -     val_val_gen_loss: 19.70756501862497
2025-01-21 12:32:34,022 - trainer - INFO -     val_val_perplexity: 362581308.1212121
2025-01-21 12:32:34,023 - trainer - INFO -     val_val_embedding_sim: 0.4233632340575709
2025-01-21 12:32:39,326 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch90.pth ...
2025-01-21 12:32:39,326 - trainer - INFO - ================================================================================
2025-01-21 12:32:39,326 - trainer - INFO - Starting epoch 91 at 2025-01-21 12:32:39
2025-01-21 12:32:43,103 - trainer - INFO - Epoch 91 completed at 2025-01-21 12:32:43
2025-01-21 12:32:43,103 - trainer - INFO -     epoch          : 91
2025-01-21 12:32:43,103 - trainer - INFO -     elapsed time   : 3.776801347732544
2025-01-21 12:32:43,103 - trainer - INFO -     loss           : 0.08807707489468157
2025-01-21 12:32:43,103 - trainer - INFO -     sim_loss       : 0.2928785145282745
2025-01-21 12:32:43,103 - trainer - INFO -     gen_loss       : 0.0003050220984732732
2025-01-21 12:32:43,103 - trainer - INFO -     val_val_loss   : 13.869988817157168
2025-01-21 12:32:43,103 - trainer - INFO -     val_val_sim_loss: 0.17276197491257722
2025-01-21 12:32:43,103 - trainer - INFO -     val_val_gen_loss: 19.74022876855099
2025-01-21 12:32:43,104 - trainer - INFO -     val_val_perplexity: 374564800.0
2025-01-21 12:32:43,104 - trainer - INFO -     val_val_embedding_sim: 0.4228075345357259
2025-01-21 12:32:43,104 - trainer - INFO - ================================================================================
2025-01-21 12:32:43,104 - trainer - INFO - Starting epoch 92 at 2025-01-21 12:32:43
2025-01-21 12:32:46,824 - trainer - INFO - Epoch 92 completed at 2025-01-21 12:32:46
2025-01-21 12:32:46,824 - trainer - INFO -     epoch          : 92
2025-01-21 12:32:46,825 - trainer - INFO -     elapsed time   : 3.720508098602295
2025-01-21 12:32:46,825 - trainer - INFO -     loss           : 0.10541982366121375
2025-01-21 12:32:46,825 - trainer - INFO -     sim_loss       : 0.350695192726198
2025-01-21 12:32:46,825 - trainer - INFO -     gen_loss       : 0.00030180003959685565
2025-01-21 12:32:46,825 - trainer - INFO -     val_val_loss   : 14.082260363029711
2025-01-21 12:32:46,825 - trainer - INFO -     val_val_sim_loss: 0.8021363923043916
2025-01-21 12:32:46,825 - trainer - INFO -     val_val_gen_loss: 19.773742097796816
2025-01-21 12:32:46,825 - trainer - INFO -     val_val_perplexity: 597715285.3333334
2025-01-21 12:32:46,825 - trainer - INFO -     val_val_embedding_sim: 0.42297401392098627
2025-01-21 12:32:46,825 - trainer - INFO - ================================================================================
2025-01-21 12:32:46,825 - trainer - INFO - Starting epoch 93 at 2025-01-21 12:32:46
2025-01-21 12:32:50,550 - trainer - INFO - Epoch 93 completed at 2025-01-21 12:32:50
2025-01-21 12:32:50,550 - trainer - INFO -     epoch          : 93
2025-01-21 12:32:50,550 - trainer - INFO -     elapsed time   : 3.7246105670928955
2025-01-21 12:32:50,550 - trainer - INFO -     loss           : 0.11191020347177982
2025-01-21 12:32:50,550 - trainer - INFO -     sim_loss       : 0.3723228633403778
2025-01-21 12:32:50,550 - trainer - INFO -     gen_loss       : 0.00030477128748316316
2025-01-21 12:32:50,550 - trainer - INFO -     val_val_loss   : 13.902001409819633
2025-01-21 12:32:50,550 - trainer - INFO -     val_val_sim_loss: 0.3575421427235459
2025-01-21 12:32:50,550 - trainer - INFO -     val_val_gen_loss: 19.706769943237305
2025-01-21 12:32:50,550 - trainer - INFO -     val_val_perplexity: 361868419.8787879
2025-01-21 12:32:50,550 - trainer - INFO -     val_val_embedding_sim: 0.42539154309214966
2025-01-21 12:32:50,550 - trainer - INFO - ================================================================================
2025-01-21 12:32:50,550 - trainer - INFO - Starting epoch 94 at 2025-01-21 12:32:50
2025-01-21 12:32:54,305 - trainer - INFO - Epoch 94 completed at 2025-01-21 12:32:54
2025-01-21 12:32:54,305 - trainer - INFO -     epoch          : 94
2025-01-21 12:32:54,305 - trainer - INFO -     elapsed time   : 3.7546560764312744
2025-01-21 12:32:54,305 - trainer - INFO -     loss           : 0.10660162713902537
2025-01-21 12:32:54,305 - trainer - INFO -     sim_loss       : 0.3546620776753116
2025-01-21 12:32:54,305 - trainer - INFO -     gen_loss       : 0.0002900015824707225
2025-01-21 12:32:54,305 - trainer - INFO -     val_val_loss   : 13.874379649306789
2025-01-21 12:32:54,305 - trainer - INFO -     val_val_sim_loss: 0.24538339629288836
2025-01-21 12:32:54,305 - trainer - INFO -     val_val_gen_loss: 19.71537873239228
2025-01-21 12:32:54,305 - trainer - INFO -     val_val_perplexity: 365100480.969697
2025-01-21 12:32:54,305 - trainer - INFO -     val_val_embedding_sim: 0.4234499895211422
2025-01-21 12:32:54,305 - trainer - INFO - ================================================================================
2025-01-21 12:32:54,305 - trainer - INFO - Starting epoch 95 at 2025-01-21 12:32:54
2025-01-21 12:32:58,034 - trainer - INFO - Epoch 95 completed at 2025-01-21 12:32:58
2025-01-21 12:32:58,034 - trainer - INFO -     epoch          : 95
2025-01-21 12:32:58,034 - trainer - INFO -     elapsed time   : 3.728289842605591
2025-01-21 12:32:58,034 - trainer - INFO -     loss           : 0.10578336622565984
2025-01-21 12:32:58,034 - trainer - INFO -     sim_loss       : 0.351935014128685
2025-01-21 12:32:58,034 - trainer - INFO -     gen_loss       : 0.0002897986851166934
2025-01-21 12:32:58,034 - trainer - INFO -     val_val_loss   : 13.917303229823258
2025-01-21 12:32:58,034 - trainer - INFO -     val_val_sim_loss: 0.2525871341878666
2025-01-21 12:32:58,034 - trainer - INFO -     val_val_gen_loss: 19.773610779733367
2025-01-21 12:32:58,034 - trainer - INFO -     val_val_perplexity: 399089250.7878788
2025-01-21 12:32:58,034 - trainer - INFO -     val_val_embedding_sim: 0.42266626339970215
2025-01-21 12:33:03,336 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch95.pth ...
2025-01-21 12:33:03,337 - trainer - INFO - ================================================================================
2025-01-21 12:33:03,337 - trainer - INFO - Starting epoch 96 at 2025-01-21 12:33:03
2025-01-21 12:33:07,158 - trainer - INFO - Epoch 96 completed at 2025-01-21 12:33:07
2025-01-21 12:33:07,158 - trainer - INFO -     epoch          : 96
2025-01-21 12:33:07,158 - trainer - INFO -     elapsed time   : 3.8208765983581543
2025-01-21 12:33:07,158 - trainer - INFO -     loss           : 0.08048597451997921
2025-01-21 12:33:07,158 - trainer - INFO -     sim_loss       : 0.2676094101712806
2025-01-21 12:33:07,158 - trainer - INFO -     gen_loss       : 0.00029021365626249465
2025-01-21 12:33:07,158 - trainer - INFO -     val_val_loss   : 13.958954030817205
2025-01-21 12:33:07,158 - trainer - INFO -     val_val_sim_loss: 0.3039528528849284
2025-01-21 12:33:07,158 - trainer - INFO -     val_val_gen_loss: 19.811098040956438
2025-01-21 12:33:07,158 - trainer - INFO -     val_val_perplexity: 528655949.57575756
2025-01-21 12:33:07,158 - trainer - INFO -     val_val_embedding_sim: 0.4212566541902947
2025-01-21 12:33:07,158 - trainer - INFO - ================================================================================
2025-01-21 12:33:07,158 - trainer - INFO - Starting epoch 97 at 2025-01-21 12:33:07
2025-01-21 12:33:10,915 - trainer - INFO - Epoch 97 completed at 2025-01-21 12:33:10
2025-01-21 12:33:10,915 - trainer - INFO -     epoch          : 97
2025-01-21 12:33:10,915 - trainer - INFO -     elapsed time   : 3.7559893131256104
2025-01-21 12:33:10,915 - trainer - INFO -     loss           : 0.11328230276703835
2025-01-21 12:33:10,915 - trainer - INFO -     sim_loss       : 0.3769317090511322
2025-01-21 12:33:10,915 - trainer - INFO -     gen_loss       : 0.00028969546547159554
2025-01-21 12:33:10,915 - trainer - INFO -     val_val_loss   : 14.017427849047111
2025-01-21 12:33:10,915 - trainer - INFO -     val_val_sim_loss: 0.47156686125879677
2025-01-21 12:33:10,915 - trainer - INFO -     val_val_gen_loss: 19.822797601873223
2025-01-21 12:33:10,915 - trainer - INFO -     val_val_perplexity: 1311339023.5151515
2025-01-21 12:33:10,915 - trainer - INFO -     val_val_embedding_sim: 0.4226483359481349
2025-01-21 12:33:10,915 - trainer - INFO - ================================================================================
2025-01-21 12:33:10,915 - trainer - INFO - Starting epoch 98 at 2025-01-21 12:33:10
2025-01-21 12:33:14,645 - trainer - INFO - Epoch 98 completed at 2025-01-21 12:33:14
2025-01-21 12:33:14,645 - trainer - INFO -     epoch          : 98
2025-01-21 12:33:14,645 - trainer - INFO -     elapsed time   : 3.7294464111328125
2025-01-21 12:33:14,645 - trainer - INFO -     loss           : 0.10993598820641637
2025-01-21 12:33:14,645 - trainer - INFO -     sim_loss       : 0.36581088826060293
2025-01-21 12:33:14,645 - trainer - INFO -     gen_loss       : 0.0002753116059466265
2025-01-21 12:33:14,645 - trainer - INFO -     val_val_loss   : 14.0127879634048
2025-01-21 12:33:14,645 - trainer - INFO -     val_val_sim_loss: 0.37958033878892433
2025-01-21 12:33:14,645 - trainer - INFO -     val_val_gen_loss: 19.85559186068448
2025-01-21 12:33:14,645 - trainer - INFO -     val_val_perplexity: 437595471.75757575
2025-01-21 12:33:14,645 - trainer - INFO -     val_val_embedding_sim: 0.42187938726309576
2025-01-21 12:33:14,645 - trainer - INFO - ================================================================================
2025-01-21 12:33:14,645 - trainer - INFO - Starting epoch 99 at 2025-01-21 12:33:14
2025-01-21 12:33:18,373 - trainer - INFO - Epoch 99 completed at 2025-01-21 12:33:18
2025-01-21 12:33:18,373 - trainer - INFO -     epoch          : 99
2025-01-21 12:33:18,373 - trainer - INFO -     elapsed time   : 3.7275850772857666
2025-01-21 12:33:18,373 - trainer - INFO -     loss           : 0.074008825096098
2025-01-21 12:33:18,373 - trainer - INFO -     sim_loss       : 0.24606813633763522
2025-01-21 12:33:18,373 - trainer - INFO -     gen_loss       : 0.0002691150177270174
2025-01-21 12:33:18,373 - trainer - INFO -     val_val_loss   : 13.928558494105484
2025-01-21 12:33:18,373 - trainer - INFO -     val_val_sim_loss: 0.2004398613254869
2025-01-21 12:33:18,373 - trainer - INFO -     val_val_gen_loss: 19.81203876842152
2025-01-21 12:33:18,373 - trainer - INFO -     val_val_perplexity: 403570361.6969697
2025-01-21 12:33:18,373 - trainer - INFO -     val_val_embedding_sim: 0.4235784754608617
2025-01-21 12:33:18,373 - trainer - INFO - ================================================================================
2025-01-21 12:33:18,373 - trainer - INFO - Starting epoch 100 at 2025-01-21 12:33:18
2025-01-21 12:33:22,081 - trainer - INFO - Epoch 100 completed at 2025-01-21 12:33:22
2025-01-21 12:33:22,082 - trainer - INFO -     epoch          : 100
2025-01-21 12:33:22,082 - trainer - INFO -     elapsed time   : 3.7079083919525146
2025-01-21 12:33:22,082 - trainer - INFO -     loss           : 0.06597436452284455
2025-01-21 12:33:22,082 - trainer - INFO -     sim_loss       : 0.21929282918572426
2025-01-21 12:33:22,082 - trainer - INFO -     gen_loss       : 0.00026644647296052425
2025-01-21 12:33:22,082 - trainer - INFO -     val_val_loss   : 13.913668314615885
2025-01-21 12:33:22,082 - trainer - INFO -     val_val_sim_loss: 0.16674353859641336
2025-01-21 12:33:22,082 - trainer - INFO -     val_val_gen_loss: 19.805208206176758
2025-01-21 12:33:22,082 - trainer - INFO -     val_val_perplexity: 533402934.3030303
2025-01-21 12:33:22,082 - trainer - INFO -     val_val_embedding_sim: 0.42449508742852643
2025-01-21 12:33:27,388 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch100.pth ...
2025-01-21 12:33:27,388 - trainer - INFO - ================================================================================
2025-01-21 12:33:27,388 - trainer - INFO - Starting epoch 101 at 2025-01-21 12:33:27
2025-01-21 12:33:31,191 - trainer - INFO - Epoch 101 completed at 2025-01-21 12:33:31
2025-01-21 12:33:31,191 - trainer - INFO -     epoch          : 101
2025-01-21 12:33:31,191 - trainer - INFO -     elapsed time   : 3.8025002479553223
2025-01-21 12:33:31,191 - trainer - INFO -     loss           : 0.12350408546626568
2025-01-21 12:33:31,191 - trainer - INFO -     sim_loss       : 0.4110603019595146
2025-01-21 12:33:31,191 - trainer - INFO -     gen_loss       : 0.00026569832261884584
2025-01-21 12:33:31,191 - trainer - INFO -     val_val_loss   : 14.007520444465406
2025-01-21 12:33:31,191 - trainer - INFO -     val_val_sim_loss: 0.36424125685836306
2025-01-21 12:33:31,191 - trainer - INFO -     val_val_gen_loss: 19.854640151515152
2025-01-21 12:33:31,191 - trainer - INFO -     val_val_perplexity: 1417278619.1515152
2025-01-21 12:33:31,191 - trainer - INFO -     val_val_embedding_sim: 0.4244743757175677
2025-01-21 12:33:31,191 - trainer - INFO - ================================================================================
2025-01-21 12:33:31,191 - trainer - INFO - Starting epoch 102 at 2025-01-21 12:33:31
2025-01-21 12:33:34,923 - trainer - INFO - Epoch 102 completed at 2025-01-21 12:33:34
2025-01-21 12:33:34,923 - trainer - INFO -     epoch          : 102
2025-01-21 12:33:34,923 - trainer - INFO -     elapsed time   : 3.731375217437744
2025-01-21 12:33:34,923 - trainer - INFO -     loss           : 0.08010637387633324
2025-01-21 12:33:34,923 - trainer - INFO -     sim_loss       : 0.26641882844269277
2025-01-21 12:33:34,923 - trainer - INFO -     gen_loss       : 0.00025817304413067177
2025-01-21 12:33:34,923 - trainer - INFO -     val_val_loss   : 13.929097926977908
2025-01-21 12:33:34,923 - trainer - INFO -     val_val_sim_loss: 0.11796162706432899
2025-01-21 12:33:34,923 - trainer - INFO -     val_val_gen_loss: 19.848156264334015
2025-01-21 12:33:34,923 - trainer - INFO -     val_val_perplexity: 430179554.6666667
2025-01-21 12:33:34,923 - trainer - INFO -     val_val_embedding_sim: 0.42303124521717883
2025-01-21 12:33:34,923 - trainer - INFO - ================================================================================
2025-01-21 12:33:34,923 - trainer - INFO - Starting epoch 103 at 2025-01-21 12:33:34
2025-01-21 12:33:38,650 - trainer - INFO - Epoch 103 completed at 2025-01-21 12:33:38
2025-01-21 12:33:38,650 - trainer - INFO -     epoch          : 103
2025-01-21 12:33:38,650 - trainer - INFO -     elapsed time   : 3.7265162467956543
2025-01-21 12:33:38,650 - trainer - INFO -     loss           : 0.08266252288594841
2025-01-21 12:33:38,650 - trainer - INFO -     sim_loss       : 0.2749339621514082
2025-01-21 12:33:38,650 - trainer - INFO -     gen_loss       : 0.0002604745066491887
2025-01-21 12:33:38,650 - trainer - INFO -     val_val_loss   : 13.95334515427098
2025-01-21 12:33:38,650 - trainer - INFO -     val_val_sim_loss: 0.16443099397601504
2025-01-21 12:33:38,650 - trainer - INFO -     val_val_gen_loss: 19.862879897608902
2025-01-21 12:33:38,650 - trainer - INFO -     val_val_perplexity: 429722465.93939394
2025-01-21 12:33:38,650 - trainer - INFO -     val_val_embedding_sim: 0.4242503823656024
2025-01-21 12:33:38,650 - trainer - INFO - ================================================================================
2025-01-21 12:33:38,650 - trainer - INFO - Starting epoch 104 at 2025-01-21 12:33:38
2025-01-21 12:33:42,376 - trainer - INFO - Epoch 104 completed at 2025-01-21 12:33:42
2025-01-21 12:33:42,376 - trainer - INFO -     epoch          : 104
2025-01-21 12:33:42,376 - trainer - INFO -     elapsed time   : 3.7249093055725098
2025-01-21 12:33:42,376 - trainer - INFO -     loss           : 0.10641442192718387
2025-01-21 12:33:42,376 - trainer - INFO -     sim_loss       : 0.35412117317318914
2025-01-21 12:33:42,376 - trainer - INFO -     gen_loss       : 0.00025437557633267716
2025-01-21 12:33:42,376 - trainer - INFO -     val_val_loss   : 13.967500773343174
2025-01-21 12:33:42,376 - trainer - INFO -     val_val_sim_loss: 0.19516397245002515
2025-01-21 12:33:42,376 - trainer - INFO -     val_val_gen_loss: 19.869931134310637
2025-01-21 12:33:42,376 - trainer - INFO -     val_val_perplexity: 426715583.030303
2025-01-21 12:33:42,376 - trainer - INFO -     val_val_embedding_sim: 0.4245905045307044
2025-01-21 12:33:42,376 - trainer - INFO - ================================================================================
2025-01-21 12:33:42,376 - trainer - INFO - Starting epoch 105 at 2025-01-21 12:33:42
2025-01-21 12:33:46,098 - trainer - INFO - Epoch 105 completed at 2025-01-21 12:33:46
2025-01-21 12:33:46,098 - trainer - INFO -     epoch          : 105
2025-01-21 12:33:46,098 - trainer - INFO -     elapsed time   : 3.7216320037841797
2025-01-21 12:33:46,098 - trainer - INFO -     loss           : 0.10753197739832103
2025-01-21 12:33:46,098 - trainer - INFO -     sim_loss       : 0.35786098837852476
2025-01-21 12:33:46,098 - trainer - INFO -     gen_loss       : 0.00024811002949718384
2025-01-21 12:33:46,098 - trainer - INFO -     val_val_loss   : 13.995113343903512
2025-01-21 12:33:46,098 - trainer - INFO -     val_val_sim_loss: 0.19533765677246692
2025-01-21 12:33:46,098 - trainer - INFO -     val_val_gen_loss: 19.90930314497514
2025-01-21 12:33:46,098 - trainer - INFO -     val_val_perplexity: 443993447.75757575
2025-01-21 12:33:46,098 - trainer - INFO -     val_val_embedding_sim: 0.42293988394014764
2025-01-21 12:33:51,396 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch105.pth ...
2025-01-21 12:33:51,397 - trainer - INFO - ================================================================================
2025-01-21 12:33:51,397 - trainer - INFO - Starting epoch 106 at 2025-01-21 12:33:51
2025-01-21 12:33:55,177 - trainer - INFO - Epoch 106 completed at 2025-01-21 12:33:55
2025-01-21 12:33:55,177 - trainer - INFO -     epoch          : 106
2025-01-21 12:33:55,177 - trainer - INFO -     elapsed time   : 3.7800869941711426
2025-01-21 12:33:55,177 - trainer - INFO -     loss           : 0.09918237198144197
2025-01-21 12:33:55,177 - trainer - INFO -     sim_loss       : 0.33003561198711395
2025-01-21 12:33:55,177 - trainer - INFO -     gen_loss       : 0.0002452637869282626
2025-01-21 12:33:55,177 - trainer - INFO -     val_val_loss   : 13.95314898635402
2025-01-21 12:33:55,177 - trainer - INFO -     val_val_sim_loss: 0.0667096557039203
2025-01-21 12:33:55,177 - trainer - INFO -     val_val_gen_loss: 19.904480442856297
2025-01-21 12:33:55,177 - trainer - INFO -     val_val_perplexity: 445841268.3636364
2025-01-21 12:33:55,177 - trainer - INFO -     val_val_embedding_sim: 0.4229601639689821
2025-01-21 12:33:55,177 - trainer - INFO - ================================================================================
2025-01-21 12:33:55,177 - trainer - INFO - Starting epoch 107 at 2025-01-21 12:33:55
2025-01-21 12:33:58,902 - trainer - INFO - Epoch 107 completed at 2025-01-21 12:33:58
2025-01-21 12:33:58,902 - trainer - INFO -     epoch          : 107
2025-01-21 12:33:58,902 - trainer - INFO -     elapsed time   : 3.7238452434539795
2025-01-21 12:33:58,902 - trainer - INFO -     loss           : 0.06462239776737988
2025-01-21 12:33:58,902 - trainer - INFO -     sim_loss       : 0.21482801544007088
2025-01-21 12:33:58,902 - trainer - INFO -     gen_loss       : 0.00024855825904523954
2025-01-21 12:33:58,902 - trainer - INFO -     val_val_loss   : 13.970553629326098
2025-01-21 12:33:58,902 - trainer - INFO -     val_val_sim_loss: 0.058994914546102256
2025-01-21 12:33:58,902 - trainer - INFO -     val_val_gen_loss: 19.932650883992512
2025-01-21 12:33:58,902 - trainer - INFO -     val_val_perplexity: 466939307.6363636
2025-01-21 12:33:58,902 - trainer - INFO -     val_val_embedding_sim: 0.42287054567626026
2025-01-21 12:33:58,902 - trainer - INFO - ================================================================================
2025-01-21 12:33:58,902 - trainer - INFO - Starting epoch 108 at 2025-01-21 12:33:58
2025-01-21 12:34:02,632 - trainer - INFO - Epoch 108 completed at 2025-01-21 12:34:02
2025-01-21 12:34:02,632 - trainer - INFO -     epoch          : 108
2025-01-21 12:34:02,632 - trainer - INFO -     elapsed time   : 3.7297704219818115
2025-01-21 12:34:02,632 - trainer - INFO -     loss           : 0.093800367883523
2025-01-21 12:34:02,632 - trainer - INFO -     sim_loss       : 0.31207396152021827
2025-01-21 12:34:02,632 - trainer - INFO -     gen_loss       : 0.0002545383060351014
2025-01-21 12:34:02,632 - trainer - INFO -     val_val_loss   : 13.936316258979566
2025-01-21 12:34:02,632 - trainer - INFO -     val_val_sim_loss: 0.04206316037611528
2025-01-21 12:34:02,632 - trainer - INFO -     val_val_gen_loss: 19.890996990781844
2025-01-21 12:34:02,632 - trainer - INFO -     val_val_perplexity: 439125197.09090906
2025-01-21 12:34:02,632 - trainer - INFO -     val_val_embedding_sim: 0.42288685341676074
2025-01-21 12:34:02,632 - trainer - INFO - ================================================================================
2025-01-21 12:34:02,632 - trainer - INFO - Starting epoch 109 at 2025-01-21 12:34:02
2025-01-21 12:34:06,357 - trainer - INFO - Epoch 109 completed at 2025-01-21 12:34:06
2025-01-21 12:34:06,357 - trainer - INFO -     epoch          : 109
2025-01-21 12:34:06,357 - trainer - INFO -     elapsed time   : 3.7248103618621826
2025-01-21 12:34:06,358 - trainer - INFO -     loss           : 0.07407205514609813
2025-01-21 12:34:06,358 - trainer - INFO -     sim_loss       : 0.2463406901806593
2025-01-21 12:34:06,358 - trainer - INFO -     gen_loss       : 0.0002426371065666899
2025-01-21 12:34:06,358 - trainer - INFO -     val_val_loss   : 13.953570914990975
2025-01-21 12:34:06,358 - trainer - INFO -     val_val_sim_loss: 0.048970786007947194
2025-01-21 12:34:06,358 - trainer - INFO -     val_val_gen_loss: 19.9126859144731
2025-01-21 12:34:06,358 - trainer - INFO -     val_val_perplexity: 553463497.6969697
2025-01-21 12:34:06,358 - trainer - INFO -     val_val_embedding_sim: 0.4230730894840125
2025-01-21 12:34:06,358 - trainer - INFO - ================================================================================
2025-01-21 12:34:06,358 - trainer - INFO - Starting epoch 110 at 2025-01-21 12:34:06
2025-01-21 12:34:10,078 - trainer - INFO - Epoch 110 completed at 2025-01-21 12:34:10
2025-01-21 12:34:10,078 - trainer - INFO -     epoch          : 110
2025-01-21 12:34:10,078 - trainer - INFO -     elapsed time   : 3.719916820526123
2025-01-21 12:34:10,078 - trainer - INFO -     loss           : 0.10580205898731947
2025-01-21 12:34:10,078 - trainer - INFO -     sim_loss       : 0.35211610943078997
2025-01-21 12:34:10,078 - trainer - INFO -     gen_loss       : 0.0002388839580817148
2025-01-21 12:34:10,078 - trainer - INFO -     val_val_loss   : 14.00627361644398
2025-01-21 12:34:10,078 - trainer - INFO -     val_val_sim_loss: 0.0963062842686971
2025-01-21 12:34:10,078 - trainer - INFO -     val_val_gen_loss: 19.967688531586617
2025-01-21 12:34:10,078 - trainer - INFO -     val_val_perplexity: 474350351.5151515
2025-01-21 12:34:10,078 - trainer - INFO -     val_val_embedding_sim: 0.4224896449031252
2025-01-21 12:34:15,371 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch110.pth ...
2025-01-21 12:34:15,371 - trainer - INFO - ================================================================================
2025-01-21 12:34:15,371 - trainer - INFO - Starting epoch 111 at 2025-01-21 12:34:15
2025-01-21 12:34:19,135 - trainer - INFO - Epoch 111 completed at 2025-01-21 12:34:19
2025-01-21 12:34:19,135 - trainer - INFO -     epoch          : 111
2025-01-21 12:34:19,135 - trainer - INFO -     elapsed time   : 3.7631890773773193
2025-01-21 12:34:19,135 - trainer - INFO -     loss           : 0.08381830717262347
2025-01-21 12:34:19,135 - trainer - INFO -     sim_loss       : 0.2788440443502623
2025-01-21 12:34:19,135 - trainer - INFO -     gen_loss       : 0.00023584659938933328
2025-01-21 12:34:19,135 - trainer - INFO -     val_val_loss   : 14.011449698245887
2025-01-21 12:34:19,135 - trainer - INFO -     val_val_sim_loss: 1.3546467181930149e-06
2025-01-21 12:34:19,135 - trainer - INFO -     val_val_gen_loss: 20.016356497099906
2025-01-21 12:34:19,135 - trainer - INFO -     val_val_perplexity: 814419223.2727273
2025-01-21 12:34:19,135 - trainer - INFO -     val_val_embedding_sim: 0.42352480057514075
2025-01-21 12:34:19,135 - trainer - INFO - ================================================================================
2025-01-21 12:34:19,135 - trainer - INFO - Starting epoch 112 at 2025-01-21 12:34:19
2025-01-21 12:34:22,850 - trainer - INFO - Epoch 112 completed at 2025-01-21 12:34:22
2025-01-21 12:34:22,850 - trainer - INFO -     epoch          : 112
2025-01-21 12:34:22,850 - trainer - INFO -     elapsed time   : 3.7140953540802
2025-01-21 12:34:22,850 - trainer - INFO -     loss           : 0.06751938592642545
2025-01-21 12:34:22,850 - trainer - INFO -     sim_loss       : 0.22453768774867058
2025-01-21 12:34:22,850 - trainer - INFO -     gen_loss       : 0.00022582633973797784
2025-01-21 12:34:22,850 - trainer - INFO -     val_val_loss   : 14.070617415688254
2025-01-21 12:34:22,850 - trainer - INFO -     val_val_sim_loss: 0.24590952107400585
2025-01-21 12:34:22,850 - trainer - INFO -     val_val_gen_loss: 19.995492299397785
2025-01-21 12:34:22,850 - trainer - INFO -     val_val_perplexity: 484443860.3636364
2025-01-21 12:34:22,850 - trainer - INFO -     val_val_embedding_sim: 0.42256601199959265
2025-01-21 12:34:22,850 - trainer - INFO - ================================================================================
2025-01-21 12:34:22,850 - trainer - INFO - Starting epoch 113 at 2025-01-21 12:34:22
2025-01-21 12:34:26,569 - trainer - INFO - Epoch 113 completed at 2025-01-21 12:34:26
2025-01-21 12:34:26,569 - trainer - INFO -     epoch          : 113
2025-01-21 12:34:26,569 - trainer - INFO -     elapsed time   : 3.7187905311584473
2025-01-21 12:34:26,569 - trainer - INFO -     loss           : 0.0919566672644578
2025-01-21 12:34:26,569 - trainer - INFO -     sim_loss       : 0.3060067587066442
2025-01-21 12:34:26,569 - trainer - INFO -     gen_loss       : 0.00022090842394391076
2025-01-21 12:34:26,569 - trainer - INFO -     val_val_loss   : 14.046912453391336
2025-01-21 12:34:26,569 - trainer - INFO -     val_val_sim_loss: 0.05551100138461865
2025-01-21 12:34:26,569 - trainer - INFO -     val_val_gen_loss: 20.043227051243637
2025-01-21 12:34:26,569 - trainer - INFO -     val_val_perplexity: 521577709.09090906
2025-01-21 12:34:26,569 - trainer - INFO -     val_val_embedding_sim: 0.4231495532122525
2025-01-21 12:34:26,569 - trainer - INFO - ================================================================================
2025-01-21 12:34:26,570 - trainer - INFO - Starting epoch 114 at 2025-01-21 12:34:26
2025-01-21 12:34:30,286 - trainer - INFO - Epoch 114 completed at 2025-01-21 12:34:30
2025-01-21 12:34:30,286 - trainer - INFO -     epoch          : 114
2025-01-21 12:34:30,286 - trainer - INFO -     elapsed time   : 3.7161359786987305
2025-01-21 12:34:30,286 - trainer - INFO -     loss           : 0.07432278695632703
2025-01-21 12:34:30,286 - trainer - INFO -     sim_loss       : 0.24724107003057724
2025-01-21 12:34:30,286 - trainer - INFO -     gen_loss       : 0.00021494630636880173
2025-01-21 12:34:30,286 - trainer - INFO -     val_val_loss   : 14.225526116111062
2025-01-21 12:34:30,286 - trainer - INFO -     val_val_sim_loss: 0.653567191326257
2025-01-21 12:34:30,286 - trainer - INFO -     val_val_gen_loss: 20.042080676916875
2025-01-21 12:34:30,286 - trainer - INFO -     val_val_perplexity: 506148857.2121212
2025-01-21 12:34:30,286 - trainer - INFO -     val_val_embedding_sim: 0.42336353388699616
2025-01-21 12:34:30,286 - trainer - INFO - ================================================================================
2025-01-21 12:34:30,286 - trainer - INFO - Starting epoch 115 at 2025-01-21 12:34:30
2025-01-21 12:34:34,017 - trainer - INFO - Epoch 115 completed at 2025-01-21 12:34:34
2025-01-21 12:34:34,017 - trainer - INFO -     epoch          : 115
2025-01-21 12:34:34,017 - trainer - INFO -     elapsed time   : 3.7301218509674072
2025-01-21 12:34:34,017 - trainer - INFO -     loss           : 0.1092398602515459
2025-01-21 12:34:34,017 - trainer - INFO -     sim_loss       : 0.3636179752647877
2025-01-21 12:34:34,017 - trainer - INFO -     gen_loss       : 0.00022066078672651203
2025-01-21 12:34:34,017 - trainer - INFO -     val_val_loss   : 14.101639776518851
2025-01-21 12:34:34,017 - trainer - INFO -     val_val_sim_loss: 0.25919604301452637
2025-01-21 12:34:34,017 - trainer - INFO -     val_val_gen_loss: 20.03411610921224
2025-01-21 12:34:34,017 - trainer - INFO -     val_val_perplexity: 502306042.1818182
2025-01-21 12:34:34,017 - trainer - INFO -     val_val_embedding_sim: 0.423234814044201
2025-01-21 12:34:39,311 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch115.pth ...
2025-01-21 12:34:39,311 - trainer - INFO - ================================================================================
2025-01-21 12:34:39,311 - trainer - INFO - Starting epoch 116 at 2025-01-21 12:34:39
2025-01-21 12:34:43,104 - trainer - INFO - Epoch 116 completed at 2025-01-21 12:34:43
2025-01-21 12:34:43,105 - trainer - INFO -     epoch          : 116
2025-01-21 12:34:43,105 - trainer - INFO -     elapsed time   : 3.7930972576141357
2025-01-21 12:34:43,105 - trainer - INFO -     loss           : 0.09519141959026456
2025-01-21 12:34:43,105 - trainer - INFO -     sim_loss       : 0.31680798828601836
2025-01-21 12:34:43,105 - trainer - INFO -     gen_loss       : 0.00021288556163199246
2025-01-21 12:34:43,105 - trainer - INFO -     val_val_loss   : 14.13097011681759
2025-01-21 12:34:43,105 - trainer - INFO -     val_val_sim_loss: 0.353990583708792
2025-01-21 12:34:43,105 - trainer - INFO -     val_val_gen_loss: 20.03539004470363
2025-01-21 12:34:43,105 - trainer - INFO -     val_val_perplexity: 503599664.4848485
2025-01-21 12:34:43,105 - trainer - INFO -     val_val_embedding_sim: 0.4225520473538023
2025-01-21 12:34:43,105 - trainer - INFO - ================================================================================
2025-01-21 12:34:43,105 - trainer - INFO - Starting epoch 117 at 2025-01-21 12:34:43
2025-01-21 12:34:46,829 - trainer - INFO - Epoch 117 completed at 2025-01-21 12:34:46
2025-01-21 12:34:46,829 - trainer - INFO -     epoch          : 117
2025-01-21 12:34:46,829 - trainer - INFO -     elapsed time   : 3.723869800567627
2025-01-21 12:34:46,829 - trainer - INFO -     loss           : 0.12133130114525556
2025-01-21 12:34:46,829 - trainer - INFO -     sim_loss       : 0.4039438523352146
2025-01-21 12:34:46,829 - trainer - INFO -     gen_loss       : 0.00021162841148907318
2025-01-21 12:34:46,829 - trainer - INFO -     val_val_loss   : 14.077161528847434
2025-01-21 12:34:46,829 - trainer - INFO -     val_val_sim_loss: 0.09754315289584073
2025-01-21 12:34:46,829 - trainer - INFO -     val_val_gen_loss: 20.068427230372574
2025-01-21 12:34:46,829 - trainer - INFO -     val_val_perplexity: 523153027.8787879
2025-01-21 12:34:46,829 - trainer - INFO -     val_val_embedding_sim: 0.4227613779631528
2025-01-21 12:34:46,829 - trainer - INFO - ================================================================================
2025-01-21 12:34:46,829 - trainer - INFO - Starting epoch 118 at 2025-01-21 12:34:46
2025-01-21 12:34:50,557 - trainer - INFO - Epoch 118 completed at 2025-01-21 12:34:50
2025-01-21 12:34:50,558 - trainer - INFO -     epoch          : 118
2025-01-21 12:34:50,558 - trainer - INFO -     elapsed time   : 3.727782726287842
2025-01-21 12:34:50,558 - trainer - INFO -     loss           : 0.08361719427630306
2025-01-21 12:34:50,558 - trainer - INFO -     sim_loss       : 0.2782615091651678
2025-01-21 12:34:50,558 - trainer - INFO -     gen_loss       : 0.0001981951601919718
2025-01-21 12:34:50,558 - trainer - INFO -     val_val_loss   : 14.219598567847049
2025-01-21 12:34:50,558 - trainer - INFO -     val_val_sim_loss: 0.530732992923621
2025-01-21 12:34:50,558 - trainer - INFO -     val_val_gen_loss: 20.086256431810785
2025-01-21 12:34:50,558 - trainer - INFO -     val_val_perplexity: 534010110.06060606
2025-01-21 12:34:50,558 - trainer - INFO -     val_val_embedding_sim: 0.4219774441285567
2025-01-21 12:34:50,558 - trainer - INFO - ================================================================================
2025-01-21 12:34:50,558 - trainer - INFO - Starting epoch 119 at 2025-01-21 12:34:50
2025-01-21 12:34:54,286 - trainer - INFO - Epoch 119 completed at 2025-01-21 12:34:54
2025-01-21 12:34:54,287 - trainer - INFO -     epoch          : 119
2025-01-21 12:34:54,287 - trainer - INFO -     elapsed time   : 3.7283787727355957
2025-01-21 12:34:54,287 - trainer - INFO -     loss           : 0.0900250853257603
2025-01-21 12:34:54,287 - trainer - INFO -     sim_loss       : 0.2995972760154473
2025-01-21 12:34:54,287 - trainer - INFO -     gen_loss       : 0.00020842545200139284
2025-01-21 12:34:54,287 - trainer - INFO -     val_val_loss   : 14.088123321533203
2025-01-21 12:34:54,287 - trainer - INFO -     val_val_sim_loss: 0.04201348622639974
2025-01-21 12:34:54,287 - trainer - INFO -     val_val_gen_loss: 20.10788484053178
2025-01-21 12:34:54,287 - trainer - INFO -     val_val_perplexity: 906213034.6666666
2025-01-21 12:34:54,287 - trainer - INFO -     val_val_embedding_sim: 0.423020985993472
2025-01-21 12:34:54,287 - trainer - INFO - ================================================================================
2025-01-21 12:34:54,287 - trainer - INFO - Starting epoch 120 at 2025-01-21 12:34:54
2025-01-21 12:34:58,009 - trainer - INFO - Epoch 120 completed at 2025-01-21 12:34:58
2025-01-21 12:34:58,009 - trainer - INFO -     epoch          : 120
2025-01-21 12:34:58,010 - trainer - INFO -     elapsed time   : 3.722203493118286
2025-01-21 12:34:58,010 - trainer - INFO -     loss           : 0.06318871386902174
2025-01-21 12:34:58,010 - trainer - INFO -     sim_loss       : 0.21015885242102286
2025-01-21 12:34:58,010 - trainer - INFO -     gen_loss       : 0.00020150816126260907
2025-01-21 12:34:58,010 - trainer - INFO -     val_val_loss   : 14.164131540240664
2025-01-21 12:34:58,010 - trainer - INFO -     val_val_sim_loss: 0.29485257827874367
2025-01-21 12:34:58,010 - trainer - INFO -     val_val_gen_loss: 20.108109214089133
2025-01-21 12:34:58,010 - trainer - INFO -     val_val_perplexity: 556642469.5757576
2025-01-21 12:34:58,010 - trainer - INFO -     val_val_embedding_sim: 0.42255391496600525
2025-01-21 12:35:03,305 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch120.pth ...
2025-01-21 12:35:03,306 - trainer - INFO - ================================================================================
2025-01-21 12:35:03,306 - trainer - INFO - Starting epoch 121 at 2025-01-21 12:35:03
2025-01-21 12:35:07,096 - trainer - INFO - Epoch 121 completed at 2025-01-21 12:35:07
2025-01-21 12:35:07,096 - trainer - INFO -     epoch          : 121
2025-01-21 12:35:07,096 - trainer - INFO -     elapsed time   : 3.7899532318115234
2025-01-21 12:35:07,096 - trainer - INFO -     loss           : 0.09037858755327761
2025-01-21 12:35:07,096 - trainer - INFO -     sim_loss       : 0.30079430192708967
2025-01-21 12:35:07,096 - trainer - INFO -     gen_loss       : 0.00020041543029947206
2025-01-21 12:35:07,096 - trainer - INFO -     val_val_loss   : 14.106097423669064
2025-01-21 12:35:07,096 - trainer - INFO -     val_val_sim_loss: 0.06301485769676418
2025-01-21 12:35:07,096 - trainer - INFO -     val_val_gen_loss: 20.12456246578332
2025-01-21 12:35:07,096 - trainer - INFO -     val_val_perplexity: 565754450.1818181
2025-01-21 12:35:07,096 - trainer - INFO -     val_val_embedding_sim: 0.4235316551092899
2025-01-21 12:35:07,096 - trainer - INFO - ================================================================================
2025-01-21 12:35:07,096 - trainer - INFO - Starting epoch 122 at 2025-01-21 12:35:07
2025-01-21 12:35:10,818 - trainer - INFO - Epoch 122 completed at 2025-01-21 12:35:10
2025-01-21 12:35:10,818 - trainer - INFO -     epoch          : 122
2025-01-21 12:35:10,818 - trainer - INFO -     elapsed time   : 3.721971273422241
2025-01-21 12:35:10,819 - trainer - INFO -     loss           : 0.07403249786511878
2025-01-21 12:35:10,819 - trainer - INFO -     sim_loss       : 0.24632390174638202
2025-01-21 12:35:10,819 - trainer - INFO -     gen_loss       : 0.00019331966614117847
2025-01-21 12:35:10,819 - trainer - INFO -     val_val_loss   : 14.139571421074145
2025-01-21 12:35:10,819 - trainer - INFO -     val_val_sim_loss: 0.21169809861616654
2025-01-21 12:35:10,819 - trainer - INFO -     val_val_gen_loss: 20.108660611239348
2025-01-21 12:35:10,819 - trainer - INFO -     val_val_perplexity: 540917427.3939394
2025-01-21 12:35:10,819 - trainer - INFO -     val_val_embedding_sim: 0.4230479363239173
2025-01-21 12:35:10,819 - trainer - INFO - ================================================================================
2025-01-21 12:35:10,819 - trainer - INFO - Starting epoch 123 at 2025-01-21 12:35:10
2025-01-21 12:35:14,544 - trainer - INFO - Epoch 123 completed at 2025-01-21 12:35:14
2025-01-21 12:35:14,544 - trainer - INFO -     epoch          : 123
2025-01-21 12:35:14,544 - trainer - INFO -     elapsed time   : 3.7246761322021484
2025-01-21 12:35:14,544 - trainer - INFO -     loss           : 0.07220495475194184
2025-01-21 12:35:14,544 - trainer - INFO -     sim_loss       : 0.24023602364450197
2025-01-21 12:35:14,544 - trainer - INFO -     gen_loss       : 0.0001916327077196911
2025-01-21 12:35:14,544 - trainer - INFO -     val_val_loss   : 14.103827909989791
2025-01-21 12:35:14,544 - trainer - INFO -     val_val_sim_loss: 0.08401995716672955
2025-01-21 12:35:14,544 - trainer - INFO -     val_val_gen_loss: 20.112317807746656
2025-01-21 12:35:14,544 - trainer - INFO -     val_val_perplexity: 563209223.7575758
2025-01-21 12:35:14,544 - trainer - INFO -     val_val_embedding_sim: 0.42318809935540863
2025-01-21 12:35:14,544 - trainer - INFO - ================================================================================
2025-01-21 12:35:14,544 - trainer - INFO - Starting epoch 124 at 2025-01-21 12:35:14
2025-01-21 12:35:18,260 - trainer - INFO - Epoch 124 completed at 2025-01-21 12:35:18
2025-01-21 12:35:18,260 - trainer - INFO -     epoch          : 124
2025-01-21 12:35:18,260 - trainer - INFO -     elapsed time   : 3.7160348892211914
2025-01-21 12:35:18,261 - trainer - INFO -     loss           : 0.11932584345340728
2025-01-21 12:35:18,261 - trainer - INFO -     sim_loss       : 0.3973071351647377
2025-01-21 12:35:18,261 - trainer - INFO -     gen_loss       : 0.00019099833152722568
2025-01-21 12:35:18,261 - trainer - INFO -     val_val_loss   : 14.156870610786207
2025-01-21 12:35:18,261 - trainer - INFO -     val_val_sim_loss: 0.11226911255807588
2025-01-21 12:35:18,261 - trainer - INFO -     val_val_gen_loss: 20.17598666566791
2025-01-21 12:35:18,261 - trainer - INFO -     val_val_perplexity: 603722985.0909091
2025-01-21 12:35:18,261 - trainer - INFO -     val_val_embedding_sim: 0.4228146979303071
2025-01-21 12:35:18,261 - trainer - INFO - ================================================================================
2025-01-21 12:35:18,261 - trainer - INFO - Starting epoch 125 at 2025-01-21 12:35:18
2025-01-21 12:35:21,983 - trainer - INFO - Epoch 125 completed at 2025-01-21 12:35:21
2025-01-21 12:35:21,983 - trainer - INFO -     epoch          : 125
2025-01-21 12:35:21,983 - trainer - INFO -     elapsed time   : 3.721897602081299
2025-01-21 12:35:21,983 - trainer - INFO -     loss           : 0.12854514671489597
2025-01-21 12:35:21,983 - trainer - INFO -     sim_loss       : 0.42804761230945587
2025-01-21 12:35:21,983 - trainer - INFO -     gen_loss       : 0.0001869408180937171
2025-01-21 12:35:21,983 - trainer - INFO -     val_val_loss   : 14.175512313842773
2025-01-21 12:35:21,983 - trainer - INFO -     val_val_sim_loss: 0.25906170498241077
2025-01-21 12:35:21,983 - trainer - INFO -     val_val_gen_loss: 20.139706293741863
2025-01-21 12:35:21,983 - trainer - INFO -     val_val_perplexity: 563723198.060606
2025-01-21 12:35:21,983 - trainer - INFO -     val_val_embedding_sim: 0.4222291653806513
2025-01-21 12:35:27,288 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch125.pth ...
2025-01-21 12:35:27,288 - trainer - INFO - ================================================================================
2025-01-21 12:35:27,288 - trainer - INFO - Starting epoch 126 at 2025-01-21 12:35:27
2025-01-21 12:35:31,054 - trainer - INFO - Epoch 126 completed at 2025-01-21 12:35:31
2025-01-21 12:35:31,054 - trainer - INFO -     epoch          : 126
2025-01-21 12:35:31,054 - trainer - INFO -     elapsed time   : 3.7653303146362305
2025-01-21 12:35:31,054 - trainer - INFO -     loss           : 0.07668511960655451
2025-01-21 12:35:31,054 - trainer - INFO -     sim_loss       : 0.2551783908158541
2025-01-21 12:35:31,054 - trainer - INFO -     gen_loss       : 0.000188000948401168
2025-01-21 12:35:31,054 - trainer - INFO -     val_val_loss   : 14.222243858106209
2025-01-21 12:35:31,054 - trainer - INFO -     val_val_sim_loss: 0.3781317508581913
2025-01-21 12:35:31,054 - trainer - INFO -     val_val_gen_loss: 20.155434695157137
2025-01-21 12:35:31,054 - trainer - INFO -     val_val_perplexity: 638969367.2727273
2025-01-21 12:35:31,054 - trainer - INFO -     val_val_embedding_sim: 0.42308512239745166
2025-01-21 12:35:31,054 - trainer - INFO - ================================================================================
2025-01-21 12:35:31,055 - trainer - INFO - Starting epoch 127 at 2025-01-21 12:35:31
2025-01-21 12:35:34,774 - trainer - INFO - Epoch 127 completed at 2025-01-21 12:35:34
2025-01-21 12:35:34,774 - trainer - INFO -     epoch          : 127
2025-01-21 12:35:34,774 - trainer - INFO -     elapsed time   : 3.719327926635742
2025-01-21 12:35:34,774 - trainer - INFO -     loss           : 0.10862615183286835
2025-01-21 12:35:34,774 - trainer - INFO -     sim_loss       : 0.36166003340199493
2025-01-21 12:35:34,774 - trainer - INFO -     gen_loss       : 0.00018305121775483713
2025-01-21 12:35:34,774 - trainer - INFO -     val_val_loss   : 14.217174616726963
2025-01-21 12:35:34,774 - trainer - INFO -     val_val_sim_loss: 0.3150762500184955
2025-01-21 12:35:34,774 - trainer - INFO -     val_val_gen_loss: 20.17521725278912
2025-01-21 12:35:34,774 - trainer - INFO -     val_val_perplexity: 580485297.4545455
2025-01-21 12:35:34,774 - trainer - INFO -     val_val_embedding_sim: 0.4237454262646762
2025-01-21 12:35:34,774 - trainer - INFO - ================================================================================
2025-01-21 12:35:34,775 - trainer - INFO - Starting epoch 128 at 2025-01-21 12:35:34
2025-01-21 12:35:38,492 - trainer - INFO - Epoch 128 completed at 2025-01-21 12:35:38
2025-01-21 12:35:38,492 - trainer - INFO -     epoch          : 128
2025-01-21 12:35:38,492 - trainer - INFO -     elapsed time   : 3.717531681060791
2025-01-21 12:35:38,492 - trainer - INFO -     loss           : 0.0817864057382394
2025-01-21 12:35:38,493 - trainer - INFO -     sim_loss       : 0.27218826206583346
2025-01-21 12:35:38,493 - trainer - INFO -     gen_loss       : 0.0001856073853559792
2025-01-21 12:35:38,493 - trainer - INFO -     val_val_loss   : 14.292511246421121
2025-01-21 12:35:38,493 - trainer - INFO -     val_val_sim_loss: 0.47174555605108087
2025-01-21 12:35:38,493 - trainer - INFO -     val_val_gen_loss: 20.215696392637312
2025-01-21 12:35:38,493 - trainer - INFO -     val_val_perplexity: 625861787.6363636
2025-01-21 12:35:38,493 - trainer - INFO -     val_val_embedding_sim: 0.4225764744209521
2025-01-21 12:35:38,493 - trainer - INFO - ================================================================================
2025-01-21 12:35:38,493 - trainer - INFO - Starting epoch 129 at 2025-01-21 12:35:38
2025-01-21 12:35:42,206 - trainer - INFO - Epoch 129 completed at 2025-01-21 12:35:42
2025-01-21 12:35:42,207 - trainer - INFO -     epoch          : 129
2025-01-21 12:35:42,207 - trainer - INFO -     elapsed time   : 3.7135379314422607
2025-01-21 12:35:42,207 - trainer - INFO -     loss           : 0.08519717362505616
2025-01-21 12:35:42,207 - trainer - INFO -     sim_loss       : 0.28358796779430123
2025-01-21 12:35:42,207 - trainer - INFO -     gen_loss       : 0.00017254132544621825
2025-01-21 12:35:42,207 - trainer - INFO -     val_val_loss   : 14.195273977337461
2025-01-21 12:35:42,207 - trainer - INFO -     val_val_sim_loss: 0.19510233041011926
2025-01-21 12:35:42,207 - trainer - INFO -     val_val_gen_loss: 20.195347063469164
2025-01-21 12:35:42,207 - trainer - INFO -     val_val_perplexity: 591028643.8787879
2025-01-21 12:35:42,207 - trainer - INFO -     val_val_embedding_sim: 0.4224911711432717
2025-01-21 12:35:42,207 - trainer - INFO - ================================================================================
2025-01-21 12:35:42,207 - trainer - INFO - Starting epoch 130 at 2025-01-21 12:35:42
2025-01-21 12:35:45,915 - trainer - INFO - Epoch 130 completed at 2025-01-21 12:35:45
2025-01-21 12:35:45,916 - trainer - INFO -     epoch          : 130
2025-01-21 12:35:45,916 - trainer - INFO -     elapsed time   : 3.708387613296509
2025-01-21 12:35:45,916 - trainer - INFO -     loss           : 0.08976396769285203
2025-01-21 12:35:45,916 - trainer - INFO -     sim_loss       : 0.29878933541476727
2025-01-21 12:35:45,916 - trainer - INFO -     gen_loss       : 0.00018166178633691744
2025-01-21 12:35:45,916 - trainer - INFO -     val_val_loss   : 14.403826626864346
2025-01-21 12:35:45,916 - trainer - INFO -     val_val_sim_loss: 0.7993040373831084
2025-01-21 12:35:45,916 - trainer - INFO -     val_val_gen_loss: 20.234336043849137
2025-01-21 12:35:45,916 - trainer - INFO -     val_val_perplexity: 705078551.2727273
2025-01-21 12:35:45,916 - trainer - INFO -     val_val_embedding_sim: 0.421179141962167
2025-01-21 12:35:51,227 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch130.pth ...
2025-01-21 12:35:51,227 - trainer - INFO - ================================================================================
2025-01-21 12:35:51,227 - trainer - INFO - Starting epoch 131 at 2025-01-21 12:35:51
2025-01-21 12:35:55,007 - trainer - INFO - Epoch 131 completed at 2025-01-21 12:35:55
2025-01-21 12:35:55,007 - trainer - INFO -     epoch          : 131
2025-01-21 12:35:55,007 - trainer - INFO -     elapsed time   : 3.7792422771453857
2025-01-21 12:35:55,007 - trainer - INFO -     loss           : 0.09194517361902399
2025-01-21 12:35:55,007 - trainer - INFO -     sim_loss       : 0.3060791235319414
2025-01-21 12:35:55,007 - trainer - INFO -     gen_loss       : 0.00017347993998555465
2025-01-21 12:35:55,007 - trainer - INFO -     val_val_loss   : 14.187572826038707
2025-01-21 12:35:55,007 - trainer - INFO -     val_val_sim_loss: 0.10107196099830396
2025-01-21 12:35:55,007 - trainer - INFO -     val_val_gen_loss: 20.22464474764737
2025-01-21 12:35:55,007 - trainer - INFO -     val_val_perplexity: 828209865.6969697
2025-01-21 12:35:55,007 - trainer - INFO -     val_val_embedding_sim: 0.42315460515744757
2025-01-21 12:35:55,007 - trainer - INFO - ================================================================================
2025-01-21 12:35:55,007 - trainer - INFO - Starting epoch 132 at 2025-01-21 12:35:55
2025-01-21 12:35:58,735 - trainer - INFO - Epoch 132 completed at 2025-01-21 12:35:58
2025-01-21 12:35:58,735 - trainer - INFO -     epoch          : 132
2025-01-21 12:35:58,735 - trainer - INFO -     elapsed time   : 3.727429151535034
2025-01-21 12:35:58,735 - trainer - INFO -     loss           : 0.08839687965810299
2025-01-21 12:35:58,735 - trainer - INFO -     sim_loss       : 0.2942525025457144
2025-01-21 12:35:58,735 - trainer - INFO -     gen_loss       : 0.0001730347517877817
2025-01-21 12:35:58,735 - trainer - INFO -     val_val_loss   : 14.234115224896055
2025-01-21 12:35:58,735 - trainer - INFO -     val_val_sim_loss: 0.3329338882908677
2025-01-21 12:35:58,735 - trainer - INFO -     val_val_gen_loss: 20.191764658147637
2025-01-21 12:35:58,735 - trainer - INFO -     val_val_perplexity: 593173686.3030303
2025-01-21 12:35:58,735 - trainer - INFO -     val_val_embedding_sim: 0.42462833541812317
2025-01-21 12:35:58,735 - trainer - INFO - ================================================================================
2025-01-21 12:35:58,735 - trainer - INFO - Starting epoch 133 at 2025-01-21 12:35:58
2025-01-21 12:36:02,475 - trainer - INFO - Epoch 133 completed at 2025-01-21 12:36:02
2025-01-21 12:36:02,475 - trainer - INFO -     epoch          : 133
2025-01-21 12:36:02,475 - trainer - INFO -     elapsed time   : 3.7393620014190674
2025-01-21 12:36:02,475 - trainer - INFO -     loss           : 0.11309279818087817
2025-01-21 12:36:02,475 - trainer - INFO -     sim_loss       : 0.376580523699522
2025-01-21 12:36:02,475 - trainer - INFO -     gen_loss       : 0.00016948295233305545
2025-01-21 12:36:02,475 - trainer - INFO -     val_val_loss   : 14.177044926267682
2025-01-21 12:36:02,475 - trainer - INFO -     val_val_sim_loss: 0.10015886480158026
2025-01-21 12:36:02,475 - trainer - INFO -     val_val_gen_loss: 20.209996194550484
2025-01-21 12:36:02,475 - trainer - INFO -     val_val_perplexity: 681653760.0
2025-01-21 12:36:02,475 - trainer - INFO -     val_val_embedding_sim: 0.42369153824719513
2025-01-21 12:36:02,475 - trainer - INFO - ================================================================================
2025-01-21 12:36:02,475 - trainer - INFO - Starting epoch 134 at 2025-01-21 12:36:02
2025-01-21 12:36:06,205 - trainer - INFO - Epoch 134 completed at 2025-01-21 12:36:06
2025-01-21 12:36:06,205 - trainer - INFO -     epoch          : 134
2025-01-21 12:36:06,205 - trainer - INFO -     elapsed time   : 3.7292585372924805
2025-01-21 12:36:06,205 - trainer - INFO -     loss           : 0.07689441395923495
2025-01-21 12:36:06,205 - trainer - INFO -     sim_loss       : 0.2559190601110458
2025-01-21 12:36:06,205 - trainer - INFO -     gen_loss       : 0.00016956116742221637
2025-01-21 12:36:06,205 - trainer - INFO -     val_val_loss   : 14.229419274763627
2025-01-21 12:36:06,205 - trainer - INFO -     val_val_sim_loss: 0.1680435050611226
2025-01-21 12:36:06,205 - trainer - INFO -     val_val_gen_loss: 20.25572262388287
2025-01-21 12:36:06,205 - trainer - INFO -     val_val_perplexity: 711237026.9090909
2025-01-21 12:36:06,205 - trainer - INFO -     val_val_embedding_sim: 0.42278757420453156
2025-01-21 12:36:06,205 - trainer - INFO - ================================================================================
2025-01-21 12:36:06,205 - trainer - INFO - Starting epoch 135 at 2025-01-21 12:36:06
2025-01-21 12:36:09,930 - trainer - INFO - Epoch 135 completed at 2025-01-21 12:36:09
2025-01-21 12:36:09,930 - trainer - INFO -     epoch          : 135
2025-01-21 12:36:09,930 - trainer - INFO -     elapsed time   : 3.7246510982513428
2025-01-21 12:36:09,930 - trainer - INFO -     loss           : 0.08644033465534448
2025-01-21 12:36:09,930 - trainer - INFO -     sim_loss       : 0.28775152415037153
2025-01-21 12:36:09,930 - trainer - INFO -     gen_loss       : 0.00016410555108450353
2025-01-21 12:36:09,930 - trainer - INFO -     val_val_loss   : 14.358068177194307
2025-01-21 12:36:09,930 - trainer - INFO -     val_val_sim_loss: 0.5041172143184778
2025-01-21 12:36:09,930 - trainer - INFO -     val_val_gen_loss: 20.295476046475496
2025-01-21 12:36:09,930 - trainer - INFO -     val_val_perplexity: 868320287.030303
2025-01-21 12:36:09,930 - trainer - INFO -     val_val_embedding_sim: 0.4225751847931833
2025-01-21 12:36:15,230 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch135.pth ...
2025-01-21 12:36:15,231 - trainer - INFO - ================================================================================
2025-01-21 12:36:15,231 - trainer - INFO - Starting epoch 136 at 2025-01-21 12:36:15
2025-01-21 12:36:19,017 - trainer - INFO - Epoch 136 completed at 2025-01-21 12:36:19
2025-01-21 12:36:19,017 - trainer - INFO -     epoch          : 136
2025-01-21 12:36:19,017 - trainer - INFO -     elapsed time   : 3.7861835956573486
2025-01-21 12:36:19,018 - trainer - INFO -     loss           : 0.07605148234870285
2025-01-21 12:36:19,018 - trainer - INFO -     sim_loss       : 0.25312807373547913
2025-01-21 12:36:19,018 - trainer - INFO -     gen_loss       : 0.00016150989977177234
2025-01-21 12:36:19,018 - trainer - INFO -     val_val_loss   : 14.375368349479906
2025-01-21 12:36:19,018 - trainer - INFO -     val_val_sim_loss: 0.5326724196925308
2025-01-21 12:36:19,018 - trainer - INFO -     val_val_gen_loss: 20.3079526496656
2025-01-21 12:36:19,018 - trainer - INFO -     val_val_perplexity: 680048123.3939394
2025-01-21 12:36:19,018 - trainer - INFO -     val_val_embedding_sim: 0.42279626564546063
2025-01-21 12:36:19,018 - trainer - INFO - ================================================================================
2025-01-21 12:36:19,018 - trainer - INFO - Starting epoch 137 at 2025-01-21 12:36:19
2025-01-21 12:36:22,732 - trainer - INFO - Epoch 137 completed at 2025-01-21 12:36:22
2025-01-21 12:36:22,732 - trainer - INFO -     epoch          : 137
2025-01-21 12:36:22,733 - trainer - INFO -     elapsed time   : 3.714362382888794
2025-01-21 12:36:22,733 - trainer - INFO -     loss           : 0.08001551317429403
2025-01-21 12:36:22,733 - trainer - INFO -     sim_loss       : 0.2663404326678574
2025-01-21 12:36:22,733 - trainer - INFO -     gen_loss       : 0.00016197291988646613
2025-01-21 12:36:22,733 - trainer - INFO -     val_val_loss   : 14.329394976298014
2025-01-21 12:36:22,733 - trainer - INFO -     val_val_sim_loss: 0.43598677895285864
2025-01-21 12:36:22,733 - trainer - INFO -     val_val_gen_loss: 20.283712907270953
2025-01-21 12:36:22,733 - trainer - INFO -     val_val_perplexity: 650234647.2727273
2025-01-21 12:36:22,733 - trainer - INFO -     val_val_embedding_sim: 0.4230328148061579
2025-01-21 12:36:22,733 - trainer - INFO - ================================================================================
2025-01-21 12:36:22,733 - trainer - INFO - Starting epoch 138 at 2025-01-21 12:36:22
2025-01-21 12:36:26,460 - trainer - INFO - Epoch 138 completed at 2025-01-21 12:36:26
2025-01-21 12:36:26,460 - trainer - INFO -     epoch          : 138
2025-01-21 12:36:26,460 - trainer - INFO -     elapsed time   : 3.727142095565796
2025-01-21 12:36:26,460 - trainer - INFO -     loss           : 0.06890181254420895
2025-01-21 12:36:26,460 - trainer - INFO -     sim_loss       : 0.2292853831189859
2025-01-21 12:36:26,460 - trainer - INFO -     gen_loss       : 0.00016599425434833394
2025-01-21 12:36:26,461 - trainer - INFO -     val_val_loss   : 14.386384790593928
2025-01-21 12:36:26,461 - trainer - INFO -     val_val_sim_loss: 0.48867115829930163
2025-01-21 12:36:26,461 - trainer - INFO -     val_val_gen_loss: 20.342547676780008
2025-01-21 12:36:26,461 - trainer - INFO -     val_val_perplexity: 905200857.2121212
2025-01-21 12:36:26,461 - trainer - INFO -     val_val_embedding_sim: 0.42324865361054737
2025-01-21 12:36:26,461 - trainer - INFO - ================================================================================
2025-01-21 12:36:26,461 - trainer - INFO - Starting epoch 139 at 2025-01-21 12:36:26
2025-01-21 12:36:30,181 - trainer - INFO - Epoch 139 completed at 2025-01-21 12:36:30
2025-01-21 12:36:30,182 - trainer - INFO -     epoch          : 139
2025-01-21 12:36:30,182 - trainer - INFO -     elapsed time   : 3.720588207244873
2025-01-21 12:36:30,182 - trainer - INFO -     loss           : 0.08400734066963196
2025-01-21 12:36:30,182 - trainer - INFO -     sim_loss       : 0.27966010570526123
2025-01-21 12:36:30,182 - trainer - INFO -     gen_loss       : 0.00015615144511684775
2025-01-21 12:36:30,182 - trainer - INFO -     val_val_loss   : 14.402678287390506
2025-01-21 12:36:30,182 - trainer - INFO -     val_val_sim_loss: 0.6279861710259369
2025-01-21 12:36:30,182 - trainer - INFO -     val_val_gen_loss: 20.306117780280836
2025-01-21 12:36:30,182 - trainer - INFO -     val_val_perplexity: 659084497.4545455
2025-01-21 12:36:30,182 - trainer - INFO -     val_val_embedding_sim: 0.4226152987191171
2025-01-21 12:36:30,182 - trainer - INFO - ================================================================================
2025-01-21 12:36:30,182 - trainer - INFO - Starting epoch 140 at 2025-01-21 12:36:30
2025-01-21 12:36:33,904 - trainer - INFO - Epoch 140 completed at 2025-01-21 12:36:33
2025-01-21 12:36:33,904 - trainer - INFO -     epoch          : 140
2025-01-21 12:36:33,904 - trainer - INFO -     elapsed time   : 3.7217459678649902
2025-01-21 12:36:33,904 - trainer - INFO -     loss           : 0.06399590661749244
2025-01-21 12:36:33,904 - trainer - INFO -     sim_loss       : 0.21296767462044955
2025-01-21 12:36:33,904 - trainer - INFO -     gen_loss       : 0.0001508594214101322
2025-01-21 12:36:33,904 - trainer - INFO -     val_val_loss   : 14.282062039230809
2025-01-21 12:36:33,904 - trainer - INFO -     val_val_sim_loss: 0.19515573255940774
2025-01-21 12:36:33,904 - trainer - INFO -     val_val_gen_loss: 20.319308078650273
2025-01-21 12:36:33,904 - trainer - INFO -     val_val_perplexity: 671404780.6060606
2025-01-21 12:36:33,904 - trainer - INFO -     val_val_embedding_sim: 0.423556210416736
2025-01-21 12:36:39,202 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch140.pth ...
2025-01-21 12:36:39,202 - trainer - INFO - ================================================================================
2025-01-21 12:36:39,202 - trainer - INFO - Starting epoch 141 at 2025-01-21 12:36:39
2025-01-21 12:36:42,978 - trainer - INFO - Epoch 141 completed at 2025-01-21 12:36:42
2025-01-21 12:36:42,978 - trainer - INFO -     epoch          : 141
2025-01-21 12:36:42,978 - trainer - INFO -     elapsed time   : 3.7757065296173096
2025-01-21 12:36:42,978 - trainer - INFO -     loss           : 0.06334401527128648
2025-01-21 12:36:42,978 - trainer - INFO -     sim_loss       : 0.2107924974956404
2025-01-21 12:36:42,978 - trainer - INFO -     gen_loss       : 0.00015180577320279555
2025-01-21 12:36:42,978 - trainer - INFO -     val_val_loss   : 14.22441731077252
2025-01-21 12:36:42,978 - trainer - INFO -     val_val_sim_loss: 0.04878653179514975
2025-01-21 12:36:42,978 - trainer - INFO -     val_val_gen_loss: 20.29968753005519
2025-01-21 12:36:42,978 - trainer - INFO -     val_val_perplexity: 655854931.3939394
2025-01-21 12:36:42,978 - trainer - INFO -     val_val_embedding_sim: 0.4239710912559972
2025-01-21 12:36:42,978 - trainer - INFO - ================================================================================
2025-01-21 12:36:42,978 - trainer - INFO - Starting epoch 142 at 2025-01-21 12:36:42
2025-01-21 12:36:46,711 - trainer - INFO - Epoch 142 completed at 2025-01-21 12:36:46
2025-01-21 12:36:46,712 - trainer - INFO -     epoch          : 142
2025-01-21 12:36:46,712 - trainer - INFO -     elapsed time   : 3.7328991889953613
2025-01-21 12:36:46,712 - trainer - INFO -     loss           : 0.061130354274064304
2025-01-21 12:36:46,712 - trainer - INFO -     sim_loss       : 0.20341858118772507
2025-01-21 12:36:46,712 - trainer - INFO -     gen_loss       : 0.00014968126342864707
2025-01-21 12:36:46,712 - trainer - INFO -     val_val_loss   : 14.31363634629683
2025-01-21 12:36:46,712 - trainer - INFO -     val_val_sim_loss: 0.19509358839554874
2025-01-21 12:36:46,712 - trainer - INFO -     val_val_gen_loss: 20.36444091796875
2025-01-21 12:36:46,712 - trainer - INFO -     val_val_perplexity: 764177422.969697
2025-01-21 12:36:46,712 - trainer - INFO -     val_val_embedding_sim: 0.4236804915196968
2025-01-21 12:36:46,712 - trainer - INFO - ================================================================================
2025-01-21 12:36:46,712 - trainer - INFO - Starting epoch 143 at 2025-01-21 12:36:46
2025-01-21 12:36:50,440 - trainer - INFO - Epoch 143 completed at 2025-01-21 12:36:50
2025-01-21 12:36:50,440 - trainer - INFO -     epoch          : 143
2025-01-21 12:36:50,440 - trainer - INFO -     elapsed time   : 3.7276759147644043
2025-01-21 12:36:50,440 - trainer - INFO -     loss           : 0.1253508862107992
2025-01-21 12:36:50,440 - trainer - INFO -     sim_loss       : 0.4174938276410103
2025-01-21 12:36:50,440 - trainer - INFO -     gen_loss       : 0.00014676080099889076
2025-01-21 12:36:50,440 - trainer - INFO -     val_val_loss   : 14.564911640051639
2025-01-21 12:36:50,440 - trainer - INFO -     val_val_sim_loss: 0.9071034662651258
2025-01-21 12:36:50,440 - trainer - INFO -     val_val_gen_loss: 20.418258089007754
2025-01-21 12:36:50,440 - trainer - INFO -     val_val_perplexity: 807011416.3939394
2025-01-21 12:36:50,440 - trainer - INFO -     val_val_embedding_sim: 0.4213277914307334
2025-01-21 12:36:50,440 - trainer - INFO - ================================================================================
2025-01-21 12:36:50,440 - trainer - INFO - Starting epoch 144 at 2025-01-21 12:36:50
2025-01-21 12:36:54,164 - trainer - INFO - Epoch 144 completed at 2025-01-21 12:36:54
2025-01-21 12:36:54,165 - trainer - INFO -     epoch          : 144
2025-01-21 12:36:54,165 - trainer - INFO -     elapsed time   : 3.723982095718384
2025-01-21 12:36:54,165 - trainer - INFO -     loss           : 0.05573530232431949
2025-01-21 12:36:54,165 - trainer - INFO -     sim_loss       : 0.18544055111675561
2025-01-21 12:36:54,165 - trainer - INFO -     gen_loss       : 0.0001473335752962157
2025-01-21 12:36:54,165 - trainer - INFO -     val_val_loss   : 14.36353706591057
2025-01-21 12:36:54,165 - trainer - INFO -     val_val_sim_loss: 0.27149009704589844
2025-01-21 12:36:54,165 - trainer - INFO -     val_val_gen_loss: 20.40298641089237
2025-01-21 12:36:54,165 - trainer - INFO -     val_val_perplexity: 971170878.060606
2025-01-21 12:36:54,165 - trainer - INFO -     val_val_embedding_sim: 0.4230695836471789
2025-01-21 12:36:54,165 - trainer - INFO - ================================================================================
2025-01-21 12:36:54,165 - trainer - INFO - Starting epoch 145 at 2025-01-21 12:36:54
2025-01-21 12:36:57,898 - trainer - INFO - Epoch 145 completed at 2025-01-21 12:36:57
2025-01-21 12:36:57,898 - trainer - INFO -     epoch          : 145
2025-01-21 12:36:57,898 - trainer - INFO -     elapsed time   : 3.7327630519866943
2025-01-21 12:36:57,898 - trainer - INFO -     loss           : 0.11070913402363658
2025-01-21 12:36:57,898 - trainer - INFO -     sim_loss       : 0.36868434622883794
2025-01-21 12:36:57,898 - trainer - INFO -     gen_loss       : 0.00014832652814220638
2025-01-21 12:36:57,898 - trainer - INFO -     val_val_loss   : 14.441360011245266
2025-01-21 12:36:57,898 - trainer - INFO -     val_val_sim_loss: 0.5326680522976396
2025-01-21 12:36:57,898 - trainer - INFO -     val_val_gen_loss: 20.402228037516277
2025-01-21 12:36:57,898 - trainer - INFO -     val_val_perplexity: 752638976.0
2025-01-21 12:36:57,898 - trainer - INFO -     val_val_embedding_sim: 0.4218231787284215
2025-01-21 12:37:03,202 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch145.pth ...
2025-01-21 12:37:03,203 - trainer - INFO - ================================================================================
2025-01-21 12:37:03,203 - trainer - INFO - Starting epoch 146 at 2025-01-21 12:37:03
2025-01-21 12:37:06,992 - trainer - INFO - Epoch 146 completed at 2025-01-21 12:37:06
2025-01-21 12:37:06,992 - trainer - INFO -     epoch          : 146
2025-01-21 12:37:06,992 - trainer - INFO -     elapsed time   : 3.7893526554107666
2025-01-21 12:37:06,992 - trainer - INFO -     loss           : 0.07211178542856941
2025-01-21 12:37:06,992 - trainer - INFO -     sim_loss       : 0.24003267995713032
2025-01-21 12:37:06,992 - trainer - INFO -     gen_loss       : 0.0001456825753848534
2025-01-21 12:37:06,992 - trainer - INFO -     val_val_loss   : 14.410711519645922
2025-01-21 12:37:06,992 - trainer - INFO -     val_val_sim_loss: 0.32578247243707487
2025-01-21 12:37:06,993 - trainer - INFO -     val_val_gen_loss: 20.447109511404328
2025-01-21 12:37:06,993 - trainer - INFO -     val_val_perplexity: 791218926.7878788
2025-01-21 12:37:06,993 - trainer - INFO -     val_val_embedding_sim: 0.4224568352554784
2025-01-21 12:37:06,993 - trainer - INFO - ================================================================================
2025-01-21 12:37:06,993 - trainer - INFO - Starting epoch 147 at 2025-01-21 12:37:06
2025-01-21 12:37:10,707 - trainer - INFO - Epoch 147 completed at 2025-01-21 12:37:10
2025-01-21 12:37:10,707 - trainer - INFO -     epoch          : 147
2025-01-21 12:37:10,707 - trainer - INFO -     elapsed time   : 3.713728904724121
2025-01-21 12:37:10,707 - trainer - INFO -     loss           : 0.10362310092823464
2025-01-21 12:37:10,707 - trainer - INFO -     sim_loss       : 0.34506817608989876
2025-01-21 12:37:10,707 - trainer - INFO -     gen_loss       : 0.00014663323308923283
2025-01-21 12:37:10,707 - trainer - INFO -     val_val_loss   : 14.31808278054902
2025-01-21 12:37:10,707 - trainer - INFO -     val_val_sim_loss: 0.09754581884904341
2025-01-21 12:37:10,707 - trainer - INFO -     val_val_gen_loss: 20.4125993902033
2025-01-21 12:37:10,707 - trainer - INFO -     val_val_perplexity: 733370160.4848485
2025-01-21 12:37:10,707 - trainer - INFO -     val_val_embedding_sim: 0.42290059635133453
2025-01-21 12:37:10,707 - trainer - INFO - ================================================================================
2025-01-21 12:37:10,707 - trainer - INFO - Starting epoch 148 at 2025-01-21 12:37:10
2025-01-21 12:37:14,431 - trainer - INFO - Epoch 148 completed at 2025-01-21 12:37:14
2025-01-21 12:37:14,431 - trainer - INFO -     epoch          : 148
2025-01-21 12:37:14,431 - trainer - INFO -     elapsed time   : 3.7235538959503174
2025-01-21 12:37:14,431 - trainer - INFO -     loss           : 0.09236868023872376
2025-01-21 12:37:14,431 - trainer - INFO -     sim_loss       : 0.30756668858230113
2025-01-21 12:37:14,431 - trainer - INFO -     gen_loss       : 0.00014095923106651753
2025-01-21 12:37:14,431 - trainer - INFO -     val_val_loss   : 14.359731500799006
2025-01-21 12:37:14,431 - trainer - INFO -     val_val_sim_loss: 0.2714827566435843
2025-01-21 12:37:14,431 - trainer - INFO -     val_val_gen_loss: 20.397552779226594
2025-01-21 12:37:14,431 - trainer - INFO -     val_val_perplexity: 725362834.4242424
2025-01-21 12:37:14,431 - trainer - INFO -     val_val_embedding_sim: 0.4226727666276874
2025-01-21 12:37:14,431 - trainer - INFO - ================================================================================
2025-01-21 12:37:14,431 - trainer - INFO - Starting epoch 149 at 2025-01-21 12:37:14
2025-01-21 12:37:18,150 - trainer - INFO - Epoch 149 completed at 2025-01-21 12:37:18
2025-01-21 12:37:18,150 - trainer - INFO -     epoch          : 149
2025-01-21 12:37:18,150 - trainer - INFO -     elapsed time   : 3.71806001663208
2025-01-21 12:37:18,150 - trainer - INFO -     loss           : 0.07242682613432408
2025-01-21 12:37:18,150 - trainer - INFO -     sim_loss       : 0.24110159948468207
2025-01-21 12:37:18,150 - trainer - INFO -     gen_loss       : 0.00013763085444225
2025-01-21 12:37:18,150 - trainer - INFO -     val_val_loss   : 14.362392165444113
2025-01-21 12:37:18,150 - trainer - INFO -     val_val_sim_loss: 0.26633199417229836
2025-01-21 12:37:18,150 - trainer - INFO -     val_val_gen_loss: 20.403561274210613
2025-01-21 12:37:18,150 - trainer - INFO -     val_val_perplexity: 729243686.7878788
2025-01-21 12:37:18,150 - trainer - INFO -     val_val_embedding_sim: 0.4231188893318176
2025-01-21 12:37:18,150 - trainer - INFO - ================================================================================
2025-01-21 12:37:18,150 - trainer - INFO - Starting epoch 150 at 2025-01-21 12:37:18
2025-01-21 12:37:21,871 - trainer - INFO - Epoch 150 completed at 2025-01-21 12:37:21
2025-01-21 12:37:21,871 - trainer - INFO -     epoch          : 150
2025-01-21 12:37:21,871 - trainer - INFO -     elapsed time   : 3.720327377319336
2025-01-21 12:37:21,871 - trainer - INFO -     loss           : 0.08978323135524988
2025-01-21 12:37:21,871 - trainer - INFO -     sim_loss       : 0.29896069690585136
2025-01-21 12:37:21,871 - trainer - INFO -     gen_loss       : 0.00013574161494034342
2025-01-21 12:37:21,871 - trainer - INFO -     val_val_loss   : 14.407641179633863
2025-01-21 12:37:21,871 - trainer - INFO -     val_val_sim_loss: 0.35564195026050915
2025-01-21 12:37:21,871 - trainer - INFO -     val_val_gen_loss: 20.429926843354195
2025-01-21 12:37:21,871 - trainer - INFO -     val_val_perplexity: 755480168.7272727
2025-01-21 12:37:21,871 - trainer - INFO -     val_val_embedding_sim: 0.42312773249366065
2025-01-21 12:37:27,178 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch150.pth ...
2025-01-21 12:37:27,178 - trainer - INFO - ================================================================================
2025-01-21 12:37:27,178 - trainer - INFO - Starting epoch 151 at 2025-01-21 12:37:27
2025-01-21 12:37:30,967 - trainer - INFO - Epoch 151 completed at 2025-01-21 12:37:30
2025-01-21 12:37:30,968 - trainer - INFO -     epoch          : 151
2025-01-21 12:37:30,968 - trainer - INFO -     elapsed time   : 3.788999319076538
2025-01-21 12:37:30,968 - trainer - INFO -     loss           : 0.053793366879835956
2025-01-21 12:37:30,968 - trainer - INFO -     sim_loss       : 0.17899372518095333
2025-01-21 12:37:30,968 - trainer - INFO -     gen_loss       : 0.00013606834181700833
2025-01-21 12:37:30,968 - trainer - INFO -     val_val_loss   : 14.479509498133805
2025-01-21 12:37:30,968 - trainer - INFO -     val_val_sim_loss: 0.5326677380186139
2025-01-21 12:37:30,968 - trainer - INFO -     val_val_gen_loss: 20.45672780817205
2025-01-21 12:37:30,968 - trainer - INFO -     val_val_perplexity: 767704128.0
2025-01-21 12:37:30,968 - trainer - INFO -     val_val_embedding_sim: 0.42327391559427435
2025-01-21 12:37:30,968 - trainer - INFO - ================================================================================
2025-01-21 12:37:30,968 - trainer - INFO - Starting epoch 152 at 2025-01-21 12:37:30
2025-01-21 12:37:35,178 - trainer - INFO - Epoch 152 completed at 2025-01-21 12:37:35
2025-01-21 12:37:35,178 - trainer - INFO -     epoch          : 152
2025-01-21 12:37:35,178 - trainer - INFO -     elapsed time   : 4.209442615509033
2025-01-21 12:37:35,178 - trainer - INFO -     loss           : 0.06988891321816482
2025-01-21 12:37:35,178 - trainer - INFO -     sim_loss       : 0.23264262649624926
2025-01-21 12:37:35,178 - trainer - INFO -     gen_loss       : 0.00013731752114836125
2025-01-21 12:37:35,178 - trainer - INFO -     val_val_loss   : 14.32267275723544
2025-01-21 12:37:35,178 - trainer - INFO -     val_val_sim_loss: 0.03329364097477895
2025-01-21 12:37:35,178 - trainer - INFO -     val_val_gen_loss: 20.44669261123195
2025-01-21 12:37:35,178 - trainer - INFO -     val_val_perplexity: 760011155.3939394
2025-01-21 12:37:35,178 - trainer - INFO -     val_val_embedding_sim: 0.42313882437619293
2025-01-21 12:37:35,178 - trainer - INFO - ================================================================================
2025-01-21 12:37:35,178 - trainer - INFO - Starting epoch 153 at 2025-01-21 12:37:35
2025-01-21 12:37:38,902 - trainer - INFO - Epoch 153 completed at 2025-01-21 12:37:38
2025-01-21 12:37:38,902 - trainer - INFO -     epoch          : 153
2025-01-21 12:37:38,902 - trainer - INFO -     elapsed time   : 3.723893880844116
2025-01-21 12:37:38,902 - trainer - INFO -     loss           : 0.06661033300770214
2025-01-21 12:37:38,902 - trainer - INFO -     sim_loss       : 0.22172445057017284
2025-01-21 12:37:38,903 - trainer - INFO -     gen_loss       : 0.00013285040331538766
2025-01-21 12:37:38,903 - trainer - INFO -     val_val_loss   : 14.560785900462758
2025-01-21 12:37:38,903 - trainer - INFO -     val_val_sim_loss: 0.7266464811382871
2025-01-21 12:37:38,903 - trainer - INFO -     val_val_gen_loss: 20.489704189878523
2025-01-21 12:37:38,903 - trainer - INFO -     val_val_perplexity: 795936373.3333334
2025-01-21 12:37:38,903 - trainer - INFO -     val_val_embedding_sim: 0.42107735258160217
2025-01-21 12:37:38,903 - trainer - INFO - ================================================================================
2025-01-21 12:37:38,903 - trainer - INFO - Starting epoch 154 at 2025-01-21 12:37:38
2025-01-21 12:37:42,618 - trainer - INFO - Epoch 154 completed at 2025-01-21 12:37:42
2025-01-21 12:37:42,618 - trainer - INFO -     epoch          : 154
2025-01-21 12:37:42,618 - trainer - INFO -     elapsed time   : 3.7146379947662354
2025-01-21 12:37:42,618 - trainer - INFO -     loss           : 0.11975026912987233
2025-01-21 12:37:42,618 - trainer - INFO -     sim_loss       : 0.39886118471622467
2025-01-21 12:37:42,618 - trainer - INFO -     gen_loss       : 0.0001312977161433082
2025-01-21 12:37:42,618 - trainer - INFO -     val_val_loss   : 14.428153298117898
2025-01-21 12:37:42,618 - trainer - INFO -     val_val_sim_loss: 0.30282709454045154
2025-01-21 12:37:42,618 - trainer - INFO -     val_val_gen_loss: 20.481864466811672
2025-01-21 12:37:42,618 - trainer - INFO -     val_val_perplexity: 1074310733.5757575
2025-01-21 12:37:42,618 - trainer - INFO -     val_val_embedding_sim: 0.42294290210261487
2025-01-21 12:37:42,618 - trainer - INFO - ================================================================================
2025-01-21 12:37:42,618 - trainer - INFO - Starting epoch 155 at 2025-01-21 12:37:42
2025-01-21 12:37:46,331 - trainer - INFO - Epoch 155 completed at 2025-01-21 12:37:46
2025-01-21 12:37:46,331 - trainer - INFO -     epoch          : 155
2025-01-21 12:37:46,331 - trainer - INFO -     elapsed time   : 3.712491273880005
2025-01-21 12:37:46,331 - trainer - INFO -     loss           : 0.06054308567836415
2025-01-21 12:37:46,331 - trainer - INFO -     sim_loss       : 0.2015015956014395
2025-01-21 12:37:46,331 - trainer - INFO -     gen_loss       : 0.00013229278483777306
2025-01-21 12:37:46,331 - trainer - INFO -     val_val_loss   : 14.509112878279252
2025-01-21 12:37:46,331 - trainer - INFO -     val_val_sim_loss: 0.567137978293679
2025-01-21 12:37:46,331 - trainer - INFO -     val_val_gen_loss: 20.484246282866508
2025-01-21 12:37:46,331 - trainer - INFO -     val_val_perplexity: 799304172.6060606
2025-01-21 12:37:46,331 - trainer - INFO -     val_val_embedding_sim: 0.42271969173893786
2025-01-21 12:37:51,635 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch155.pth ...
2025-01-21 12:37:51,635 - trainer - INFO - ================================================================================
2025-01-21 12:37:51,635 - trainer - INFO - Starting epoch 156 at 2025-01-21 12:37:51
2025-01-21 12:37:55,402 - trainer - INFO - Epoch 156 completed at 2025-01-21 12:37:55
2025-01-21 12:37:55,402 - trainer - INFO -     epoch          : 156
2025-01-21 12:37:55,402 - trainer - INFO -     elapsed time   : 3.766136407852173
2025-01-21 12:37:55,402 - trainer - INFO -     loss           : 0.0769017541941139
2025-01-21 12:37:55,402 - trainer - INFO -     sim_loss       : 0.2560446696775898
2025-01-21 12:37:55,402 - trainer - INFO -     gen_loss       : 0.00012621364076039753
2025-01-21 12:37:55,402 - trainer - INFO -     val_val_loss   : 14.389290405042244
2025-01-21 12:37:55,402 - trainer - INFO -     val_val_sim_loss: 0.10859430558753715
2025-01-21 12:37:55,402 - trainer - INFO -     val_val_gen_loss: 20.50958945534446
2025-01-21 12:37:55,402 - trainer - INFO -     val_val_perplexity: 807884408.2424242
2025-01-21 12:37:55,402 - trainer - INFO -     val_val_embedding_sim: 0.4232536762049704
2025-01-21 12:37:55,402 - trainer - INFO - ================================================================================
2025-01-21 12:37:55,402 - trainer - INFO - Starting epoch 157 at 2025-01-21 12:37:55
2025-01-21 12:37:59,114 - trainer - INFO - Epoch 157 completed at 2025-01-21 12:37:59
2025-01-21 12:37:59,114 - trainer - INFO -     epoch          : 157
2025-01-21 12:37:59,114 - trainer - INFO -     elapsed time   : 3.711146116256714
2025-01-21 12:37:59,114 - trainer - INFO -     loss           : 0.09685633964836597
2025-01-21 12:37:59,114 - trainer - INFO -     sim_loss       : 0.32254734858870504
2025-01-21 12:37:59,114 - trainer - INFO -     gen_loss       : 0.00013161241295165383
2025-01-21 12:37:59,114 - trainer - INFO -     val_val_loss   : 14.438576698303223
2025-01-21 12:37:59,114 - trainer - INFO -     val_val_sim_loss: 0.29264074383359967
2025-01-21 12:37:59,114 - trainer - INFO -     val_val_gen_loss: 20.501120133833453
2025-01-21 12:37:59,114 - trainer - INFO -     val_val_perplexity: 807863707.1515151
2025-01-21 12:37:59,114 - trainer - INFO -     val_val_embedding_sim: 0.42316692345070117
2025-01-21 12:37:59,114 - trainer - INFO - ================================================================================
2025-01-21 12:37:59,114 - trainer - INFO - Starting epoch 158 at 2025-01-21 12:37:59
2025-01-21 12:38:02,838 - trainer - INFO - Epoch 158 completed at 2025-01-21 12:38:02
2025-01-21 12:38:02,838 - trainer - INFO -     epoch          : 158
2025-01-21 12:38:02,838 - trainer - INFO -     elapsed time   : 3.7236764430999756
2025-01-21 12:38:02,838 - trainer - INFO -     loss           : 0.08461386077105999
2025-01-21 12:38:02,838 - trainer - INFO -     sim_loss       : 0.2817456007003784
2025-01-21 12:38:02,838 - trainer - INFO -     gen_loss       : 0.0001288206498429645
2025-01-21 12:38:02,838 - trainer - INFO -     val_val_loss   : 14.474409941470984
2025-01-21 12:38:02,838 - trainer - INFO -     val_val_sim_loss: 0.37809588692405005
2025-01-21 12:38:02,838 - trainer - INFO -     val_val_gen_loss: 20.515687306722004
2025-01-21 12:38:02,838 - trainer - INFO -     val_val_perplexity: 817292613.8181819
2025-01-21 12:38:02,838 - trainer - INFO -     val_val_embedding_sim: 0.42258660450126184
2025-01-21 12:38:02,838 - trainer - INFO - ================================================================================
2025-01-21 12:38:02,839 - trainer - INFO - Starting epoch 159 at 2025-01-21 12:38:02
2025-01-21 12:38:06,558 - trainer - INFO - Epoch 159 completed at 2025-01-21 12:38:06
2025-01-21 12:38:06,558 - trainer - INFO -     epoch          : 159
2025-01-21 12:38:06,558 - trainer - INFO -     elapsed time   : 3.7189016342163086
2025-01-21 12:38:06,558 - trainer - INFO -     loss           : 0.08529246468096971
2025-01-21 12:38:06,558 - trainer - INFO -     sim_loss       : 0.2840233825147152
2025-01-21 12:38:06,558 - trainer - INFO -     gen_loss       : 0.00012206730971229263
2025-01-21 12:38:06,558 - trainer - INFO -     val_val_loss   : 14.429600195451217
2025-01-21 12:38:06,558 - trainer - INFO -     val_val_sim_loss: 0.24385913212970053
2025-01-21 12:38:06,558 - trainer - INFO -     val_val_gen_loss: 20.50920324614554
2025-01-21 12:38:06,558 - trainer - INFO -     val_val_perplexity: 807526322.4242424
2025-01-21 12:38:06,558 - trainer - INFO -     val_val_embedding_sim: 0.42331190542741254
2025-01-21 12:38:06,558 - trainer - INFO - ================================================================================
2025-01-21 12:38:06,558 - trainer - INFO - Starting epoch 160 at 2025-01-21 12:38:06
2025-01-21 12:38:10,267 - trainer - INFO - Epoch 160 completed at 2025-01-21 12:38:10
2025-01-21 12:38:10,268 - trainer - INFO -     epoch          : 160
2025-01-21 12:38:10,268 - trainer - INFO -     elapsed time   : 3.7091543674468994
2025-01-21 12:38:10,268 - trainer - INFO -     loss           : 0.06226916308660293
2025-01-21 12:38:10,268 - trainer - INFO -     sim_loss       : 0.20727589491464188
2025-01-21 12:38:10,268 - trainer - INFO -     gen_loss       : 0.00012341703913989476
2025-01-21 12:38:10,268 - trainer - INFO -     val_val_loss   : 14.43097007635868
2025-01-21 12:38:10,268 - trainer - INFO -     val_val_sim_loss: 0.2171856128808224
2025-01-21 12:38:10,268 - trainer - INFO -     val_val_gen_loss: 20.52259133078835
2025-01-21 12:38:10,268 - trainer - INFO -     val_val_perplexity: 820792608.969697
2025-01-21 12:38:10,268 - trainer - INFO -     val_val_embedding_sim: 0.4224757299278722
2025-01-21 12:38:15,566 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch160.pth ...
2025-01-21 12:38:15,566 - trainer - INFO - ================================================================================
2025-01-21 12:38:15,566 - trainer - INFO - Starting epoch 161 at 2025-01-21 12:38:15
2025-01-21 12:38:19,358 - trainer - INFO - Epoch 161 completed at 2025-01-21 12:38:19
2025-01-21 12:38:19,358 - trainer - INFO -     epoch          : 161
2025-01-21 12:38:19,358 - trainer - INFO -     elapsed time   : 3.791654586791992
2025-01-21 12:38:19,358 - trainer - INFO -     loss           : 0.06327852141112089
2025-01-21 12:38:19,358 - trainer - INFO -     sim_loss       : 0.21064427644014358
2025-01-21 12:38:19,358 - trainer - INFO -     gen_loss       : 0.0001217655255459249
2025-01-21 12:38:19,358 - trainer - INFO -     val_val_loss   : 14.406832897301877
2025-01-21 12:38:19,359 - trainer - INFO -     val_val_sim_loss: 0.042017781373226065
2025-01-21 12:38:19,359 - trainer - INFO -     val_val_gen_loss: 20.563182368423
2025-01-21 12:38:19,359 - trainer - INFO -     val_val_perplexity: 855643333.8181819
2025-01-21 12:38:19,359 - trainer - INFO -     val_val_embedding_sim: 0.4224458553574302
2025-01-21 12:38:19,359 - trainer - INFO - ================================================================================
2025-01-21 12:38:19,359 - trainer - INFO - Starting epoch 162 at 2025-01-21 12:38:19
2025-01-21 12:38:23,081 - trainer - INFO - Epoch 162 completed at 2025-01-21 12:38:23
2025-01-21 12:38:23,081 - trainer - INFO -     epoch          : 162
2025-01-21 12:38:23,081 - trainer - INFO -     elapsed time   : 3.7219927310943604
2025-01-21 12:38:23,081 - trainer - INFO -     loss           : 0.10435054022964323
2025-01-21 12:38:23,081 - trainer - INFO -     sim_loss       : 0.347550591079289
2025-01-21 12:38:23,081 - trainer - INFO -     gen_loss       : 0.00012193973889225162
2025-01-21 12:38:23,081 - trainer - INFO -     val_val_loss   : 14.51723948392001
2025-01-21 12:38:23,081 - trainer - INFO -     val_val_sim_loss: 0.3780863248940668
2025-01-21 12:38:23,081 - trainer - INFO -     val_val_gen_loss: 20.57687788298636
2025-01-21 12:38:23,081 - trainer - INFO -     val_val_perplexity: 868309879.2727273
2025-01-21 12:38:23,081 - trainer - INFO -     val_val_embedding_sim: 0.42245717843373615
2025-01-21 12:38:23,081 - trainer - INFO - ================================================================================
2025-01-21 12:38:23,081 - trainer - INFO - Starting epoch 163 at 2025-01-21 12:38:23
2025-01-21 12:38:26,798 - trainer - INFO - Epoch 163 completed at 2025-01-21 12:38:26
2025-01-21 12:38:26,798 - trainer - INFO -     epoch          : 163
2025-01-21 12:38:26,798 - trainer - INFO -     elapsed time   : 3.716327667236328
2025-01-21 12:38:26,798 - trainer - INFO -     loss           : 0.10294175635863212
2025-01-21 12:38:26,798 - trainer - INFO -     sim_loss       : 0.3428483970458899
2025-01-21 12:38:26,798 - trainer - INFO -     gen_loss       : 0.00012461780788726174
2025-01-21 12:38:26,798 - trainer - INFO -     val_val_loss   : 14.599117828137947
2025-01-21 12:38:26,798 - trainer - INFO -     val_val_sim_loss: 0.6301397590926027
2025-01-21 12:38:26,798 - trainer - INFO -     val_val_gen_loss: 20.585823174678918
2025-01-21 12:38:26,798 - trainer - INFO -     val_val_perplexity: 905246254.5454545
2025-01-21 12:38:26,798 - trainer - INFO -     val_val_embedding_sim: 0.42334958459391736
2025-01-21 12:38:26,798 - trainer - INFO - ================================================================================
2025-01-21 12:38:26,798 - trainer - INFO - Starting epoch 164 at 2025-01-21 12:38:26
2025-01-21 12:38:30,513 - trainer - INFO - Epoch 164 completed at 2025-01-21 12:38:30
2025-01-21 12:38:30,513 - trainer - INFO -     epoch          : 164
2025-01-21 12:38:30,513 - trainer - INFO -     elapsed time   : 3.714808940887451
2025-01-21 12:38:30,513 - trainer - INFO -     loss           : 0.07312346070757485
2025-01-21 12:38:30,514 - trainer - INFO -     sim_loss       : 0.24346280246866173
2025-01-21 12:38:30,514 - trainer - INFO -     gen_loss       : 0.00012088402145309374
2025-01-21 12:38:30,514 - trainer - INFO -     val_val_loss   : 14.52244538971872
2025-01-21 12:38:30,514 - trainer - INFO -     val_val_sim_loss: 0.4118926669612075
2025-01-21 12:38:30,514 - trainer - INFO -     val_val_gen_loss: 20.56982450774222
2025-01-21 12:38:30,514 - trainer - INFO -     val_val_perplexity: 863786150.7878788
2025-01-21 12:38:30,514 - trainer - INFO -     val_val_embedding_sim: 0.4232224542083162
2025-01-21 12:38:30,514 - trainer - INFO - ================================================================================
2025-01-21 12:38:30,514 - trainer - INFO - Starting epoch 165 at 2025-01-21 12:38:30
2025-01-21 12:38:34,240 - trainer - INFO - Epoch 165 completed at 2025-01-21 12:38:34
2025-01-21 12:38:34,241 - trainer - INFO -     epoch          : 165
2025-01-21 12:38:34,241 - trainer - INFO -     elapsed time   : 3.7266454696655273
2025-01-21 12:38:34,241 - trainer - INFO -     loss           : 0.07921629366101116
2025-01-21 12:38:34,241 - trainer - INFO -     sim_loss       : 0.26377861052751256
2025-01-21 12:38:34,241 - trainer - INFO -     gen_loss       : 0.00011815113612101413
2025-01-21 12:38:34,241 - trainer - INFO -     val_val_loss   : 14.45712153116862
2025-01-21 12:38:34,241 - trainer - INFO -     val_val_sim_loss: 0.14189280885638614
2025-01-21 12:38:34,241 - trainer - INFO -     val_val_gen_loss: 20.59221990180738
2025-01-21 12:38:34,241 - trainer - INFO -     val_val_perplexity: 904246639.5151515
2025-01-21 12:38:34,241 - trainer - INFO -     val_val_embedding_sim: 0.42330098874641187
2025-01-21 12:38:39,547 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch165.pth ...
2025-01-21 12:38:39,547 - trainer - INFO - ================================================================================
2025-01-21 12:38:39,547 - trainer - INFO - Starting epoch 166 at 2025-01-21 12:38:39
2025-01-21 12:38:43,340 - trainer - INFO - Epoch 166 completed at 2025-01-21 12:38:43
2025-01-21 12:38:43,340 - trainer - INFO -     epoch          : 166
2025-01-21 12:38:43,340 - trainer - INFO -     elapsed time   : 3.7926595211029053
2025-01-21 12:38:43,340 - trainer - INFO -     loss           : 0.09269525185227394
2025-01-21 12:38:43,340 - trainer - INFO -     sim_loss       : 0.3087017461657524
2025-01-21 12:38:43,340 - trainer - INFO -     gen_loss       : 0.00012103607441531495
2025-01-21 12:38:43,340 - trainer - INFO -     val_val_loss   : 14.577879732305353
2025-01-21 12:38:43,340 - trainer - INFO -     val_val_sim_loss: 0.5041159427527225
2025-01-21 12:38:43,340 - trainer - INFO -     val_val_gen_loss: 20.60949337121212
2025-01-21 12:38:43,340 - trainer - INFO -     val_val_perplexity: 931978317.5757576
2025-01-21 12:38:43,340 - trainer - INFO -     val_val_embedding_sim: 0.4231330120202267
2025-01-21 12:38:43,340 - trainer - INFO - ================================================================================
2025-01-21 12:38:43,340 - trainer - INFO - Starting epoch 167 at 2025-01-21 12:38:43
2025-01-21 12:38:47,079 - trainer - INFO - Epoch 167 completed at 2025-01-21 12:38:47
2025-01-21 12:38:47,080 - trainer - INFO -     epoch          : 167
2025-01-21 12:38:47,080 - trainer - INFO -     elapsed time   : 3.7387726306915283
2025-01-21 12:38:47,080 - trainer - INFO -     loss           : 0.07786754693152034
2025-01-21 12:38:47,080 - trainer - INFO -     sim_loss       : 0.25929320361465213
2025-01-21 12:38:47,080 - trainer - INFO -     gen_loss       : 0.00011368822524673305
2025-01-21 12:38:47,080 - trainer - INFO -     val_val_loss   : 14.519231044884885
2025-01-21 12:38:47,080 - trainer - INFO -     val_val_sim_loss: 0.32579060756798944
2025-01-21 12:38:47,080 - trainer - INFO -     val_val_gen_loss: 20.602133201830316
2025-01-21 12:38:47,080 - trainer - INFO -     val_val_perplexity: 899695336.7272727
2025-01-21 12:38:47,080 - trainer - INFO -     val_val_embedding_sim: 0.4219150362592755
2025-01-21 12:38:47,080 - trainer - INFO - ================================================================================
2025-01-21 12:38:47,080 - trainer - INFO - Starting epoch 168 at 2025-01-21 12:38:47
2025-01-21 12:38:50,800 - trainer - INFO - Epoch 168 completed at 2025-01-21 12:38:50
2025-01-21 12:38:50,800 - trainer - INFO -     epoch          : 168
2025-01-21 12:38:50,800 - trainer - INFO -     elapsed time   : 3.7197179794311523
2025-01-21 12:38:50,800 - trainer - INFO -     loss           : 0.08960283156484365
2025-01-21 12:38:50,800 - trainer - INFO -     sim_loss       : 0.2984030582010746
2025-01-21 12:38:50,800 - trainer - INFO -     gen_loss       : 0.00011701545954565518
2025-01-21 12:38:50,800 - trainer - INFO -     val_val_loss   : 14.682479685003107
2025-01-21 12:38:50,800 - trainer - INFO -     val_val_sim_loss: 0.8191884358723959
2025-01-21 12:38:50,800 - trainer - INFO -     val_val_gen_loss: 20.62389067447547
2025-01-21 12:38:50,800 - trainer - INFO -     val_val_perplexity: 910014604.6060606
2025-01-21 12:38:50,800 - trainer - INFO -     val_val_embedding_sim: 0.421707348390059
2025-01-21 12:38:50,800 - trainer - INFO - ================================================================================
2025-01-21 12:38:50,800 - trainer - INFO - Starting epoch 169 at 2025-01-21 12:38:50
2025-01-21 12:38:54,513 - trainer - INFO - Epoch 169 completed at 2025-01-21 12:38:54
2025-01-21 12:38:54,514 - trainer - INFO -     epoch          : 169
2025-01-21 12:38:54,514 - trainer - INFO -     elapsed time   : 3.712850570678711
2025-01-21 12:38:54,514 - trainer - INFO -     loss           : 0.07589211401573266
2025-01-21 12:38:54,514 - trainer - INFO -     sim_loss       : 0.25270646177218625
2025-01-21 12:38:54,514 - trainer - INFO -     gen_loss       : 0.0001145332156738732
2025-01-21 12:38:54,514 - trainer - INFO -     val_val_loss   : 14.539476510250207
2025-01-21 12:38:54,514 - trainer - INFO -     val_val_sim_loss: 0.35160061807343457
2025-01-21 12:38:54,514 - trainer - INFO -     val_val_gen_loss: 20.619995001590613
2025-01-21 12:38:54,514 - trainer - INFO -     val_val_perplexity: 948563549.0909091
2025-01-21 12:38:54,514 - trainer - INFO -     val_val_embedding_sim: 0.42351570996371185
2025-01-21 12:38:54,514 - trainer - INFO - ================================================================================
2025-01-21 12:38:54,514 - trainer - INFO - Starting epoch 170 at 2025-01-21 12:38:54
2025-01-21 12:38:58,235 - trainer - INFO - Epoch 170 completed at 2025-01-21 12:38:58
2025-01-21 12:38:58,235 - trainer - INFO -     epoch          : 170
2025-01-21 12:38:58,235 - trainer - INFO -     elapsed time   : 3.7211124897003174
2025-01-21 12:38:58,235 - trainer - INFO -     loss           : 0.10528311603411566
2025-01-21 12:38:58,235 - trainer - INFO -     sim_loss       : 0.3506883633824344
2025-01-21 12:38:58,235 - trainer - INFO -     gen_loss       : 0.00010942943627014756
2025-01-21 12:38:58,235 - trainer - INFO -     val_val_loss   : 14.471135139465332
2025-01-21 12:38:58,235 - trainer - INFO -     val_val_sim_loss: 0.12603102308331113
2025-01-21 12:38:58,236 - trainer - INFO -     val_val_gen_loss: 20.61903751257694
2025-01-21 12:38:58,236 - trainer - INFO -     val_val_perplexity: 914600468.3636364
2025-01-21 12:38:58,236 - trainer - INFO -     val_val_embedding_sim: 0.4232473373413086
2025-01-21 12:39:03,546 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch170.pth ...
2025-01-21 12:39:03,546 - trainer - INFO - ================================================================================
2025-01-21 12:39:03,546 - trainer - INFO - Starting epoch 171 at 2025-01-21 12:39:03
2025-01-21 12:39:07,319 - trainer - INFO - Epoch 171 completed at 2025-01-21 12:39:07
2025-01-21 12:39:07,320 - trainer - INFO -     epoch          : 171
2025-01-21 12:39:07,320 - trainer - INFO -     elapsed time   : 3.7727527618408203
2025-01-21 12:39:07,320 - trainer - INFO -     loss           : 0.049237946958237445
2025-01-21 12:39:07,320 - trainer - INFO -     sim_loss       : 0.16387829990720207
2025-01-21 12:39:07,320 - trainer - INFO -     gen_loss       : 0.00010636541919666343
2025-01-21 12:39:07,320 - trainer - INFO -     val_val_loss   : 14.756351442048043
2025-01-21 12:39:07,320 - trainer - INFO -     val_val_sim_loss: 0.9321695963541666
2025-01-21 12:39:07,320 - trainer - INFO -     val_val_gen_loss: 20.681000565037582
2025-01-21 12:39:07,320 - trainer - INFO -     val_val_perplexity: 1051724882.3030303
2025-01-21 12:39:07,320 - trainer - INFO -     val_val_embedding_sim: 0.4214611161838878
2025-01-21 12:39:07,320 - trainer - INFO - ================================================================================
2025-01-21 12:39:07,320 - trainer - INFO - Starting epoch 172 at 2025-01-21 12:39:07
2025-01-21 12:39:11,043 - trainer - INFO - Epoch 172 completed at 2025-01-21 12:39:11
2025-01-21 12:39:11,043 - trainer - INFO -     epoch          : 172
2025-01-21 12:39:11,043 - trainer - INFO -     elapsed time   : 3.722543954849243
2025-01-21 12:39:11,043 - trainer - INFO -     loss           : 0.11324652777984738
2025-01-21 12:39:11,043 - trainer - INFO -     sim_loss       : 0.3772350665181875
2025-01-21 12:39:11,043 - trainer - INFO -     gen_loss       : 0.00010857959787244909
2025-01-21 12:39:11,043 - trainer - INFO -     val_val_loss   : 14.533396489692457
2025-01-21 12:39:11,043 - trainer - INFO -     val_val_sim_loss: 0.2948447140780362
2025-01-21 12:39:11,043 - trainer - INFO -     val_val_gen_loss: 20.63563317963571
2025-01-21 12:39:11,043 - trainer - INFO -     val_val_perplexity: 1044385714.4242424
2025-01-21 12:39:11,043 - trainer - INFO -     val_val_embedding_sim: 0.4232639345255765
2025-01-21 12:39:11,043 - trainer - INFO - ================================================================================
2025-01-21 12:39:11,043 - trainer - INFO - Starting epoch 173 at 2025-01-21 12:39:11
2025-01-21 12:39:14,768 - trainer - INFO - Epoch 173 completed at 2025-01-21 12:39:14
2025-01-21 12:39:14,768 - trainer - INFO -     epoch          : 173
2025-01-21 12:39:14,768 - trainer - INFO -     elapsed time   : 3.724567174911499
2025-01-21 12:39:14,768 - trainer - INFO -     loss           : 0.09063923303037882
2025-01-21 12:39:14,768 - trainer - INFO -     sim_loss       : 0.3018757522106171
2025-01-21 12:39:14,768 - trainer - INFO -     gen_loss       : 0.00010928871852229349
2025-01-21 12:39:14,768 - trainer - INFO -     val_val_loss   : 14.480649745825565
2025-01-21 12:39:14,768 - trainer - INFO -     val_val_sim_loss: 0.02101367712020874
2025-01-21 12:39:14,768 - trainer - INFO -     val_val_gen_loss: 20.67763704242128
2025-01-21 12:39:14,768 - trainer - INFO -     val_val_perplexity: 997067562.4242424
2025-01-21 12:39:14,768 - trainer - INFO -     val_val_embedding_sim: 0.4232714158115965
2025-01-21 12:39:14,768 - trainer - INFO - ================================================================================
2025-01-21 12:39:14,768 - trainer - INFO - Starting epoch 174 at 2025-01-21 12:39:14
2025-01-21 12:39:18,486 - trainer - INFO - Epoch 174 completed at 2025-01-21 12:39:18
2025-01-21 12:39:18,486 - trainer - INFO -     epoch          : 174
2025-01-21 12:39:18,486 - trainer - INFO -     elapsed time   : 3.717531681060791
2025-01-21 12:39:18,486 - trainer - INFO -     loss           : 0.0832915611572389
2025-01-21 12:39:18,486 - trainer - INFO -     sim_loss       : 0.277394562028087
2025-01-21 12:39:18,486 - trainer - INFO -     gen_loss       : 0.00010455648589413613
2025-01-21 12:39:18,486 - trainer - INFO -     val_val_loss   : 14.505187699289033
2025-01-21 12:39:18,486 - trainer - INFO -     val_val_sim_loss: 0.09988222338936373
2025-01-21 12:39:18,486 - trainer - INFO -     val_val_gen_loss: 20.678889939279266
2025-01-21 12:39:18,486 - trainer - INFO -     val_val_perplexity: 958042199.2727273
2025-01-21 12:39:18,487 - trainer - INFO -     val_val_embedding_sim: 0.42314905470067804
2025-01-21 12:39:18,487 - trainer - INFO - ================================================================================
2025-01-21 12:39:18,487 - trainer - INFO - Starting epoch 175 at 2025-01-21 12:39:18
2025-01-21 12:39:22,218 - trainer - INFO - Epoch 175 completed at 2025-01-21 12:39:22
2025-01-21 12:39:22,218 - trainer - INFO -     epoch          : 175
2025-01-21 12:39:22,218 - trainer - INFO -     elapsed time   : 3.730821371078491
2025-01-21 12:39:22,218 - trainer - INFO -     loss           : 0.10149615267291665
2025-01-21 12:39:22,218 - trainer - INFO -     sim_loss       : 0.33807133696973324
2025-01-21 12:39:22,218 - trainer - INFO -     gen_loss       : 0.00010678388280211948
2025-01-21 12:39:22,218 - trainer - INFO -     val_val_loss   : 14.636362769386984
2025-01-21 12:39:22,218 - trainer - INFO -     val_val_sim_loss: 0.4411023746837269
2025-01-21 12:39:22,218 - trainer - INFO -     val_val_gen_loss: 20.720045552109227
2025-01-21 12:39:22,218 - trainer - INFO -     val_val_perplexity: 1696985522.4242425
2025-01-21 12:39:22,218 - trainer - INFO -     val_val_embedding_sim: 0.4210561649365859
2025-01-21 12:39:27,528 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch175.pth ...
2025-01-21 12:39:27,529 - trainer - INFO - ================================================================================
2025-01-21 12:39:27,529 - trainer - INFO - Starting epoch 176 at 2025-01-21 12:39:27
2025-01-21 12:39:31,326 - trainer - INFO - Epoch 176 completed at 2025-01-21 12:39:31
2025-01-21 12:39:31,326 - trainer - INFO -     epoch          : 176
2025-01-21 12:39:31,326 - trainer - INFO -     elapsed time   : 3.7970917224884033
2025-01-21 12:39:31,326 - trainer - INFO -     loss           : 0.1006890815566294
2025-01-21 12:39:31,326 - trainer - INFO -     sim_loss       : 0.3353791575877267
2025-01-21 12:39:31,326 - trainer - INFO -     gen_loss       : 0.00010761028825072572
2025-01-21 12:39:31,326 - trainer - INFO -     val_val_loss   : 14.596199411334414
2025-01-21 12:39:31,326 - trainer - INFO -     val_val_sim_loss: 0.39950350559119024
2025-01-21 12:39:31,327 - trainer - INFO -     val_val_gen_loss: 20.680498758951824
2025-01-21 12:39:31,327 - trainer - INFO -     val_val_perplexity: 964529051.1515151
2025-01-21 12:39:31,327 - trainer - INFO -     val_val_embedding_sim: 0.4226898311665564
2025-01-21 12:39:31,327 - trainer - INFO - ================================================================================
2025-01-21 12:39:31,327 - trainer - INFO - Starting epoch 177 at 2025-01-21 12:39:31
2025-01-21 12:39:35,055 - trainer - INFO - Epoch 177 completed at 2025-01-21 12:39:35
2025-01-21 12:39:35,055 - trainer - INFO -     epoch          : 177
2025-01-21 12:39:35,055 - trainer - INFO -     elapsed time   : 3.7282485961914062
2025-01-21 12:39:35,055 - trainer - INFO -     loss           : 0.09697631403105333
2025-01-21 12:39:35,055 - trainer - INFO -     sim_loss       : 0.32300702482225463
2025-01-21 12:39:35,055 - trainer - INFO -     gen_loss       : 0.00010600042151054367
2025-01-21 12:39:35,055 - trainer - INFO -     val_val_loss   : 14.699307094920766
2025-01-21 12:39:35,055 - trainer - INFO -     val_val_sim_loss: 0.6002215255390514
2025-01-21 12:39:35,055 - trainer - INFO -     val_val_gen_loss: 20.741771697998047
2025-01-21 12:39:35,055 - trainer - INFO -     val_val_perplexity: 1059738575.030303
2025-01-21 12:39:35,055 - trainer - INFO -     val_val_embedding_sim: 0.42154070464047516
2025-01-21 12:39:35,056 - trainer - INFO - ================================================================================
2025-01-21 12:39:35,056 - trainer - INFO - Starting epoch 178 at 2025-01-21 12:39:35
2025-01-21 12:39:38,778 - trainer - INFO - Epoch 178 completed at 2025-01-21 12:39:38
2025-01-21 12:39:38,778 - trainer - INFO -     epoch          : 178
2025-01-21 12:39:38,778 - trainer - INFO -     elapsed time   : 3.7219295501708984
2025-01-21 12:39:38,778 - trainer - INFO -     loss           : 0.09164824132603826
2025-01-21 12:39:38,778 - trainer - INFO -     sim_loss       : 0.3052491266276661
2025-01-21 12:39:38,778 - trainer - INFO -     gen_loss       : 0.00010499942800379358
2025-01-21 12:39:38,778 - trainer - INFO -     val_val_loss   : 14.690343076532537
2025-01-21 12:39:38,778 - trainer - INFO -     val_val_sim_loss: 0.5582087039947501
2025-01-21 12:39:38,778 - trainer - INFO -     val_val_gen_loss: 20.7469719395493
2025-01-21 12:39:38,778 - trainer - INFO -     val_val_perplexity: 1069249676.6060606
2025-01-21 12:39:38,778 - trainer - INFO -     val_val_embedding_sim: 0.4225212534268697
2025-01-21 12:39:38,778 - trainer - INFO - ================================================================================
2025-01-21 12:39:38,778 - trainer - INFO - Starting epoch 179 at 2025-01-21 12:39:38
2025-01-21 12:39:42,506 - trainer - INFO - Epoch 179 completed at 2025-01-21 12:39:42
2025-01-21 12:39:42,506 - trainer - INFO -     epoch          : 179
2025-01-21 12:39:42,506 - trainer - INFO -     elapsed time   : 3.7273921966552734
2025-01-21 12:39:42,506 - trainer - INFO -     loss           : 0.10630589202046395
2025-01-21 12:39:42,506 - trainer - INFO -     sim_loss       : 0.3541040509939194
2025-01-21 12:39:42,506 - trainer - INFO -     gen_loss       : 0.00010667756432667375
2025-01-21 12:39:42,506 - trainer - INFO -     val_val_loss   : 14.529088280417703
2025-01-21 12:39:42,506 - trainer - INFO -     val_val_sim_loss: 0.08402176336808638
2025-01-21 12:39:42,506 - trainer - INFO -     val_val_gen_loss: 20.71983123548103
2025-01-21 12:39:42,506 - trainer - INFO -     val_val_perplexity: 1135762323.3939395
2025-01-21 12:39:42,506 - trainer - INFO -     val_val_embedding_sim: 0.42335671999237756
2025-01-21 12:39:42,506 - trainer - INFO - ================================================================================
2025-01-21 12:39:42,506 - trainer - INFO - Starting epoch 180 at 2025-01-21 12:39:42
2025-01-21 12:39:46,216 - trainer - INFO - Epoch 180 completed at 2025-01-21 12:39:46
2025-01-21 12:39:46,216 - trainer - INFO -     epoch          : 180
2025-01-21 12:39:46,216 - trainer - INFO -     elapsed time   : 3.7092370986938477
2025-01-21 12:39:46,216 - trainer - INFO -     loss           : 0.11330475136637688
2025-01-21 12:39:46,216 - trainer - INFO -     sim_loss       : 0.37745066434144975
2025-01-21 12:39:46,216 - trainer - INFO -     gen_loss       : 9.935179332387634e-05
2025-01-21 12:39:46,216 - trainer - INFO -     val_val_loss   : 14.557151332046047
2025-01-21 12:39:46,216 - trainer - INFO -     val_val_sim_loss: 0.2520690181038588
2025-01-21 12:39:46,216 - trainer - INFO -     val_val_gen_loss: 20.68790117899577
2025-01-21 12:39:46,216 - trainer - INFO -     val_val_perplexity: 967561627.1515151
2025-01-21 12:39:46,216 - trainer - INFO -     val_val_embedding_sim: 0.4218632497570731
2025-01-21 12:39:51,530 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch180.pth ...
2025-01-21 12:39:51,530 - trainer - INFO - ================================================================================
2025-01-21 12:39:51,530 - trainer - INFO - Starting epoch 181 at 2025-01-21 12:39:51
2025-01-21 12:39:55,312 - trainer - INFO - Epoch 181 completed at 2025-01-21 12:39:55
2025-01-21 12:39:55,312 - trainer - INFO -     epoch          : 181
2025-01-21 12:39:55,312 - trainer - INFO -     elapsed time   : 3.7813520431518555
2025-01-21 12:39:55,312 - trainer - INFO -     loss           : 0.0790620499290526
2025-01-21 12:39:55,312 - trainer - INFO -     sim_loss       : 0.2633073817938566
2025-01-21 12:39:55,312 - trainer - INFO -     gen_loss       : 9.97595037915744e-05
2025-01-21 12:39:55,312 - trainer - INFO -     val_val_loss   : 14.486394968899814
2025-01-21 12:39:55,312 - trainer - INFO -     val_val_sim_loss: 3.612400646626625e-08
2025-01-21 12:39:55,312 - trainer - INFO -     val_val_gen_loss: 20.694850748235528
2025-01-21 12:39:55,312 - trainer - INFO -     val_val_perplexity: 1120179851.6363637
2025-01-21 12:39:55,312 - trainer - INFO -     val_val_embedding_sim: 0.42332503154422296
2025-01-21 12:39:55,312 - trainer - INFO - ================================================================================
2025-01-21 12:39:55,312 - trainer - INFO - Starting epoch 182 at 2025-01-21 12:39:55
2025-01-21 12:39:59,036 - trainer - INFO - Epoch 182 completed at 2025-01-21 12:39:59
2025-01-21 12:39:59,036 - trainer - INFO -     epoch          : 182
2025-01-21 12:39:59,036 - trainer - INFO -     elapsed time   : 3.7236039638519287
2025-01-21 12:39:59,036 - trainer - INFO -     loss           : 0.09263508073054254
2025-01-21 12:39:59,036 - trainer - INFO -     sim_loss       : 0.3085598453879356
2025-01-21 12:39:59,036 - trainer - INFO -     gen_loss       : 9.589072287781164e-05
2025-01-21 12:39:59,036 - trainer - INFO -     val_val_loss   : 14.498048840147076
2025-01-21 12:39:59,036 - trainer - INFO -     val_val_sim_loss: 0.0420097799012138
2025-01-21 12:39:59,036 - trainer - INFO -     val_val_gen_loss: 20.693494565559156
2025-01-21 12:39:59,036 - trainer - INFO -     val_val_perplexity: 972848946.4242424
2025-01-21 12:39:59,036 - trainer - INFO -     val_val_embedding_sim: 0.42321039510495734
2025-01-21 12:39:59,036 - trainer - INFO - ================================================================================
2025-01-21 12:39:59,036 - trainer - INFO - Starting epoch 183 at 2025-01-21 12:39:59
2025-01-21 12:40:02,764 - trainer - INFO - Epoch 183 completed at 2025-01-21 12:40:02
2025-01-21 12:40:02,764 - trainer - INFO -     epoch          : 183
2025-01-21 12:40:02,764 - trainer - INFO -     elapsed time   : 3.727125883102417
2025-01-21 12:40:02,764 - trainer - INFO -     loss           : 0.05738919237628579
2025-01-21 12:40:02,764 - trainer - INFO -     sim_loss       : 0.19106720797717572
2025-01-21 12:40:02,764 - trainer - INFO -     gen_loss       : 9.86107588687446e-05
2025-01-21 12:40:02,764 - trainer - INFO -     val_val_loss   : 14.552822835517652
2025-01-21 12:40:02,764 - trainer - INFO -     val_val_sim_loss: 0.1628878333351829
2025-01-21 12:40:02,764 - trainer - INFO -     val_val_gen_loss: 20.71993908737645
2025-01-21 12:40:02,764 - trainer - INFO -     val_val_perplexity: 1004927892.3636364
2025-01-21 12:40:02,764 - trainer - INFO -     val_val_embedding_sim: 0.42333489024277887
2025-01-21 12:40:02,764 - trainer - INFO - ================================================================================
2025-01-21 12:40:02,764 - trainer - INFO - Starting epoch 184 at 2025-01-21 12:40:02
2025-01-21 12:40:06,477 - trainer - INFO - Epoch 184 completed at 2025-01-21 12:40:06
2025-01-21 12:40:06,477 - trainer - INFO -     epoch          : 184
2025-01-21 12:40:06,477 - trainer - INFO -     elapsed time   : 3.712446689605713
2025-01-21 12:40:06,477 - trainer - INFO -     loss           : 0.07144929062851588
2025-01-21 12:40:06,477 - trainer - INFO -     sim_loss       : 0.23793969563664633
2025-01-21 12:40:06,477 - trainer - INFO -     gen_loss       : 9.625596503610722e-05
2025-01-21 12:40:06,477 - trainer - INFO -     val_val_loss   : 14.553601178255947
2025-01-21 12:40:06,477 - trainer - INFO -     val_val_sim_loss: 0.09754799351547704
2025-01-21 12:40:06,477 - trainer - INFO -     val_val_gen_loss: 20.749052105527937
2025-01-21 12:40:06,477 - trainer - INFO -     val_val_perplexity: 1265420691.3939395
2025-01-21 12:40:06,477 - trainer - INFO -     val_val_embedding_sim: 0.42297118721586285
2025-01-21 12:40:06,477 - trainer - INFO - ================================================================================
2025-01-21 12:40:06,477 - trainer - INFO - Starting epoch 185 at 2025-01-21 12:40:06
2025-01-21 12:40:10,206 - trainer - INFO - Epoch 185 completed at 2025-01-21 12:40:10
2025-01-21 12:40:10,206 - trainer - INFO -     epoch          : 185
2025-01-21 12:40:10,206 - trainer - INFO -     elapsed time   : 3.7282166481018066
2025-01-21 12:40:10,206 - trainer - INFO -     loss           : 0.09500229243785725
2025-01-21 12:40:10,206 - trainer - INFO -     sim_loss       : 0.31644647565371997
2025-01-21 12:40:10,206 - trainer - INFO -     gen_loss       : 9.763345151441172e-05
2025-01-21 12:40:10,206 - trainer - INFO -     val_val_loss   : 14.57465969432484
2025-01-21 12:40:10,206 - trainer - INFO -     val_val_sim_loss: 0.17961723154241388
2025-01-21 12:40:10,206 - trainer - INFO -     val_val_gen_loss: 20.74396428194913
2025-01-21 12:40:10,206 - trainer - INFO -     val_val_perplexity: 1021552413.0909091
2025-01-21 12:40:10,206 - trainer - INFO -     val_val_embedding_sim: 0.4233486733653329
2025-01-21 12:40:15,514 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch185.pth ...
2025-01-21 12:40:15,514 - trainer - INFO - ================================================================================
2025-01-21 12:40:15,514 - trainer - INFO - Starting epoch 186 at 2025-01-21 12:40:15
2025-01-21 12:40:19,286 - trainer - INFO - Epoch 186 completed at 2025-01-21 12:40:19
2025-01-21 12:40:19,286 - trainer - INFO -     epoch          : 186
2025-01-21 12:40:19,286 - trainer - INFO -     elapsed time   : 3.7713968753814697
2025-01-21 12:40:19,286 - trainer - INFO -     loss           : 0.0782951444387436
2025-01-21 12:40:19,286 - trainer - INFO -     sim_loss       : 0.26075153015553953
2025-01-21 12:40:19,286 - trainer - INFO -     gen_loss       : 9.95459922705777e-05
2025-01-21 12:40:19,286 - trainer - INFO -     val_val_loss   : 14.555773850643273
2025-01-21 12:40:19,286 - trainer - INFO -     val_val_sim_loss: 0.12555132128975607
2025-01-21 12:40:19,287 - trainer - INFO -     val_val_gen_loss: 20.740155306729402
2025-01-21 12:40:19,287 - trainer - INFO -     val_val_perplexity: 1017647806.060606
2025-01-21 12:40:19,287 - trainer - INFO -     val_val_embedding_sim: 0.42335074598138983
2025-01-21 12:40:19,287 - trainer - INFO - ================================================================================
2025-01-21 12:40:19,287 - trainer - INFO - Starting epoch 187 at 2025-01-21 12:40:19
2025-01-21 12:43:06,882 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:43:09,275 - trainer - INFO - 
================================================================================
2025-01-21 12:43:09,275 - trainer - INFO - Starting epoch 1 at 2025-01-21 12:43:09
2025-01-21 12:46:12,946 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:46:15,259 - trainer - INFO - 
================================================================================
2025-01-21 12:46:15,259 - trainer - INFO - Starting epoch 1 at 2025-01-21 12:46:15
2025-01-21 12:50:04,942 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:52:02,094 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:52:04,406 - trainer - INFO - 
================================================================================
2025-01-21 12:52:04,406 - trainer - INFO - Starting epoch 1 at 2025-01-21 12:52:04
2025-01-21 12:55:46,162 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:57:57,134 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 12:58:04,658 - trainer - INFO -     epoch          : 1
2025-01-21 12:58:04,658 - trainer - INFO -     loss           : 7.44499379938299
2025-01-21 12:58:04,658 - trainer - INFO -     sim_loss       : 2.813464748136925
2025-01-21 12:58:04,658 - trainer - INFO -     gen_loss       : 9.429935339725379
2025-01-21 12:58:04,658 - trainer - INFO -     val_loss       : 7.4923428333166875
2025-01-21 12:58:04,658 - trainer - INFO -     val_sim_loss   : 2.955413153677276
2025-01-21 12:58:04,658 - trainer - INFO -     val_gen_loss   : 9.436741554375851
2025-01-21 12:58:04,658 - trainer - INFO -     val_perplexity : 12973.939774946733
2025-01-21 12:58:04,658 - trainer - INFO -     val_embedding_sim: 0.3151333693302039
2025-01-21 12:58:04,658 - trainer - INFO -     perplexity     : 12462.661991003788
2025-01-21 12:58:04,658 - trainer - INFO -     embedding_sim  : 0.3141968051592509
2025-01-21 12:58:08,612 - trainer - INFO -     epoch          : 2
2025-01-21 12:58:08,612 - trainer - INFO -     loss           : 7.271693142977628
2025-01-21 12:58:08,612 - trainer - INFO -     sim_loss       : 0.6131228533658114
2025-01-21 12:58:08,612 - trainer - INFO -     gen_loss       : 10.125366268735943
2025-01-21 12:58:08,612 - trainer - INFO -     val_loss       : 7.314260396090421
2025-01-21 12:58:08,612 - trainer - INFO -     val_sim_loss   : 0.7475933595137163
2025-01-21 12:58:08,612 - trainer - INFO -     val_gen_loss   : 10.128546454689719
2025-01-21 12:58:08,612 - trainer - INFO -     val_perplexity : 25185.848603219696
2025-01-21 12:58:08,612 - trainer - INFO -     val_embedding_sim: 0.3984655232140512
2025-01-21 12:58:08,612 - trainer - INFO -     perplexity     : 25107.70975378788
2025-01-21 12:58:08,612 - trainer - INFO -     embedding_sim  : 0.3984655010880846
2025-01-21 12:58:12,554 - trainer - INFO -     epoch          : 3
2025-01-21 12:58:12,555 - trainer - INFO -     loss           : 8.192708564527107
2025-01-21 12:58:12,555 - trainer - INFO -     sim_loss       : 0.7433510693636808
2025-01-21 12:58:12,555 - trainer - INFO -     gen_loss       : 11.38529109954834
2025-01-21 12:58:12,555 - trainer - INFO -     val_loss       : 8.342807191790957
2025-01-21 12:58:12,555 - trainer - INFO -     val_sim_loss   : 1.119072209676784
2025-01-21 12:58:12,555 - trainer - INFO -     val_gen_loss   : 11.438693393360484
2025-01-21 12:58:12,555 - trainer - INFO -     val_perplexity : 98293.82537286932
2025-01-21 12:58:12,555 - trainer - INFO -     val_embedding_sim: 0.42206268057678686
2025-01-21 12:58:12,555 - trainer - INFO -     perplexity     : 88037.71756628787
2025-01-21 12:58:12,555 - trainer - INFO -     embedding_sim  : 0.42206266973957873
2025-01-21 12:58:16,502 - trainer - INFO -     epoch          : 4
2025-01-21 12:58:16,502 - trainer - INFO -     loss           : 9.109179959152684
2025-01-21 12:58:16,502 - trainer - INFO -     sim_loss       : 0.5795493712930968
2025-01-21 12:58:16,503 - trainer - INFO -     gen_loss       : 12.764736435630105
2025-01-21 12:58:16,503 - trainer - INFO -     val_loss       : 9.145843592557041
2025-01-21 12:58:16,503 - trainer - INFO -     val_sim_loss   : 0.6974109056702053
2025-01-21 12:58:16,503 - trainer - INFO -     val_gen_loss   : 12.766600464329574
2025-01-21 12:58:16,503 - trainer - INFO -     val_perplexity : 353696.39015151514
2025-01-21 12:58:16,503 - trainer - INFO -     val_embedding_sim: 0.41952863245299366
2025-01-21 12:58:16,503 - trainer - INFO -     perplexity     : 350654.7850378788
2025-01-21 12:58:16,503 - trainer - INFO -     embedding_sim  : 0.4195286180033828
2025-01-21 12:58:20,429 - trainer - INFO -     epoch          : 5
2025-01-21 12:58:20,430 - trainer - INFO -     loss           : 9.649950114163486
2025-01-21 12:58:20,430 - trainer - INFO -     sim_loss       : 0.15522659186160925
2025-01-21 12:58:20,430 - trainer - INFO -     gen_loss       : 13.719117135712594
2025-01-21 12:58:20,430 - trainer - INFO -     val_loss       : 9.818115465568773
2025-01-21 12:58:20,430 - trainer - INFO -     val_sim_loss   : 0.7076339147796248
2025-01-21 12:58:20,430 - trainer - INFO -     val_gen_loss   : 13.72260741031531
2025-01-21 12:58:20,430 - trainer - INFO -     val_perplexity : 911783.6742424242
2025-01-21 12:58:20,430 - trainer - INFO -     val_embedding_sim: 0.4199349248048031
2025-01-21 12:58:20,430 - trainer - INFO -     perplexity     : 913068.7339015151
2025-01-21 12:58:20,430 - trainer - INFO -     embedding_sim  : 0.4199349112582929
2025-01-21 12:58:25,655 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 12:58:29,651 - trainer - INFO -     epoch          : 6
2025-01-21 12:58:29,651 - trainer - INFO -     loss           : 9.997054678021055
2025-01-21 12:58:29,651 - trainer - INFO -     sim_loss       : 0.36276073200684605
2025-01-21 12:58:29,651 - trainer - INFO -     gen_loss       : 14.12603826233835
2025-01-21 12:58:29,651 - trainer - INFO -     val_loss       : 10.065348133896336
2025-01-21 12:58:29,651 - trainer - INFO -     val_sim_loss   : 0.583922941802126
2025-01-21 12:58:29,651 - trainer - INFO -     val_gen_loss   : 14.12881579543605
2025-01-21 12:58:29,651 - trainer - INFO -     val_perplexity : 1638025.4242424243
2025-01-21 12:58:29,651 - trainer - INFO -     val_embedding_sim: 0.4207082444971258
2025-01-21 12:58:29,651 - trainer - INFO -     perplexity     : 1364737.3333333333
2025-01-21 12:58:29,651 - trainer - INFO -     embedding_sim  : 0.4207082517219312
2025-01-21 12:58:33,592 - trainer - INFO -     epoch          : 7
2025-01-21 12:58:33,592 - trainer - INFO -     loss           : 10.280195033911502
2025-01-21 12:58:33,592 - trainer - INFO -     sim_loss       : 0.38802686240601225
2025-01-21 12:58:33,592 - trainer - INFO -     gen_loss       : 14.519695628773082
2025-01-21 12:58:33,592 - trainer - INFO -     val_loss       : 10.226223252036355
2025-01-21 12:58:33,592 - trainer - INFO -     val_sim_loss   : 0.20867100987313528
2025-01-21 12:58:33,593 - trainer - INFO -     val_gen_loss   : 14.519459666627826
2025-01-21 12:58:33,593 - trainer - INFO -     val_perplexity : 2023848.0984848484
2025-01-21 12:58:33,593 - trainer - INFO -     val_embedding_sim: 0.419834472916343
2025-01-21 12:58:33,593 - trainer - INFO -     perplexity     : 2054910.696969697
2025-01-21 12:58:33,593 - trainer - INFO -     embedding_sim  : 0.4198344656915376
2025-01-21 12:58:37,527 - trainer - INFO -     epoch          : 8
2025-01-21 12:58:37,528 - trainer - INFO -     loss           : 10.746594978101326
2025-01-21 12:58:37,528 - trainer - INFO -     sim_loss       : 0.9608145952217704
2025-01-21 12:58:37,528 - trainer - INFO -     gen_loss       : 14.940500952980734
2025-01-21 12:58:37,528 - trainer - INFO -     val_loss       : 10.594347433610396
2025-01-21 12:58:37,528 - trainer - INFO -     val_sim_loss   : 0.41204335834040784
2025-01-21 12:58:37,528 - trainer - INFO -     val_gen_loss   : 14.95819242072828
2025-01-21 12:58:37,528 - trainer - INFO -     val_perplexity : 3458521.878787879
2025-01-21 12:58:37,528 - trainer - INFO -     val_embedding_sim: 0.41936966234987433
2025-01-21 12:58:37,528 - trainer - INFO -     perplexity     : 3088467.409090909
2025-01-21 12:58:37,528 - trainer - INFO -     embedding_sim  : 0.4196133758082534
2025-01-21 12:58:41,476 - trainer - INFO -     epoch          : 9
2025-01-21 12:58:41,477 - trainer - INFO -     loss           : 10.796152461658824
2025-01-21 12:58:41,477 - trainer - INFO -     sim_loss       : 0.38157599893483246
2025-01-21 12:58:41,477 - trainer - INFO -     gen_loss       : 15.2595421184193
2025-01-21 12:58:41,477 - trainer - INFO -     val_loss       : 10.812015475648822
2025-01-21 12:58:41,477 - trainer - INFO -     val_sim_loss   : 0.4305105248508467
2025-01-21 12:58:41,477 - trainer - INFO -     val_gen_loss   : 15.261232867385402
2025-01-21 12:58:41,477 - trainer - INFO -     val_perplexity : 4249089.242424242
2025-01-21 12:58:41,477 - trainer - INFO -     val_embedding_sim: 0.41930530107382574
2025-01-21 12:58:41,477 - trainer - INFO -     perplexity     : 4239420.363636363
2025-01-21 12:58:41,477 - trainer - INFO -     embedding_sim  : 0.4193052884304162
2025-01-21 12:58:45,418 - trainer - INFO -     epoch          : 10
2025-01-21 12:58:45,418 - trainer - INFO -     loss           : 10.91920147520123
2025-01-21 12:58:45,418 - trainer - INFO -     sim_loss       : 0.22776351846528775
2025-01-21 12:58:45,418 - trainer - INFO -     gen_loss       : 15.501246770222982
2025-01-21 12:58:45,418 - trainer - INFO -     val_loss       : 11.027160095446037
2025-01-21 12:58:45,418 - trainer - INFO -     val_sim_loss   : 0.5925024674121012
2025-01-21 12:58:45,418 - trainer - INFO -     val_gen_loss   : 15.49915651841597
2025-01-21 12:58:45,418 - trainer - INFO -     val_perplexity : 5392744.348484849
2025-01-21 12:58:45,418 - trainer - INFO -     val_embedding_sim: 0.4197895581072027
2025-01-21 12:58:45,418 - trainer - INFO -     perplexity     : 6355733.939393939
2025-01-21 12:58:45,418 - trainer - INFO -     embedding_sim  : 0.41936694130753027
2025-01-21 12:58:50,645 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 12:58:54,626 - trainer - INFO -     epoch          : 11
2025-01-21 12:58:54,626 - trainer - INFO -     loss           : 10.990156896186598
2025-01-21 12:58:54,626 - trainer - INFO -     sim_loss       : 0.8867867159706568
2025-01-21 12:58:54,626 - trainer - INFO -     gen_loss       : 15.320173205751361
2025-01-21 12:58:54,626 - trainer - INFO -     val_loss       : 10.800532572197191
2025-01-21 12:58:54,626 - trainer - INFO -     val_sim_loss   : 0.3155372352343737
2025-01-21 12:58:54,626 - trainer - INFO -     val_gen_loss   : 15.294102582064541
2025-01-21 12:58:54,626 - trainer - INFO -     val_perplexity : 4391316.886363637
2025-01-21 12:58:54,626 - trainer - INFO -     val_embedding_sim: 0.4194182410384669
2025-01-21 12:58:54,626 - trainer - INFO -     perplexity     : 4754194.181818182
2025-01-21 12:58:54,626 - trainer - INFO -     embedding_sim  : 0.41907956970460486
2025-01-21 12:58:58,584 - trainer - INFO -     epoch          : 12
2025-01-21 12:58:58,584 - trainer - INFO -     loss           : 11.28548307129831
2025-01-21 12:58:58,584 - trainer - INFO -     sim_loss       : 0.712741069495678
2025-01-21 12:58:58,584 - trainer - INFO -     gen_loss       : 15.816658020019531
2025-01-21 12:58:58,584 - trainer - INFO -     val_loss       : 11.21288790847316
2025-01-21 12:58:58,584 - trainer - INFO -     val_sim_loss   : 0.45149455016309564
2025-01-21 12:58:58,584 - trainer - INFO -     val_gen_loss   : 15.824913949677438
2025-01-21 12:58:58,584 - trainer - INFO -     val_perplexity : 8805032.484848484
2025-01-21 12:58:58,584 - trainer - INFO -     val_embedding_sim: 0.4197918077309926
2025-01-21 12:58:58,584 - trainer - INFO -     perplexity     : 7398952.515151516
2025-01-21 12:58:58,584 - trainer - INFO -     embedding_sim  : 0.420863951697494
2025-01-21 12:59:02,527 - trainer - INFO -     epoch          : 13
2025-01-21 12:59:02,527 - trainer - INFO -     loss           : 11.477376013091117
2025-01-21 12:59:02,528 - trainer - INFO -     sim_loss       : 0.9340977513153726
2025-01-21 12:59:02,528 - trainer - INFO -     gen_loss       : 15.995923360188803
2025-01-21 12:59:02,528 - trainer - INFO -     val_loss       : 11.276519226305412
2025-01-21 12:59:02,528 - trainer - INFO -     val_sim_loss   : 0.19719898334535008
2025-01-21 12:59:02,528 - trainer - INFO -     val_gen_loss   : 16.024799404722273
2025-01-21 12:59:02,528 - trainer - INFO -     val_perplexity : 20713287.757575758
2025-01-21 12:59:02,528 - trainer - INFO -     val_embedding_sim: 0.4194965168382182
2025-01-21 12:59:02,528 - trainer - INFO -     perplexity     : 9041861.102272727
2025-01-21 12:59:02,528 - trainer - INFO -     embedding_sim  : 0.4194965091618625
2025-01-21 12:59:06,475 - trainer - INFO -     epoch          : 14
2025-01-21 12:59:06,475 - trainer - INFO -     loss           : 11.287049495812619
2025-01-21 12:59:06,475 - trainer - INFO -     sim_loss       : 0.271424190176538
2025-01-21 12:59:06,475 - trainer - INFO -     gen_loss       : 16.008032683170203
2025-01-21 12:59:06,475 - trainer - INFO -     val_loss       : 11.339253338900479
2025-01-21 12:59:06,475 - trainer - INFO -     val_sim_loss   : 0.43303553603420203
2025-01-21 12:59:06,475 - trainer - INFO -     val_gen_loss   : 16.0133469321511
2025-01-21 12:59:06,476 - trainer - INFO -     val_perplexity : 9517068.363636363
2025-01-21 12:59:06,476 - trainer - INFO -     val_embedding_sim: 0.42179824818264355
2025-01-21 12:59:06,476 - trainer - INFO -     perplexity     : 9127835.515151516
2025-01-21 12:59:06,476 - trainer - INFO -     embedding_sim  : 0.421798232829932
2025-01-21 12:59:10,426 - trainer - INFO -     epoch          : 15
2025-01-21 12:59:10,426 - trainer - INFO -     loss           : 11.480426846128521
2025-01-21 12:59:10,426 - trainer - INFO -     sim_loss       : 0.43498042135527637
2025-01-21 12:59:10,426 - trainer - INFO -     gen_loss       : 16.214189702814277
2025-01-21 12:59:10,426 - trainer - INFO -     val_loss       : 11.412595373211484
2025-01-21 12:59:10,426 - trainer - INFO -     val_sim_loss   : 0.27682271468405484
2025-01-21 12:59:10,426 - trainer - INFO -     val_gen_loss   : 16.18506957545425
2025-01-21 12:59:10,426 - trainer - INFO -     val_perplexity : 10706024.93939394
2025-01-21 12:59:10,426 - trainer - INFO -     val_embedding_sim: 0.4196813702583313
2025-01-21 12:59:10,426 - trainer - INFO -     perplexity     : 20885328.484848484
2025-01-21 12:59:10,426 - trainer - INFO -     embedding_sim  : 0.4201502641945174
2025-01-21 13:01:15,962 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 13:01:23,228 - trainer - INFO -     epoch          : 1
2025-01-21 13:01:23,228 - trainer - INFO -     loss           : 7.492318688016949
2025-01-21 13:01:23,228 - trainer - INFO -     sim_loss       : 2.955412257801403
2025-01-21 13:01:23,228 - trainer - INFO -     gen_loss       : 9.436706774162523
2025-01-21 13:01:23,228 - trainer - INFO -     perplexity     : 12540.350622995855
2025-01-21 13:01:23,228 - trainer - INFO -     embedding_sim  : 0.3151333693302039
2025-01-21 13:01:23,228 - trainer - WARNING - Warning: Metric 'val_gen_loss' is not found. Model performance monitoring is disabled.
2025-01-21 13:01:26,936 - trainer - INFO -     epoch          : 2
2025-01-21 13:01:26,936 - trainer - INFO -     loss           : 7.918113968589089
2025-01-21 13:01:26,937 - trainer - INFO -     sim_loss       : 1.523917996522152
2025-01-21 13:01:26,937 - trainer - INFO -     gen_loss       : 10.65848376534202
2025-01-21 13:01:26,937 - trainer - INFO -     perplexity     : 42552.06931385459
2025-01-21 13:01:26,937 - trainer - INFO -     embedding_sim  : 0.4148093552300424
2025-01-21 13:01:30,636 - trainer - INFO -     epoch          : 3
2025-01-21 13:01:30,636 - trainer - INFO -     loss           : 8.441709619579893
2025-01-21 13:01:30,636 - trainer - INFO -     sim_loss       : 0.6025039547433456
2025-01-21 13:01:30,636 - trainer - INFO -     gen_loss       : 11.801369551456336
2025-01-21 13:01:30,636 - trainer - INFO -     perplexity     : 133434.97392543743
2025-01-21 13:01:30,636 - trainer - INFO -     embedding_sim  : 0.42036227746443316
2025-01-21 13:01:34,345 - trainer - INFO -     epoch          : 4
2025-01-21 13:01:34,346 - trainer - INFO -     loss           : 9.683575283397328
2025-01-21 13:01:34,346 - trainer - INFO -     sim_loss       : 1.392853968071215
2025-01-21 13:01:34,346 - trainer - INFO -     gen_loss       : 13.236741586164994
2025-01-21 13:01:34,346 - trainer - INFO -     perplexity     : 560588.0416618314
2025-01-21 13:01:34,346 - trainer - INFO -     embedding_sim  : 0.41997564922679553
2025-01-21 13:01:38,072 - trainer - INFO -     epoch          : 5
2025-01-21 13:01:38,072 - trainer - INFO -     loss           : 9.52921084201697
2025-01-21 13:01:38,072 - trainer - INFO -     sim_loss       : 0.130860133502045
2025-01-21 13:01:38,072 - trainer - INFO -     gen_loss       : 13.557075500488281
2025-01-21 13:01:38,072 - trainer - INFO -     perplexity     : 772259.1818811655
2025-01-21 13:01:38,072 - trainer - INFO -     embedding_sim  : 0.41931650494084216
2025-01-21 13:01:43,304 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 13:01:47,072 - trainer - INFO -     epoch          : 6
2025-01-21 13:01:47,072 - trainer - INFO -     loss           : 10.011014649362275
2025-01-21 13:01:47,072 - trainer - INFO -     sim_loss       : 0.3728877874267654
2025-01-21 13:01:47,072 - trainer - INFO -     gen_loss       : 14.141639882867986
2025-01-21 13:01:47,072 - trainer - INFO -     perplexity     : 1385594.549167953
2025-01-21 13:01:47,072 - trainer - INFO -     embedding_sim  : 0.4185959290374409
2025-01-21 13:01:50,789 - trainer - INFO -     epoch          : 7
2025-01-21 13:01:50,789 - trainer - INFO -     loss           : 10.605303244157271
2025-01-21 13:01:50,789 - trainer - INFO -     sim_loss       : 0.3942671189557366
2025-01-21 13:01:50,790 - trainer - INFO -     gen_loss       : 14.981461438265713
2025-01-21 13:01:50,790 - trainer - INFO -     perplexity     : 3208972.781934894
2025-01-21 13:01:50,790 - trainer - INFO -     embedding_sim  : 0.4183183854276484
2025-01-21 13:01:54,499 - trainer - INFO -     epoch          : 8
2025-01-21 13:01:54,499 - trainer - INFO -     loss           : 10.464568513812441
2025-01-21 13:01:54,499 - trainer - INFO -     sim_loss       : 0.16849393984585098
2025-01-21 13:01:54,499 - trainer - INFO -     gen_loss       : 14.877172036604447
2025-01-21 13:01:54,499 - trainer - INFO -     perplexity     : 2891170.619151389
2025-01-21 13:01:54,499 - trainer - INFO -     embedding_sim  : 0.41797727888280695
2025-01-21 13:01:58,216 - trainer - INFO -     epoch          : 9
2025-01-21 13:01:58,216 - trainer - INFO -     loss           : 11.010851455457283
2025-01-21 13:01:58,217 - trainer - INFO -     sim_loss       : 0.5372148317630601
2025-01-21 13:01:58,217 - trainer - INFO -     gen_loss       : 15.499553738218365
2025-01-21 13:01:58,217 - trainer - INFO -     perplexity     : 5387293.796436776
2025-01-21 13:01:58,217 - trainer - INFO -     embedding_sim  : 0.4179479095971946
2025-01-21 13:02:01,941 - trainer - INFO -     epoch          : 10
2025-01-21 13:02:01,941 - trainer - INFO -     loss           : 11.165334325848203
2025-01-21 13:02:01,941 - trainer - INFO -     sim_loss       : 0.696869741571418
2025-01-21 13:02:01,941 - trainer - INFO -     gen_loss       : 15.651819864908854
2025-01-21 13:02:01,941 - trainer - INFO -     perplexity     : 6273342.501537258
2025-01-21 13:02:01,941 - trainer - INFO -     embedding_sim  : 0.4181587479331277
2025-01-21 13:02:07,167 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 13:02:10,913 - trainer - INFO -     epoch          : 11
2025-01-21 13:02:10,913 - trainer - INFO -     loss           : 10.949459307121508
2025-01-21 13:02:10,913 - trainer - INFO -     sim_loss       : 0.7172874754125421
2025-01-21 13:02:10,913 - trainer - INFO -     gen_loss       : 15.33467639576305
2025-01-21 13:02:10,913 - trainer - INFO -     perplexity     : 4568412.808004578
2025-01-21 13:02:10,913 - trainer - INFO -     embedding_sim  : 0.4212042165525032
2025-01-21 13:02:14,624 - trainer - INFO -     epoch          : 12
2025-01-21 13:02:14,624 - trainer - INFO -     loss           : 11.235791090762977
2025-01-21 13:02:14,624 - trainer - INFO -     sim_loss       : 0.19264240627826162
2025-01-21 13:02:14,624 - trainer - INFO -     gen_loss       : 15.968569033073656
2025-01-21 13:02:14,624 - trainer - INFO -     perplexity     : 8611155.166411392
2025-01-21 13:02:14,624 - trainer - INFO -     embedding_sim  : 0.4168666908235261
2025-01-21 13:02:18,340 - trainer - INFO -     epoch          : 13
2025-01-21 13:02:18,340 - trainer - INFO -     loss           : 11.242034391923385
2025-01-21 13:02:18,340 - trainer - INFO -     sim_loss       : 0.24933323352657186
2025-01-21 13:02:18,340 - trainer - INFO -     gen_loss       : 15.953191988395922
2025-01-21 13:02:18,340 - trainer - INFO -     perplexity     : 8479753.919294622
2025-01-21 13:02:18,340 - trainer - INFO -     embedding_sim  : 0.4220078641718084
2025-01-21 13:02:22,063 - trainer - INFO -     epoch          : 14
2025-01-21 13:02:22,063 - trainer - INFO -     loss           : 11.578865629253965
2025-01-21 13:02:22,063 - trainer - INFO -     sim_loss       : 0.245167392558263
2025-01-21 13:02:22,063 - trainer - INFO -     gen_loss       : 16.43616520274769
2025-01-21 13:02:22,063 - trainer - INFO -     perplexity     : 13744718.548801158
2025-01-21 13:02:22,063 - trainer - INFO -     embedding_sim  : 0.41672574299754517
2025-01-21 13:02:25,782 - trainer - INFO -     epoch          : 15
2025-01-21 13:02:25,782 - trainer - INFO -     loss           : 11.571693073619496
2025-01-21 13:02:25,782 - trainer - INFO -     sim_loss       : 0.20058112072221643
2025-01-21 13:02:25,782 - trainer - INFO -     gen_loss       : 16.4450277559685
2025-01-21 13:02:25,783 - trainer - INFO -     perplexity     : 13867073.235044444
2025-01-21 13:02:25,783 - trainer - INFO -     embedding_sim  : 0.4169906039129604
2025-01-21 13:02:31,013 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 13:02:34,770 - trainer - INFO -     epoch          : 16
2025-01-21 13:02:34,771 - trainer - INFO -     loss           : 11.896291068105986
2025-01-21 13:02:34,771 - trainer - INFO -     sim_loss       : 0.3773890697594845
2025-01-21 13:02:34,771 - trainer - INFO -     gen_loss       : 16.83296382788456
2025-01-21 13:02:34,771 - trainer - INFO -     perplexity     : 20439172.290472254
2025-01-21 13:02:34,771 - trainer - INFO -     embedding_sim  : 0.41713856837966223
2025-01-21 13:02:38,477 - trainer - INFO -     epoch          : 17
2025-01-21 13:02:38,477 - trainer - INFO -     loss           : 11.779777237863252
2025-01-21 13:02:38,477 - trainer - INFO -     sim_loss       : 0.08136202349807277
2025-01-21 13:02:38,477 - trainer - INFO -     gen_loss       : 16.79338397401752
2025-01-21 13:02:38,477 - trainer - INFO -     perplexity     : 19645993.33608908
2025-01-21 13:02:38,477 - trainer - INFO -     embedding_sim  : 0.41730730641971936
2025-01-21 13:02:42,193 - trainer - INFO -     epoch          : 18
2025-01-21 13:02:42,194 - trainer - INFO -     loss           : 12.025782642942486
2025-01-21 13:02:42,194 - trainer - INFO -     sim_loss       : 0.27444831891079957
2025-01-21 13:02:42,194 - trainer - INFO -     gen_loss       : 17.06206818782922
2025-01-21 13:02:42,194 - trainer - INFO -     perplexity     : 25701712.652732115
2025-01-21 13:02:42,194 - trainer - INFO -     embedding_sim  : 0.41729050603779877
2025-01-21 13:02:45,904 - trainer - INFO -     epoch          : 19
2025-01-21 13:02:45,904 - trainer - INFO -     loss           : 12.102868051239938
2025-01-21 13:02:45,904 - trainer - INFO -     sim_loss       : 0.04907091084918868
2025-01-21 13:02:45,904 - trainer - INFO -     gen_loss       : 17.26878093950676
2025-01-21 13:02:45,904 - trainer - INFO -     perplexity     : 31603579.248698756
2025-01-21 13:02:45,904 - trainer - INFO -     embedding_sim  : 0.4190055312532367
2025-01-21 13:02:49,615 - trainer - INFO -     epoch          : 20
2025-01-21 13:02:49,616 - trainer - INFO -     loss           : 12.244438258084385
2025-01-21 13:02:49,616 - trainer - INFO -     sim_loss       : 0.467066551647418
2025-01-21 13:02:49,616 - trainer - INFO -     gen_loss       : 17.291884220007695
2025-01-21 13:02:49,616 - trainer - INFO -     perplexity     : 32342225.323865894
2025-01-21 13:02:49,616 - trainer - INFO -     embedding_sim  : 0.4175833644288959
2025-01-21 13:02:54,851 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 13:02:58,609 - trainer - INFO -     epoch          : 21
2025-01-21 13:02:58,609 - trainer - INFO -     loss           : 12.201827251549924
2025-01-21 13:02:58,609 - trainer - INFO -     sim_loss       : 0.2197404049233724
2025-01-21 13:02:58,609 - trainer - INFO -     gen_loss       : 17.33700769597834
2025-01-21 13:02:58,609 - trainer - INFO -     perplexity     : 33835046.29747306
2025-01-21 13:02:58,609 - trainer - INFO -     embedding_sim  : 0.4175543279358835
2025-01-21 13:03:02,320 - trainer - INFO -     epoch          : 22
2025-01-21 13:03:02,320 - trainer - INFO -     loss           : 12.314453067201557
2025-01-21 13:03:02,320 - trainer - INFO -     sim_loss       : 0.2483844179095644
2025-01-21 13:03:02,320 - trainer - INFO -     gen_loss       : 17.485625758315578
2025-01-21 13:03:02,320 - trainer - INFO -     perplexity     : 39256427.95411736
2025-01-21 13:03:02,320 - trainer - INFO -     embedding_sim  : 0.4208366780570059
2025-01-21 13:03:06,055 - trainer - INFO -     epoch          : 23
2025-01-21 13:03:06,056 - trainer - INFO -     loss           : 12.2207876552235
2025-01-21 13:03:06,056 - trainer - INFO -     sim_loss       : 0.1216332621618428
2025-01-21 13:03:06,056 - trainer - INFO -     gen_loss       : 17.40613989396529
2025-01-21 13:03:06,056 - trainer - INFO -     perplexity     : 36256886.511928946
2025-01-21 13:03:06,056 - trainer - INFO -     embedding_sim  : 0.41805042100675177
2025-01-21 13:03:09,805 - trainer - INFO -     epoch          : 24
2025-01-21 13:03:09,805 - trainer - INFO -     loss           : 12.539910345366508
2025-01-21 13:03:09,805 - trainer - INFO -     sim_loss       : 0.6292902953696801
2025-01-21 13:03:09,805 - trainer - INFO -     gen_loss       : 17.644462036364008
2025-01-21 13:03:09,805 - trainer - INFO -     perplexity     : 46014265.97958617
2025-01-21 13:03:09,805 - trainer - INFO -     embedding_sim  : 0.4208201964696248
2025-01-21 13:03:13,515 - trainer - INFO -     epoch          : 25
2025-01-21 13:03:13,515 - trainer - INFO -     loss           : 12.732644225611832
2025-01-21 13:03:13,515 - trainer - INFO -     sim_loss       : 1.1312936183172828
2025-01-21 13:03:13,515 - trainer - INFO -     gen_loss       : 17.704652179371227
2025-01-21 13:03:13,515 - trainer - INFO -     perplexity     : 48868920.479726605
2025-01-21 13:03:13,515 - trainer - INFO -     embedding_sim  : 0.4196428241151752
2025-01-21 13:03:18,741 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 13:03:22,495 - trainer - INFO -     epoch          : 26
2025-01-21 13:03:22,495 - trainer - INFO -     loss           : 12.415911241011186
2025-01-21 13:03:22,495 - trainer - INFO -     sim_loss       : 0.04277447136965665
2025-01-21 13:03:22,495 - trainer - INFO -     gen_loss       : 17.718684109774504
2025-01-21 13:03:22,495 - trainer - INFO -     perplexity     : 49559479.37737728
2025-01-21 13:03:22,495 - trainer - INFO -     embedding_sim  : 0.41935259826255566
2025-01-21 13:03:26,209 - trainer - INFO -     epoch          : 27
2025-01-21 13:03:26,209 - trainer - INFO -     loss           : 12.492934371485855
2025-01-21 13:03:26,209 - trainer - INFO -     sim_loss       : 0.10535294356922156
2025-01-21 13:03:26,209 - trainer - INFO -     gen_loss       : 17.8018991874926
2025-01-21 13:03:26,209 - trainer - INFO -     perplexity     : 53860029.19993086
2025-01-21 13:03:26,209 - trainer - INFO -     embedding_sim  : 0.41991494144454145
2025-01-21 13:03:29,920 - trainer - INFO -     epoch          : 28
2025-01-21 13:03:29,920 - trainer - INFO -     loss           : 12.507467703385787
2025-01-21 13:03:29,920 - trainer - INFO -     sim_loss       : 0.04269512494403388
2025-01-21 13:03:29,920 - trainer - INFO -     gen_loss       : 17.849513429583926
2025-01-21 13:03:29,920 - trainer - INFO -     perplexity     : 56486567.78782852
2025-01-21 13:03:29,920 - trainer - INFO -     embedding_sim  : 0.4204948585141789
2025-01-21 13:03:33,628 - trainer - INFO -     epoch          : 29
2025-01-21 13:03:33,628 - trainer - INFO -     loss           : 12.656502550298518
2025-01-21 13:03:33,628 - trainer - INFO -     sim_loss       : 0.27228432786774426
2025-01-21 13:03:33,628 - trainer - INFO -     gen_loss       : 17.96402387908011
2025-01-21 13:03:33,628 - trainer - INFO -     perplexity     : 63339764.375976585
2025-01-21 13:03:33,628 - trainer - INFO -     embedding_sim  : 0.4198946546424519
2025-01-21 13:03:37,339 - trainer - INFO -     epoch          : 30
2025-01-21 13:03:37,339 - trainer - INFO -     loss           : 12.728730837504068
2025-01-21 13:03:37,339 - trainer - INFO -     sim_loss       : 0.47153435331402405
2025-01-21 13:03:37,339 - trainer - INFO -     gen_loss       : 17.9818159161192
2025-01-21 13:03:37,339 - trainer - INFO -     perplexity     : 64476792.84176125
2025-01-21 13:03:37,339 - trainer - INFO -     embedding_sim  : 0.41985267400741577
2025-01-21 13:03:42,573 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 13:03:46,335 - trainer - INFO -     epoch          : 31
2025-01-21 13:03:46,335 - trainer - INFO -     loss           : 12.887727910822088
2025-01-21 13:03:46,335 - trainer - INFO -     sim_loss       : 0.7934110091728419
2025-01-21 13:03:46,335 - trainer - INFO -     gen_loss       : 18.07100689049923
2025-01-21 13:03:46,335 - trainer - INFO -     perplexity     : 70491795.87892562
2025-01-21 13:03:46,335 - trainer - INFO -     embedding_sim  : 0.42230985471696564
2025-01-21 13:03:50,052 - trainer - INFO -     epoch          : 32
2025-01-21 13:03:50,052 - trainer - INFO -     loss           : 12.791898120533336
2025-01-21 13:03:50,052 - trainer - INFO -     sim_loss       : 0.3498696811271419
2025-01-21 13:03:50,052 - trainer - INFO -     gen_loss       : 18.124196370442707
2025-01-21 13:03:50,052 - trainer - INFO -     perplexity     : 74342724.43319905
2025-01-21 13:03:50,052 - trainer - INFO -     embedding_sim  : 0.4201829568906264
2025-01-21 13:03:53,770 - trainer - INFO -     epoch          : 33
2025-01-21 13:03:53,770 - trainer - INFO -     loss           : 12.983668703021426
2025-01-21 13:03:53,771 - trainer - INFO -     sim_loss       : 0.8127126404733369
2025-01-21 13:03:53,771 - trainer - INFO -     gen_loss       : 18.19979245734937
2025-01-21 13:03:53,771 - trainer - INFO -     perplexity     : 80180624.77868383
2025-01-21 13:03:53,771 - trainer - INFO -     embedding_sim  : 0.42048396305604413
2025-01-21 13:03:57,480 - trainer - INFO -     epoch          : 34
2025-01-21 13:03:57,480 - trainer - INFO -     loss           : 12.824154073541814
2025-01-21 13:03:57,480 - trainer - INFO -     sim_loss       : 0.18956714354907023
2025-01-21 13:03:57,480 - trainer - INFO -     gen_loss       : 18.238977547847863
2025-01-21 13:03:57,480 - trainer - INFO -     perplexity     : 83384879.32615307
2025-01-21 13:03:57,480 - trainer - INFO -     embedding_sim  : 0.4206618142850471
2025-01-21 13:04:01,210 - trainer - INFO -     epoch          : 35
2025-01-21 13:04:01,210 - trainer - INFO -     loss           : 12.900241822907418
2025-01-21 13:04:01,210 - trainer - INFO -     sim_loss       : 0.3659122026327781
2025-01-21 13:04:01,210 - trainer - INFO -     gen_loss       : 18.272098310065992
2025-01-21 13:04:01,210 - trainer - INFO -     perplexity     : 86192895.20885673
2025-01-21 13:04:01,210 - trainer - INFO -     embedding_sim  : 0.4195422078623916
2025-01-21 13:04:06,444 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 13:04:10,206 - trainer - INFO -     epoch          : 36
2025-01-21 13:04:10,206 - trainer - INFO -     loss           : 12.948451706857393
2025-01-21 13:04:10,206 - trainer - INFO -     sim_loss       : 0.41657397241151833
2025-01-21 13:04:10,206 - trainer - INFO -     gen_loss       : 18.319257042624734
2025-01-21 13:04:10,206 - trainer - INFO -     perplexity     : 90355011.63865837
2025-01-21 13:04:10,206 - trainer - INFO -     embedding_sim  : 0.4202160839781617
2025-01-21 13:04:13,915 - trainer - INFO -     epoch          : 37
2025-01-21 13:04:13,916 - trainer - INFO -     loss           : 12.850973215970127
2025-01-21 13:04:13,916 - trainer - INFO -     sim_loss       : 0.05475613565155954
2025-01-21 13:04:13,916 - trainer - INFO -     gen_loss       : 18.335066361860797
2025-01-21 13:04:13,916 - trainer - INFO -     perplexity     : 91794814.02208215
2025-01-21 13:04:13,916 - trainer - INFO -     embedding_sim  : 0.42023527441602765
2025-01-21 13:04:17,619 - trainer - INFO -     epoch          : 38
2025-01-21 13:04:17,619 - trainer - INFO -     loss           : 13.055070270191539
2025-01-21 13:04:17,619 - trainer - INFO -     sim_loss       : 0.4181284326495546
2025-01-21 13:04:17,619 - trainer - INFO -     gen_loss       : 18.47090380119555
2025-01-21 13:04:17,619 - trainer - INFO -     perplexity     : 105150561.61633182
2025-01-21 13:04:17,619 - trainer - INFO -     embedding_sim  : 0.42178891734643414
2025-01-21 13:04:21,343 - trainer - INFO -     epoch          : 39
2025-01-21 13:04:21,343 - trainer - INFO -     loss           : 13.123224113926742
2025-01-21 13:04:21,343 - trainer - INFO -     sim_loss       : 0.6981791980338802
2025-01-21 13:04:21,343 - trainer - INFO -     gen_loss       : 18.44824253429066
2025-01-21 13:04:21,343 - trainer - INFO -     perplexity     : 102794513.0222267
2025-01-21 13:04:21,343 - trainer - INFO -     embedding_sim  : 0.42127929402120184
2025-01-21 13:04:25,069 - trainer - INFO -     epoch          : 40
2025-01-21 13:04:25,069 - trainer - INFO -     loss           : 13.068295883409904
2025-01-21 13:04:25,069 - trainer - INFO -     sim_loss       : 0.3300240690057928
2025-01-21 13:04:25,069 - trainer - INFO -     gen_loss       : 18.52755610148112
2025-01-21 13:04:25,069 - trainer - INFO -     perplexity     : 111279554.42482872
2025-01-21 13:04:25,069 - trainer - INFO -     embedding_sim  : 0.42052302577278833
2025-01-21 13:04:30,296 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 13:04:34,067 - trainer - INFO -     epoch          : 41
2025-01-21 13:04:34,067 - trainer - INFO -     loss           : 13.027509660431832
2025-01-21 13:04:34,067 - trainer - INFO -     sim_loss       : 0.16001721945675937
2025-01-21 13:04:34,067 - trainer - INFO -     gen_loss       : 18.54214963045987
2025-01-21 13:04:34,067 - trainer - INFO -     perplexity     : 112915423.34468462
2025-01-21 13:04:34,067 - trainer - INFO -     embedding_sim  : 0.4207227826118469
2025-01-21 13:04:37,778 - trainer - INFO -     epoch          : 42
2025-01-21 13:04:37,778 - trainer - INFO -     loss           : 13.102082801587654
2025-01-21 13:04:37,778 - trainer - INFO -     sim_loss       : 0.2716723653403195
2025-01-21 13:04:37,778 - trainer - INFO -     gen_loss       : 18.60083071390788
2025-01-21 13:04:37,778 - trainer - INFO -     perplexity     : 119739692.32204708
2025-01-21 13:04:37,778 - trainer - INFO -     embedding_sim  : 0.4223160003170823
2025-01-21 13:04:41,488 - trainer - INFO -     epoch          : 43
2025-01-21 13:04:41,489 - trainer - INFO -     loss           : 13.093687375386557
2025-01-21 13:04:41,489 - trainer - INFO -     sim_loss       : 0.05447446938689444
2025-01-21 13:04:41,489 - trainer - INFO -     gen_loss       : 18.68192077405525
2025-01-21 13:04:41,489 - trainer - INFO -     perplexity     : 129853931.65551206
2025-01-21 13:04:41,489 - trainer - INFO -     embedding_sim  : 0.42085961320183496
2025-01-21 13:04:45,208 - trainer - INFO -     epoch          : 44
2025-01-21 13:04:45,208 - trainer - INFO -     loss           : 13.244861920674643
2025-01-21 13:04:45,208 - trainer - INFO -     sim_loss       : 0.6209918802433507
2025-01-21 13:04:45,208 - trainer - INFO -     gen_loss       : 18.65509131460479
2025-01-21 13:04:45,208 - trainer - INFO -     perplexity     : 126416341.40711294
2025-01-21 13:04:45,208 - trainer - INFO -     embedding_sim  : 0.42262792948520544
2025-01-21 13:04:48,928 - trainer - INFO -     epoch          : 45
2025-01-21 13:04:48,928 - trainer - INFO -     loss           : 13.1767615404996
2025-01-21 13:04:48,928 - trainer - INFO -     sim_loss       : 0.17717152653314328
2025-01-21 13:04:48,928 - trainer - INFO -     gen_loss       : 18.748014392274797
2025-01-21 13:04:48,929 - trainer - INFO -     perplexity     : 138726425.83654988
2025-01-21 13:04:48,929 - trainer - INFO -     embedding_sim  : 0.42217777985515015
2025-01-21 13:04:54,152 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 13:04:57,899 - trainer - INFO -     epoch          : 46
2025-01-21 13:04:57,899 - trainer - INFO -     loss           : 13.14146952195601
2025-01-21 13:04:57,899 - trainer - INFO -     sim_loss       : 0.12099439447576349
2025-01-21 13:04:57,899 - trainer - INFO -     gen_loss       : 18.72167344526811
2025-01-21 13:04:57,899 - trainer - INFO -     perplexity     : 135119947.9523658
2025-01-21 13:04:57,899 - trainer - INFO -     embedding_sim  : 0.42122967315442633
2025-01-21 13:05:01,632 - trainer - INFO -     epoch          : 47
2025-01-21 13:05:01,632 - trainer - INFO -     loss           : 13.186736453663219
2025-01-21 13:05:01,632 - trainer - INFO -     sim_loss       : 0.16294428073656905
2025-01-21 13:05:01,632 - trainer - INFO -     gen_loss       : 18.768362854466293
2025-01-21 13:05:01,632 - trainer - INFO -     perplexity     : 141578211.5948185
2025-01-21 13:05:01,632 - trainer - INFO -     embedding_sim  : 0.4208119222612092
2025-01-21 13:05:05,339 - trainer - INFO -     epoch          : 48
2025-01-21 13:05:05,340 - trainer - INFO -     loss           : 13.29466368935325
2025-01-21 13:05:05,340 - trainer - INFO -     sim_loss       : 0.44918583739887563
2025-01-21 13:05:05,340 - trainer - INFO -     gen_loss       : 18.799868901570637
2025-01-21 13:05:05,340 - trainer - INFO -     perplexity     : 146109792.65871456
2025-01-21 13:05:05,340 - trainer - INFO -     embedding_sim  : 0.4233185359925935
2025-01-21 13:05:09,068 - trainer - INFO -     epoch          : 49
2025-01-21 13:05:09,069 - trainer - INFO -     loss           : 13.398882143425219
2025-01-21 13:05:09,069 - trainer - INFO -     sim_loss       : 0.7574937415845466
2025-01-21 13:05:09,069 - trainer - INFO -     gen_loss       : 18.816621086814187
2025-01-21 13:05:09,069 - trainer - INFO -     perplexity     : 148578067.74842307
2025-01-21 13:05:09,069 - trainer - INFO -     embedding_sim  : 0.4229144634622516
2025-01-21 13:05:12,784 - trainer - INFO -     epoch          : 50
2025-01-21 13:05:12,784 - trainer - INFO -     loss           : 13.355286020221133
2025-01-21 13:05:12,784 - trainer - INFO -     sim_loss       : 0.4157408511999744
2025-01-21 13:05:12,784 - trainer - INFO -     gen_loss       : 18.900805733420633
2025-01-21 13:05:12,784 - trainer - INFO -     perplexity     : 161627640.70970836
2025-01-21 13:05:12,784 - trainer - INFO -     embedding_sim  : 0.4231384748762304
2025-01-21 13:05:18,013 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 13:05:21,788 - trainer - INFO -     epoch          : 51
2025-01-21 13:05:21,788 - trainer - INFO -     loss           : 13.270060828237822
2025-01-21 13:05:21,788 - trainer - INFO -     sim_loss       : 0.10088427812672418
2025-01-21 13:05:21,788 - trainer - INFO -     gen_loss       : 18.913993719852332
2025-01-21 13:05:21,788 - trainer - INFO -     perplexity     : 163773301.21497408
2025-01-21 13:05:21,788 - trainer - INFO -     embedding_sim  : 0.42265130534316553
2025-01-21 13:05:25,494 - trainer - INFO -     epoch          : 52
2025-01-21 13:05:25,494 - trainer - INFO -     loss           : 13.315015677249793
2025-01-21 13:05:25,494 - trainer - INFO -     sim_loss       : 0.11847327333508094
2025-01-21 13:05:25,494 - trainer - INFO -     gen_loss       : 18.970677635886453
2025-01-21 13:05:25,494 - trainer - INFO -     perplexity     : 173324763.08111444
2025-01-21 13:05:25,494 - trainer - INFO -     embedding_sim  : 0.4232437285509976
2025-01-21 13:05:29,206 - trainer - INFO -     epoch          : 53
2025-01-21 13:05:29,206 - trainer - INFO -     loss           : 13.309683684146766
2025-01-21 13:05:29,206 - trainer - INFO -     sim_loss       : 0.16827896507757859
2025-01-21 13:05:29,207 - trainer - INFO -     gen_loss       : 18.941714893687855
2025-01-21 13:05:29,207 - trainer - INFO -     perplexity     : 168376801.7893458
2025-01-21 13:05:29,207 - trainer - INFO -     embedding_sim  : 0.4232651410680829
2025-01-21 13:05:32,922 - trainer - INFO -     epoch          : 54
2025-01-21 13:05:32,922 - trainer - INFO -     loss           : 13.442174073421594
2025-01-21 13:05:32,922 - trainer - INFO -     sim_loss       : 0.5046718144616479
2025-01-21 13:05:32,922 - trainer - INFO -     gen_loss       : 18.98681894938151
2025-01-21 13:05:32,922 - trainer - INFO -     perplexity     : 176145153.58654377
2025-01-21 13:05:32,922 - trainer - INFO -     embedding_sim  : 0.42308534456021857
2025-01-21 13:05:36,633 - trainer - INFO -     epoch          : 55
2025-01-21 13:05:36,633 - trainer - INFO -     loss           : 13.580947731480453
2025-01-21 13:05:36,633 - trainer - INFO -     sim_loss       : 0.8486293193065759
2025-01-21 13:05:36,633 - trainer - INFO -     gen_loss       : 19.037656090476297
2025-01-21 13:05:36,633 - trainer - INFO -     perplexity     : 185331392.33444074
2025-01-21 13:05:36,633 - trainer - INFO -     embedding_sim  : 0.42396678527196247
2025-01-21 13:05:41,861 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch55.pth ...
2025-01-21 13:05:45,638 - trainer - INFO -     epoch          : 56
2025-01-21 13:05:45,638 - trainer - INFO -     loss           : 13.389630202091102
2025-01-21 13:05:45,638 - trainer - INFO -     sim_loss       : 0.2525837060176965
2025-01-21 13:05:45,638 - trainer - INFO -     gen_loss       : 19.01979348153779
2025-01-21 13:05:45,638 - trainer - INFO -     perplexity     : 182050281.98694322
2025-01-21 13:05:45,638 - trainer - INFO -     embedding_sim  : 0.4220280340223601
2025-01-21 13:05:49,349 - trainer - INFO -     epoch          : 57
2025-01-21 13:05:49,349 - trainer - INFO -     loss           : 13.433447635535037
2025-01-21 13:05:49,349 - trainer - INFO -     sim_loss       : 0.2542059132546883
2025-01-21 13:05:49,349 - trainer - INFO -     gen_loss       : 19.08169463186553
2025-01-21 13:05:49,349 - trainer - INFO -     perplexity     : 193675499.17535213
2025-01-21 13:05:49,349 - trainer - INFO -     embedding_sim  : 0.42398306456479157
2025-01-21 13:06:29,529 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 13:06:36,755 - trainer - INFO -     epoch          : 1
2025-01-21 13:06:36,755 - trainer - INFO -     loss           : 5.3753972198023945
2025-01-21 13:06:36,755 - trainer - INFO -     sim_loss       : 2.863174380678119
2025-01-21 13:06:36,756 - trainer - INFO -     gen_loss       : 6.452064543059378
2025-01-21 13:06:36,756 - trainer - INFO -     perplexity     : 634.0098832634774
2025-01-21 13:06:36,756 - trainer - INFO -     embedding_sim  : 0.2738661729928219
2025-01-21 13:06:36,756 - trainer - INFO -     topic_accuracy : 0.2727272727272727
2025-01-21 13:06:36,756 - trainer - WARNING - Warning: Metric 'val_gen_loss' is not found. Model performance monitoring is disabled.
2025-01-21 13:06:40,449 - trainer - INFO -     epoch          : 2
2025-01-21 13:06:40,449 - trainer - INFO -     loss           : 4.639009938095555
2025-01-21 13:06:40,449 - trainer - INFO -     sim_loss       : 1.4553861473545884
2025-01-21 13:06:40,449 - trainer - INFO -     gen_loss       : 6.003420179540461
2025-01-21 13:06:40,449 - trainer - INFO -     perplexity     : 404.81095467062926
2025-01-21 13:06:40,449 - trainer - INFO -     embedding_sim  : 0.2779076063271725
2025-01-21 13:06:40,449 - trainer - INFO -     topic_accuracy : 0.48484848484848486
2025-01-21 13:09:12,895 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 13:11:40,868 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 13:11:43,867 - trainer - INFO - ================================================================================
2025-01-21 13:11:43,867 - trainer - INFO - Starting epoch 1 at 2025-01-21 13:11:43
2025-01-21 13:14:00,620 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 13:14:02,930 - trainer - INFO - ================================================================================
2025-01-21 13:14:02,931 - trainer - INFO - Starting epoch 1 at 2025-01-21 13:14:02
2025-01-21 13:14:07,803 - trainer - INFO - Epoch 1 completed at 2025-01-21 13:14:07
2025-01-21 13:14:07,803 - trainer - INFO -     epoch          : 1
2025-01-21 13:14:07,803 - trainer - INFO -     elapsed_time   : 4.872162342071533
2025-01-21 13:14:07,803 - trainer - INFO -     train_loss     : 7.6664114853868455
2025-01-21 13:14:07,803 - trainer - INFO -     train_sim_loss : 6.291270730503374
2025-01-21 13:14:07,803 - trainer - INFO -     train_gen_loss : 8.255757247886784
2025-01-21 13:14:07,803 - trainer - INFO -     train_perplexity: 3849.7259690818664
2025-01-21 13:14:07,803 - trainer - INFO -     train_embedding_sim: 0.2435403428600476
2025-01-21 13:14:07,803 - trainer - INFO -     val_loss       : 5.375313701051654
2025-01-21 13:14:07,803 - trainer - INFO -     val_sim_loss   : 2.8631636590668648
2025-01-21 13:14:07,803 - trainer - INFO -     val_gen_loss   : 6.45194893172293
2025-01-21 13:14:07,803 - trainer - INFO -     val_perplexity : 633.9365887704707
2025-01-21 13:14:07,803 - trainer - INFO -     val_embedding_sim: 0.2738660555897337
2025-01-21 13:14:07,803 - trainer - INFO -     val_topic_accuracy: 0.2727272727272727
2025-01-21 13:14:07,803 - trainer - INFO - ================================================================================
2025-01-21 13:14:07,803 - trainer - INFO - Starting epoch 2 at 2025-01-21 13:14:07
2025-01-21 13:14:11,480 - trainer - INFO - Epoch 2 completed at 2025-01-21 13:14:11
2025-01-21 13:14:11,480 - trainer - INFO -     epoch          : 2
2025-01-21 13:14:11,480 - trainer - INFO -     elapsed_time   : 3.6762375831604004
2025-01-21 13:14:11,480 - trainer - INFO -     train_loss     : 5.028281717205364
2025-01-21 13:14:11,480 - trainer - INFO -     train_sim_loss : 1.9071023983020718
2025-01-21 13:14:11,480 - trainer - INFO -     train_gen_loss : 6.365930099423938
2025-01-21 13:14:11,480 - trainer - INFO -     train_perplexity: 581.685602234835
2025-01-21 13:14:11,480 - trainer - INFO -     train_embedding_sim: 0.311118033340207
2025-01-21 13:14:11,480 - trainer - INFO -     val_loss       : 4.638802354986018
2025-01-21 13:14:11,480 - trainer - INFO -     val_sim_loss   : 1.4553547564781073
2025-01-21 13:14:11,480 - trainer - INFO -     val_gen_loss   : 6.003137111663818
2025-01-21 13:14:11,480 - trainer - INFO -     val_perplexity : 404.69638190994806
2025-01-21 13:14:11,480 - trainer - INFO -     val_embedding_sim: 0.277906546086976
2025-01-21 13:14:11,480 - trainer - INFO -     val_topic_accuracy: 0.48484848484848486
2025-01-21 13:14:11,480 - trainer - INFO - ================================================================================
2025-01-21 13:14:11,480 - trainer - INFO - Starting epoch 3 at 2025-01-21 13:14:11
2025-01-21 13:14:15,172 - trainer - INFO - Epoch 3 completed at 2025-01-21 13:14:15
2025-01-21 13:14:15,172 - trainer - INFO -     epoch          : 3
2025-01-21 13:14:15,172 - trainer - INFO -     elapsed_time   : 3.691713333129883
2025-01-21 13:14:15,172 - trainer - INFO -     train_loss     : 4.463347583910159
2025-01-21 13:14:15,172 - trainer - INFO -     train_sim_loss : 1.1706330836611332
2025-01-21 13:14:15,172 - trainer - INFO -     train_gen_loss : 5.874510952008523
2025-01-21 13:14:15,172 - trainer - INFO -     train_perplexity: 355.8505900934641
2025-01-21 13:14:15,172 - trainer - INFO -     train_embedding_sim: 0.3168051600258216
2025-01-21 13:14:15,172 - trainer - INFO -     val_loss       : 4.205747329827511
2025-01-21 13:14:15,172 - trainer - INFO -     val_sim_loss   : 0.6050568857992237
2025-01-21 13:14:15,172 - trainer - INFO -     val_gen_loss   : 5.748900384613962
2025-01-21 13:14:15,172 - trainer - INFO -     val_perplexity : 313.84536128433524
2025-01-21 13:14:15,172 - trainer - INFO -     val_embedding_sim: 0.2856737492662488
2025-01-21 13:14:15,172 - trainer - INFO -     val_topic_accuracy: 0.8181818181818182
2025-01-21 13:14:15,172 - trainer - INFO - ================================================================================
2025-01-21 13:14:15,172 - trainer - INFO - Starting epoch 4 at 2025-01-21 13:14:15
2025-01-21 13:14:18,855 - trainer - INFO - Epoch 4 completed at 2025-01-21 13:14:18
2025-01-21 13:14:18,855 - trainer - INFO -     epoch          : 4
2025-01-21 13:14:18,855 - trainer - INFO -     elapsed_time   : 3.682466983795166
2025-01-21 13:14:18,855 - trainer - INFO -     train_loss     : 3.9146071937789158
2025-01-21 13:14:18,855 - trainer - INFO -     train_sim_loss : 0.593673561455255
2025-01-21 13:14:18,855 - trainer - INFO -     train_gen_loss : 5.337864546284723
2025-01-21 13:14:18,855 - trainer - INFO -     train_perplexity: 208.0679161349193
2025-01-21 13:14:18,855 - trainer - INFO -     train_embedding_sim: 0.3363190252717547
2025-01-21 13:14:18,855 - trainer - INFO -     val_loss       : 4.275981137246797
2025-01-21 13:14:18,855 - trainer - INFO -     val_sim_loss   : 1.3902932694464019
2025-01-21 13:14:18,855 - trainer - INFO -     val_gen_loss   : 5.512704141212232
2025-01-21 13:14:18,855 - trainer - INFO -     val_perplexity : 247.82036306248526
2025-01-21 13:14:18,855 - trainer - INFO -     val_embedding_sim: 0.2909628739862731
2025-01-21 13:14:18,855 - trainer - INFO -     val_topic_accuracy: 0.6060606060606061
2025-01-21 13:14:18,855 - trainer - INFO - ================================================================================
2025-01-21 13:14:18,855 - trainer - INFO - Starting epoch 5 at 2025-01-21 13:14:18
2025-01-21 13:14:22,528 - trainer - INFO - Epoch 5 completed at 2025-01-21 13:14:22
2025-01-21 13:14:22,528 - trainer - INFO -     epoch          : 5
2025-01-21 13:14:22,528 - trainer - INFO -     elapsed_time   : 3.672680377960205
2025-01-21 13:14:22,528 - trainer - INFO -     train_loss     : 3.617980240191336
2025-01-21 13:14:22,528 - trainer - INFO -     train_sim_loss : 0.6121692080731408
2025-01-21 13:14:22,528 - trainer - INFO -     train_gen_loss : 4.906185058264241
2025-01-21 13:14:22,529 - trainer - INFO -     train_perplexity: 135.12294372459132
2025-01-21 13:14:22,529 - trainer - INFO -     train_embedding_sim: 0.34832831860776753
2025-01-21 13:14:22,529 - trainer - INFO -     val_loss       : 3.7568070671775122
2025-01-21 13:14:22,529 - trainer - INFO -     val_sim_loss   : 0.11221874840504659
2025-01-21 13:14:22,529 - trainer - INFO -     val_gen_loss   : 5.318773558645537
2025-01-21 13:14:22,529 - trainer - INFO -     val_perplexity : 204.13337079795156
2025-01-21 13:14:22,529 - trainer - INFO -     val_embedding_sim: 0.29785023765130475
2025-01-21 13:14:22,529 - trainer - INFO -     val_topic_accuracy: 1.0
2025-01-21 13:14:27,757 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 13:14:32,973 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 13:14:32,973 - trainer - INFO - ================================================================================
2025-01-21 13:14:32,973 - trainer - INFO - Starting epoch 6 at 2025-01-21 13:14:32
2025-01-21 13:14:36,723 - trainer - INFO - Epoch 6 completed at 2025-01-21 13:14:36
2025-01-21 13:14:36,723 - trainer - INFO -     epoch          : 6
2025-01-21 13:14:36,723 - trainer - INFO -     elapsed_time   : 3.7493834495544434
2025-01-21 13:14:36,723 - trainer - INFO -     train_loss     : 3.330196122394448
2025-01-21 13:14:36,723 - trainer - INFO -     train_sim_loss : 0.652782589692214
2025-01-21 13:14:36,723 - trainer - INFO -     train_gen_loss : 4.477659109818975
2025-01-21 13:14:36,723 - trainer - INFO -     train_perplexity: 88.02836656094732
2025-01-21 13:14:36,723 - trainer - INFO -     train_embedding_sim: 0.35628731345813536
2025-01-21 13:14:36,723 - trainer - INFO -     val_loss       : 3.768701900135387
2025-01-21 13:14:36,723 - trainer - INFO -     val_sim_loss   : 0.39347968516857224
2025-01-21 13:14:36,723 - trainer - INFO -     val_gen_loss   : 5.215225711013332
2025-01-21 13:14:36,723 - trainer - INFO -     val_perplexity : 184.0533591618612
2025-01-21 13:14:36,723 - trainer - INFO -     val_embedding_sim: 0.2908915091644634
2025-01-21 13:14:36,723 - trainer - INFO -     val_topic_accuracy: 0.9393939393939394
2025-01-21 13:14:36,723 - trainer - INFO - ================================================================================
2025-01-21 13:14:36,723 - trainer - INFO - Starting epoch 7 at 2025-01-21 13:14:36
2025-01-21 13:14:40,396 - trainer - INFO - Epoch 7 completed at 2025-01-21 13:14:40
2025-01-21 13:14:40,396 - trainer - INFO -     epoch          : 7
2025-01-21 13:14:40,397 - trainer - INFO -     elapsed_time   : 3.672938108444214
2025-01-21 13:14:40,397 - trainer - INFO -     train_loss     : 3.0144339677107292
2025-01-21 13:14:40,397 - trainer - INFO -     train_sim_loss : 0.5721182193718479
2025-01-21 13:14:40,397 - trainer - INFO -     train_gen_loss : 4.0611407630071295
2025-01-21 13:14:40,397 - trainer - INFO -     train_perplexity: 58.040483764901985
2025-01-21 13:14:40,397 - trainer - INFO -     train_embedding_sim: 0.3645036128470272
2025-01-21 13:14:40,397 - trainer - INFO -     val_loss       : 3.6009105769070713
2025-01-21 13:14:40,397 - trainer - INFO -     val_sim_loss   : 0.32719939237347606
2025-01-21 13:14:40,397 - trainer - INFO -     val_gen_loss   : 5.003929513873476
2025-01-21 13:14:40,397 - trainer - INFO -     val_perplexity : 148.9974980022814
2025-01-21 13:14:40,397 - trainer - INFO -     val_embedding_sim: 0.30027165738019074
2025-01-21 13:14:40,397 - trainer - INFO -     val_topic_accuracy: 0.9393939393939394
2025-01-21 13:14:40,397 - trainer - INFO - ================================================================================
2025-01-21 13:14:40,397 - trainer - INFO - Starting epoch 8 at 2025-01-21 13:14:40
2025-01-21 13:14:44,071 - trainer - INFO - Epoch 8 completed at 2025-01-21 13:14:44
2025-01-21 13:14:44,071 - trainer - INFO -     epoch          : 8
2025-01-21 13:14:44,071 - trainer - INFO -     elapsed_time   : 3.674121379852295
2025-01-21 13:14:44,071 - trainer - INFO -     train_loss     : 2.730516589757216
2025-01-21 13:14:44,071 - trainer - INFO -     train_sim_loss : 0.5016329712249908
2025-01-21 13:14:44,071 - trainer - INFO -     train_gen_loss : 3.6857523918151855
2025-01-21 13:14:44,071 - trainer - INFO -     train_perplexity: 39.87511287472806
2025-01-21 13:14:44,071 - trainer - INFO -     train_embedding_sim: 0.3711030946617507
2025-01-21 13:14:44,071 - trainer - INFO -     val_loss       : 3.5380293329556785
2025-01-21 13:14:44,072 - trainer - INFO -     val_sim_loss   : 0.1696952066638253
2025-01-21 13:14:44,072 - trainer - INFO -     val_gen_loss   : 4.981601193095699
2025-01-21 13:14:44,072 - trainer - INFO -     val_perplexity : 145.70750081370335
2025-01-21 13:14:44,072 - trainer - INFO -     val_embedding_sim: 0.2929398435534853
2025-01-21 13:14:44,072 - trainer - INFO -     val_topic_accuracy: 0.9393939393939394
2025-01-21 13:14:44,072 - trainer - INFO - ================================================================================
2025-01-21 13:14:44,072 - trainer - INFO - Starting epoch 9 at 2025-01-21 13:14:44
2025-01-21 13:14:47,762 - trainer - INFO - Epoch 9 completed at 2025-01-21 13:14:47
2025-01-21 13:14:47,762 - trainer - INFO -     epoch          : 9
2025-01-21 13:14:47,762 - trainer - INFO -     elapsed_time   : 3.6900205612182617
2025-01-21 13:14:47,762 - trainer - INFO -     train_loss     : 2.445747276477243
2025-01-21 13:14:47,762 - trainer - INFO -     train_sim_loss : 0.4272878534374047
2025-01-21 13:14:47,762 - trainer - INFO -     train_gen_loss : 3.3108013175254642
2025-01-21 13:14:47,762 - trainer - INFO -     train_perplexity: 27.407078447358188
2025-01-21 13:14:47,762 - trainer - INFO -     train_embedding_sim: 0.38343077006926174
2025-01-21 13:14:47,762 - trainer - INFO -     val_loss       : 3.66951128208276
2025-01-21 13:14:47,762 - trainer - INFO -     val_sim_loss   : 0.5931262203472821
2025-01-21 13:14:47,762 - trainer - INFO -     val_gen_loss   : 4.987962029196999
2025-01-21 13:14:47,762 - trainer - INFO -     val_perplexity : 146.63727628489184
2025-01-21 13:14:47,762 - trainer - INFO -     val_embedding_sim: 0.2900421583291256
2025-01-21 13:14:47,762 - trainer - INFO -     val_topic_accuracy: 0.8787878787878788
2025-01-21 13:14:47,762 - trainer - INFO - ================================================================================
2025-01-21 13:14:47,762 - trainer - INFO - Starting epoch 10 at 2025-01-21 13:14:47
2025-01-21 13:14:51,448 - trainer - INFO - Epoch 10 completed at 2025-01-21 13:14:51
2025-01-21 13:14:51,448 - trainer - INFO -     epoch          : 10
2025-01-21 13:14:51,449 - trainer - INFO -     elapsed_time   : 3.685976028442383
2025-01-21 13:14:51,449 - trainer - INFO -     train_loss     : 2.1915114654655077
2025-01-21 13:14:51,449 - trainer - INFO -     train_sim_loss : 0.3724560413348714
2025-01-21 13:14:51,449 - trainer - INFO -     train_gen_loss : 2.97110669240603
2025-01-21 13:14:51,449 - trainer - INFO -     train_perplexity: 19.51350309637206
2025-01-21 13:14:51,449 - trainer - INFO -     train_embedding_sim: 0.3967359901662681
2025-01-21 13:14:51,449 - trainer - INFO -     val_loss       : 3.6523405132871685
2025-01-21 13:14:51,449 - trainer - INFO -     val_sim_loss   : 0.8786410967621839
2025-01-21 13:14:51,449 - trainer - INFO -     val_gen_loss   : 4.8410688169074785
2025-01-21 13:14:51,449 - trainer - INFO -     val_perplexity : 126.60459657463504
2025-01-21 13:14:51,449 - trainer - INFO -     val_embedding_sim: 0.3031512765270291
2025-01-21 13:14:51,449 - trainer - INFO -     val_topic_accuracy: 0.6666666666666666
2025-01-21 13:14:56,681 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 13:15:01,959 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 13:15:01,959 - trainer - INFO - ================================================================================
2025-01-21 13:15:01,959 - trainer - INFO - Starting epoch 11 at 2025-01-21 13:15:01
2025-01-21 13:15:05,725 - trainer - INFO - Epoch 11 completed at 2025-01-21 13:15:05
2025-01-21 13:15:05,725 - trainer - INFO -     epoch          : 11
2025-01-21 13:15:05,725 - trainer - INFO -     elapsed_time   : 3.7657670974731445
2025-01-21 13:15:05,725 - trainer - INFO -     train_loss     : 2.0382407769016253
2025-01-21 13:15:05,725 - trainer - INFO -     train_sim_loss : 0.48276492911220786
2025-01-21 13:15:05,725 - trainer - INFO -     train_gen_loss : 2.70487328700449
2025-01-21 13:15:05,725 - trainer - INFO -     train_perplexity: 14.952421904311944
2025-01-21 13:15:05,725 - trainer - INFO -     train_embedding_sim: 0.4040465348978771
2025-01-21 13:15:05,725 - trainer - INFO -     val_loss       : 3.5668891126459297
2025-01-21 13:15:05,725 - trainer - INFO -     val_sim_loss   : 0.6250564979784416
2025-01-21 13:15:05,725 - trainer - INFO -     val_gen_loss   : 4.827674490032774
2025-01-21 13:15:05,725 - trainer - INFO -     val_perplexity : 124.92011962568492
2025-01-21 13:15:05,725 - trainer - INFO -     val_embedding_sim: 0.2900384935465726
2025-01-21 13:15:05,725 - trainer - INFO -     val_topic_accuracy: 0.7575757575757576
2025-01-21 13:15:05,725 - trainer - INFO - ================================================================================
2025-01-21 13:15:05,725 - trainer - INFO - Starting epoch 12 at 2025-01-21 13:15:05
2025-01-21 13:15:09,413 - trainer - INFO - Epoch 12 completed at 2025-01-21 13:15:09
2025-01-21 13:15:09,413 - trainer - INFO -     epoch          : 12
2025-01-21 13:15:09,413 - trainer - INFO -     elapsed_time   : 3.6873648166656494
2025-01-21 13:15:09,413 - trainer - INFO -     train_loss     : 1.8576315613680108
2025-01-21 13:15:09,413 - trainer - INFO -     train_sim_loss : 0.4284527198816851
2025-01-21 13:15:09,413 - trainer - INFO -     train_gen_loss : 2.4701368507752783
2025-01-21 13:15:09,413 - trainer - INFO -     train_perplexity: 11.824064873374935
2025-01-21 13:15:09,413 - trainer - INFO -     train_embedding_sim: 0.4075740041130801
2025-01-21 13:15:09,413 - trainer - INFO -     val_loss       : 3.5075677524913442
2025-01-21 13:15:09,413 - trainer - INFO -     val_sim_loss   : 0.2881811505578684
2025-01-21 13:15:09,413 - trainer - INFO -     val_gen_loss   : 4.887304826216265
2025-01-21 13:15:09,413 - trainer - INFO -     val_perplexity : 132.595723515355
2025-01-21 13:15:09,413 - trainer - INFO -     val_embedding_sim: 0.296576918074579
2025-01-21 13:15:09,413 - trainer - INFO -     val_topic_accuracy: 0.9393939393939394
2025-01-21 13:15:09,413 - trainer - INFO - ================================================================================
2025-01-21 13:15:09,413 - trainer - INFO - Starting epoch 13 at 2025-01-21 13:15:09
2025-01-21 13:15:13,091 - trainer - INFO - Epoch 13 completed at 2025-01-21 13:15:13
2025-01-21 13:15:13,091 - trainer - INFO -     epoch          : 13
2025-01-21 13:15:13,091 - trainer - INFO -     elapsed_time   : 3.6772923469543457
2025-01-21 13:15:13,091 - trainer - INFO -     train_loss     : 1.7186594144054426
2025-01-21 13:15:13,091 - trainer - INFO -     train_sim_loss : 0.49015291609439343
2025-01-21 13:15:13,091 - trainer - INFO -     train_gen_loss : 2.245162242274744
2025-01-21 13:15:13,091 - trainer - INFO -     train_perplexity: 9.441947315209413
2025-01-21 13:15:13,091 - trainer - INFO -     train_embedding_sim: 0.42429617413650716
2025-01-21 13:15:13,091 - trainer - INFO -     val_loss       : 3.4512385563416914
2025-01-21 13:15:13,091 - trainer - INFO -     val_sim_loss   : 0.26412360481812025
2025-01-21 13:15:13,091 - trainer - INFO -     val_gen_loss   : 4.817145166975079
2025-01-21 13:15:13,091 - trainer - INFO -     val_perplexity : 123.61169582653625
2025-01-21 13:15:13,091 - trainer - INFO -     val_embedding_sim: 0.29932883652773773
2025-01-21 13:15:13,091 - trainer - INFO -     val_topic_accuracy: 0.9696969696969697
2025-01-21 13:15:13,091 - trainer - INFO - ================================================================================
2025-01-21 13:15:13,091 - trainer - INFO - Starting epoch 14 at 2025-01-21 13:15:13
2025-01-21 13:15:16,774 - trainer - INFO - Epoch 14 completed at 2025-01-21 13:15:16
2025-01-21 13:15:16,775 - trainer - INFO -     epoch          : 14
2025-01-21 13:15:16,775 - trainer - INFO -     elapsed_time   : 3.683072566986084
2025-01-21 13:15:16,775 - trainer - INFO -     train_loss     : 1.6430259990533722
2025-01-21 13:15:16,775 - trainer - INFO -     train_sim_loss : 0.6616567599020923
2025-01-21 13:15:16,775 - trainer - INFO -     train_gen_loss : 2.063612832579502
2025-01-21 13:15:16,775 - trainer - INFO -     train_perplexity: 7.874367252380615
2025-01-21 13:15:16,775 - trainer - INFO -     train_embedding_sim: 0.4261376251810017
2025-01-21 13:15:16,775 - trainer - INFO -     val_loss       : 3.405948862884984
2025-01-21 13:15:16,775 - trainer - INFO -     val_sim_loss   : 0.2516267949884588
2025-01-21 13:15:16,775 - trainer - INFO -     val_gen_loss   : 4.757801359350031
2025-01-21 13:15:16,775 - trainer - INFO -     val_perplexity : 116.48952553001415
2025-01-21 13:15:16,775 - trainer - INFO -     val_embedding_sim: 0.28976242740948993
2025-01-21 13:15:16,775 - trainer - INFO -     val_topic_accuracy: 0.8484848484848485
2025-01-21 13:15:16,775 - trainer - INFO - ================================================================================
2025-01-21 13:15:16,775 - trainer - INFO - Starting epoch 15 at 2025-01-21 13:15:16
2025-01-21 13:15:20,464 - trainer - INFO - Epoch 15 completed at 2025-01-21 13:15:20
2025-01-21 13:15:20,465 - trainer - INFO -     epoch          : 15
2025-01-21 13:15:20,465 - trainer - INFO -     elapsed_time   : 3.689380407333374
2025-01-21 13:15:20,465 - trainer - INFO -     train_loss     : 1.4418818950653076
2025-01-21 13:15:20,465 - trainer - INFO -     train_sim_loss : 0.3197257250448398
2025-01-21 13:15:20,465 - trainer - INFO -     train_gen_loss : 1.9228060055412723
2025-01-21 13:15:20,465 - trainer - INFO -     train_perplexity: 6.840124994664669
2025-01-21 13:15:20,465 - trainer - INFO -     train_embedding_sim: 0.4349499488391749
2025-01-21 13:15:20,465 - trainer - INFO -     val_loss       : 3.432213407574278
2025-01-21 13:15:20,465 - trainer - INFO -     val_sim_loss   : 0.2177358973042856
2025-01-21 13:15:20,465 - trainer - INFO -     val_gen_loss   : 4.809846690206816
2025-01-21 13:15:20,465 - trainer - INFO -     val_perplexity : 122.71280300062821
2025-01-21 13:15:20,465 - trainer - INFO -     val_embedding_sim: 0.29018916641220904
2025-01-21 13:15:20,465 - trainer - INFO -     val_topic_accuracy: 0.8787878787878788
2025-01-21 13:15:25,691 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 13:15:25,692 - trainer - INFO - ================================================================================
2025-01-21 13:15:25,692 - trainer - INFO - Starting epoch 16 at 2025-01-21 13:15:25
2025-01-21 13:15:29,420 - trainer - INFO - Epoch 16 completed at 2025-01-21 13:15:29
2025-01-21 13:15:29,420 - trainer - INFO -     epoch          : 16
2025-01-21 13:15:29,420 - trainer - INFO -     elapsed_time   : 3.728583574295044
2025-01-21 13:15:29,420 - trainer - INFO -     train_loss     : 1.3143992725004785
2025-01-21 13:15:29,420 - trainer - INFO -     train_sim_loss : 0.23890595212331245
2025-01-21 13:15:29,420 - trainer - INFO -     train_gen_loss : 1.775325009989184
2025-01-21 13:15:29,421 - trainer - INFO -     train_perplexity: 5.90219909828883
2025-01-21 13:15:29,421 - trainer - INFO -     train_embedding_sim: 0.4366139754702483
2025-01-21 13:15:29,421 - trainer - INFO -     val_loss       : 3.423289320685647
2025-01-21 13:15:29,421 - trainer - INFO -     val_sim_loss   : 0.17460612817244095
2025-01-21 13:15:29,421 - trainer - INFO -     val_gen_loss   : 4.815582022522435
2025-01-21 13:15:29,421 - trainer - INFO -     val_perplexity : 123.41862382894702
2025-01-21 13:15:29,421 - trainer - INFO -     val_embedding_sim: 0.29327025738629425
2025-01-21 13:15:29,421 - trainer - INFO -     val_topic_accuracy: 0.9090909090909091
2025-01-21 13:15:29,421 - trainer - INFO - ================================================================================
2025-01-21 13:15:29,421 - trainer - INFO - Starting epoch 17 at 2025-01-21 13:15:29
2025-01-21 13:15:33,097 - trainer - INFO - Epoch 17 completed at 2025-01-21 13:15:33
2025-01-21 13:15:33,097 - trainer - INFO -     epoch          : 17
2025-01-21 13:15:33,097 - trainer - INFO -     elapsed_time   : 3.6760528087615967
2025-01-21 13:15:33,097 - trainer - INFO -     train_loss     : 1.2508388151758136
2025-01-21 13:15:33,097 - trainer - INFO -     train_sim_loss : 0.25671301089053933
2025-01-21 13:15:33,097 - trainer - INFO -     train_gen_loss : 1.6768927732575376
2025-01-21 13:15:33,097 - trainer - INFO -     train_perplexity: 5.348909847154096
2025-01-21 13:15:33,097 - trainer - INFO -     train_embedding_sim: 0.4399235354507484
2025-01-21 13:15:33,097 - trainer - INFO -     val_loss       : 3.3900132323756362
2025-01-21 13:15:33,097 - trainer - INFO -     val_sim_loss   : 0.06635935559417262
2025-01-21 13:15:33,097 - trainer - INFO -     val_gen_loss   : 4.81443639235063
2025-01-21 13:15:33,097 - trainer - INFO -     val_perplexity : 123.2773126903335
2025-01-21 13:15:33,097 - trainer - INFO -     val_embedding_sim: 0.29476577043533325
2025-01-21 13:15:33,097 - trainer - INFO -     val_topic_accuracy: 0.9696969696969697
2025-01-21 13:15:33,097 - trainer - INFO - ================================================================================
2025-01-21 13:15:33,097 - trainer - INFO - Starting epoch 18 at 2025-01-21 13:15:33
2025-01-21 13:15:36,782 - trainer - INFO - Epoch 18 completed at 2025-01-21 13:15:36
2025-01-21 13:15:36,782 - trainer - INFO -     epoch          : 18
2025-01-21 13:15:36,782 - trainer - INFO -     elapsed_time   : 3.6845755577087402
2025-01-21 13:15:36,782 - trainer - INFO -     train_loss     : 1.2142333429913188
2025-01-21 13:15:36,782 - trainer - INFO -     train_sim_loss : 0.3303409575227883
2025-01-21 13:15:36,782 - trainer - INFO -     train_gen_loss : 1.5930443816010738
2025-01-21 13:15:36,782 - trainer - INFO -     train_perplexity: 4.918700559027046
2025-01-21 13:15:36,782 - trainer - INFO -     train_embedding_sim: 0.44269786047381027
2025-01-21 13:15:36,782 - trainer - INFO -     val_loss       : 3.5233784498590413
2025-01-21 13:15:36,782 - trainer - INFO -     val_sim_loss   : 0.28473959547097544
2025-01-21 13:15:36,782 - trainer - INFO -     val_gen_loss   : 4.911366560242393
2025-01-21 13:15:36,782 - trainer - INFO -     val_perplexity : 135.82490054962423
2025-01-21 13:15:36,782 - trainer - INFO -     val_embedding_sim: 0.28674825755032624
2025-01-21 13:15:36,783 - trainer - INFO -     val_topic_accuracy: 0.8787878787878788
2025-01-21 13:15:36,783 - trainer - INFO - ================================================================================
2025-01-21 13:15:36,783 - trainer - INFO - Starting epoch 19 at 2025-01-21 13:15:36
2025-01-21 13:15:40,466 - trainer - INFO - Epoch 19 completed at 2025-01-21 13:15:40
2025-01-21 13:15:40,466 - trainer - INFO -     epoch          : 19
2025-01-21 13:15:40,466 - trainer - INFO -     elapsed_time   : 3.6829521656036377
2025-01-21 13:15:40,466 - trainer - INFO -     train_loss     : 1.174493775019218
2025-01-21 13:15:40,466 - trainer - INFO -     train_sim_loss : 0.4418059187474045
2025-01-21 13:15:40,466 - trainer - INFO -     train_gen_loss : 1.4885028426433322
2025-01-21 13:15:40,466 - trainer - INFO -     train_perplexity: 4.430457459155142
2025-01-21 13:15:40,466 - trainer - INFO -     train_embedding_sim: 0.44002313283194733
2025-01-21 13:15:40,466 - trainer - INFO -     val_loss       : 3.399468349687981
2025-01-21 13:15:40,466 - trainer - INFO -     val_sim_loss   : 0.06720765192541435
2025-01-21 13:15:40,466 - trainer - INFO -     val_gen_loss   : 4.827580278570002
2025-01-21 13:15:40,466 - trainer - INFO -     val_perplexity : 124.90835127285084
2025-01-21 13:15:40,466 - trainer - INFO -     val_embedding_sim: 0.2934248158425996
2025-01-21 13:15:40,466 - trainer - INFO -     val_topic_accuracy: 0.9696969696969697
2025-01-21 13:15:40,466 - trainer - INFO - ================================================================================
2025-01-21 13:15:40,466 - trainer - INFO - Starting epoch 20 at 2025-01-21 13:15:40
2025-01-21 13:15:44,159 - trainer - INFO - Epoch 20 completed at 2025-01-21 13:15:44
2025-01-21 13:15:44,159 - trainer - INFO -     epoch          : 20
2025-01-21 13:15:44,159 - trainer - INFO -     elapsed_time   : 3.692568302154541
2025-01-21 13:15:44,159 - trainer - INFO -     train_loss     : 1.0978999961650253
2025-01-21 13:15:44,159 - trainer - INFO -     train_sim_loss : 0.3371274683499195
2025-01-21 13:15:44,159 - trainer - INFO -     train_gen_loss : 1.4239453556529706
2025-01-21 13:15:44,159 - trainer - INFO -     train_perplexity: 4.153475093013748
2025-01-21 13:15:44,159 - trainer - INFO -     train_embedding_sim: 0.44198962867854047
2025-01-21 13:15:44,159 - trainer - INFO -     val_loss       : 3.5865107088377983
2025-01-21 13:15:44,159 - trainer - INFO -     val_sim_loss   : 0.4608231566073135
2025-01-21 13:15:44,159 - trainer - INFO -     val_gen_loss   : 4.926091233889262
2025-01-21 13:15:44,159 - trainer - INFO -     val_perplexity : 137.83967492811934
2025-01-21 13:15:44,159 - trainer - INFO -     val_embedding_sim: 0.2802282978187908
2025-01-21 13:15:44,159 - trainer - INFO -     val_topic_accuracy: 0.8181818181818182
2025-01-21 13:15:49,392 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 13:15:49,392 - trainer - INFO - ================================================================================
2025-01-21 13:15:49,392 - trainer - INFO - Starting epoch 21 at 2025-01-21 13:15:49
2025-01-21 13:15:53,121 - trainer - INFO - Epoch 21 completed at 2025-01-21 13:15:53
2025-01-21 13:15:53,121 - trainer - INFO -     epoch          : 21
2025-01-21 13:15:53,121 - trainer - INFO -     elapsed_time   : 3.7284114360809326
2025-01-21 13:15:53,121 - trainer - INFO -     train_loss     : 1.0413532767977034
2025-01-21 13:15:53,121 - trainer - INFO -     train_sim_loss : 0.28321178846116923
2025-01-21 13:15:53,121 - trainer - INFO -     train_gen_loss : 1.366271085121307
2025-01-21 13:15:53,121 - trainer - INFO -     train_perplexity: 3.920703433877375
2025-01-21 13:15:53,121 - trainer - INFO -     train_embedding_sim: 0.44608191596313174
2025-01-21 13:15:53,121 - trainer - INFO -     val_loss       : 3.6177531589161265
2025-01-21 13:15:53,121 - trainer - INFO -     val_sim_loss   : 0.22244401365451544
2025-01-21 13:15:53,121 - trainer - INFO -     val_gen_loss   : 5.072885961243601
2025-01-21 13:15:53,121 - trainer - INFO -     val_perplexity : 159.63436178447657
2025-01-21 13:15:53,121 - trainer - INFO -     val_embedding_sim: 0.2681547087250334
2025-01-21 13:15:53,121 - trainer - INFO -     val_topic_accuracy: 0.9090909090909091
2025-01-21 13:15:53,121 - trainer - INFO - ================================================================================
2025-01-21 13:15:53,121 - trainer - INFO - Starting epoch 22 at 2025-01-21 13:15:53
2025-01-21 13:15:56,811 - trainer - INFO - Epoch 22 completed at 2025-01-21 13:15:56
2025-01-21 13:15:56,811 - trainer - INFO -     epoch          : 22
2025-01-21 13:15:56,811 - trainer - INFO -     elapsed_time   : 3.6891486644744873
2025-01-21 13:15:56,811 - trainer - INFO -     train_loss     : 1.0437367283228625
2025-01-21 13:15:56,811 - trainer - INFO -     train_sim_loss : 0.4587195323551216
2025-01-21 13:15:56,811 - trainer - INFO -     train_gen_loss : 1.2944584063121252
2025-01-21 13:15:56,811 - trainer - INFO -     train_perplexity: 3.649019153132431
2025-01-21 13:15:56,811 - trainer - INFO -     train_embedding_sim: 0.4453757533995416
2025-01-21 13:15:56,811 - trainer - INFO -     val_loss       : 3.5002919832865396
2025-01-21 13:15:56,811 - trainer - INFO -     val_sim_loss   : 0.24809601090171035
2025-01-21 13:15:56,811 - trainer - INFO -     val_gen_loss   : 4.894090045582164
2025-01-21 13:15:56,811 - trainer - INFO -     val_perplexity : 133.49847380226225
2025-01-21 13:15:56,811 - trainer - INFO -     val_embedding_sim: 0.2747944225416039
2025-01-21 13:15:56,811 - trainer - INFO -     val_topic_accuracy: 0.8484848484848485
2025-01-21 13:15:56,811 - trainer - INFO - ================================================================================
2025-01-21 13:15:56,811 - trainer - INFO - Starting epoch 23 at 2025-01-21 13:15:56
2025-01-21 13:16:00,491 - trainer - INFO - Epoch 23 completed at 2025-01-21 13:16:00
2025-01-21 13:16:00,491 - trainer - INFO -     epoch          : 23
2025-01-21 13:16:00,491 - trainer - INFO -     elapsed_time   : 3.6799681186676025
2025-01-21 13:16:00,491 - trainer - INFO -     train_loss     : 0.9970759672183928
2025-01-21 13:16:00,491 - trainer - INFO -     train_sim_loss : 0.436472904741566
2025-01-21 13:16:00,491 - trainer - INFO -     train_gen_loss : 1.2373344518021492
2025-01-21 13:16:00,491 - trainer - INFO -     train_perplexity: 3.446414625939923
2025-01-21 13:16:00,491 - trainer - INFO -     train_embedding_sim: 0.4422212444072546
2025-01-21 13:16:00,491 - trainer - INFO -     val_loss       : 3.533758307948257
2025-01-21 13:16:00,492 - trainer - INFO -     val_sim_loss   : 0.11597635133357746
2025-01-21 13:16:00,492 - trainer - INFO -     val_gen_loss   : 4.9985221516002305
2025-01-21 13:16:00,492 - trainer - INFO -     val_perplexity : 148.1939889429166
2025-01-21 13:16:00,492 - trainer - INFO -     val_embedding_sim: 0.27616056528958405
2025-01-21 13:16:00,492 - trainer - INFO -     val_topic_accuracy: 0.9393939393939394
2025-01-21 13:16:00,492 - trainer - INFO - ================================================================================
2025-01-21 13:16:00,492 - trainer - INFO - Starting epoch 24 at 2025-01-21 13:16:00
2025-01-21 13:16:04,175 - trainer - INFO - Epoch 24 completed at 2025-01-21 13:16:04
2025-01-21 13:16:04,175 - trainer - INFO -     epoch          : 24
2025-01-21 13:16:04,175 - trainer - INFO -     elapsed_time   : 3.683502674102783
2025-01-21 13:16:04,175 - trainer - INFO -     train_loss     : 0.9440803088223023
2025-01-21 13:16:04,175 - trainer - INFO -     train_sim_loss : 0.34076727738610135
2025-01-21 13:16:04,176 - trainer - INFO -     train_gen_loss : 1.2026430487236708
2025-01-21 13:16:04,176 - trainer - INFO -     train_perplexity: 3.3289037604365195
2025-01-21 13:16:04,176 - trainer - INFO -     train_embedding_sim: 0.44409194063902696
2025-01-21 13:16:04,176 - trainer - INFO -     val_loss       : 3.7370257955608945
2025-01-21 13:16:04,176 - trainer - INFO -     val_sim_loss   : 0.7364819230454859
2025-01-21 13:16:04,176 - trainer - INFO -     val_gen_loss   : 5.022973465197014
2025-01-21 13:16:04,176 - trainer - INFO -     val_perplexity : 151.86219005140686
2025-01-21 13:16:04,176 - trainer - INFO -     val_embedding_sim: 0.272413658824834
2025-01-21 13:16:04,176 - trainer - INFO -     val_topic_accuracy: 0.8181818181818182
2025-01-21 13:16:04,176 - trainer - INFO - ================================================================================
2025-01-21 13:16:04,176 - trainer - INFO - Starting epoch 25 at 2025-01-21 13:16:04
2025-01-21 13:16:07,868 - trainer - INFO - Epoch 25 completed at 2025-01-21 13:16:07
2025-01-21 13:16:07,868 - trainer - INFO -     epoch          : 25
2025-01-21 13:16:07,868 - trainer - INFO -     elapsed_time   : 3.6917102336883545
2025-01-21 13:16:07,868 - trainer - INFO -     train_loss     : 0.9662926898050149
2025-01-21 13:16:07,868 - trainer - INFO -     train_sim_loss : 0.5404777485270833
2025-01-21 13:16:07,868 - trainer - INFO -     train_gen_loss : 1.148784810522466
2025-01-21 13:16:07,868 - trainer - INFO -     train_perplexity: 3.154357437782424
2025-01-21 13:16:07,868 - trainer - INFO -     train_embedding_sim: 0.4454396688858932
2025-01-21 13:16:07,868 - trainer - INFO -     val_loss       : 3.8064023581418125
2025-01-21 13:16:07,868 - trainer - INFO -     val_sim_loss   : 1.059226180567886
2025-01-21 13:16:07,868 - trainer - INFO -     val_gen_loss   : 4.983763925956957
2025-01-21 13:16:07,868 - trainer - INFO -     val_perplexity : 146.02296822675106
2025-01-21 13:16:07,868 - trainer - INFO -     val_embedding_sim: 0.2714243477041071
2025-01-21 13:16:07,868 - trainer - INFO -     val_topic_accuracy: 0.6363636363636364
2025-01-21 13:16:13,099 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 13:16:13,100 - trainer - INFO - ================================================================================
2025-01-21 13:16:13,100 - trainer - INFO - Starting epoch 26 at 2025-01-21 13:16:13
2025-01-21 13:16:16,828 - trainer - INFO - Epoch 26 completed at 2025-01-21 13:16:16
2025-01-21 13:16:16,829 - trainer - INFO -     epoch          : 26
2025-01-21 13:16:16,829 - trainer - INFO -     elapsed_time   : 3.728750467300415
2025-01-21 13:16:16,829 - trainer - INFO -     train_loss     : 0.8589950976181664
2025-01-21 13:16:16,829 - trainer - INFO -     train_sim_loss : 0.2709847072331216
2025-01-21 13:16:16,829 - trainer - INFO -     train_gen_loss : 1.1109995465738036
2025-01-21 13:16:16,829 - trainer - INFO -     train_perplexity: 3.0373928932813428
2025-01-21 13:16:16,829 - trainer - INFO -     train_embedding_sim: 0.4460809051594465
2025-01-21 13:16:16,829 - trainer - INFO -     val_loss       : 3.4942369172067353
2025-01-21 13:16:16,829 - trainer - INFO -     val_sim_loss   : 0.053790719347131075
2025-01-21 13:16:16,829 - trainer - INFO -     val_gen_loss   : 4.968714098135631
2025-01-21 13:16:16,829 - trainer - INFO -     val_perplexity : 143.84180195427507
2025-01-21 13:16:16,829 - trainer - INFO -     val_embedding_sim: 0.27295477010987024
2025-01-21 13:16:16,829 - trainer - INFO -     val_topic_accuracy: 0.9696969696969697
2025-01-21 13:16:16,829 - trainer - INFO - ================================================================================
2025-01-21 13:16:16,829 - trainer - INFO - Starting epoch 27 at 2025-01-21 13:16:16
2025-01-21 13:16:20,508 - trainer - INFO - Epoch 27 completed at 2025-01-21 13:16:20
2025-01-21 13:16:20,508 - trainer - INFO -     epoch          : 27
2025-01-21 13:16:20,508 - trainer - INFO -     elapsed_time   : 3.679114580154419
2025-01-21 13:16:20,508 - trainer - INFO -     train_loss     : 0.8276103200310488
2025-01-21 13:16:20,508 - trainer - INFO -     train_sim_loss : 0.27283616490705415
2025-01-21 13:16:20,508 - trainer - INFO -     train_gen_loss : 1.0653706955355267
2025-01-21 13:16:20,508 - trainer - INFO -     train_perplexity: 2.901914511454592
2025-01-21 13:16:20,508 - trainer - INFO -     train_embedding_sim: 0.445033068276719
2025-01-21 13:16:20,509 - trainer - INFO -     val_loss       : 3.5438627781289997
2025-01-21 13:16:20,509 - trainer - INFO -     val_sim_loss   : 0.23612798344005237
2025-01-21 13:16:20,509 - trainer - INFO -     val_gen_loss   : 4.961463436935887
2025-01-21 13:16:20,509 - trainer - INFO -     val_perplexity : 142.80262569208077
2025-01-21 13:16:20,509 - trainer - INFO -     val_embedding_sim: 0.27646446679577685
2025-01-21 13:16:20,509 - trainer - INFO -     val_topic_accuracy: 0.9090909090909091
2025-01-21 13:16:20,509 - trainer - INFO - ================================================================================
2025-01-21 13:16:20,509 - trainer - INFO - Starting epoch 28 at 2025-01-21 13:16:20
2025-01-21 13:16:24,196 - trainer - INFO - Epoch 28 completed at 2025-01-21 13:16:24
2025-01-21 13:16:24,196 - trainer - INFO -     epoch          : 28
2025-01-21 13:16:24,196 - trainer - INFO -     elapsed_time   : 3.6867926120758057
2025-01-21 13:16:24,196 - trainer - INFO -     train_loss     : 0.8717390928553584
2025-01-21 13:16:24,196 - trainer - INFO -     train_sim_loss : 0.5069426297151369
2025-01-21 13:16:24,196 - trainer - INFO -     train_gen_loss : 1.0280804412309514
2025-01-21 13:16:24,196 - trainer - INFO -     train_perplexity: 2.7956941814648486
2025-01-21 13:16:24,196 - trainer - INFO -     train_embedding_sim: 0.4459904421405539
2025-01-21 13:16:24,196 - trainer - INFO -     val_loss       : 3.4755493944341485
2025-01-21 13:16:24,196 - trainer - INFO -     val_sim_loss   : 0.059530995108857634
2025-01-21 13:16:24,196 - trainer - INFO -     val_gen_loss   : 4.939557462027579
2025-01-21 13:16:24,196 - trainer - INFO -     val_perplexity : 139.708409601432
2025-01-21 13:16:24,196 - trainer - INFO -     val_embedding_sim: 0.27156817235729913
2025-01-21 13:16:24,196 - trainer - INFO -     val_topic_accuracy: 0.9696969696969697
2025-01-21 13:16:24,196 - trainer - INFO - ================================================================================
2025-01-21 13:16:24,196 - trainer - INFO - Starting epoch 29 at 2025-01-21 13:16:24
2025-01-21 13:16:27,882 - trainer - INFO - Epoch 29 completed at 2025-01-21 13:16:27
2025-01-21 13:16:27,882 - trainer - INFO -     epoch          : 29
2025-01-21 13:16:27,882 - trainer - INFO -     elapsed_time   : 3.685509204864502
2025-01-21 13:16:27,882 - trainer - INFO -     train_loss     : 0.7897814827107907
2025-01-21 13:16:27,882 - trainer - INFO -     train_sim_loss : 0.3199939586197419
2025-01-21 13:16:27,882 - trainer - INFO -     train_gen_loss : 0.991118997434445
2025-01-21 13:16:27,882 - trainer - INFO -     train_perplexity: 2.694247642369659
2025-01-21 13:16:27,882 - trainer - INFO -     train_embedding_sim: 0.44673610664285296
2025-01-21 13:16:27,882 - trainer - INFO -     val_loss       : 3.596619766769987
2025-01-21 13:16:27,882 - trainer - INFO -     val_sim_loss   : 0.5841372839221908
2025-01-21 13:16:27,882 - trainer - INFO -     val_gen_loss   : 4.887683843121384
2025-01-21 13:16:27,882 - trainer - INFO -     val_perplexity : 132.64598906125798
2025-01-21 13:16:27,882 - trainer - INFO -     val_embedding_sim: 0.2684906635320548
2025-01-21 13:16:27,882 - trainer - INFO -     val_topic_accuracy: 0.8787878787878788
2025-01-21 13:16:27,882 - trainer - INFO - ================================================================================
2025-01-21 13:16:27,882 - trainer - INFO - Starting epoch 30 at 2025-01-21 13:16:27
2025-01-21 13:16:31,564 - trainer - INFO - Epoch 30 completed at 2025-01-21 13:16:31
2025-01-21 13:16:31,564 - trainer - INFO -     epoch          : 30
2025-01-21 13:16:31,564 - trainer - INFO -     elapsed_time   : 3.681762218475342
2025-01-21 13:16:31,564 - trainer - INFO -     train_loss     : 0.8093142796592458
2025-01-21 13:16:31,564 - trainer - INFO -     train_sim_loss : 0.40218932707283483
2025-01-21 13:16:31,564 - trainer - INFO -     train_gen_loss : 0.9837964002872226
2025-01-21 13:16:31,564 - trainer - INFO -     train_perplexity: 2.6745908096372824
2025-01-21 13:16:31,564 - trainer - INFO -     train_embedding_sim: 0.4435468914104855
2025-01-21 13:16:31,564 - trainer - INFO -     val_loss       : 3.583475315209591
2025-01-21 13:16:31,564 - trainer - INFO -     val_sim_loss   : 0.34482037298600904
2025-01-21 13:16:31,564 - trainer - INFO -     val_gen_loss   : 4.9714703848867705
2025-01-21 13:16:31,564 - trainer - INFO -     val_perplexity : 144.2388181010863
2025-01-21 13:16:31,565 - trainer - INFO -     val_embedding_sim: 0.2662541742126147
2025-01-21 13:16:31,565 - trainer - INFO -     val_topic_accuracy: 0.8484848484848485
2025-01-21 13:16:31,565 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
2025-01-21 13:17:39,107 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 46274177.0
2025-01-21 13:17:41,309 - trainer - INFO - Loading checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 13:17:51,589 - trainer - INFO - Checkpoint loaded. Resume training from epoch 16
2025-01-21 13:17:53,241 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:17:53,241 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:17:55,233 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:17:55,233 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:17:56,990 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:17:56,990 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:17:58,723 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:17:58,723 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:00,379 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:00,379 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:02,047 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:02,047 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:03,674 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:03,674 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:05,353 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:05,353 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:07,063 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:07,064 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:08,771 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:08,771 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:10,475 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:10,475 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:12,172 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:12,172 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:13,843 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:13,843 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:15,579 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:15,579 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:17,480 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:17,480 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:19,219 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:19,219 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:20,990 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:20,990 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:22,771 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:22,771 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:24,605 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:24,605 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:26,251 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:26,251 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:27,907 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:27,907 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:29,711 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:29,711 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:31,458 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:31,458 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:33,291 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:33,291 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:35,096 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:35,096 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:36,811 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:36,811 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:38,424 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:38,424 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:40,201 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:40,201 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:42,298 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:42,298 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:44,127 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:44,127 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:45,925 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:45,925 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:47,579 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:47,579 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-01-21 13:18:49,275 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda
2025-01-21 13:18:49,276 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
