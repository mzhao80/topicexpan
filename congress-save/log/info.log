2025-01-21 10:42:31,946 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 10:44:05,864 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 10:45:52,359 - train - INFO - TopicExpan(
  (doc_encoder): BertDocEncoder(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-5): 6 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
  (phrase_decoder): TransformerPhraseDecoder(
    (input_embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 384, padding_idx=0)
      (position_embeddings): Embedding(512, 384)
      (token_type_embeddings): Embedding(2, 384)
      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_embeddings): Linear(in_features=384, out_features=30522, bias=False)
    (context_proj): Linear(in_features=384, out_features=384, bias=True)
    (context_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (model): TransformerDecoder(
      (layers): ModuleList(
        (0-7): 8 x TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
          )
          (linear1): Linear(in_features=384, out_features=2048, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=2048, out_features=384, bias=True)
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
        )
      )
    )
  )
  (topic_encoder): GCNTopicEncoder(
    (downward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (upward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
    (sideward_layers): ModuleList(
      (0-1): 2 x GraphConv(in=384, out=384, normalization=right, activation=None)
    )
  )
  (interaction): BilinearInteraction()
  (linear_combiner): Linear(in_features=768, out_features=384, bias=True)
)
Trainable parameters: 57994624
2025-01-21 10:45:54,673 - trainer - INFO - ================================================================================
2025-01-21 10:45:54,674 - trainer - INFO - Starting epoch 1 at 2025-01-21 10:45:54
2025-01-21 10:46:00,781 - trainer - INFO - Epoch 1 completed at 2025-01-21 10:46:00
2025-01-21 10:46:00,781 - trainer - INFO -     epoch          : 1
2025-01-21 10:46:00,781 - trainer - INFO -     elapsed time   : 6.107114791870117
2025-01-21 10:46:00,781 - trainer - INFO -     loss           : 1369.6109558105468
2025-01-21 10:46:00,781 - trainer - INFO -     sim_loss       : 79.97843494415284
2025-01-21 10:46:00,781 - trainer - INFO -     gen_loss       : 1289.6325256347657
2025-01-21 10:46:00,781 - trainer - INFO -     val_loss       : 599.1997909545898
2025-01-21 10:46:00,781 - trainer - INFO -     val_sim_loss   : 30.916400909423828
2025-01-21 10:46:00,781 - trainer - INFO -     val_gen_loss   : 568.2834091186523
2025-01-21 10:46:00,781 - trainer - INFO -     val_perplexity : 34.34333038330078
2025-01-21 10:46:00,781 - trainer - INFO -     val_embedding_sim: 0.11081544309854507
2025-01-21 10:46:00,781 - trainer - INFO - ================================================================================
2025-01-21 10:46:00,781 - trainer - INFO - Starting epoch 2 at 2025-01-21 10:46:00
2025-01-21 10:46:05,598 - trainer - INFO - Epoch 2 completed at 2025-01-21 10:46:05
2025-01-21 10:46:05,599 - trainer - INFO -     epoch          : 2
2025-01-21 10:46:05,599 - trainer - INFO -     elapsed time   : 4.8169028759002686
2025-01-21 10:46:05,599 - trainer - INFO -     loss           : 1199.584326171875
2025-01-21 10:46:05,599 - trainer - INFO -     sim_loss       : 45.95102252960205
2025-01-21 10:46:05,599 - trainer - INFO -     gen_loss       : 1153.6332885742188
2025-01-21 10:46:05,599 - trainer - INFO -     val_loss       : 565.3709888458252
2025-01-21 10:46:05,599 - trainer - INFO -     val_sim_loss   : 19.683780670166016
2025-01-21 10:46:05,599 - trainer - INFO -     val_gen_loss   : 545.6872119903564
2025-01-21 10:46:05,599 - trainer - INFO -     val_perplexity : 32.816829681396484
2025-01-21 10:46:05,599 - trainer - INFO -     val_embedding_sim: 0.11196853220462799
2025-01-21 10:46:05,599 - trainer - INFO - ================================================================================
2025-01-21 10:46:05,599 - trainer - INFO - Starting epoch 3 at 2025-01-21 10:46:05
2025-01-21 10:46:10,405 - trainer - INFO - Epoch 3 completed at 2025-01-21 10:46:10
2025-01-21 10:46:10,405 - trainer - INFO -     epoch          : 3
2025-01-21 10:46:10,405 - trainer - INFO -     elapsed time   : 4.805685997009277
2025-01-21 10:46:10,405 - trainer - INFO -     loss           : 1125.555825805664
2025-01-21 10:46:10,405 - trainer - INFO -     sim_loss       : 30.757434368133545
2025-01-21 10:46:10,405 - trainer - INFO -     gen_loss       : 1094.7983764648438
2025-01-21 10:46:10,405 - trainer - INFO -     val_loss       : 547.7815227508545
2025-01-21 10:46:10,405 - trainer - INFO -     val_sim_loss   : 21.381855010986328
2025-01-21 10:46:10,405 - trainer - INFO -     val_gen_loss   : 526.3996868133545
2025-01-21 10:46:10,405 - trainer - INFO -     val_perplexity : 30.934947967529297
2025-01-21 10:46:10,405 - trainer - INFO -     val_embedding_sim: 0.08402667939662933
2025-01-21 10:46:10,405 - trainer - INFO - ================================================================================
2025-01-21 10:46:10,405 - trainer - INFO - Starting epoch 4 at 2025-01-21 10:46:10
2025-01-21 10:46:15,208 - trainer - INFO - Epoch 4 completed at 2025-01-21 10:46:15
2025-01-21 10:46:15,209 - trainer - INFO -     epoch          : 4
2025-01-21 10:46:15,209 - trainer - INFO -     elapsed time   : 4.802807092666626
2025-01-21 10:46:15,209 - trainer - INFO -     loss           : 1076.0108215332032
2025-01-21 10:46:15,209 - trainer - INFO -     sim_loss       : 37.71494035720825
2025-01-21 10:46:15,209 - trainer - INFO -     gen_loss       : 1038.295883178711
2025-01-21 10:46:15,209 - trainer - INFO -     val_loss       : 534.7682952880859
2025-01-21 10:46:15,209 - trainer - INFO -     val_sim_loss   : 25.963642120361328
2025-01-21 10:46:15,209 - trainer - INFO -     val_gen_loss   : 508.8046417236328
2025-01-21 10:46:15,209 - trainer - INFO -     val_perplexity : 30.36557388305664
2025-01-21 10:46:15,209 - trainer - INFO -     val_embedding_sim: 0.11475953459739685
2025-01-21 10:46:15,209 - trainer - INFO - ================================================================================
2025-01-21 10:46:15,209 - trainer - INFO - Starting epoch 5 at 2025-01-21 10:46:15
2025-01-21 10:46:20,025 - trainer - INFO - Epoch 5 completed at 2025-01-21 10:46:20
2025-01-21 10:46:20,025 - trainer - INFO -     epoch          : 5
2025-01-21 10:46:20,025 - trainer - INFO -     elapsed time   : 4.815541982650757
2025-01-21 10:46:20,025 - trainer - INFO -     loss           : 1018.9400939941406
2025-01-21 10:46:20,025 - trainer - INFO -     sim_loss       : 34.45925502777099
2025-01-21 10:46:20,025 - trainer - INFO -     gen_loss       : 984.480825805664
2025-01-21 10:46:20,025 - trainer - INFO -     val_loss       : 506.5482063293457
2025-01-21 10:46:20,025 - trainer - INFO -     val_sim_loss   : 15.52965259552002
2025-01-21 10:46:20,025 - trainer - INFO -     val_gen_loss   : 491.0185432434082
2025-01-21 10:46:20,025 - trainer - INFO -     val_perplexity : 29.916358947753906
2025-01-21 10:46:20,025 - trainer - INFO -     val_embedding_sim: 0.07780478149652481
2025-01-21 10:46:26,574 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch5.pth ...
2025-01-21 10:46:33,119 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 10:46:33,119 - trainer - INFO - ================================================================================
2025-01-21 10:46:33,119 - trainer - INFO - Starting epoch 6 at 2025-01-21 10:46:33
2025-01-21 10:46:37,957 - trainer - INFO - Epoch 6 completed at 2025-01-21 10:46:37
2025-01-21 10:46:37,957 - trainer - INFO -     epoch          : 6
2025-01-21 10:46:37,957 - trainer - INFO -     elapsed time   : 4.837599515914917
2025-01-21 10:46:37,957 - trainer - INFO -     loss           : 965.7547607421875
2025-01-21 10:46:37,957 - trainer - INFO -     sim_loss       : 33.22187557220459
2025-01-21 10:46:37,957 - trainer - INFO -     gen_loss       : 932.5328826904297
2025-01-21 10:46:37,957 - trainer - INFO -     val_loss       : 488.0107316970825
2025-01-21 10:46:37,957 - trainer - INFO -     val_sim_loss   : 13.814872741699219
2025-01-21 10:46:37,957 - trainer - INFO -     val_gen_loss   : 474.19585132598877
2025-01-21 10:46:37,958 - trainer - INFO -     val_perplexity : 28.6573486328125
2025-01-21 10:46:37,958 - trainer - INFO -     val_embedding_sim: 0.1065688207745552
2025-01-21 10:46:37,958 - trainer - INFO - ================================================================================
2025-01-21 10:46:37,958 - trainer - INFO - Starting epoch 7 at 2025-01-21 10:46:37
2025-01-21 10:46:42,766 - trainer - INFO - Epoch 7 completed at 2025-01-21 10:46:42
2025-01-21 10:46:42,766 - trainer - INFO -     epoch          : 7
2025-01-21 10:46:42,766 - trainer - INFO -     elapsed time   : 4.808164596557617
2025-01-21 10:46:42,766 - trainer - INFO -     loss           : 915.4918975830078
2025-01-21 10:46:42,766 - trainer - INFO -     sim_loss       : 35.63006849288941
2025-01-21 10:46:42,766 - trainer - INFO -     gen_loss       : 879.8618316650391
2025-01-21 10:46:42,766 - trainer - INFO -     val_loss       : 471.33287811279297
2025-01-21 10:46:42,766 - trainer - INFO -     val_sim_loss   : 17.143146514892578
2025-01-21 10:46:42,766 - trainer - INFO -     val_gen_loss   : 454.1897201538086
2025-01-21 10:46:42,766 - trainer - INFO -     val_perplexity : 27.41900634765625
2025-01-21 10:46:42,766 - trainer - INFO -     val_embedding_sim: 0.08756288886070251
2025-01-21 10:46:42,767 - trainer - INFO - ================================================================================
2025-01-21 10:46:42,767 - trainer - INFO - Starting epoch 8 at 2025-01-21 10:46:42
2025-01-21 10:46:47,577 - trainer - INFO - Epoch 8 completed at 2025-01-21 10:46:47
2025-01-21 10:46:47,577 - trainer - INFO -     epoch          : 8
2025-01-21 10:46:47,577 - trainer - INFO -     elapsed time   : 4.809902667999268
2025-01-21 10:46:47,577 - trainer - INFO -     loss           : 862.1496795654297
2025-01-21 10:46:47,577 - trainer - INFO -     sim_loss       : 29.290739870071413
2025-01-21 10:46:47,577 - trainer - INFO -     gen_loss       : 832.8589385986328
2025-01-21 10:46:47,577 - trainer - INFO -     val_loss       : 455.45822525024414
2025-01-21 10:46:47,577 - trainer - INFO -     val_sim_loss   : 14.331469535827637
2025-01-21 10:46:47,577 - trainer - INFO -     val_gen_loss   : 441.1267433166504
2025-01-21 10:46:47,577 - trainer - INFO -     val_perplexity : 27.000991821289062
2025-01-21 10:46:47,577 - trainer - INFO -     val_embedding_sim: 0.10784125328063965
2025-01-21 10:46:47,577 - trainer - INFO - ================================================================================
2025-01-21 10:46:47,577 - trainer - INFO - Starting epoch 9 at 2025-01-21 10:46:47
2025-01-21 10:46:52,383 - trainer - INFO - Epoch 9 completed at 2025-01-21 10:46:52
2025-01-21 10:46:52,383 - trainer - INFO -     epoch          : 9
2025-01-21 10:46:52,383 - trainer - INFO -     elapsed time   : 4.805406093597412
2025-01-21 10:46:52,383 - trainer - INFO -     loss           : 818.9103485107422
2025-01-21 10:46:52,383 - trainer - INFO -     sim_loss       : 31.63125524520874
2025-01-21 10:46:52,383 - trainer - INFO -     gen_loss       : 787.2790924072266
2025-01-21 10:46:52,383 - trainer - INFO -     val_loss       : 448.9077196121216
2025-01-21 10:46:52,383 - trainer - INFO -     val_sim_loss   : 18.31360626220703
2025-01-21 10:46:52,383 - trainer - INFO -     val_gen_loss   : 430.5941209793091
2025-01-21 10:46:52,383 - trainer - INFO -     val_perplexity : 26.179534912109375
2025-01-21 10:46:52,383 - trainer - INFO -     val_embedding_sim: 0.10211639106273651
2025-01-21 10:46:52,383 - trainer - INFO - ================================================================================
2025-01-21 10:46:52,383 - trainer - INFO - Starting epoch 10 at 2025-01-21 10:46:52
2025-01-21 10:46:57,205 - trainer - INFO - Epoch 10 completed at 2025-01-21 10:46:57
2025-01-21 10:46:57,205 - trainer - INFO -     epoch          : 10
2025-01-21 10:46:57,205 - trainer - INFO -     elapsed time   : 4.821949005126953
2025-01-21 10:46:57,206 - trainer - INFO -     loss           : 777.6560546875
2025-01-21 10:46:57,206 - trainer - INFO -     sim_loss       : 29.2363582611084
2025-01-21 10:46:57,206 - trainer - INFO -     gen_loss       : 748.4196899414062
2025-01-21 10:46:57,206 - trainer - INFO -     val_loss       : 446.26233863830566
2025-01-21 10:46:57,206 - trainer - INFO -     val_sim_loss   : 24.20516586303711
2025-01-21 10:46:57,206 - trainer - INFO -     val_gen_loss   : 422.0571689605713
2025-01-21 10:46:57,206 - trainer - INFO -     val_perplexity : 24.91714859008789
2025-01-21 10:46:57,206 - trainer - INFO -     val_embedding_sim: 0.09984926879405975
2025-01-21 10:47:03,741 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch10.pth ...
2025-01-21 10:47:10,344 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 10:47:10,344 - trainer - INFO - ================================================================================
2025-01-21 10:47:10,345 - trainer - INFO - Starting epoch 11 at 2025-01-21 10:47:10
2025-01-21 10:47:15,222 - trainer - INFO - Epoch 11 completed at 2025-01-21 10:47:15
2025-01-21 10:47:15,222 - trainer - INFO -     epoch          : 11
2025-01-21 10:47:15,222 - trainer - INFO -     elapsed time   : 4.8770904541015625
2025-01-21 10:47:15,222 - trainer - INFO -     loss           : 738.2757629394531
2025-01-21 10:47:15,222 - trainer - INFO -     sim_loss       : 31.040835428237916
2025-01-21 10:47:15,222 - trainer - INFO -     gen_loss       : 707.2349304199219
2025-01-21 10:47:15,222 - trainer - INFO -     val_loss       : 441.71826457977295
2025-01-21 10:47:15,222 - trainer - INFO -     val_sim_loss   : 21.1186466217041
2025-01-21 10:47:15,222 - trainer - INFO -     val_gen_loss   : 420.59961223602295
2025-01-21 10:47:15,222 - trainer - INFO -     val_perplexity : 25.32406234741211
2025-01-21 10:47:15,222 - trainer - INFO -     val_embedding_sim: 0.11818166077136993
2025-01-21 10:47:15,222 - trainer - INFO - ================================================================================
2025-01-21 10:47:15,222 - trainer - INFO - Starting epoch 12 at 2025-01-21 10:47:15
2025-01-21 10:47:20,036 - trainer - INFO - Epoch 12 completed at 2025-01-21 10:47:20
2025-01-21 10:47:20,036 - trainer - INFO -     epoch          : 12
2025-01-21 10:47:20,036 - trainer - INFO -     elapsed time   : 4.813723087310791
2025-01-21 10:47:20,036 - trainer - INFO -     loss           : 698.2775512695313
2025-01-21 10:47:20,036 - trainer - INFO -     sim_loss       : 27.542349433898927
2025-01-21 10:47:20,036 - trainer - INFO -     gen_loss       : 670.7351989746094
2025-01-21 10:47:20,037 - trainer - INFO -     val_loss       : 418.81935024261475
2025-01-21 10:47:20,037 - trainer - INFO -     val_sim_loss   : 12.567255973815918
2025-01-21 10:47:20,037 - trainer - INFO -     val_gen_loss   : 406.25208950042725
2025-01-21 10:47:20,037 - trainer - INFO -     val_perplexity : 24.40106201171875
2025-01-21 10:47:20,037 - trainer - INFO -     val_embedding_sim: 0.10558601468801498
2025-01-21 10:47:20,037 - trainer - INFO - ================================================================================
2025-01-21 10:47:20,037 - trainer - INFO - Starting epoch 13 at 2025-01-21 10:47:20
2025-01-21 10:47:24,850 - trainer - INFO - Epoch 13 completed at 2025-01-21 10:47:24
2025-01-21 10:47:24,850 - trainer - INFO -     epoch          : 13
2025-01-21 10:47:24,850 - trainer - INFO -     elapsed time   : 4.812829494476318
2025-01-21 10:47:24,850 - trainer - INFO -     loss           : 657.5975494384766
2025-01-21 10:47:24,850 - trainer - INFO -     sim_loss       : 28.570126914978026
2025-01-21 10:47:24,850 - trainer - INFO -     gen_loss       : 629.0274200439453
2025-01-21 10:47:24,850 - trainer - INFO -     val_loss       : 417.7165365219116
2025-01-21 10:47:24,850 - trainer - INFO -     val_sim_loss   : 14.844354629516602
2025-01-21 10:47:24,850 - trainer - INFO -     val_gen_loss   : 402.8721761703491
2025-01-21 10:47:24,850 - trainer - INFO -     val_perplexity : 24.255800247192383
2025-01-21 10:47:24,850 - trainer - INFO -     val_embedding_sim: 0.09923648834228516
2025-01-21 10:47:24,850 - trainer - INFO - ================================================================================
2025-01-21 10:47:24,850 - trainer - INFO - Starting epoch 14 at 2025-01-21 10:47:24
2025-01-21 10:47:29,659 - trainer - INFO - Epoch 14 completed at 2025-01-21 10:47:29
2025-01-21 10:47:29,660 - trainer - INFO -     epoch          : 14
2025-01-21 10:47:29,660 - trainer - INFO -     elapsed time   : 4.809006452560425
2025-01-21 10:47:29,660 - trainer - INFO -     loss           : 630.4322326660156
2025-01-21 10:47:29,660 - trainer - INFO -     sim_loss       : 34.39746279716492
2025-01-21 10:47:29,660 - trainer - INFO -     gen_loss       : 596.0347732543945
2025-01-21 10:47:29,660 - trainer - INFO -     val_loss       : 415.9088578224182
2025-01-21 10:47:29,660 - trainer - INFO -     val_sim_loss   : 20.68381118774414
2025-01-21 10:47:29,660 - trainer - INFO -     val_gen_loss   : 395.22505044937134
2025-01-21 10:47:29,660 - trainer - INFO -     val_perplexity : 24.415388107299805
2025-01-21 10:47:29,660 - trainer - INFO -     val_embedding_sim: 0.08439198136329651
2025-01-21 10:47:29,660 - trainer - INFO - ================================================================================
2025-01-21 10:47:29,660 - trainer - INFO - Starting epoch 15 at 2025-01-21 10:47:29
2025-01-21 10:47:34,477 - trainer - INFO - Epoch 15 completed at 2025-01-21 10:47:34
2025-01-21 10:47:34,477 - trainer - INFO -     epoch          : 15
2025-01-21 10:47:34,477 - trainer - INFO -     elapsed time   : 4.8166491985321045
2025-01-21 10:47:34,477 - trainer - INFO -     loss           : 588.4675750732422
2025-01-21 10:47:34,477 - trainer - INFO -     sim_loss       : 28.59732675552368
2025-01-21 10:47:34,477 - trainer - INFO -     gen_loss       : 559.8702514648437
2025-01-21 10:47:34,477 - trainer - INFO -     val_loss       : 403.50042152404785
2025-01-21 10:47:34,477 - trainer - INFO -     val_sim_loss   : 13.230703353881836
2025-01-21 10:47:34,477 - trainer - INFO -     val_gen_loss   : 390.26970863342285
2025-01-21 10:47:34,477 - trainer - INFO -     val_perplexity : 23.775209426879883
2025-01-21 10:47:34,477 - trainer - INFO -     val_embedding_sim: 0.1156994104385376
2025-01-21 10:47:41,025 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch15.pth ...
2025-01-21 10:47:47,710 - trainer - INFO - Saving current best: model_best.pth ...
2025-01-21 10:47:47,710 - trainer - INFO - ================================================================================
2025-01-21 10:47:47,710 - trainer - INFO - Starting epoch 16 at 2025-01-21 10:47:47
2025-01-21 10:47:52,582 - trainer - INFO - Epoch 16 completed at 2025-01-21 10:47:52
2025-01-21 10:47:52,583 - trainer - INFO -     epoch          : 16
2025-01-21 10:47:52,583 - trainer - INFO -     elapsed time   : 4.872111082077026
2025-01-21 10:47:52,583 - trainer - INFO -     loss           : 559.2645599365235
2025-01-21 10:47:52,583 - trainer - INFO -     sim_loss       : 32.766415214538576
2025-01-21 10:47:52,583 - trainer - INFO -     gen_loss       : 526.4981475830078
2025-01-21 10:47:52,583 - trainer - INFO -     val_loss       : 402.0352473258972
2025-01-21 10:47:52,583 - trainer - INFO -     val_sim_loss   : 18.33638572692871
2025-01-21 10:47:52,583 - trainer - INFO -     val_gen_loss   : 383.69885206222534
2025-01-21 10:47:52,583 - trainer - INFO -     val_perplexity : 23.576274871826172
2025-01-21 10:47:52,583 - trainer - INFO -     val_embedding_sim: 0.0839196965098381
2025-01-21 10:47:52,583 - trainer - INFO - ================================================================================
2025-01-21 10:47:52,583 - trainer - INFO - Starting epoch 17 at 2025-01-21 10:47:52
2025-01-21 10:47:57,406 - trainer - INFO - Epoch 17 completed at 2025-01-21 10:47:57
2025-01-21 10:47:57,406 - trainer - INFO -     epoch          : 17
2025-01-21 10:47:57,406 - trainer - INFO -     elapsed time   : 4.822418689727783
2025-01-21 10:47:57,406 - trainer - INFO -     loss           : 528.9395965576172
2025-01-21 10:47:57,406 - trainer - INFO -     sim_loss       : 29.909957122802734
2025-01-21 10:47:57,406 - trainer - INFO -     gen_loss       : 499.0296463012695
2025-01-21 10:47:57,406 - trainer - INFO -     val_loss       : 403.3125171661377
2025-01-21 10:47:57,406 - trainer - INFO -     val_sim_loss   : 18.567184448242188
2025-01-21 10:47:57,406 - trainer - INFO -     val_gen_loss   : 384.74534797668457
2025-01-21 10:47:57,406 - trainer - INFO -     val_perplexity : 22.42820930480957
2025-01-21 10:47:57,406 - trainer - INFO -     val_embedding_sim: 0.09808013588190079
2025-01-21 10:47:57,406 - trainer - INFO - ================================================================================
2025-01-21 10:47:57,406 - trainer - INFO - Starting epoch 18 at 2025-01-21 10:47:57
2025-01-21 10:48:02,223 - trainer - INFO - Epoch 18 completed at 2025-01-21 10:48:02
2025-01-21 10:48:02,223 - trainer - INFO -     epoch          : 18
2025-01-21 10:48:02,223 - trainer - INFO -     elapsed time   : 4.816474437713623
2025-01-21 10:48:02,223 - trainer - INFO -     loss           : 499.8344985961914
2025-01-21 10:48:02,223 - trainer - INFO -     sim_loss       : 30.952124214172365
2025-01-21 10:48:02,223 - trainer - INFO -     gen_loss       : 468.882373046875
2025-01-21 10:48:02,223 - trainer - INFO -     val_loss       : 397.05137848854065
2025-01-21 10:48:02,223 - trainer - INFO -     val_sim_loss   : 14.300776481628418
2025-01-21 10:48:02,223 - trainer - INFO -     val_gen_loss   : 382.75059723854065
2025-01-21 10:48:02,223 - trainer - INFO -     val_perplexity : 23.78631019592285
2025-01-21 10:48:02,223 - trainer - INFO -     val_embedding_sim: 0.12653428316116333
2025-01-21 10:48:02,223 - trainer - INFO - ================================================================================
2025-01-21 10:48:02,223 - trainer - INFO - Starting epoch 19 at 2025-01-21 10:48:02
2025-01-21 10:48:07,041 - trainer - INFO - Epoch 19 completed at 2025-01-21 10:48:07
2025-01-21 10:48:07,041 - trainer - INFO -     epoch          : 19
2025-01-21 10:48:07,041 - trainer - INFO -     elapsed time   : 4.8170342445373535
2025-01-21 10:48:07,041 - trainer - INFO -     loss           : 479.5122894287109
2025-01-21 10:48:07,041 - trainer - INFO -     sim_loss       : 34.32706995010376
2025-01-21 10:48:07,041 - trainer - INFO -     gen_loss       : 445.18522491455076
2025-01-21 10:48:07,041 - trainer - INFO -     val_loss       : 397.9071960449219
2025-01-21 10:48:07,041 - trainer - INFO -     val_sim_loss   : 18.302104949951172
2025-01-21 10:48:07,041 - trainer - INFO -     val_gen_loss   : 379.6051025390625
2025-01-21 10:48:07,041 - trainer - INFO -     val_perplexity : 21.59284019470215
2025-01-21 10:48:07,041 - trainer - INFO -     val_embedding_sim: 0.1066560447216034
2025-01-21 10:48:07,041 - trainer - INFO - ================================================================================
2025-01-21 10:48:07,041 - trainer - INFO - Starting epoch 20 at 2025-01-21 10:48:07
2025-01-21 10:48:11,846 - trainer - INFO - Epoch 20 completed at 2025-01-21 10:48:11
2025-01-21 10:48:11,846 - trainer - INFO -     epoch          : 20
2025-01-21 10:48:11,846 - trainer - INFO -     elapsed time   : 4.8043437004089355
2025-01-21 10:48:11,846 - trainer - INFO -     loss           : 445.03893280029297
2025-01-21 10:48:11,846 - trainer - INFO -     sim_loss       : 26.913550472259523
2025-01-21 10:48:11,846 - trainer - INFO -     gen_loss       : 418.12537994384763
2025-01-21 10:48:11,846 - trainer - INFO -     val_loss       : 397.940064907074
2025-01-21 10:48:11,846 - trainer - INFO -     val_sim_loss   : 18.301332473754883
2025-01-21 10:48:11,846 - trainer - INFO -     val_gen_loss   : 379.6387343406677
2025-01-21 10:48:11,846 - trainer - INFO -     val_perplexity : 23.562602996826172
2025-01-21 10:48:11,846 - trainer - INFO -     val_embedding_sim: 0.10275830328464508
2025-01-21 10:48:18,394 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch20.pth ...
2025-01-21 10:48:18,394 - trainer - INFO - ================================================================================
2025-01-21 10:48:18,394 - trainer - INFO - Starting epoch 21 at 2025-01-21 10:48:18
2025-01-21 10:48:23,242 - trainer - INFO - Epoch 21 completed at 2025-01-21 10:48:23
2025-01-21 10:48:23,242 - trainer - INFO -     epoch          : 21
2025-01-21 10:48:23,242 - trainer - INFO -     elapsed time   : 4.847228288650513
2025-01-21 10:48:23,242 - trainer - INFO -     loss           : 434.9444091796875
2025-01-21 10:48:23,242 - trainer - INFO -     sim_loss       : 35.95100498199463
2025-01-21 10:48:23,242 - trainer - INFO -     gen_loss       : 398.9934020996094
2025-01-21 10:48:23,242 - trainer - INFO -     val_loss       : 392.48146629333496
2025-01-21 10:48:23,242 - trainer - INFO -     val_sim_loss   : 11.315189361572266
2025-01-21 10:48:23,242 - trainer - INFO -     val_gen_loss   : 381.16628074645996
2025-01-21 10:48:23,242 - trainer - INFO -     val_perplexity : 22.438793182373047
2025-01-21 10:48:23,242 - trainer - INFO -     val_embedding_sim: 0.10110048949718475
2025-01-21 10:48:23,242 - trainer - INFO - ================================================================================
2025-01-21 10:48:23,242 - trainer - INFO - Starting epoch 22 at 2025-01-21 10:48:23
2025-01-21 10:48:28,060 - trainer - INFO - Epoch 22 completed at 2025-01-21 10:48:28
2025-01-21 10:48:28,060 - trainer - INFO -     epoch          : 22
2025-01-21 10:48:28,060 - trainer - INFO -     elapsed time   : 4.817548990249634
2025-01-21 10:48:28,060 - trainer - INFO -     loss           : 403.1597152709961
2025-01-21 10:48:28,060 - trainer - INFO -     sim_loss       : 27.14413697719574
2025-01-21 10:48:28,060 - trainer - INFO -     gen_loss       : 376.0155776977539
2025-01-21 10:48:28,060 - trainer - INFO -     val_loss       : 394.8543701171875
2025-01-21 10:48:28,060 - trainer - INFO -     val_sim_loss   : 15.338509559631348
2025-01-21 10:48:28,060 - trainer - INFO -     val_gen_loss   : 379.515869140625
2025-01-21 10:48:28,060 - trainer - INFO -     val_perplexity : 22.192903518676758
2025-01-21 10:48:28,060 - trainer - INFO -     val_embedding_sim: 0.10398957878351212
2025-01-21 10:48:28,060 - trainer - INFO - ================================================================================
2025-01-21 10:48:28,060 - trainer - INFO - Starting epoch 23 at 2025-01-21 10:48:28
2025-01-21 10:48:32,870 - trainer - INFO - Epoch 23 completed at 2025-01-21 10:48:32
2025-01-21 10:48:32,871 - trainer - INFO -     epoch          : 23
2025-01-21 10:48:32,871 - trainer - INFO -     elapsed time   : 4.809879541397095
2025-01-21 10:48:32,871 - trainer - INFO -     loss           : 393.86521911621094
2025-01-21 10:48:32,871 - trainer - INFO -     sim_loss       : 34.59785132408142
2025-01-21 10:48:32,871 - trainer - INFO -     gen_loss       : 359.2673675537109
2025-01-21 10:48:32,871 - trainer - INFO -     val_loss       : 396.5127639770508
2025-01-21 10:48:32,871 - trainer - INFO -     val_sim_loss   : 16.851835250854492
2025-01-21 10:48:32,871 - trainer - INFO -     val_gen_loss   : 379.66092681884766
2025-01-21 10:48:32,871 - trainer - INFO -     val_perplexity : 23.153247833251953
2025-01-21 10:48:32,871 - trainer - INFO -     val_embedding_sim: 0.09564117342233658
2025-01-21 10:48:32,871 - trainer - INFO - ================================================================================
2025-01-21 10:48:32,871 - trainer - INFO - Starting epoch 24 at 2025-01-21 10:48:32
2025-01-21 10:48:37,686 - trainer - INFO - Epoch 24 completed at 2025-01-21 10:48:37
2025-01-21 10:48:37,686 - trainer - INFO -     epoch          : 24
2025-01-21 10:48:37,686 - trainer - INFO -     elapsed time   : 4.815050363540649
2025-01-21 10:48:37,686 - trainer - INFO -     loss           : 374.68178405761716
2025-01-21 10:48:37,686 - trainer - INFO -     sim_loss       : 30.976931500434876
2025-01-21 10:48:37,687 - trainer - INFO -     gen_loss       : 343.70485229492186
2025-01-21 10:48:37,687 - trainer - INFO -     val_loss       : 393.7406482696533
2025-01-21 10:48:37,687 - trainer - INFO -     val_sim_loss   : 13.671549797058105
2025-01-21 10:48:37,687 - trainer - INFO -     val_gen_loss   : 380.0691089630127
2025-01-21 10:48:37,687 - trainer - INFO -     val_perplexity : 22.208969116210938
2025-01-21 10:48:37,687 - trainer - INFO -     val_embedding_sim: 0.07899478077888489
2025-01-21 10:48:37,687 - trainer - INFO - ================================================================================
2025-01-21 10:48:37,687 - trainer - INFO - Starting epoch 25 at 2025-01-21 10:48:37
2025-01-21 10:48:42,513 - trainer - INFO - Epoch 25 completed at 2025-01-21 10:48:42
2025-01-21 10:48:42,513 - trainer - INFO -     epoch          : 25
2025-01-21 10:48:42,513 - trainer - INFO -     elapsed time   : 4.826107025146484
2025-01-21 10:48:42,513 - trainer - INFO -     loss           : 354.84844360351565
2025-01-21 10:48:42,513 - trainer - INFO -     sim_loss       : 30.710000896453856
2025-01-21 10:48:42,513 - trainer - INFO -     gen_loss       : 324.138444519043
2025-01-21 10:48:42,513 - trainer - INFO -     val_loss       : 400.5384941101074
2025-01-21 10:48:42,513 - trainer - INFO -     val_sim_loss   : 19.210315704345703
2025-01-21 10:48:42,513 - trainer - INFO -     val_gen_loss   : 381.3281669616699
2025-01-21 10:48:42,514 - trainer - INFO -     val_perplexity : 22.849292755126953
2025-01-21 10:48:42,514 - trainer - INFO -     val_embedding_sim: 0.10918746143579483
2025-01-21 10:48:49,052 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch25.pth ...
2025-01-21 10:48:49,053 - trainer - INFO - ================================================================================
2025-01-21 10:48:49,053 - trainer - INFO - Starting epoch 26 at 2025-01-21 10:48:49
2025-01-21 10:48:53,926 - trainer - INFO - Epoch 26 completed at 2025-01-21 10:48:53
2025-01-21 10:48:53,927 - trainer - INFO -     epoch          : 26
2025-01-21 10:48:53,927 - trainer - INFO -     elapsed time   : 4.873642921447754
2025-01-21 10:48:53,927 - trainer - INFO -     loss           : 341.77057189941405
2025-01-21 10:48:53,927 - trainer - INFO -     sim_loss       : 32.16030683517456
2025-01-21 10:48:53,927 - trainer - INFO -     gen_loss       : 309.61026763916016
2025-01-21 10:48:53,927 - trainer - INFO -     val_loss       : 393.79281973838806
2025-01-21 10:48:53,927 - trainer - INFO -     val_sim_loss   : 14.147798538208008
2025-01-21 10:48:53,927 - trainer - INFO -     val_gen_loss   : 379.6450231075287
2025-01-21 10:48:53,927 - trainer - INFO -     val_perplexity : 23.589876174926758
2025-01-21 10:48:53,927 - trainer - INFO -     val_embedding_sim: 0.10256873071193695
2025-01-21 10:48:53,927 - trainer - INFO - ================================================================================
2025-01-21 10:48:53,927 - trainer - INFO - Starting epoch 27 at 2025-01-21 10:48:53
2025-01-21 10:48:58,754 - trainer - INFO - Epoch 27 completed at 2025-01-21 10:48:58
2025-01-21 10:48:58,754 - trainer - INFO -     epoch          : 27
2025-01-21 10:48:58,754 - trainer - INFO -     elapsed time   : 4.826586484909058
2025-01-21 10:48:58,754 - trainer - INFO -     loss           : 324.9523864746094
2025-01-21 10:48:58,754 - trainer - INFO -     sim_loss       : 30.93100881576538
2025-01-21 10:48:58,754 - trainer - INFO -     gen_loss       : 294.02138061523436
2025-01-21 10:48:58,754 - trainer - INFO -     val_loss       : 396.7584767341614
2025-01-21 10:48:58,754 - trainer - INFO -     val_sim_loss   : 16.857994079589844
2025-01-21 10:48:58,754 - trainer - INFO -     val_gen_loss   : 379.900475025177
2025-01-21 10:48:58,754 - trainer - INFO -     val_perplexity : 23.57114601135254
2025-01-21 10:48:58,754 - trainer - INFO -     val_embedding_sim: 0.10207002609968185
2025-01-21 10:48:58,754 - trainer - INFO - ================================================================================
2025-01-21 10:48:58,754 - trainer - INFO - Starting epoch 28 at 2025-01-21 10:48:58
2025-01-21 10:49:03,567 - trainer - INFO - Epoch 28 completed at 2025-01-21 10:49:03
2025-01-21 10:49:03,568 - trainer - INFO -     epoch          : 28
2025-01-21 10:49:03,568 - trainer - INFO -     elapsed time   : 4.812901973724365
2025-01-21 10:49:03,568 - trainer - INFO -     loss           : 317.6174774169922
2025-01-21 10:49:03,568 - trainer - INFO -     sim_loss       : 31.65202679634094
2025-01-21 10:49:03,568 - trainer - INFO -     gen_loss       : 285.9654479980469
2025-01-21 10:49:03,568 - trainer - INFO -     val_loss       : 397.9495189189911
2025-01-21 10:49:03,568 - trainer - INFO -     val_sim_loss   : 22.351224899291992
2025-01-21 10:49:03,568 - trainer - INFO -     val_gen_loss   : 375.59829211235046
2025-01-21 10:49:03,568 - trainer - INFO -     val_perplexity : 23.226951599121094
2025-01-21 10:49:03,568 - trainer - INFO -     val_embedding_sim: 0.11186184734106064
2025-01-21 10:49:03,568 - trainer - INFO - ================================================================================
2025-01-21 10:49:03,568 - trainer - INFO - Starting epoch 29 at 2025-01-21 10:49:03
2025-01-21 10:49:08,380 - trainer - INFO - Epoch 29 completed at 2025-01-21 10:49:08
2025-01-21 10:49:08,380 - trainer - INFO -     epoch          : 29
2025-01-21 10:49:08,380 - trainer - INFO -     elapsed time   : 4.812166929244995
2025-01-21 10:49:08,381 - trainer - INFO -     loss           : 305.2306884765625
2025-01-21 10:49:08,381 - trainer - INFO -     sim_loss       : 32.81855411529541
2025-01-21 10:49:08,381 - trainer - INFO -     gen_loss       : 272.4121353149414
2025-01-21 10:49:08,381 - trainer - INFO -     val_loss       : 394.83479154109955
2025-01-21 10:49:08,381 - trainer - INFO -     val_sim_loss   : 19.248859405517578
2025-01-21 10:49:08,381 - trainer - INFO -     val_gen_loss   : 375.5859206914902
2025-01-21 10:49:08,381 - trainer - INFO -     val_perplexity : 23.357654571533203
2025-01-21 10:49:08,381 - trainer - INFO -     val_embedding_sim: 0.14255480468273163
2025-01-21 10:49:08,381 - trainer - INFO - ================================================================================
2025-01-21 10:49:08,381 - trainer - INFO - Starting epoch 30 at 2025-01-21 10:49:08
2025-01-21 10:49:13,195 - trainer - INFO - Epoch 30 completed at 2025-01-21 10:49:13
2025-01-21 10:49:13,195 - trainer - INFO -     epoch          : 30
2025-01-21 10:49:13,195 - trainer - INFO -     elapsed time   : 4.81372332572937
2025-01-21 10:49:13,195 - trainer - INFO -     loss           : 287.38933181762695
2025-01-21 10:49:13,195 - trainer - INFO -     sim_loss       : 30.41061635017395
2025-01-21 10:49:13,195 - trainer - INFO -     gen_loss       : 256.97871551513674
2025-01-21 10:49:13,195 - trainer - INFO -     val_loss       : 388.91957569122314
2025-01-21 10:49:13,195 - trainer - INFO -     val_sim_loss   : 12.550445556640625
2025-01-21 10:49:13,195 - trainer - INFO -     val_gen_loss   : 376.3691301345825
2025-01-21 10:49:13,195 - trainer - INFO -     val_perplexity : 22.71086883544922
2025-01-21 10:49:13,195 - trainer - INFO -     val_embedding_sim: 0.12395073473453522
2025-01-21 10:49:19,749 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch30.pth ...
2025-01-21 10:49:19,749 - trainer - INFO - ================================================================================
2025-01-21 10:49:19,749 - trainer - INFO - Starting epoch 31 at 2025-01-21 10:49:19
2025-01-21 10:49:24,627 - trainer - INFO - Epoch 31 completed at 2025-01-21 10:49:24
2025-01-21 10:49:24,627 - trainer - INFO -     epoch          : 31
2025-01-21 10:49:24,627 - trainer - INFO -     elapsed time   : 4.877745151519775
2025-01-21 10:49:24,627 - trainer - INFO -     loss           : 277.2946266174316
2025-01-21 10:49:24,627 - trainer - INFO -     sim_loss       : 30.753433418273925
2025-01-21 10:49:24,627 - trainer - INFO -     gen_loss       : 246.54119491577148
2025-01-21 10:49:24,627 - trainer - INFO -     val_loss       : 391.09555435180664
2025-01-21 10:49:24,627 - trainer - INFO -     val_sim_loss   : 15.484879493713379
2025-01-21 10:49:24,627 - trainer - INFO -     val_gen_loss   : 375.6106605529785
2025-01-21 10:49:24,628 - trainer - INFO -     val_perplexity : 22.96759605407715
2025-01-21 10:49:24,628 - trainer - INFO -     val_embedding_sim: 0.1637103408575058
2025-01-21 10:49:24,628 - trainer - INFO - ================================================================================
2025-01-21 10:49:24,628 - trainer - INFO - Starting epoch 32 at 2025-01-21 10:49:24
2025-01-21 10:49:29,439 - trainer - INFO - Epoch 32 completed at 2025-01-21 10:49:29
2025-01-21 10:49:29,440 - trainer - INFO -     epoch          : 32
2025-01-21 10:49:29,440 - trainer - INFO -     elapsed time   : 4.811503171920776
2025-01-21 10:49:29,440 - trainer - INFO -     loss           : 266.5342788696289
2025-01-21 10:49:29,440 - trainer - INFO -     sim_loss       : 30.75958490371704
2025-01-21 10:49:29,440 - trainer - INFO -     gen_loss       : 235.77469329833986
2025-01-21 10:49:29,440 - trainer - INFO -     val_loss       : 389.6946145296097
2025-01-21 10:49:29,440 - trainer - INFO -     val_sim_loss   : 11.23299789428711
2025-01-21 10:49:29,440 - trainer - INFO -     val_gen_loss   : 378.4616128206253
2025-01-21 10:49:29,440 - trainer - INFO -     val_perplexity : 23.540586471557617
2025-01-21 10:49:29,440 - trainer - INFO -     val_embedding_sim: 0.14488184452056885
2025-01-21 10:49:29,440 - trainer - INFO - ================================================================================
2025-01-21 10:49:29,440 - trainer - INFO - Starting epoch 33 at 2025-01-21 10:49:29
2025-01-21 10:49:34,254 - trainer - INFO - Epoch 33 completed at 2025-01-21 10:49:34
2025-01-21 10:49:34,254 - trainer - INFO -     epoch          : 33
2025-01-21 10:49:34,254 - trainer - INFO -     elapsed time   : 4.813548564910889
2025-01-21 10:49:34,254 - trainer - INFO -     loss           : 249.80601425170897
2025-01-21 10:49:34,254 - trainer - INFO -     sim_loss       : 27.138663387298585
2025-01-21 10:49:34,254 - trainer - INFO -     gen_loss       : 222.6673500061035
2025-01-21 10:49:34,254 - trainer - INFO -     val_loss       : 390.30864334106445
2025-01-21 10:49:34,254 - trainer - INFO -     val_sim_loss   : 15.843292236328125
2025-01-21 10:49:34,254 - trainer - INFO -     val_gen_loss   : 374.4653511047363
2025-01-21 10:49:34,254 - trainer - INFO -     val_perplexity : 22.30007553100586
2025-01-21 10:49:34,254 - trainer - INFO -     val_embedding_sim: 0.1325576901435852
2025-01-21 10:49:34,254 - trainer - INFO - ================================================================================
2025-01-21 10:49:34,254 - trainer - INFO - Starting epoch 34 at 2025-01-21 10:49:34
2025-01-21 10:49:39,062 - trainer - INFO - Epoch 34 completed at 2025-01-21 10:49:39
2025-01-21 10:49:39,063 - trainer - INFO -     epoch          : 34
2025-01-21 10:49:39,063 - trainer - INFO -     elapsed time   : 4.808013439178467
2025-01-21 10:49:39,063 - trainer - INFO -     loss           : 245.40157089233398
2025-01-21 10:49:39,063 - trainer - INFO -     sim_loss       : 31.117100524902344
2025-01-21 10:49:39,063 - trainer - INFO -     gen_loss       : 214.2844680786133
2025-01-21 10:49:39,063 - trainer - INFO -     val_loss       : 387.99470138549805
2025-01-21 10:49:39,063 - trainer - INFO -     val_sim_loss   : 13.051055908203125
2025-01-21 10:49:39,063 - trainer - INFO -     val_gen_loss   : 374.9436454772949
2025-01-21 10:49:39,063 - trainer - INFO -     val_perplexity : 22.573976516723633
2025-01-21 10:49:39,063 - trainer - INFO -     val_embedding_sim: 0.1147899180650711
2025-01-21 10:49:39,063 - trainer - INFO - ================================================================================
2025-01-21 10:49:39,063 - trainer - INFO - Starting epoch 35 at 2025-01-21 10:49:39
2025-01-21 10:49:43,895 - trainer - INFO - Epoch 35 completed at 2025-01-21 10:49:43
2025-01-21 10:49:43,895 - trainer - INFO -     epoch          : 35
2025-01-21 10:49:43,895 - trainer - INFO -     elapsed time   : 4.831695079803467
2025-01-21 10:49:43,895 - trainer - INFO -     loss           : 234.36908798217775
2025-01-21 10:49:43,895 - trainer - INFO -     sim_loss       : 28.50132222175598
2025-01-21 10:49:43,895 - trainer - INFO -     gen_loss       : 205.867765045166
2025-01-21 10:49:43,895 - trainer - INFO -     val_loss       : 400.79817962646484
2025-01-21 10:49:43,895 - trainer - INFO -     val_sim_loss   : 20.599018096923828
2025-01-21 10:49:43,895 - trainer - INFO -     val_gen_loss   : 380.1991500854492
2025-01-21 10:49:43,895 - trainer - INFO -     val_perplexity : 22.934917449951172
2025-01-21 10:49:43,895 - trainer - INFO -     val_embedding_sim: 0.13917595148086548
2025-01-21 10:49:50,442 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch35.pth ...
2025-01-21 10:49:50,442 - trainer - INFO - ================================================================================
2025-01-21 10:49:50,442 - trainer - INFO - Starting epoch 36 at 2025-01-21 10:49:50
2025-01-21 10:49:55,298 - trainer - INFO - Epoch 36 completed at 2025-01-21 10:49:55
2025-01-21 10:49:55,298 - trainer - INFO -     epoch          : 36
2025-01-21 10:49:55,298 - trainer - INFO -     elapsed time   : 4.855706214904785
2025-01-21 10:49:55,298 - trainer - INFO -     loss           : 233.30460052490236
2025-01-21 10:49:55,298 - trainer - INFO -     sim_loss       : 32.09045066833496
2025-01-21 10:49:55,298 - trainer - INFO -     gen_loss       : 201.21415176391602
2025-01-21 10:49:55,298 - trainer - INFO -     val_loss       : 384.2394320964813
2025-01-21 10:49:55,299 - trainer - INFO -     val_sim_loss   : 9.159360885620117
2025-01-21 10:49:55,299 - trainer - INFO -     val_gen_loss   : 375.0800693035126
2025-01-21 10:49:55,299 - trainer - INFO -     val_perplexity : 23.239023208618164
2025-01-21 10:49:55,299 - trainer - INFO -     val_embedding_sim: 0.1364957094192505
2025-01-21 10:49:55,299 - trainer - INFO - ================================================================================
2025-01-21 10:49:55,299 - trainer - INFO - Starting epoch 37 at 2025-01-21 10:49:55
2025-01-21 10:50:00,118 - trainer - INFO - Epoch 37 completed at 2025-01-21 10:50:00
2025-01-21 10:50:00,119 - trainer - INFO -     epoch          : 37
2025-01-21 10:50:00,119 - trainer - INFO -     elapsed time   : 4.819438695907593
2025-01-21 10:50:00,119 - trainer - INFO -     loss           : 212.5009963989258
2025-01-21 10:50:00,119 - trainer - INFO -     sim_loss       : 24.450569009780885
2025-01-21 10:50:00,119 - trainer - INFO -     gen_loss       : 188.0504264831543
2025-01-21 10:50:00,119 - trainer - INFO -     val_loss       : 393.23276686668396
2025-01-21 10:50:00,119 - trainer - INFO -     val_sim_loss   : 19.08019256591797
2025-01-21 10:50:00,119 - trainer - INFO -     val_gen_loss   : 374.15256667137146
2025-01-21 10:50:00,119 - trainer - INFO -     val_perplexity : 23.24462890625
2025-01-21 10:50:00,119 - trainer - INFO -     val_embedding_sim: 0.1351199448108673
2025-01-21 10:50:00,119 - trainer - INFO - ================================================================================
2025-01-21 10:50:00,119 - trainer - INFO - Starting epoch 38 at 2025-01-21 10:50:00
2025-01-21 10:50:04,933 - trainer - INFO - Epoch 38 completed at 2025-01-21 10:50:04
2025-01-21 10:50:04,933 - trainer - INFO -     epoch          : 38
2025-01-21 10:50:04,933 - trainer - INFO -     elapsed time   : 4.81377911567688
2025-01-21 10:50:04,933 - trainer - INFO -     loss           : 212.4815460205078
2025-01-21 10:50:04,933 - trainer - INFO -     sim_loss       : 30.601406717300414
2025-01-21 10:50:04,933 - trainer - INFO -     gen_loss       : 181.88014068603516
2025-01-21 10:50:04,933 - trainer - INFO -     val_loss       : 398.5499280691147
2025-01-21 10:50:04,933 - trainer - INFO -     val_sim_loss   : 22.836288452148438
2025-01-21 10:50:04,933 - trainer - INFO -     val_gen_loss   : 375.7136548757553
2025-01-21 10:50:04,933 - trainer - INFO -     val_perplexity : 23.405649185180664
2025-01-21 10:50:04,933 - trainer - INFO -     val_embedding_sim: 0.11061957478523254
2025-01-21 10:50:04,933 - trainer - INFO - ================================================================================
2025-01-21 10:50:04,933 - trainer - INFO - Starting epoch 39 at 2025-01-21 10:50:04
2025-01-21 10:50:09,752 - trainer - INFO - Epoch 39 completed at 2025-01-21 10:50:09
2025-01-21 10:50:09,752 - trainer - INFO -     epoch          : 39
2025-01-21 10:50:09,752 - trainer - INFO -     elapsed time   : 4.818180322647095
2025-01-21 10:50:09,752 - trainer - INFO -     loss           : 210.3788963317871
2025-01-21 10:50:09,752 - trainer - INFO -     sim_loss       : 33.5661018371582
2025-01-21 10:50:09,752 - trainer - INFO -     gen_loss       : 176.81279296875
2025-01-21 10:50:09,752 - trainer - INFO -     val_loss       : 399.40915393829346
2025-01-21 10:50:09,752 - trainer - INFO -     val_sim_loss   : 19.419002532958984
2025-01-21 10:50:09,752 - trainer - INFO -     val_gen_loss   : 379.9901475906372
2025-01-21 10:50:09,752 - trainer - INFO -     val_perplexity : 23.05858612060547
2025-01-21 10:50:09,752 - trainer - INFO -     val_embedding_sim: 0.12069274485111237
2025-01-21 10:50:09,752 - trainer - INFO - ================================================================================
2025-01-21 10:50:09,752 - trainer - INFO - Starting epoch 40 at 2025-01-21 10:50:09
2025-01-21 10:50:14,565 - trainer - INFO - Epoch 40 completed at 2025-01-21 10:50:14
2025-01-21 10:50:14,566 - trainer - INFO -     epoch          : 40
2025-01-21 10:50:14,566 - trainer - INFO -     elapsed time   : 4.812953233718872
2025-01-21 10:50:14,566 - trainer - INFO -     loss           : 204.63107833862304
2025-01-21 10:50:14,566 - trainer - INFO -     sim_loss       : 36.29660053253174
2025-01-21 10:50:14,566 - trainer - INFO -     gen_loss       : 168.33447723388673
2025-01-21 10:50:14,566 - trainer - INFO -     val_loss       : 403.9571285247803
2025-01-21 10:50:14,566 - trainer - INFO -     val_sim_loss   : 24.111244201660156
2025-01-21 10:50:14,566 - trainer - INFO -     val_gen_loss   : 379.84589195251465
2025-01-21 10:50:14,566 - trainer - INFO -     val_perplexity : 22.21405601501465
2025-01-21 10:50:14,566 - trainer - INFO -     val_embedding_sim: 0.15088176727294922
2025-01-21 10:50:21,100 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch40.pth ...
2025-01-21 10:50:21,101 - trainer - INFO - ================================================================================
2025-01-21 10:50:21,101 - trainer - INFO - Starting epoch 41 at 2025-01-21 10:50:21
2025-01-21 10:50:25,976 - trainer - INFO - Epoch 41 completed at 2025-01-21 10:50:25
2025-01-21 10:50:25,976 - trainer - INFO -     epoch          : 41
2025-01-21 10:50:25,976 - trainer - INFO -     elapsed time   : 4.874939441680908
2025-01-21 10:50:25,976 - trainer - INFO -     loss           : 187.5630874633789
2025-01-21 10:50:25,976 - trainer - INFO -     sim_loss       : 28.00229663848877
2025-01-21 10:50:25,976 - trainer - INFO -     gen_loss       : 159.5607894897461
2025-01-21 10:50:25,976 - trainer - INFO -     val_loss       : 395.9670124053955
2025-01-21 10:50:25,976 - trainer - INFO -     val_sim_loss   : 14.141426086425781
2025-01-21 10:50:25,976 - trainer - INFO -     val_gen_loss   : 381.82559394836426
2025-01-21 10:50:25,976 - trainer - INFO -     val_perplexity : 23.77194595336914
2025-01-21 10:50:25,976 - trainer - INFO -     val_embedding_sim: 0.1418771743774414
2025-01-21 10:50:25,976 - trainer - INFO - ================================================================================
2025-01-21 10:50:25,976 - trainer - INFO - Starting epoch 42 at 2025-01-21 10:50:25
2025-01-21 10:50:30,802 - trainer - INFO - Epoch 42 completed at 2025-01-21 10:50:30
2025-01-21 10:50:30,802 - trainer - INFO -     epoch          : 42
2025-01-21 10:50:30,802 - trainer - INFO -     elapsed time   : 4.825645685195923
2025-01-21 10:50:30,802 - trainer - INFO -     loss           : 183.44055404663087
2025-01-21 10:50:30,802 - trainer - INFO -     sim_loss       : 28.808132553100585
2025-01-21 10:50:30,802 - trainer - INFO -     gen_loss       : 154.63242111206054
2025-01-21 10:50:30,802 - trainer - INFO -     val_loss       : 394.3270092010498
2025-01-21 10:50:30,802 - trainer - INFO -     val_sim_loss   : 13.331523895263672
2025-01-21 10:50:30,802 - trainer - INFO -     val_gen_loss   : 380.99549674987793
2025-01-21 10:50:30,802 - trainer - INFO -     val_perplexity : 22.293798446655273
2025-01-21 10:50:30,802 - trainer - INFO -     val_embedding_sim: 0.15184758603572845
2025-01-21 10:50:30,803 - trainer - INFO - ================================================================================
2025-01-21 10:50:30,803 - trainer - INFO - Starting epoch 43 at 2025-01-21 10:50:30
2025-01-21 10:50:35,605 - trainer - INFO - Epoch 43 completed at 2025-01-21 10:50:35
2025-01-21 10:50:35,605 - trainer - INFO -     epoch          : 43
2025-01-21 10:50:35,605 - trainer - INFO -     elapsed time   : 4.802346706390381
2025-01-21 10:50:35,605 - trainer - INFO -     loss           : 183.36957473754882
2025-01-21 10:50:35,605 - trainer - INFO -     sim_loss       : 32.336151361465454
2025-01-21 10:50:35,605 - trainer - INFO -     gen_loss       : 151.0334228515625
2025-01-21 10:50:35,605 - trainer - INFO -     val_loss       : 396.4515724182129
2025-01-21 10:50:35,605 - trainer - INFO -     val_sim_loss   : 16.239620208740234
2025-01-21 10:50:35,605 - trainer - INFO -     val_gen_loss   : 380.2119483947754
2025-01-21 10:50:35,606 - trainer - INFO -     val_perplexity : 21.35956382751465
2025-01-21 10:50:35,606 - trainer - INFO -     val_embedding_sim: 0.14814183115959167
2025-01-21 10:50:35,606 - trainer - INFO - ================================================================================
2025-01-21 10:50:35,606 - trainer - INFO - Starting epoch 44 at 2025-01-21 10:50:35
2025-01-21 10:50:40,422 - trainer - INFO - Epoch 44 completed at 2025-01-21 10:50:40
2025-01-21 10:50:40,423 - trainer - INFO -     epoch          : 44
2025-01-21 10:50:40,423 - trainer - INFO -     elapsed time   : 4.8165366649627686
2025-01-21 10:50:40,423 - trainer - INFO -     loss           : 175.03924331665038
2025-01-21 10:50:40,423 - trainer - INFO -     sim_loss       : 29.001865005493165
2025-01-21 10:50:40,423 - trainer - INFO -     gen_loss       : 146.03737869262696
2025-01-21 10:50:40,423 - trainer - INFO -     val_loss       : 395.6640808582306
2025-01-21 10:50:40,423 - trainer - INFO -     val_sim_loss   : 16.19811248779297
2025-01-21 10:50:40,423 - trainer - INFO -     val_gen_loss   : 379.4659607410431
2025-01-21 10:50:40,423 - trainer - INFO -     val_perplexity : 23.62320327758789
2025-01-21 10:50:40,423 - trainer - INFO -     val_embedding_sim: 0.15721772611141205
2025-01-21 10:50:40,423 - trainer - INFO - ================================================================================
2025-01-21 10:50:40,423 - trainer - INFO - Starting epoch 45 at 2025-01-21 10:50:40
2025-01-21 10:50:45,238 - trainer - INFO - Epoch 45 completed at 2025-01-21 10:50:45
2025-01-21 10:50:45,238 - trainer - INFO -     epoch          : 45
2025-01-21 10:50:45,238 - trainer - INFO -     elapsed time   : 4.814816951751709
2025-01-21 10:50:45,238 - trainer - INFO -     loss           : 175.10747680664062
2025-01-21 10:50:45,238 - trainer - INFO -     sim_loss       : 32.68118267059326
2025-01-21 10:50:45,238 - trainer - INFO -     gen_loss       : 142.4262939453125
2025-01-21 10:50:45,238 - trainer - INFO -     val_loss       : 395.85959649086
2025-01-21 10:50:45,238 - trainer - INFO -     val_sim_loss   : 12.897171020507812
2025-01-21 10:50:45,238 - trainer - INFO -     val_gen_loss   : 382.96244072914124
2025-01-21 10:50:45,238 - trainer - INFO -     val_perplexity : 23.748836517333984
2025-01-21 10:50:45,238 - trainer - INFO -     val_embedding_sim: 0.12440762668848038
2025-01-21 10:50:51,780 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch45.pth ...
2025-01-21 10:50:51,781 - trainer - INFO - ================================================================================
2025-01-21 10:50:51,781 - trainer - INFO - Starting epoch 46 at 2025-01-21 10:50:51
2025-01-21 10:50:56,621 - trainer - INFO - Epoch 46 completed at 2025-01-21 10:50:56
2025-01-21 10:50:56,622 - trainer - INFO -     epoch          : 46
2025-01-21 10:50:56,622 - trainer - INFO -     elapsed time   : 4.84038233757019
2025-01-21 10:50:56,622 - trainer - INFO -     loss           : 164.9540222167969
2025-01-21 10:50:56,622 - trainer - INFO -     sim_loss       : 28.414172554016112
2025-01-21 10:50:56,622 - trainer - INFO -     gen_loss       : 136.53985252380372
2025-01-21 10:50:56,622 - trainer - INFO -     val_loss       : 398.39782524108887
2025-01-21 10:50:56,622 - trainer - INFO -     val_sim_loss   : 15.64415454864502
2025-01-21 10:50:56,622 - trainer - INFO -     val_gen_loss   : 382.75366020202637
2025-01-21 10:50:56,622 - trainer - INFO -     val_perplexity : 23.276647567749023
2025-01-21 10:50:56,622 - trainer - INFO -     val_embedding_sim: 0.1373768299818039
2025-01-21 10:50:56,622 - trainer - INFO - ================================================================================
2025-01-21 10:50:56,622 - trainer - INFO - Starting epoch 47 at 2025-01-21 10:50:56
2025-01-21 10:51:01,442 - trainer - INFO - Epoch 47 completed at 2025-01-21 10:51:01
2025-01-21 10:51:01,442 - trainer - INFO -     epoch          : 47
2025-01-21 10:51:01,443 - trainer - INFO -     elapsed time   : 4.820190668106079
2025-01-21 10:51:01,443 - trainer - INFO -     loss           : 164.97270545959472
2025-01-21 10:51:01,443 - trainer - INFO -     sim_loss       : 31.276664209365844
2025-01-21 10:51:01,443 - trainer - INFO -     gen_loss       : 133.69604415893554
2025-01-21 10:51:01,443 - trainer - INFO -     val_loss       : 397.70173263549805
2025-01-21 10:51:01,443 - trainer - INFO -     val_sim_loss   : 13.308136940002441
2025-01-21 10:51:01,443 - trainer - INFO -     val_gen_loss   : 384.3935966491699
2025-01-21 10:51:01,443 - trainer - INFO -     val_perplexity : 22.96169090270996
2025-01-21 10:51:01,443 - trainer - INFO -     val_embedding_sim: 0.11599251627922058
2025-01-21 10:51:01,443 - trainer - INFO - ================================================================================
2025-01-21 10:51:01,443 - trainer - INFO - Starting epoch 48 at 2025-01-21 10:51:01
2025-01-21 10:51:06,248 - trainer - INFO - Epoch 48 completed at 2025-01-21 10:51:06
2025-01-21 10:51:06,248 - trainer - INFO -     epoch          : 48
2025-01-21 10:51:06,249 - trainer - INFO -     elapsed time   : 4.805238962173462
2025-01-21 10:51:06,249 - trainer - INFO -     loss           : 167.567573928833
2025-01-21 10:51:06,249 - trainer - INFO -     sim_loss       : 34.298275518417356
2025-01-21 10:51:06,249 - trainer - INFO -     gen_loss       : 133.26929969787597
2025-01-21 10:51:06,249 - trainer - INFO -     val_loss       : 393.0992805957794
2025-01-21 10:51:06,249 - trainer - INFO -     val_sim_loss   : 12.757413864135742
2025-01-21 10:51:06,249 - trainer - INFO -     val_gen_loss   : 380.34186482429504
2025-01-21 10:51:06,249 - trainer - INFO -     val_perplexity : 23.685653686523438
2025-01-21 10:51:06,249 - trainer - INFO -     val_embedding_sim: 0.16010263562202454
2025-01-21 10:51:06,249 - trainer - INFO - ================================================================================
2025-01-21 10:51:06,249 - trainer - INFO - Starting epoch 49 at 2025-01-21 10:51:06
2025-01-21 10:51:11,066 - trainer - INFO - Epoch 49 completed at 2025-01-21 10:51:11
2025-01-21 10:51:11,067 - trainer - INFO -     epoch          : 49
2025-01-21 10:51:11,067 - trainer - INFO -     elapsed time   : 4.817335844039917
2025-01-21 10:51:11,067 - trainer - INFO -     loss           : 162.0410671234131
2025-01-21 10:51:11,067 - trainer - INFO -     sim_loss       : 32.43530282974243
2025-01-21 10:51:11,067 - trainer - INFO -     gen_loss       : 129.60576362609862
2025-01-21 10:51:11,067 - trainer - INFO -     val_loss       : 401.8621175289154
2025-01-21 10:51:11,067 - trainer - INFO -     val_sim_loss   : 18.468074798583984
2025-01-21 10:51:11,067 - trainer - INFO -     val_gen_loss   : 383.39403891563416
2025-01-21 10:51:11,067 - trainer - INFO -     val_perplexity : 23.880754470825195
2025-01-21 10:51:11,067 - trainer - INFO -     val_embedding_sim: 0.16450488567352295
2025-01-21 10:51:11,067 - trainer - INFO - ================================================================================
2025-01-21 10:51:11,067 - trainer - INFO - Starting epoch 50 at 2025-01-21 10:51:11
2025-01-21 10:51:15,880 - trainer - INFO - Epoch 50 completed at 2025-01-21 10:51:15
2025-01-21 10:51:15,880 - trainer - INFO -     epoch          : 50
2025-01-21 10:51:15,880 - trainer - INFO -     elapsed time   : 4.812724351882935
2025-01-21 10:51:15,880 - trainer - INFO -     loss           : 164.55848541259766
2025-01-21 10:51:15,880 - trainer - INFO -     sim_loss       : 36.783971309661865
2025-01-21 10:51:15,880 - trainer - INFO -     gen_loss       : 127.77451591491699
2025-01-21 10:51:15,880 - trainer - INFO -     val_loss       : 401.8114981651306
2025-01-21 10:51:15,880 - trainer - INFO -     val_sim_loss   : 17.093158721923828
2025-01-21 10:51:15,880 - trainer - INFO -     val_gen_loss   : 384.718327999115
2025-01-21 10:51:15,880 - trainer - INFO -     val_perplexity : 23.837135314941406
2025-01-21 10:51:15,880 - trainer - INFO -     val_embedding_sim: 0.15106098353862762
2025-01-21 10:51:22,411 - trainer - INFO - Saving checkpoint: congress-save/models/checkpoint-epoch50.pth ...
2025-01-21 10:51:22,411 - trainer - INFO - ================================================================================
2025-01-21 10:51:22,411 - trainer - INFO - Starting epoch 51 at 2025-01-21 10:51:22
2025-01-21 10:51:27,274 - trainer - INFO - Epoch 51 completed at 2025-01-21 10:51:27
2025-01-21 10:51:27,275 - trainer - INFO -     epoch          : 51
2025-01-21 10:51:27,275 - trainer - INFO -     elapsed time   : 4.862979888916016
2025-01-21 10:51:27,275 - trainer - INFO -     loss           : 157.28786697387696
2025-01-21 10:51:27,275 - trainer - INFO -     sim_loss       : 31.25523509979248
2025-01-21 10:51:27,275 - trainer - INFO -     gen_loss       : 126.03263092041016
2025-01-21 10:51:27,275 - trainer - INFO -     val_loss       : 402.805477142334
2025-01-21 10:51:27,275 - trainer - INFO -     val_sim_loss   : 16.19904327392578
2025-01-21 10:51:27,275 - trainer - INFO -     val_gen_loss   : 386.60644149780273
2025-01-21 10:51:27,275 - trainer - INFO -     val_perplexity : 22.717506408691406
2025-01-21 10:51:27,275 - trainer - INFO -     val_embedding_sim: 0.13062235713005066
2025-01-21 10:51:27,275 - trainer - INFO - ================================================================================
2025-01-21 10:51:27,275 - trainer - INFO - Starting epoch 52 at 2025-01-21 10:51:27
2025-01-21 10:51:32,096 - trainer - INFO - Epoch 52 completed at 2025-01-21 10:51:32
2025-01-21 10:51:32,096 - trainer - INFO -     epoch          : 52
2025-01-21 10:51:32,096 - trainer - INFO -     elapsed time   : 4.820922613143921
2025-01-21 10:51:32,096 - trainer - INFO -     loss           : 153.19731597900392
2025-01-21 10:51:32,096 - trainer - INFO -     sim_loss       : 31.446194553375243
2025-01-21 10:51:32,096 - trainer - INFO -     gen_loss       : 121.75112266540528
2025-01-21 10:51:32,096 - trainer - INFO -     val_loss       : 394.7464141845703
2025-01-21 10:51:32,096 - trainer - INFO -     val_sim_loss   : 12.542559623718262
2025-01-21 10:51:32,096 - trainer - INFO -     val_gen_loss   : 382.20384216308594
2025-01-21 10:51:32,097 - trainer - INFO -     val_perplexity : 21.51721954345703
2025-01-21 10:51:32,097 - trainer - INFO -     val_embedding_sim: 0.13213828206062317
2025-01-21 10:51:32,097 - trainer - INFO - ================================================================================
2025-01-21 10:51:32,097 - trainer - INFO - Starting epoch 53 at 2025-01-21 10:51:32
2025-01-21 10:51:36,915 - trainer - INFO - Epoch 53 completed at 2025-01-21 10:51:36
2025-01-21 10:51:36,915 - trainer - INFO -     epoch          : 53
2025-01-21 10:51:36,915 - trainer - INFO -     elapsed time   : 4.8180108070373535
2025-01-21 10:51:36,915 - trainer - INFO -     loss           : 155.89758911132813
2025-01-21 10:51:36,915 - trainer - INFO -     sim_loss       : 33.947761917114256
2025-01-21 10:51:36,915 - trainer - INFO -     gen_loss       : 121.94983100891113
2025-01-21 10:51:36,915 - trainer - INFO -     val_loss       : 403.14966106414795
2025-01-21 10:51:36,915 - trainer - INFO -     val_sim_loss   : 17.56873321533203
2025-01-21 10:51:36,915 - trainer - INFO -     val_gen_loss   : 385.58093547821045
2025-01-21 10:51:36,915 - trainer - INFO -     val_perplexity : 23.28032112121582
2025-01-21 10:51:36,915 - trainer - INFO -     val_embedding_sim: 0.19131164252758026
2025-01-21 10:51:36,915 - trainer - INFO - Validation performance didn't improve for 15 epochs. Training stops.
